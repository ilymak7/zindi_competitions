{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from keras import Model\n",
    "from keras.layers import Dense , Flatten,Concatenate, Embedding,Input,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "seed = 2891  \n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = pd.read_csv('Train.csv')\n",
    "band_names = [l.strip() for l in open('bandnames.txt', 'r').readlines()]\n",
    "ss = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_im(fid, folder='image_arrays_train'):\n",
    "  fn = f'{folder}/{fid}.npy'\n",
    "  arr = np.load(fn)\n",
    "  bands_of_interest = ['S2_B1','S2_B2','S2_B3','S2_B4','S2_B5','S2_B6','S2_B7','S2_B8','S2_B8A','S2_B9','S2_B10',\n",
    "                       'S2_B11','S2_B12','S2_QA10','S2_QA20' ,'S2_QA60','CLIM_aet','CLIM_def','CLIM_pdsi','CLIM_pet',\n",
    "                       'CLIM_pr','CLIM_ro','CLIM_soil' ,'CLIM_srad' ,'CLIM_swe','CLIM_tmmn','CLIM_tmmx',\n",
    "                       'CLIM_vap','CLIM_vpd','CLIM_vs']\n",
    "  \n",
    "  values = {}\n",
    "  for month in range(12):\n",
    "    bns = [str(month) + '_' + b for b in bands_of_interest] # Bands of interest for this month \n",
    "    idxs = np.where(np.isin(band_names, bns)) # Index of these bands\n",
    "    vs = arr[idxs, 20, 20] # Sample the im at the center point\n",
    "    for bn, v in zip(bns, vs[0]):\n",
    "      values[bn] = v\n",
    "  return values\n",
    "def to_submit(pred_y,name_out):\n",
    "    y_predict = list(itertools.islice(pred_y, test.shape[0]))\n",
    "    y_predict = pd.DataFrame(prepro_y.inverse_transform(np.array(y_predict).reshape(len(y_predict),1)), columns = ['Yield'])\n",
    "    y_predict = y_predict.join(t)   #Field_ID\n",
    "    y_predic = y_predict[['Field_ID', 'Yield']]\n",
    "    y_predic.to_csv(name_out + '.csv',index=False)\n",
    "def input_fn_new(data_set, training = True):\n",
    "    continuous_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n",
    "    \n",
    "    categorical_cols = {k: tf.SparseTensor(\n",
    "        indices=[[i, 0] for i in range(data_set[k].size)], values = data_set[k].values, dense_shape = [data_set[k].size, 1]) for k in FEATURES_CAT}\n",
    "\n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(list(continuous_cols.items()) + list(categorical_cols.items()))\n",
    "    \n",
    "    if training == True:\n",
    "        # Converts the label column into a constant Tensor.\n",
    "        label = tf.constant(data_set[LABEL].values)\n",
    "\n",
    "        # Returns the feature columns and the label.\n",
    "        return feature_cols, label\n",
    "    \n",
    "    return feature_cols\n",
    "train_sampled = pd.DataFrame([process_im(fid) for fid in train_new['Field_ID'].values])\n",
    "\n",
    "# Add in the field ID and yield\n",
    "train_sampled['Field_ID'] = train_new['Field_ID'].values\n",
    "train_sampled['Yield'] = train_new['Yield'].values\n",
    "# train_sampled.head()\n",
    "test_sampled = pd.DataFrame([process_im(fid, folder='image_arrays_test') for fid in ss['Field_ID'].values])\n",
    "# test_sampled['Field_ID'] = ss['Field_ID']\n",
    "# test_sampled['Yield'] = 0\n",
    "# Example\n",
    "# process_im('35AFSDD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_sampled.copy()\n",
    "test = test_sampled.copy()\n",
    "add_info = pd.read_csv('fields_w_additional_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_info.isna().sum()\n",
    "# A=add_info[add_info.columns[9]]\n",
    "# Anan=A[~np.isnan(A)] # Remove the NaNs\n",
    "# sns.distplot(Anan)\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# imputer = imputer.fit(add_info)\n",
    "# X= imputer.transform(add_info)\n",
    "add_info[add_info.columns.tolist()[1:]] = add_info[add_info.columns.tolist()[1:]].apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "prepo_add_info = MinMaxScaler()\n",
    "add_info[add_info.columns.tolist()[1:]] = prepo_add_info.fit_transform(add_info[add_info.columns.tolist()[1:]])\n",
    "# add_info.isna().sum()\n",
    "add_info_train = add_info.loc[add_info['Field_ID'].isin(train.Field_ID.values)]\n",
    "add_info_test =  add_info.loc[add_info['Field_ID'].isin(ss.Field_ID.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.Field_ID\n",
    "# add_info.where(add_info.Field_ID == train.Field_ID.values)\n",
    "# add_info_test\n",
    "add_info_cols = add_info.columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Import and split\n",
    "# # train = pd.read_csv('train_df_cust.csv')\n",
    "# train_numerical = train.select_dtypes(exclude=['object'])\n",
    "# train_categoric = train.select_dtypes(include=['object'])\n",
    "# train = train_numerical.merge(train_categoric, left_index = True, right_index = True) \n",
    "\n",
    "# # test = pd.read_csv('test_df_cust.csv')\n",
    "# Yield_ID = ss.Field_ID\n",
    "# test_numerical = test.select_dtypes(exclude=['object'])\n",
    "# test_categoric = test.select_dtypes(include=['object'])\n",
    "# test = test_numerical.merge(test_categoric, left_index = True, right_index = True) \n",
    "# # Removie the outliers\n",
    "\n",
    "# clf = IsolationForest(max_samples = 100, random_state = 42)\n",
    "# clf.fit(train_numerical)\n",
    "# y_noano = clf.predict(train_numerical)\n",
    "# y_noano = pd.DataFrame(y_noano, columns = ['Top'])\n",
    "# y_noano[y_noano['Top'] == 1].index.values\n",
    "\n",
    "# train_numerical = train_numerical.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
    "# train_numerical.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# train_categoric = train_categoric.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
    "# train_categoric.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# train = train.iloc[y_noano[y_noano['Top'] == 1].index.values]\n",
    "train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numerical = test.select_dtypes(exclude=['object'])\n",
    "test_categoric = test.select_dtypes(include=['object'])\n",
    "train_numerical = train.select_dtypes(exclude=['object'])\n",
    "train_categoric = train.select_dtypes(include=['object'])\n",
    "col_train = list(train.columns)\n",
    "col_train_bis = list(train.columns)\n",
    "col_train_bis.remove('Yield')\n",
    "\n",
    "col_train_num = list(train_numerical.columns)\n",
    "col_train_num_bis = list(train_numerical.columns)\n",
    "\n",
    "col_train_cat = list(train_categoric.columns)\n",
    "\n",
    "col_train_num_bis.remove('Yield')\n",
    "\n",
    "mat_train = np.matrix(train_numerical)\n",
    "mat_test  = np.matrix(test_numerical)\n",
    "mat_new = np.matrix(train_numerical.drop('Yield',axis = 1))\n",
    "mat_y = np.array(train.Yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat_test[2].shape\n",
    "# \n",
    "# (mat_new ==  ) .sum()\n",
    "# mat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_y = MinMaxScaler()\n",
    "prepro_y.fit(mat_y.reshape(2977,1))\n",
    "\n",
    "prepro = MinMaxScaler()\n",
    "prepro.fit(mat_train)\n",
    "\n",
    "prepro_test = MinMaxScaler()\n",
    "prepro_test.fit(mat_test)\n",
    "\n",
    "train_num_scale = pd.DataFrame(prepro.transform(mat_train),columns = col_train_num)\n",
    "test_num_scale  = pd.DataFrame(prepro_test.transform(mat_test),columns = col_train_num_bis)\n",
    "\n",
    "train[col_train_num] = pd.DataFrame(prepro.transform(mat_train),columns = col_train_num)\n",
    "test[col_train_num_bis]  = test_num_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       MH2O0YH\n",
       "1       O9TURWL\n",
       "2       35AFSDD\n",
       "3       PM05EG9\n",
       "4       V7PZBCG\n",
       "         ...   \n",
       "2972    FFX8W83\n",
       "2973    JAOFQM9\n",
       "2974    Z4D9MU8\n",
       "2975    SX57GH1\n",
       "2976    A69YGTK\n",
       "Name: Field_ID, Length: 2977, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Yield']\n",
    "Experiment_name=\"simple_model\"\n",
    "import os\n",
    "os.makedirs(\"proc_data\", exist_ok=True)\n",
    "# os.makedirs(\"model_save/lgbm/{}\".format(Experiment_name), exist_ok=True)\n",
    "# os.makedirs(\"model_save/catboost/{}\".format(Experiment_name), exist_ok=True)\n",
    "# os.makedirs(\"model_save/xgboost/{}\".format(Experiment_name), exist_ok=True)\n",
    "try : \n",
    "    folds=pd.read_csv(\"./proc_data/folds_id.csv\")\n",
    "    train=train.merge(folds,on=\"Field_ID\",how=\"left\")\n",
    "    train.fold.nunique()\n",
    "except : \n",
    "    #  you run this cell  only for the first time \n",
    "    from sklearn.model_selection import KFold \n",
    "    kfold=KFold(n_splits=5,shuffle=True,random_state=2020) # change this random_state or all of you will have the same score  :D \n",
    "    train.reset_index(drop=True,inplace=True)\n",
    "    folds=train[[\"Field_ID\"]].copy()\n",
    "    folds[\"fold\"]=0\n",
    "    for fold,(tr_indx,val_ind) in enumerate(kfold.split(folds)) : \n",
    "        folds.loc[val_ind,\"fold\"]=fold\n",
    "    folds.to_csv(\"./proc_data/folds_id.csv\",index=False)\n",
    "    train=train.merge(folds,on=\"Field_ID\",how=\"left\")\n",
    "    \n",
    "    del folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import  lightgbm as lgbm \n",
    "def metric(y,x):\n",
    "    return np.sqrt(mean_squared_error(x,y))\n",
    "def train_function(model,train,test,params,other_params,target_name,features,metric):\n",
    "    folds_num=train.fold.nunique()\n",
    "    validation=train[[id_name,\"fold\",target_name]].copy()\n",
    "    validation[\"pred_\"+target_name]=0\n",
    "    sub=test[[id_name]].copy()\n",
    "    sub[target_name]=0\n",
    "    for fold in np.sort(train.fold.unique()):\n",
    "        print(\"#\"*50+\" {} \".format(fold)+\"#\"*50)\n",
    "        os.makedirs(\"model_save/lgbm/{}/{}\".format(Experiment_name,str(int(fold))), exist_ok=True)\n",
    "        X_train=train[train.fold!=fold]\n",
    "        X_val=train[train.fold==fold]\n",
    "        \n",
    "        train_pred,validation_pred,test_pred=model(X_train,X_val,test,params,other_params)\n",
    "        \n",
    "        validation.loc[validation.fold==fold,\"pred_\"+target_name]=validation_pred\n",
    "        sub[target_name]+=test_pred/folds_num\n",
    "        train_score=metric(X_train[target_name],train_pred)\n",
    "        val_score=metric(X_val[target_name],validation_pred)\n",
    "        print(\"train score : {} validation score : {}\".format(round(train_score,4),round(val_score,4)))\n",
    "    final_validation_score=metric(validation[target_name],validation[\"pred_\"+target_name])\n",
    "    print(\"final validation score : {}\".format(final_validation_score))\n",
    "        \n",
    "    return sub,validation,final_validation_score\n",
    "\n",
    "def lgbm_model(X_train,X_val,X_test,params,other_params):\n",
    "    dtrain = lgbm.Dataset(data=X_train[features], label=X_train[target_name], feature_name=features)\n",
    "    dval = lgbm.Dataset(data=X_val[features], label=X_val[target_name], feature_name=features)\n",
    "\n",
    "    model = lgbm.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=other_params[\"num_boost_round\"],\n",
    "        valid_sets=(dtrain, dval),\n",
    "        early_stopping_rounds=other_params[\"early_stopping_rounds\"],\n",
    "        verbose_eval=other_params[\"verbose_eval\"],\n",
    "    )        \n",
    "    best_iteration = model.best_iteration\n",
    "    train_pred=model.predict(X_train[features], num_iteration=best_iteration)\n",
    "    validation_pred=model.predict(X_val[features], num_iteration=best_iteration)\n",
    "    test_pred=model.predict(test[features], num_iteration=best_iteration)\n",
    "        \n",
    "    return train_pred,validation_pred,test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name=\"Yield\"\n",
    "id_name=\"Field_ID\"\n",
    "features_to_remove=[target_name,\"fold\"]\n",
    "features=train.columns.tolist()\n",
    "features=[ fea for fea in  features if fea not in features_to_remove  ]\n",
    "test['Field_ID'] = ss.Field_ID\n",
    "train = train.astype({\"Field_ID\":'category'})\n",
    "test = test.astype({\"Field_ID\":'category'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.Field_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.Yield\n",
    "other_params={\"num_boost_round\":50000000,\n",
    "              \"early_stopping_rounds\":50,\n",
    "              \"verbose_eval\":1000,\n",
    "}\n",
    "lgbm_params = {\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 2,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_threads\": 16,\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"reg_lambda\": 5,\n",
    "    \"seed\": 2020,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 0 ##################################################\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's rmse: 0.0841254\tvalid_1's rmse: 0.111079\n",
      "train score : 0.0841 validation score : 0.1111\n",
      "################################################## 1 ##################################################\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's rmse: 0.0808469\tvalid_1's rmse: 0.105704\n",
      "train score : 0.0808 validation score : 0.1057\n",
      "################################################## 2 ##################################################\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\ttraining's rmse: 0.0789019\tvalid_1's rmse: 0.111711\n",
      "train score : 0.0789 validation score : 0.1117\n",
      "################################################## 3 ##################################################\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[264]\ttraining's rmse: 0.0801064\tvalid_1's rmse: 0.101574\n",
      "train score : 0.0801 validation score : 0.1016\n",
      "################################################## 4 ##################################################\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[476]\ttraining's rmse: 0.0665125\tvalid_1's rmse: 0.102503\n",
      "train score : 0.0665 validation score : 0.1025\n",
      "final validation score : 0.10659927784413398\n"
     ]
    }
   ],
   "source": [
    "sub,validation,score=train_function(model=lgbm_model,\n",
    "                                    train=train,\n",
    "                                    test=test,\n",
    "                                    params=lgbm_params,\n",
    "                                    other_params=other_params,\n",
    "                                    target_name=target_name,\n",
    "                                    features=features,\n",
    "                                    metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Yield'] = prepro_y.inverse_transform(np.array(sub.Yield.values.reshape((sub.Yield.shape[0],1))))\n",
    "# mat_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(Experiment_name+str(i)+'.csv',index=False)\n",
    "i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E9UZCEA</td>\n",
       "      <td>3.465100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1WGGS1Q</td>\n",
       "      <td>3.706014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EG2KXE2</td>\n",
       "      <td>3.641288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HC3GQXF</td>\n",
       "      <td>3.510425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7AK6GFK</td>\n",
       "      <td>3.526212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>3H89LWV</td>\n",
       "      <td>3.082509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>I6EYSGB</td>\n",
       "      <td>2.808866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>XOEIR44</td>\n",
       "      <td>2.203332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>YB307JG</td>\n",
       "      <td>2.539080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>8TT86NF</td>\n",
       "      <td>2.760940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1055 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Field_ID     Yield\n",
       "0     E9UZCEA  3.465100\n",
       "1     1WGGS1Q  3.706014\n",
       "2     EG2KXE2  3.641288\n",
       "3     HC3GQXF  3.510425\n",
       "4     7AK6GFK  3.526212\n",
       "...       ...       ...\n",
       "1050  3H89LWV  3.082509\n",
       "1051  I6EYSGB  2.808866\n",
       "1052  XOEIR44  2.203332\n",
       "1053  YB307JG  2.539080\n",
       "1054  8TT86NF  2.760940\n",
       "\n",
       "[1055 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
