{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Action Prediction model","metadata":{"id":"TmbvAhxqPo5L"}},{"cell_type":"markdown","source":"## Load modules and Utility functions","metadata":{"id":"W55dO0rfPo5P"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport warnings \nfrom sklearn.preprocessing import LabelEncoder\nfrom IPython.display import display\n\nwarnings.filterwarnings('ignore')","metadata":{"id":"jfCaEfSzPo5S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data & Preprocessing","metadata":{"id":"0MnmPiu4Po5W"}},{"cell_type":"markdown","source":"### Basic preprocessing","metadata":{"id":"ua-LnyVKPo5X"}},{"cell_type":"code","source":"from math import atan, sqrt\n\ndef reduce_memory_usage(df):\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type not in  ['object', 'datetime64[ns]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n\n        else:\n            df[col] = df[col].astype('category')\n            # pass\n    \n    return df\n\n\n\n# function to drop some columns from the game statsics and load the files \ndef preprocess_all(path, Goals=True):\n    '''\n        path: the original data path\n        Goals: bool if True the Goal_scored and Goals_coceded columns will be dropped\n        modnames: the new names for the dataframes\n    '''\n\n    # read the original data\n    Train = pd.read_csv(path+'Train.csv')\n    Test = pd.read_csv(path+'Test.csv')\n    trgs = pd.read_csv(path+'train_game_statistics.csv')\n    tsgs = pd.read_csv(path+'test_game_statistics.csv')\n\n    cols = [\"next_action\"]\n    if Goals:\n        cols.extend([\"Goals_scored\", \"Goals_conceded\"])\n\n    # drop the columns that are found only in train\n    trgs.drop(\n        columns=cols,\n        inplace=True\n    )\n\n\n    nx_cols = ['next_player',\n                'next_x',\n                'next_y',\n                'next_team',\n                'next_event_id',\n                'event_id',\n                'xt_value'\n    ]\n    # since this columns as almost null to train let's drop them\n    trgs.drop(columns=nx_cols, inplace=True)\n    tsgs.drop(columns=nx_cols, inplace=True)\n\n    trgs = reduce_memory_usage(trgs)\n    tsgs = reduce_memory_usage(tsgs)\n\n\n    return Train, Test, trgs, tsgs \n\n\n\n\n# calculate the distance from the postion of a player to goal\ndef distance_from_goal(xy, xg=0, yg=34):\n    '''\n        Calculate distance from (xg, yg) to (x, y)\n        by default the (xg, yg) = (0, 34)\n    '''\n    x, y = xy\n\n    return ((x-xg)**2 + (y-yg)**2)**.5\n\n\n# the angle view of position to a goal\ndef angle_width(xy, gs=7.32):\n    '''\n        Calculate angle view from (x, y) with a goal width of gs\n        by default goal size is 7.32\n    '''\n    x, y = xy \n\n    return atan(gs*x/(x**2+y**2-(gs/2)**2))\n\n\n# calulate euclidean distance b/n two points\ndef calc_distance(xy1xy2):\n    '''\n        Calculate distance from (x1, y1) to (x2, y2)\n    '''\n    x1, y1, x2, y2 = xy1xy2 \n    return sqrt((x2 - x1)**2 + (y2 - y1)**2)\n\n\n# Function that adds features to the game statstics \ndef preprocess_fe(df):\n    '''\n        df : game stastics data frame \n        returns modified data frame\n    '''\n\n    # sort the gamestatics first by Game ID then Action ID\n    df = df.sort_values(['Season', 'Game_ID', 'id'])\n    # Drop unessary columns the manager and Action ID\n    df = df.drop(columns=['Manager', 'id'])\n\n\n    # Feature Engineering\n    \n    # distance from goal and angle view from (X, Y)\n    df['dist_from_goal'] = list(map(distance_from_goal, zip(df['X'], df['Y'])))\n    df['angle_width'] = list(map(angle_width, zip(df['X'], df['Y'])))\n    df['goal_prob'] = 1 / (1 + np.exp(-3.9 + 3.54*df['angle_width']))\n\n    # X\n    df['last x'] = df.X.shift(1)   # last action's X position\n    df['last2 x'] = df.X.shift(2)  # last 2 action's X position\n    df['next x'] = df.X.shift(-1)  # next actions's X position\n    df['next2 x'] = df.X.shift(-2)  # next 2 action's X position\n\n    # Y\n    df['last y'] = df.Y.shift(1)   # last action's Y position\n    df['last2 y'] = df.Y.shift(2)  # last 2 action's Y position\n    df['next y'] = df.Y.shift(-1)  # next action's Y position\n    df['next2 y'] = df.Y.shift(-2)  # next 2 action's Y position\n\n\n\n    # Team\n    df['prev_same_team'] = (df['Team'].shift(1) == df.Team).astype(int)  # which team took the last action\n    df['next_same_team'] = (df['Team'].shift(-1) == df.Team).astype(int) # which team will take the next action\n\n    # Player\n    df['prev_same_player'] = (df['Player_ID'].shift(1) == df.Player_ID).astype(int)  # which player took the last action\n    df['next_same_player'] = (df['Player_ID'].shift(-1) == df.Player_ID).astype(int) # which player will take the next action\n\n    # Time\n    df['prev_time_diff'] = df['Start_minutes'] - df['Start_minutes'].shift(1) # action starting time difference from previous action\n    df['event_time'] = df.End_minutes - df.Start_minutes                      # how long does the action took\n\n    # Goal dist\n    df['last_goal_dist'] = df['dist_from_goal'].shift(1)   # what was the last action's distance from the goal\n    df['next_goal_dist'] = df['dist_from_goal'].shift(-1)  # what will be the next action's distance from the goal\n\n\n\n    # Missing values \n    ncols = ['last x', 'last2 x', 'next2 x', 'next x', 'last y', 'last2 y',\n        'next2 y', 'next y', 'prev_time_diff', 'last_goal_dist',\n        'next_goal_dist']\n    for col in ncols:\n        df[col].fillna(-1, inplace=True) # for shifted values since we can't have the data let's fill them with -1\n\n\n    # no need to add the actions with pass and shot since those columns are given to us\n    df = df[~((df.Shots == 1)|(df.Passes == 1))]\n\n    # drop the unnessary columns\n    df.drop(columns=['Accurate passes', 'Inaccurate passes', 'Shots', 'SoT', 'Passes'], inplace=True)\n\n  \n    return df\n\n","metadata":{"id":"_2F_tOZ3Po5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/content/drive/MyDrive/Landuma/' # change your path here\n\nTrain, Test, train_gs, test_gs = preprocess_all(path) # bring the files\n\n# apply the preprocess function to both game stastics\ntrain_gs = preprocess_fe(train_gs)\ntest_gs = preprocess_fe(test_gs)\n\ntrain_gs.shape, test_gs.shape","metadata":{"id":"IRGetIU7Po5e","outputId":"9c2f5871-c4a9-4962-e572-a953c4ad6046"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoding","metadata":{"id":"5ECvOKKePo5h"}},{"cell_type":"code","source":"game_map = None # game id decoder\nteam_map = None # team decoder\n\ndf = pd.concat([train_gs.assign(train=1), test_gs.assign(train=0)])\nle = LabelEncoder()\n\n# select the categorical and string type columns and encode them\nfor c in df.select_dtypes(['object', 'category']).columns.drop('Action'):\n  df[c] = le.fit_transform(df[c]) \n  if c == \"Game_ID\":\n    game_map = dict(zip(range(len(le.classes_)), le.classes_))\n  elif c == 'Team':\n    team_map = dict(zip(range(len(le.classes_)), le.classes_))\n\ntrain_gs = df[df.train == 1].drop(columns='train')\ntest_gs = df[df.train == 0].drop(columns=['train', 'Action'])","metadata":{"id":"dmTiPl9kPo5i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Limit the action types\n\ntrain_gs['Action'] = train_gs.Action.str.replace(\"Positional attacks with shots\", \"Positional attacks\")\ntrain_gs = train_gs[train_gs.Action.apply(\n    lambda x:x not in['Extra attacking pass','Inaccurate extra attacking pass', 'Not forced mistake']\n)]\n\ntrain_gs.Action.nunique()","metadata":{"id":"aQJYvZ0GPo5l","outputId":"4830e78f-8379-493b-a475-c8b3b1413e4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gs.Action = le.fit_transform(train_gs.Action)\naction_map = dict(zip(range(len(le.classes_)), le.classes_))\nreverse_map = {i:j for j, i in action_map.items()}\n\ndef get_action_num(action):\n    return reverse_map[action]","metadata":{"id":"mib8Mj9kPo5o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling & Prediction","metadata":{"id":"KEWC8X8IPo5q"}},{"cell_type":"markdown","source":"### Separate the seasons","metadata":{"id":"hyUVAQkPPo5q"}},{"cell_type":"code","source":"train_gs = train_gs.reset_index(drop=True)\ntest_gs = test_gs.reset_index(drop=True)\n\ntrain_gs_s1 = train_gs[train_gs.Season == 1].drop(columns='Season')\ntrain_gs_s2 = train_gs[train_gs.Season == 2].drop(columns='Season')\ntest_gs = test_gs.drop(columns='Season')\ntrain_gs = train_gs.drop(columns='Season')\n\ntrain_gs_s1.shape, train_gs_s2.shape, test_gs.shape","metadata":{"id":"vSJi-K0iPo5r","outputId":"41232b30-45b3-488b-a583-7beb2c23a03e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Undersampling","metadata":{"id":"yOanKK0nPo5r"}},{"cell_type":"code","source":"import imblearn.under_sampling as us\n\ndef resample(X, y, ty='valid'):\n      y = y.map(action_map)\n      vc = y.value_counts()\n\n      stra = {\n            'Positional attacks': 5000,  'Counter-attacks': 2500,\n            'Lost balls': 2500, 'Challenges lost': 2500,\n            'Challenges won': 2500, 'Picking-ups': 1000,\n            'Interceptions': 1000, 'Passes into the penalty box': 1000,\n            'Corner attacks': 1000, 'Air challenges lost': 1000,\n            'Air challenges won': 1000, 'Free-kick attacks': 1000,\n            'Opp half pick-ups': 1000, 'Dribbling': 1000,\n            'Successful tackles': 800, 'Opp half lost balls': 800,\n            'Fouls': 800,  'Successful dribbles': 800,\n            'Unsuccessful tackles': 800, 'Bad ball control': 800,\n            'Inaccurate crosses': 800, 'Unsuccessful dribbles': 800,\n            'Throw-in attacks': 800, 'Opp half interceptions': 800,\n            'Goal kicks': 800, 'Wide shot (Goalkeepers)': 800,\n            'Wide shot': 800, 'Errors': 800,\n            'Inaccurate key passes': 600,  'Accurate crosses': 600,\n            'Shot on target (saved)': 600, 'Shot on target': 600,\n            'Supersaves': 600, 'Accurate key passes': 600,\n            'Offsides': 600, 'Errors leading to goal': 600,\n            'Goals conceded': vc['Goals conceded'], 'Goals': vc['Goals'],\n            'Assists': vc['Assists'], 'Bar/Post shots': vc['Bar/Post shots'],\n            'Penalty': vc['Penalty'], 'Penalty attack': vc['Penalty attack'],\n            'Own goal':vc['Own goal']\n            }\n            \n      sampler = us.RandomUnderSampler(random_state=21, sampling_strategy=stra)\n\n      X, y = sampler.fit_resample(X, y)\n      y = y.map(reverse_map)\n      \n      return X, y\n","metadata":{"id":"7mmXAMjRPo5s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{"id":"_wOpuCuXPo5t"}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\ndef get_model():\n\n    return  XGBClassifier(n_estimators=50, random_state=21)","metadata":{"id":"8-5fhfP5Po5u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and prediction","metadata":{"id":"mVj64oL1Po5v"}},{"cell_type":"code","source":"goals_related = [\n    get_action_num(a) for a in [\n        'Goals', 'Goals conceded', 'Own goal'\n    ]\n]","metadata":{"id":"tZAGRKhHPo5v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### training on season 1 prediction on season 2 & season 3","metadata":{"id":"9n7QdxVuPo5w"}},{"cell_type":"code","source":"X, y = resample(train_gs_s1.drop(columns='Action'), train_gs_s1.Action, 'valid')\nval = train_gs_s2.drop(columns='Action')\ngr_inx = train_gs_s2[train_gs_s2.Action.map(lambda x:x in goals_related)].index\neval_x = val.loc[gr_inx]\neval_y = train_gs_s2.Action[gr_inx]","metadata":{"id":"zle83jbhPo5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.fit(X, y, eval_set=[(eval_x, eval_y)], verbose=0)\npreds2 = model.predict_proba(val)\ntest_pred1 = model.predict_proba(test_gs.fillna(-1))","metadata":{"id":"SxdaAb-IPo5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ngc.collect()","metadata":{"id":"KR9zMHfKPo5y","outputId":"02bb1c64-be75-4897-e15c-16325895a5d9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### training on season 2 prediction on season 1&3","metadata":{"id":"MP4qVsDsPo50"}},{"cell_type":"code","source":"X, y = resample(train_gs_s2.drop(columns='Action'), train_gs_s2.Action, 'valid')\nval = train_gs_s1.drop(columns='Action') \ngr_inx = train_gs_s1[train_gs_s1.Action.map(lambda x:x in goals_related)].index\neval_x = val.loc[gr_inx]\neval_y = train_gs_s1.Action[gr_inx]","metadata":{"id":"_8xYqooFPo50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.fit(X, y, eval_set=[(eval_x, eval_y)], verbose=0)\npreds1 = model.predict_proba(val)\ntest_pred2 = model.predict_proba(test_gs.fillna(-1))","metadata":{"id":"YzeV7qMXPo50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ngc.collect()","metadata":{"id":"SncNBcQvPo51","outputId":"3f50e6a2-1339-4b30-a6c9-ef67ed210df6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Post processing","metadata":{"id":"ls__aE1HPo51"}},{"cell_type":"code","source":"from tqdm import tqdm\n\nA = 'Assists'\nG = 'Goals'\nC = 'Goals conceded'\nO = 'Own goal'\nTH = 0.95 # threshold\n\nclass PostProcess:\n\n    '''\n        Used for Post process the predicted games\n\n        #Parameters\n        game_statics : the preprocessed game statstics data frame\n        prediction : model predictions \n        action_map : dictionary for action column mapping\n    '''\n\n    def __init__(self, game_statics, prediction, action_map):\n        self.df = game_statics[['Game_ID', 'Team']].reset_index(drop=True)\n        self.prediction = prediction \n        self.action_map = action_map\n        self._initialize()\n\n\n    def _initialize(self):\n        reverse_map = {i:j for j, i in self.action_map.items()}\n        gl_inx = reverse_map['Goals']\n        gc_inx = reverse_map['Goals conceded']\n        self.df['pred'] = pd.Series(np.argmax(self.prediction, axis=1)).map(self.action_map)\n        self.df['goal_prob'] = self.prediction[:, gl_inx]\n        self.df['conced_prob'] = self.prediction[:, gc_inx]\n        \n        # fetch only where the model predicts Assists, Goals, Goals conceded or Own goal\n        self.df = self.df[self.df.pred.apply(lambda x:x in [A, G, C, O])]\n\n\n    def postprocess(self, show_unabel=True):\n\n        '''\n            will run a simple 1, 2, 3 group prediction checks to improve models performance\n        '''\n        group_indices = self._get_groups() # fetch closer goal related predictions\n        group_indices2 = {} # store the predictions that are not modified\n        for _, val in tqdm(group_indices.items()):\n            flag, ptype = self._is_okay(val)\n            if not flag:\n                try:\n                    group_indices2[ptype].append(val)\n                except:\n                    group_indices2[ptype] = [val]\n        if show_unabel:\n            tot = 0 \n            for v in group_indices2.items():\n                tot += len(v)\n            if tot == 0:\n                print(\"All are corrected\")\n            else:\n                print(f\"{tot} number of groups unfixed\")\n            print(group_indices2)\n\n        return self.df.drop(columns='pred')\n\n\n    def _get_groups(self): # depending on their index in the data fetch the closer ones\n        group_indices = {}\n        num = -1 \n        curr_ind = -4\n        for ind in self.df.index:\n            pred, goal_prob, conced_prob, team = \\\n                self.df.loc[ind][['pred', 'goal_prob', 'conced_prob', 'Team']]\n            val = (ind, pred, goal_prob, conced_prob, team)\n\n            if abs(curr_ind - ind) <= 3:\n                group_indices[num].append(val)\n                curr_ind = ind\n            else:\n                num += 1 \n                curr_ind = ind\n                group_indices[num] = [val]\n\n        return group_indices\n\n\n    def _corr_3probs(self, preds, teams):\n        '''\n            Same team means Goals or either Own goal or Assits\n            The unique team indicates goal conceded\n        '''\n        if teams[0] == teams[1]:\n            return [(0, 0), (TH, 0), (0, TH)]\n        elif teams[1] == teams[2]:\n            return [(0, TH), (TH, 0), (0, 0)]\n        elif teams[0] == teams[2]:\n            return [(0, 0), (0, TH), (TH, 0)]\n        else:\n            raise Exception(\"Atleast two teams must be similar\")\n\n\n    def _corr_2probs(self, gprobs, cprobs):\n        '''\n            The higher the sum of goal probability, more probable that \n            it would be a Goals\n        '''\n\n        fr_inx = gprobs[0] + cprobs[1]\n        sc_inx = gprobs[1] + cprobs[0]\n\n        if fr_inx >= sc_inx:\n            return [(TH/2, 0), (0, TH/2)]\n        else:\n            return [(0, TH/2), (TH/2, 0)]\n\n\n    def _is_okay(self, conn_ind):\n        '''\n            Check whether the prediction of a model is good or not\n            from the groups created\n\n\n        '''\n        preds = [i[1] for i in conn_ind] # predictions\n        teams = [i[-1] for i in conn_ind] # team\n        indces = [i[0] for i in conn_ind] # incices\n        gprobs = [i[2] for i in conn_ind] # goal probabilities\n        cprobs = [i[3] for i in conn_ind] # goals conceded probabilities\n\n        if len(conn_ind) == 1: # single group\n            # Assist predictions\n            self.df.loc[indces[0], \"goal_prob\"] = 0\n            self.df.loc[indces[0], \"conced_prob\"] = 0\n\n            return True, None\n        \n        elif len(conn_ind) == 2: # two group\n            if sorted(preds) == [G, C]:\n                # n = preds.index(G)\n                # self.df.loc[indces[int(not n)], \"goal_prob\"] =  0\n                # self.df.loc[indces[n], \"conced_prob\"] = 0\n\n                return True, None\n            \n            elif C in preds and teams[0] != teams[1]:\n                n = preds.index(C)\n                self.df.loc[indces[int(not n)], \"goal_prob\"] =  cprobs[n]\n                self.df.loc[indces[int(not n)], \"conced_prob\"] = gprobs[n]\n\n                return True, None\n            \n            elif teams[0] != teams[1]:\n                for i, (gl, cn) in enumerate(self._corr_2probs(gprobs, cprobs)):\n                    self.df.loc[indces[i], \"goal_prob\"] = gl\n                    self.df.loc[indces[i], \"conced_prob\"] = cn\n\n                return True, None\n            \n            else:\n                return False, 2\n        \n        elif len(conn_ind) == 3: # three group\n            if sorted(preds) == [A, G, C]:\n                return True, None\n\n            elif (preds.count(C) > 1 or preds.count(G) > 1 \\\n                or sorted(preds) == [G, C, O] or sorted(preds)== [A, A, C]\\\n                or sorted(preds) == [G, O, O]) and len(set(teams))==2:\n                for i, (gl, cn) in enumerate(self._corr_3probs(preds, teams)):\n                    self.df.loc[indces[i], \"goal_prob\"] = gl\n                    self.df.loc[indces[i], \"conced_prob\"] = cn\n\n                return True, None\n            else:\n                return False, 3 \n        elif len(conn_ind) == 4:\n            return False, 4\n        else:\n            return False, False\n\n","metadata":{"id":"rWHovLqGPo52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from postprocess import PostProcess\n\ntrain_pred = np.concatenate([preds1, preds2])\ntest_pred = (test_pred1 * .5 + test_pred2 * .5)\n\ntr_pp = PostProcess(train_gs, train_pred, action_map)\nts_pp = PostProcess(test_gs, test_pred, action_map)\n\ntrain_df = tr_pp.postprocess(show_unabel=False)\ntest_df = ts_pp.postprocess(show_unabel=False)\n\ntrain_df.shape, test_df.shape","metadata":{"id":"7ZSTaLo0Po54","outputId":"12b4c167-ee5a-4fdc-ec75-11c105077d55"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Revert the original data of game ID and Team info","metadata":{"id":"54ZOBnW8Po55"}},{"cell_type":"code","source":"train_df['Game_ID'] = train_df['Game_ID'].map(game_map)\ntest_df['Game_ID'] = test_df['Game_ID'].map(game_map)\n\ntrain_df['Team'] = train_df['Team'].map(team_map)\ntest_df['Team'] = test_df['Team'].map(team_map)\n\ntrain_df","metadata":{"id":"CyWN1FwvPo56","outputId":"033b56ed-9bc0-49ca-b22e-f6fc5995b5c1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Aggregation of the probabiities by sum","metadata":{"id":"pn9CciRfPo57"}},{"cell_type":"code","source":"# grouping by first Game ID then Team\ntrgpby = train_df.groupby(['Game_ID', 'Team']).agg(\n    goal_prob_sum=('goal_prob', 'sum'),\n    goal_prob_conced_sum=('conced_prob', 'sum'),\n    )\ntrain_goal_prob = trgpby['goal_prob_sum']\ntrain_goal_conced_prob = trgpby['goal_prob_conced_sum']\ntrain_goal_prob","metadata":{"id":"SwmWz-fpPo57","outputId":"0942795a-5349-40f5-c179-ad31e635aa32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grouping by first Game ID then Team\ntsgpby = test_df.groupby(['Game_ID', 'Team']).agg(\n    goal_prob_sum=('goal_prob', 'sum'),\n    goal_prob_conced_sum=('conced_prob', 'sum'),\n)\ntest_goal_prob = tsgpby['goal_prob_sum']\ntest_goal_conced_prob = tsgpby['goal_prob_conced_sum']\ntest_goal_prob","metadata":{"id":"xWTVRCS3Po59","outputId":"48a864b4-7d75-4f03-ee57-3659681d2fae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Add the aggregation to the Train and Test data","metadata":{"id":"bhKWTnu2Po5-"}},{"cell_type":"code","source":"# function to get the probabiity sum values from the aggregated value \ndef add_prob(df, gp, gcp):\n    hgpr = []     # home goal probability\n    hgcpr = []    # home goal conceded probability\n    agpr = []     # away goal probability\n    agcpr = []    # away goal conceded probability\n    for i in df.index:\n        gid, htm, atm = df.loc[i][['Game_ID', 'Home Team', 'Away Team']].values \n        try:\n            hgpr.append(gp[gid][htm])\n        except:\n            hgpr.append(0)\n        try:\n            hgcpr.append(gcp[gid][htm])\n        except:\n            hgcpr.append(0)\n        try:\n            agpr.append(gp[gid][atm])\n        except:\n            agpr.append(0)\n        try:\n            agcpr.append(gcp[gid][atm])\n        except:\n            agcpr.append(0)\n    df['Home_goal_prob'] = hgpr \n    df['Home_goal_conced_prob'] = hgcpr \n    df['Away_goal_prob'] = agpr \n    df['Away_goal_conced_prob'] = agcpr \n    df['Diff_goal_prob'] = df['Home_goal_prob'] - df['Away_goal_prob'] \n    df['Diff_goal_conced_prob'] = df['Home_goal_conced_prob'] - df['Away_goal_conced_prob'] \n    df['Diff_goalpr_conced'] = df['Diff_goal_prob'] + df['Diff_goal_conced_prob'] \n\n    return df \n\nTrain = add_prob(Train, train_goal_prob, train_goal_conced_prob) # add it to train\nTest = add_prob(Test, test_goal_prob, test_goal_conced_prob)     # add it to test\n\ndisplay(Train.head(5), Test.head(2))","metadata":{"id":"Oh3QsZTlPo5_","outputId":"db53e4a0-b6d1-4cfb-b7bf-ab34bb190609"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Export the new data","metadata":{"id":"Udsbb6hVPo6A"}},{"cell_type":"code","source":"Train.to_csv(path+'Train_modified.csv', index=False)\nTest.to_csv(path+'Test_modified.csv', index=False)","metadata":{"id":"EBmY4kxBPo6A"},"execution_count":null,"outputs":[]}]}