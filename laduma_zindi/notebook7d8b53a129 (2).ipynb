{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/mkm-world/laduma-analytics/blob/main/zindi_football_baseline_public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"#Zindi Weekendz: Laduma Analytics Football League Winners Prediction Challenge\n\n- **Can you predict the outcome of a football match based on historical data?**","metadata":{"id":"IqkjT4oTpVwE"}},{"cell_type":"markdown","source":"# Downloading all datasets directly from Zindi platform using url:","metadata":{"id":"S4SwkOLKpcsm"}},{"cell_type":"markdown","source":"#### Import Libraries","metadata":{"id":"bdfbc4dd"}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom datetime import datetime as dt\nimport itertools\nfrom tqdm import tqdm\n%matplotlib inline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\n# from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\npd.set_option('display.max_columns', None)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport lightgbm as lgb \nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,log_loss\n# import lightgbm as lgb\nimport gc\n\nfrom sklearn.model_selection import StratifiedKFold,KFold\nfrom sklearn import metrics\nimport xgboost as xgb\n","metadata":{"id":"210ce524","execution":{"iopub.status.busy":"2022-09-04T16:19:47.850516Z","iopub.execute_input":"2022-09-04T16:19:47.850886Z","iopub.status.idle":"2022-09-04T16:19:49.509782Z","shell.execute_reply.started":"2022-09-04T16:19:47.850813Z","shell.execute_reply":"2022-09-04T16:19:49.508881Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#Load Datasets:","metadata":{"id":"0cjdIcdQrFAN"}},{"cell_type":"code","source":"path = '../input/laduma/'","metadata":{"execution":{"iopub.status.busy":"2022-09-04T16:21:05.054270Z","iopub.execute_input":"2022-09-04T16:21:05.054605Z","iopub.status.idle":"2022-09-04T16:21:05.059071Z","shell.execute_reply.started":"2022-09-04T16:21:05.054580Z","shell.execute_reply":"2022-09-04T16:21:05.058005Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(path+\"Train.csv\",parse_dates=['Date'])\ntest = pd.read_csv(path+\"Test.csv\",parse_dates=['Date'])\ntrain_stats = pd.read_csv('../input/laduma/train_game_statistics.csv')\ntest_stats = pd.read_csv('../input/laduma/test_game_statistics.csv')","metadata":{"id":"6247095e","execution":{"iopub.status.busy":"2022-09-04T16:21:06.602965Z","iopub.execute_input":"2022-09-04T16:21:06.603309Z","iopub.status.idle":"2022-09-04T16:21:14.458731Z","shell.execute_reply.started":"2022-09-04T16:21:06.603285Z","shell.execute_reply":"2022-09-04T16:21:14.457805Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def mean_X_change(stats):\n    \n    ch = stats.groupby(['Game_ID','Team']).apply(lambda x: x.Player_ID.unique().shape[0]%11  )\n    first_appear = stats.groupby(['Game_ID','Team','Player_ID']).apply(lambda x: x['Start_minutes'].min())\n    mean_X = stats.groupby(['Game_ID','Team','Player_ID']).apply(lambda x:  x['X'].mean())\n    new_df = first_appear.reset_index().merge(mean_X.reset_index(),on = ['Game_ID','Team','Player_ID'],how = 'left')\n    new_df = new_df.groupby(['Game_ID','Team']).apply(lambda x : x.sort_values(by = '0_x',ascending = False)).reset_index(drop = True)\n    df = ch.reset_index()[['Game_ID','Team']].copy()\n    df[['mean_change_X' ]] =np.nan\n    ch = ch.reset_index()\n    for g in tqdm(ch.Game_ID.unique()):\n        for t in ch.loc[ch.Game_ID == g,'Team']:\n            i = ch.loc[(ch.Game_ID == g)&(ch.Team == t),0].values[0]\n            df.loc[(df.Game_ID == g)&(df.Team == t),'mean_change_X'] = np.mean(new_df.loc[(new_df.Game_ID == g)&(new_df.Team == t),'0_y'].values[:i])\n    \n    return df\ndef mean_min_change(stats):\n    ch = stats.groupby(['Game_ID','Team']).apply(lambda x: x.Player_ID.unique().shape[0]%11  )\n    first_appear = stats.groupby(['Game_ID','Team','Player_ID']).apply(lambda x: x['Start_minutes'].min())\n    mean_X = stats.groupby(['Game_ID','Team','Player_ID']).apply(lambda x:  x['X'].mean())\n    new_df = first_appear.reset_index().merge(mean_X.reset_index(),on = ['Game_ID','Team','Player_ID'],how = 'left')\n    new_df = new_df.groupby(['Game_ID','Team']).apply(lambda x : x.sort_values(by = '0_x',ascending = False)).reset_index(drop = True)\n    df = ch.reset_index()[['Game_ID','Team']].copy()\n    df[['mean_change_min' ]] =np.nan\n    ch = ch.reset_index()\n    for g in tqdm(ch.Game_ID.unique()):\n        for t in ch.loc[ch.Game_ID == g,'Team']:\n            i = ch.loc[(ch.Game_ID == g)&(ch.Team == t),0].values[0]\n            df.loc[(df.Game_ID == g)&(df.Team == t),'mean_change_min'] = np.mean(new_df.loc[(new_df.Game_ID == g)&(new_df.Team == t),'0_x'].values[:i])\n    \n    return df\ndef get_stats(train,train_stats):\n    teams = train_stats.loc[train_stats['Goals_scored']==1]\n    team_goals = teams.groupby(['Game_ID','Team'])['Goals_scored'].sum()\n    team_goals =team_goals.reset_index()\n    for game in train.Game_ID:\n        s1 = train.loc[train.Game_ID == game,['Home Team','Away Team']].values\n    #     team_goals.loc[team_goals.Game_ID == 'ID_00EFNL7L']\n        s2 = team_goals.loc[team_goals.Game_ID == game,'Team'].values\n        diff = np.setdiff1d(s1,s2)\n        if diff.shape[0] == 1: \n            team_goals.loc[-1] = [game, diff[0], 0]  # adding a row\n            team_goals.index = team_goals.index + 1  # shifting index\n            team_goals = team_goals.sort_index()\n    teams2 = train_stats.loc[train_stats['Goals_conceded']==1]\n    team_goals2 = teams2.groupby(['Game_ID','Team'])['Goals_conceded'].sum()\n    team_goals2 =team_goals2.reset_index()\n    for game in train.Game_ID:\n        s1 = train.loc[train.Game_ID == game,['Home Team','Away Team']].values\n    #     team_goals.loc[team_goals.Game_ID == 'ID_00EFNL7L']\n        s2 = team_goals2.loc[team_goals2.Game_ID == game,'Team'].values\n        diff = np.setdiff1d(s1,s2)\n        if diff.shape[0] == 1: \n            team_goals2.loc[-1] = [game, diff[0], 0]  # adding a row\n            team_goals2.index = team_goals2.index + 1  # shifting index\n            team_goals2 = team_goals2.sort_index()  \n    diff_score = team_goals2.groupby('Team')['Goals_conceded'].mean().reset_index().merge(team_goals.groupby('Team')['Goals_scored'].mean().reset_index(),on = 'Team' )\n    ast =team_goals2.merge(team_goals,on = ['Game_ID','Team']).merge(train[['Game_ID','Home Team','Away Team']],on = 'Game_ID')\n    as_home = ast.loc[ast['Team'] == ast['Home Team']].groupby('Team')[['Goals_scored','Goals_conceded']].mean().reset_index()\n    as_away = ast.loc[ast['Team'] == ast['Away Team']].groupby('Team')[['Goals_scored','Goals_conceded']].mean().reset_index()\n    as_home['diff_score_h'] = as_home['Goals_scored'] - as_home['Goals_conceded'] \n    as_away['diff_score_a'] = as_away['Goals_scored'] - as_away['Goals_conceded'] \n    as_home = as_home[['Team','diff_score_h']]\n    as_away = as_away[['Team','diff_score_a']]\n    diff_score = team_goals2.groupby('Team')['Goals_conceded'].mean().reset_index().merge(team_goals.groupby('Team')['Goals_scored'].mean().reset_index(),on = 'Team' )\n    diff_score['diff_score'] = diff_score['Goals_scored'] - diff_score['Goals_conceded']\n    diff_score = diff_score[['Team','diff_score']]\n    diff_score = diff_score.merge(as_home,on = 'Team').merge(as_away,on = 'Team')\n#     st = get_stats(train,train_stats)\n    diff_score.index = diff_score.Team\n    diff_score.drop('Team',axis = 1,inplace = True)\n    return diff_score\ndef preprocess(train,test,train_stats,test_stats,scale = False,th = 2,encode = False):\n    train['Train']=1\n    test['Train']=0\n    home_teams=train['Home Team'].unique()\n    all_data=pd.concat([train,test])\n    if encode:\n        lb = LabelEncoder()\n        all_data['Away_ID'] = lb.fit_transform(all_data['Away Team'].values.reshape(-1,1))\n        all_data['Home_ID'] = lb.transform(all_data['Home Team'].values.reshape(-1,1))\n\n    else:\n        for team in home_teams:\n            all_data['home_'+team]=0\n            all_data.loc[all_data['Home Team']==team,'home_'+team]=1\n        away_teams=train['Away Team'].unique()\n        for team in away_teams:\n            all_data['away_'+team]=0\n            all_data.loc[all_data['Away Team']==team,'away_'+team]=1\n#     print(all_data.isna().sum())\n    all_data['unique_id'] = all_data.apply(lambda x : '_'.join(np.sort(x[['Home Team', 'Away Team']].values)),axis = 1).values\n#     lbb = LabelEncoder()\n    new_seas1 = [l for l in all_data.loc[all_data.Season == 2 , 'Home Team'].unique() if l not in all_data.loc[all_data.Season == 1 , 'Home Team'].unique()]\n    new_seas2 = [l for l in all_data.loc[all_data.Season == 3 , 'Home Team'].unique() if l not in all_data.loc[all_data.Season == 2 , 'Home Team'].unique()]\n    all_data['is_new_h'] = 0\n    all_data['is_new_a'] = 0\n    all_data.loc[(all_data['Home Team'].isin(new_seas1))& (all_data.Season ==2),'is_new_h'] = 1\n    all_data.loc[(all_data['Home Team'].isin(new_seas2))& (all_data.Season ==3),'is_new_h'] = 1\n    all_data.loc[(all_data['Away Team'].isin(new_seas1))& (all_data.Season ==2),'is_new_a'] = 1\n    all_data.loc[(all_data['Away Team'].isin(new_seas2))& (all_data.Season ==3),'is_new_a'] = 1\n#     all_data['unique_id'] = lbb.fit_transform(all_data['unique_id'].values.reshape(-1,1))\n    all_data = pd.get_dummies(all_data,columns = ['unique_id'])\n    all_data.fillna(all_data.mean(),inplace=True)\n    all_data['month'] = all_data.Date.dt.month\n    all_data['year'] = all_data.Date.dt.year\n    all_data['day'] = all_data.Date.dt.day\n    all_data['week'] = all_data.Date.dt.week\n    all_data['dow'] = all_data.Date.dt.dayofweek\n    all_data['woy'] = all_data.Date.dt.weekofyear\n    train = all_data[all_data[\"Train\"] == 1]\n    test = all_data[all_data[\"Train\"] == 0]\n    train_inv= train.copy()\n    train_inv['Home Team'] = train['Away Team']\n    train_inv['Away Team'] = train['Home Team']\n    train['last_Score'] = 0\n    test['last_Score'] = 0\n    for game in tqdm(train.Game_ID):\n        teamh = train.loc[train.Game_ID == game,'Home Team'].values[0]\n        teama = train.loc[train.Game_ID == game,'Away Team'].values[0]\n        date = train.loc[train.Game_ID == game,'Date'].values[0]\n        seas = train.loc[train.Game_ID == game,'Season'].values[0]\n        temp = train.loc[(train['Home Team'] == teamh) & (train['Away Team'] == teama),\n                         ['Game_ID','Date','Season','Score'] ]\n        temp_inv = train_inv.loc[(train_inv['Home Team'] == teamh) & (train_inv['Away Team'] == teama),\n                         ['Game_ID','Date','Season','Score']]\n        temp_inv['Score'] = temp_inv['Score'].map({0:2,2:0})\n        if (temp.shape[0] ==0) & (temp_inv.shape[0] ==0):\n            train.loc[train.Game_ID == game,'last_Score'] = -1 # No data\n        elif (temp.shape[0] ==0):\n            game_id = -1\n            for g in temp_inv.Game_ID:\n                if temp_inv.loc[temp_inv.Game_ID == g,'Date'].values[0]<date:\n                    game_id = g\n            if game_id == -1:\n                train.loc[train.Game_ID == game,'last_Score'] = -1 # No recent data\n            else:\n                train.loc[train.Game_ID == game,'last_Score'] = temp_inv.loc[temp_inv.Game_ID == game_id,'Score'].values[0]\n        elif (temp_inv.shape[0] ==0):\n            game_id = -1\n            for g in temp.Game_ID:\n                if temp.loc[temp.Game_ID == g,'Date'].values[0]<date:\n                    game_id = g\n            if game_id == -1:\n                train.loc[train.Game_ID == game,'last_Score'] = -1 # No recent data\n            else:\n                train.loc[train.Game_ID == game,'last_Score'] = temp.loc[temp.Game_ID == game_id,'Score'].values[0]\n        else:\n            game_id_inv = -1\n            for g in temp_inv.Game_ID:\n                if temp_inv.loc[temp_inv.Game_ID == g,'Date'].values[0]<date:\n                    game_id_inv = g\n            game_id = -1\n            for g in temp.Game_ID:\n                if temp.loc[temp.Game_ID == g,'Date'].values[0]<date:\n                    game_id = g\n            if (game_id == -1) & (game_id_inv == -1):\n                train.loc[train.Game_ID == game,'last_Score'] = -1 # No data\n            elif game_id ==-1:\n                train.loc[train.Game_ID == game,'last_Score'] = temp_inv.loc[temp_inv.Game_ID == game_id_inv,'Score'].values[0]\n            elif game_id_inv == -1:\n                train.loc[train.Game_ID == game,'last_Score'] = temp.loc[temp.Game_ID == game_id,'Score'].values[0]\n            else:\n                if temp.loc[temp.Game_ID == game_id,'Date'].values[0]> temp_inv.loc[temp_inv.Game_ID == game_id_inv,'Date'].values[0]:\n                    train.loc[train.Game_ID == game,'last_Score'] = temp_inv.loc[temp_inv.Game_ID == game_id_inv,'Score'].values[0]\n                else:\n                    train.loc[train.Game_ID == game,'last_Score'] = temp.loc[temp.Game_ID == game_id,'Score'].values[0]\n    for game in tqdm(test.Game_ID):\n        teamh = test.loc[test.Game_ID == game,'Home Team'].values[0]\n        teama = test.loc[test.Game_ID == game,'Away Team'].values[0]\n        date = test.loc[test.Game_ID == game,'Date'].values[0]\n        seas = test.loc[test.Game_ID == game,'Season'].values[0]\n        temp = train.loc[(train['Home Team'] == teamh) & (train['Away Team'] == teama),\n                         ['Game_ID','Date','Season','Score'] ]\n        temp_inv = train_inv.loc[(train_inv['Home Team'] == teamh) & (train_inv['Away Team'] == teama),\n                         ['Game_ID','Date','Season','Score']]\n        temp_inv['Score'] = temp_inv['Score'].map({0:2,2:0})\n        if (temp.shape[0] ==0) & (temp_inv.shape[0] ==0):\n            test.loc[test.Game_ID == game,'last_Score'] = np.nan # No data\n        elif (temp.shape[0] ==0):\n            game_id = None\n            for g in temp_inv.Game_ID:\n                if temp_inv.loc[temp_inv.Game_ID == g,'Date'].values[0]<date:\n                    game_id = g\n            if game_id == None:\n                test.loc[test.Game_ID == game,'last_Score'] = np.nan # No recent data\n            else:\n                test.loc[test.Game_ID == game,'last_Score'] = temp_inv.loc[temp_inv.Game_ID == game_id,'Score'].values[0]\n        elif (temp_inv.shape[0] ==0):\n            game_id = None\n            for g in temp.Game_ID:\n                if temp.loc[temp.Game_ID == g,'Date'].values[0]<date:\n                    game_id = g\n            if game_id == None:\n                test.loc[test.Game_ID == game,'last_Score'] = np.nan # No recent data\n            else:\n                test.loc[test.Game_ID == game,'last_Score'] = temp.loc[temp.Game_ID == game_id,'Score'].values[0]\n        else:\n            game_id_inv = None\n            for g in temp_inv.Game_ID:\n                if temp_inv.loc[temp_inv.Game_ID == g,'Date'].values[0]<date:\n                    game_id_inv = g\n            game_id = None\n            for g in temp.Game_ID:\n                if temp.loc[temp.Game_ID == g,'Date'].values[0]<date:\n                    game_id = g\n            if (game_id == None) & (game_id_inv == None):\n                test.loc[test.Game_ID == game,'last_Score'] = np.nan # No data\n            elif game_id ==None:\n                test.loc[test.Game_ID == game,'last_Score'] = temp_inv.loc[temp_inv.Game_ID == game_id_inv,'Score'].values[0]\n            elif game_id_inv == None:\n                test.loc[test.Game_ID == game,'last_Score'] = temp.loc[temp.Game_ID == game_id,'Score'].values[0]\n            else:\n                if temp.loc[temp.Game_ID == game_id,'Date'].values[0]> temp_inv.loc[temp_inv.Game_ID == game_id_inv,'Date'].values[0]:\n                    test.loc[test.Game_ID == game,'last_Score'] = temp_inv.loc[temp_inv.Game_ID == game_id_inv,'Score'].values[0]\n                else:\n                    test.loc[test.Game_ID == game,'last_Score'] = temp.loc[temp.Game_ID == game_id,'Score'].values[0]\n    train['last_Score'] = train['last_Score'].fillna(0).astype('int')\n    test['last_Score'] =  test['last_Score'].fillna(0).astype('int')\n    all_stats = pd.concat([train_stats,test_stats])\n    all_stats.drop(['Action', 'Goals_scored', 'Goals_conceded', 'next_action'],axis=1,inplace = True)\n    all_stats.drop(['next_player','next_x','next_y','event_id','next_team','next_event_id','xt_value'],axis =1,inplace = True)\n    # use grouped to calculate other statistics\n    all_stats = all_stats[all_stats.X !=300]\n    grouped = all_stats.groupby(['Game_ID','Team','Player_ID','Half'])[['Shots','SoT','Accurate passes','Inaccurate passes','Passes']].sum()\n    grouped =grouped.reset_index()\n    accu_shots = grouped.groupby(['Game_ID','Team','Half']).apply(lambda x : x['SoT'].sum()/x['Shots'].sum()).reset_index()\n    accu_pass = grouped.groupby(['Game_ID','Team','Half']).apply(lambda x : x['Accurate passes'].sum()/x['Passes'].sum()).reset_index()\n    n_shots = grouped.groupby(['Game_ID','Team','Half']).apply(lambda x : x['SoT'].sum()).reset_index()\n    n_passes = grouped.groupby(['Game_ID','Team','Half']).apply(lambda x : x['Passes'].sum()).reset_index()\n    train[['n_passes_home1','n_shots_home1','accu_pass_home1','accu_shots_home1',\n          'n_passes_away1','n_shots_away1','accu_pass_away1','accu_shots_away1',\n          'n_passes_home2','n_shots_home2','accu_pass_home2','accu_shots_home2',\n          'n_passes_away2','n_shots_away2','accu_pass_away2','accu_shots_away2']]=0\n    for game in tqdm(train.Game_ID):\n        train.loc[train.Game_ID == game,'n_passes_home1'] = n_passes.loc[(n_passes.Game_ID == game)&(n_passes.Team == train.loc[train.Game_ID == game,'Home Team'].values[0]) & (n_passes.Half == '1st half' ),0].values[0]\n        train.loc[train.Game_ID == game,'n_passes_home2'] = n_passes.loc[(n_passes.Game_ID == game)&(n_passes.Team == train.loc[train.Game_ID == game,'Home Team'].values[0]) & (n_passes.Half == '2nd half' ),0].values[0]\n        train.loc[train.Game_ID == game,'n_passes_away1'] = n_passes.loc[(n_passes.Game_ID == game)&(n_passes.Team == train.loc[train.Game_ID == game,'Away Team'].values[0]) & (n_passes.Half == '1st half' ),0].values[0]\n        train.loc[train.Game_ID == game,'n_passes_away2'] = n_passes.loc[(n_passes.Game_ID == game)&(n_passes.Team == train.loc[train.Game_ID == game,'Away Team'].values[0]) & (n_passes.Half == '2nd half' ),0].values[0]\n        train.loc[train.Game_ID == game,'n_shots_home1'] = n_shots.loc[(n_shots.Game_ID == game)&(n_shots.Team == train.loc[train.Game_ID == game,'Home Team'].values[0]) & (n_shots.Half == '1st half' ),0].values[0]\n        train.loc[train.Game_ID == game,'n_shots_home2'] = n_shots.loc[(n_shots.Game_ID == game)&(n_shots.Team == train.loc[train.Game_ID == game,'Home Team'].values[0]) & (n_shots.Half == '2nd half' ),0].values[0]\n        train.loc[train.Game_ID == game,'n_shots_away1'] = n_shots.loc[(n_shots.Game_ID == game)&(n_shots.Team == train.loc[train.Game_ID == game,'Away Team'].values[0]) & (n_shots.Half == '1st half' ),0].values[0]\n        train.loc[train.Game_ID == game,'n_shots_away2'] = n_shots.loc[(n_shots.Game_ID == game)&(n_shots.Team == train.loc[train.Game_ID == game,'Away Team'].values[0]) & (n_shots.Half == '2nd half' ),0].values[0]\n        train.loc[train.Game_ID == game,'accu_pass_home1'] = accu_pass.loc[(accu_pass.Game_ID == game)&(accu_pass.Team == train.loc[train.Game_ID == game,'Home Team'].values[0]) & (accu_pass.Half == '1st half' ),0].values[0]\n        train.loc[train.Game_ID == game,'accu_pass_home2'] = accu_pass.loc[(accu_pass.Game_ID == game)&(accu_pass.Team == train.loc[train.Game_ID == game,'Home Team'].values[0]) & (accu_pass.Half == '2nd half' ),0].values[0]\n        train.loc[train.Game_ID == game,'accu_pass_away1'] = accu_pass.loc[(accu_pass.Game_ID == game)&(accu_pass.Team == train.loc[train.Game_ID == game,'Away Team'].values[0]) & (accu_pass.Half == '1st half' ),0].values[0]\n        train.loc[train.Game_ID == game,'accu_pass_away2'] = accu_pass.loc[(accu_pass.Game_ID == game)&(accu_pass.Team == train.loc[train.Game_ID == game,'Away Team'].values[0]) & (accu_pass.Half == '2nd half' ),0].values[0]\n        train.loc[train.Game_ID == game,'accu_shots_home1'] = accu_shots.loc[(accu_shots.Game_ID == game)&(accu_shots.Team == train.loc[train.Game_ID == game,'Home Team'].values[0]) & (accu_shots.Half == '1st half' ),0].values[0]\n        train.loc[train.Game_ID == game,'accu_shots_home2'] = accu_shots.loc[(accu_shots.Game_ID == game)&(accu_shots.Team == train.loc[train.Game_ID == game,'Home Team'].values[0]) & (accu_shots.Half == '2nd half' ),0].values[0]\n        train.loc[train.Game_ID == game,'accu_shots_away1'] = accu_shots.loc[(accu_shots.Game_ID == game)&(accu_shots.Team == train.loc[train.Game_ID == game,'Away Team'].values[0]) & (accu_shots.Half == '1st half' ),0].values[0]\n        train.loc[train.Game_ID == game,'accu_shots_away2'] = accu_shots.loc[(accu_shots.Game_ID == game)&(accu_shots.Team == train.loc[train.Game_ID == game,'Away Team'].values[0]) & (accu_shots.Half == '2nd half' ),0].values[0]\n    test[['n_passes_home1','n_shots_home1','accu_pass_home1','accu_shots_home1',\n          'n_passes_away1','n_shots_away1','accu_pass_away1','accu_shots_away1',\n          'n_passes_home2','n_shots_home2','accu_pass_home2','accu_shots_home2',\n          'n_passes_away2','n_shots_away2','accu_pass_away2','accu_shots_away2']]=0\n    exep = []\n    for game in tqdm(test.Game_ID):\n        try:\n            test.loc[test.Game_ID == game,'n_passes_home1'] = n_passes.loc[(n_passes.Game_ID == game)&(n_passes.Team == test.loc[test.Game_ID == game,'Home Team'].values[0]) & (n_passes.Half == '1st half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'n_passes_home2'] = n_passes.loc[(n_passes.Game_ID == game)&(n_passes.Team == test.loc[test.Game_ID == game,'Home Team'].values[0]) & (n_passes.Half == '2nd half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n\n        try:\n            test.loc[test.Game_ID == game,'n_passes_away1'] = n_passes.loc[(n_passes.Game_ID == game)&(n_passes.Team == test.loc[test.Game_ID == game,'Away Team'].values[0]) & (n_passes.Half == '1st half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'n_passes_away2'] = n_passes.loc[(n_passes.Game_ID == game)&(n_passes.Team == test.loc[test.Game_ID == game,'Away Team'].values[0]) & (n_passes.Half == '2nd half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'n_shots_home1'] = n_shots.loc[(n_shots.Game_ID == game)&(n_shots.Team == test.loc[test.Game_ID == game,'Home Team'].values[0]) & (n_shots.Half == '1st half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'n_shots_home2'] = n_shots.loc[(n_shots.Game_ID == game)&(n_shots.Team == test.loc[test.Game_ID == game,'Home Team'].values[0]) & (n_shots.Half == '2nd half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'n_shots_away1'] = n_shots.loc[(n_shots.Game_ID == game)&(n_shots.Team == test.loc[test.Game_ID == game,'Away Team'].values[0]) & (n_shots.Half == '1st half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'n_shots_away2'] = n_shots.loc[(n_shots.Game_ID == game)&(n_shots.Team == test.loc[test.Game_ID == game,'Away Team'].values[0]) & (n_shots.Half == '2nd half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'accu_pass_home1'] = accu_pass.loc[(accu_pass.Game_ID == game)&(accu_pass.Team == test.loc[test.Game_ID == game,'Home Team'].values[0]) & (accu_pass.Half == '1st half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'accu_pass_home2'] = accu_pass.loc[(accu_pass.Game_ID == game)&(accu_pass.Team == test.loc[test.Game_ID == game,'Home Team'].values[0]) & (accu_pass.Half == '2nd half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'accu_pass_away1'] = accu_pass.loc[(accu_pass.Game_ID == game)&(accu_pass.Team == test.loc[test.Game_ID == game,'Away Team'].values[0]) & (accu_pass.Half == '1st half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'accu_pass_away2'] = accu_pass.loc[(accu_pass.Game_ID == game)&(accu_pass.Team == test.loc[test.Game_ID == game,'Away Team'].values[0]) & (accu_pass.Half == '2nd half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'accu_shots_home1'] = accu_shots.loc[(accu_shots.Game_ID == game)&(accu_shots.Team == test.loc[test.Game_ID == game,'Home Team'].values[0]) & (accu_shots.Half == '1st half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'accu_shots_home2'] = accu_shots.loc[(accu_shots.Game_ID == game)&(accu_shots.Team == test.loc[test.Game_ID == game,'Home Team'].values[0]) & (accu_shots.Half == '2nd half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'accu_shots_away1'] = accu_shots.loc[(accu_shots.Game_ID == game)&(accu_shots.Team == test.loc[test.Game_ID == game,'Away Team'].values[0]) & (accu_shots.Half == '1st half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n        try:\n            test.loc[test.Game_ID == game,'accu_shots_away2'] = accu_shots.loc[(accu_shots.Game_ID == game)&(accu_shots.Team == test.loc[test.Game_ID == game,'Away Team'].values[0]) & (accu_shots.Half == '2nd half' ),0].values[0]\n        except:\n            exep.append(game)\n            continue\n    # train\n# train[train.Game_ID == 'ID_00EFNL7L']\n# train\n#     th= 2\n    test_stats = test_stats[test_stats.X<300]\n    train_stats['dist_cent'] = np.sqrt((train_stats.X - 52.5)**2 + (train_stats.Y - 34)**2) \n    a = train_stats[train_stats['Accurate passes']==1].groupby(['Game_ID','Team']).apply(lambda x : (x['dist_cent']<th).sum())\n    b = a.reset_index().copy()\n    ch = train_stats.groupby(['Game_ID','Team']).apply(lambda x: x.Player_ID.unique().shape[0]%11)\n    ch = ch.reset_index()\n    change_mean_X = mean_X_change(train_stats)\n    change_mean_min = mean_min_change(train_stats)\n    c =train_stats.groupby(['Game_ID','Team','End_minutes']).apply(lambda x: x['Start_minutes'].min()).reset_index()\n    c =c.groupby(['Game_ID','Team']).apply(lambda x: (x['End_minutes']-x[0]).mean()).reset_index()\n    train['n_changes_home'] = 0\n    train['n_changes_away'] = 0\n    train['mean_X_home'] = 0\n    train['mean_X_away'] = 0\n    train['change_mean_X_home'] = 0\n    train['change_mean_X_away'] = 0\n    train['change_mean_min_home'] = 0\n    train['change_mean_min_away'] = 0\n    train['sum_min_home'] = 0\n    train['sum_min_away'] = 0\n    mean_X = train_stats.groupby(['Game_ID','Team']).apply(lambda x : x['X'].mean()).reset_index()\n    train['h_cent'] = 0\n    train['a_cent'] = 0\n    for g in tqdm(train.Game_ID):\n        home = train.loc[train.Game_ID == g ,'Home Team'].values[0]\n        away = train.loc[train.Game_ID == g ,'Away Team'].values[0]\n        train.loc[train.Game_ID == g,'h_cent'] = b.loc[(b.Game_ID == g)&(b.Team == home),0].values[0]\n        train.loc[train.Game_ID == g,'a_cent'] = b.loc[(b.Game_ID == g)&(b.Team == away),0].values[0]\n        train.loc[train.Game_ID == g,'mean_X_home'] = mean_X.loc[(mean_X.Game_ID == g)&(mean_X.Team == home),0].values[0]\n        train.loc[train.Game_ID == g,'mean_X_away'] = mean_X.loc[(mean_X.Game_ID == g)&(mean_X.Team == away),0].values[0]\n        train.loc[train.Game_ID == g,'n_changes_home'] = ch.loc[(ch.Game_ID == g)&(ch.Team == home),0].values[0]\n        train.loc[train.Game_ID == g,'n_changes_away'] = ch.loc[(ch.Game_ID == g)&(ch.Team == away),0].values[0]\n        train.loc[train.Game_ID == g,'change_mean_X_home'] = change_mean_X.loc[(change_mean_X.Game_ID == g)&(change_mean_X.Team == home),'mean_change_X'].values[0]\n        train.loc[train.Game_ID == g,'change_mean_X_away'] = change_mean_X.loc[(change_mean_X.Game_ID == g)&(change_mean_X.Team == away),'mean_change_X'].values[0]\n        train.loc[train.Game_ID == g,'change_mean_min_home'] = change_mean_min.loc[(change_mean_min.Game_ID == g)&(change_mean_min.Team == home),'mean_change_min'].values[0]\n        train.loc[train.Game_ID == g,'change_mean_min_away'] = change_mean_min.loc[(change_mean_min.Game_ID == g)&(change_mean_min.Team == away),'mean_change_min'].values[0]\n        train.loc[train.Game_ID == g,'sum_min_home'] = c.loc[(c.Game_ID == g)&(c.Team == home),0].values[0]\n        train.loc[train.Game_ID == g,'sum_min_away'] = c.loc[(c.Game_ID == g)&(c.Team == away),0].values[0]\n    test_stats['dist_cent'] = np.sqrt((test_stats.X - 52.5)**2 + (test_stats.Y - 34)**2) \n    a = test_stats[test_stats['Accurate passes']==1].groupby(['Game_ID','Team']).apply(lambda x : (x['dist_cent']<th).sum())\n    b = a.reset_index().copy()\n    mean_X = test_stats.groupby(['Game_ID','Team']).apply(lambda x : x['X'].mean()).reset_index()\n    ch = test_stats.groupby(['Game_ID','Team']).apply(lambda x: x.Player_ID.unique().shape[0]%11)\n    ch = ch.reset_index()\n    change_mean_X = mean_X_change(test_stats)\n    c =test_stats.groupby(['Game_ID','Team','End_minutes']).apply(lambda x: x['Start_minutes'].min()).reset_index()\n    c =c.groupby(['Game_ID','Team']).apply(lambda x: (x['End_minutes']-x[0]).mean()).reset_index()\n    change_mean_min = mean_min_change(test_stats)\n\n    test['change_mean_X_home'] = 0\n    test['change_mean_X_away'] = 0\n    test['h_cent'] = 0\n    test['a_cent'] = 0\n    test['n_changes_home'] = 0\n    test['n_changes_away'] = 0\n    test['mean_X_home'] = 0\n    test['mean_X_away'] = 0\n    test['change_mean_min_home'] = 0\n    test['change_mean_min_away'] = 0\n    test['sum_min_home'] = 0\n    test['sum_min_away'] = 0\n    for g in tqdm(test.Game_ID):\n        home = test.loc[test.Game_ID == g ,'Home Team'].values[0]\n        away = test.loc[test.Game_ID == g ,'Away Team'].values[0]\n        try:\n            test.loc[test.Game_ID == g,'mean_X_home'] = mean_X.loc[(mean_X.Game_ID == g)&(mean_X.Team == home),0].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'mean_X_away'] = mean_X.loc[(mean_X.Game_ID == g)&(mean_X.Team == away),0].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'n_changes_home'] = ch.loc[(ch.Game_ID == g)&(ch.Team == home),0].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'n_changes_away'] = ch.loc[(ch.Game_ID == g)&(ch.Team == away),0].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'change_mean_X_home'] = change_mean_X.loc[(change_mean_X.Game_ID == g)&(change_mean_X.Team == home),'mean_change_X'].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'change_mean_X_away'] = change_mean_X.loc[(change_mean_X.Game_ID == g)&(change_mean_X.Team == away),'mean_change_X'].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'sum_min_home'] = c.loc[(c.Game_ID == g)&(c.Team == home),0].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'sum_min_away'] = c.loc[(c.Game_ID == g)&(c.Team == away),0].values[0]\n        except:\n            continue\n\n        try:\n            test.loc[test.Game_ID == g,'h_cent'] = b.loc[(b.Game_ID == g)&(b.Team == home),0].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'a_cent'] = b.loc[(b.Game_ID == g)&(b.Team == away),0].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'change_mean_min_home'] = change_mean_min.loc[(change_mean_min.Game_ID == g)&(change_mean_min.Team == home),'mean_change_min'].values[0]\n        except:\n            continue\n        try:\n            test.loc[test.Game_ID == g,'change_mean_min_away'] = change_mean_min.loc[(change_mean_min.Game_ID == g)&(change_mean_min.Team == away),'mean_change_min'].values[0]\n        except:\n            continue\n    st = get_stats(train,train_stats)\n    train['diff_score'] = train['Home Team'].map(st['diff_score'])\n    train['diff_score_h'] = train['Home Team'].map(st['diff_score_h'])\n    train['diff_score_h'] = train['Home Team'].map(st['diff_score_h'])\n    train['diff_score1'] = train['Away Team'].map(st['diff_score'])\n    train['diff_score_h1'] = train['Away Team'].map(st['diff_score_h'])\n    train['diff_score_h1'] = train['Away Team'].map(st['diff_score_h'])\n    test['diff_score'] = test['Home Team'].map(st['diff_score'])\n    test['diff_score_h'] = test['Home Team'].map(st['diff_score_h'])\n    test['diff_score_h'] = test['Home Team'].map(st['diff_score_h'])\n    test['diff_score1'] = test['Away Team'].map(st['diff_score'])\n    test['diff_score_h1'] = test['Away Team'].map(st['diff_score_h'])\n    test['diff_score_h1'] = test['Away Team'].map(st['diff_score_h'])\n    \n    train.fillna(0,inplace = True)# grouped.loc[(grouped.Game_ID == game)]\n    test.fillna(0,inplace = True)\n    train_cols = train.columns.difference(['Date', 'Season','Match_ID', 'Game_ID','Score','Train','Home Team','Away Team'])\n    if scale:\n        from sklearn.preprocessing import MinMaxScaler\n        sc = MinMaxScaler()\n        scal = ['n_passes_away1',\n        'n_passes_away2',       \n        'n_passes_home1',        \n        'n_passes_home2',        \n        'n_shots_away1',\n        'n_shots_away2',\n        'n_shots_home1',\n        'n_shots_home2']\n        for s in scal:\n            sc = MinMaxScaler()\n            train[s] = sc.fit_transform(train[s].values.reshape(-1, 1))\n            test[s] = sc.transform(test[s].values.reshape(-1, 1))\n    if encode:\n        return train[train_cols],test[train_cols],train['Score'],test['Score'],lb\n    else:\n        return train[train_cols],test[train_cols],train['Score'],test['Score']\n#     return train , test\n        # test.loc[test.Game_ID =='ID_00EFNL7L']\n            # train.loc[train.Game_ID =='ID_00EFNL7L']\n\ndef _get_X_Y_DF_from_CV(train_X, train_Y, train_index, validation_index):\n        X_train, X_validation = (\n            train_X.iloc[train_index],\n            train_X.iloc[validation_index],\n        )\n        y_train, y_validation = (\n            train_Y.iloc[train_index],\n            train_Y.iloc[validation_index],\n        )\n        return X_train, X_validation, y_train, y_validation\ndef scale_fea(X, test_data):\n    scale = ['change_mean_X_home', 'change_mean_min_away', 'change_mean_min_home',\n           'mean_X_away', 'mean_X_home',\n             'n_passes_away1', 'n_passes_away2', 'n_passes_home1',\n           'n_passes_home2', 'n_shots_away1', 'n_shots_away2',\n           'n_shots_home1', 'n_shots_home2']\n    # X[scale]\n    sc = MinMaxScaler()\n    X_scaled = X.copy()\n    test_scaled = test_data.copy()\n    X_scaled[scale] = sc.fit_transform(X[scale])\n    test_scaled[scale] = sc.transform(test_data[scale])\n    return X_scaled,test_scaled\ndef train_lgb(X,y,test_data,params,seed_lgb,shuffle_lgb):\n    features_importance= pd.DataFrame({'Feature':[], 'Importance':[]})\n    models =[]\n    train_X = X.copy()\n    train_Y = y.copy()\n    test_X = test_data.copy()\n    print(f\"Shape of train_X : {train_X.shape}, test_X: {test_X.shape}, train_Y: {train_Y.shape}\")\n\n    predictors = list(train_X.columns)\n    # print(f\"List of features to be used {list(predictors)}\")\n\n    # Selecting n_splits to be 3, since class 42 has \n    # just 3 instances\n    kf = KFold(random_state=seed_lgb,n_splits=K_FOLDS, shuffle=shuffle_lgb)\n    y_oof_lgb = np.zeros(shape=(len(train_X), NUM_CLASSES))\n    y_predicted_lgb = np.zeros(shape=(len(test_X), NUM_CLASSES))\n    cv_scores = []\n    fold = 0\n    n_folds = kf.get_n_splits()\n    for train_index, validation_index in kf.split(X=train_X, y=train_Y):\n        fold += 1\n        print(f\"fold {fold} of {n_folds}\")\n\n        X_train, X_validation, y_train, y_validation = _get_X_Y_DF_from_CV(\n            train_X, train_Y, train_index, validation_index\n        )\n\n        lgb_train = lgb.Dataset(X_train, y_train)\n        lgb_eval = lgb.Dataset(X_validation, y_validation, reference=lgb_train)\n\n        model = lgb.train(\n            lgb_params,\n            lgb_train,\n            valid_sets=[lgb_train, lgb_eval],\n            verbose_eval=100,\n            early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n            num_boost_round=N_ESTIMATORS,\n            feature_name=predictors,\n            categorical_feature=\"auto\",\n        )\n        del lgb_train, lgb_eval, train_index, X_train, y_train\n        gc.collect()\n\n        y_oof_lgb[validation_index] = model.predict(\n            X_validation, num_iteration=model.best_iteration\n        )\n\n        y_predicted_lgb += model.predict(\n            test_data.values, num_iteration=model.best_iteration\n        )\n        fold_importance_df= pd.DataFrame({'Feature':[], 'Importance':[]})\n        fold_importance_df['Feature']= predictors\n        fold_importance_df['Importance']= model.feature_importance()\n        fold_importance_df[\"fold\"] = fold + 1\n        features_importance = pd.concat([features_importance, fold_importance_df], axis=0)\n        models.append(model)\n\n        best_iteration = model.best_iteration\n        print(f\"Best number of iterations for fold {fold} is: {best_iteration}\")\n\n        cv_oof_score = metrics.log_loss(y_validation, y_oof_lgb[validation_index])\n        cv_scores.append(cv_oof_score)\n        print(f\"CV OOF Score for fold {fold} is {cv_oof_score}\")\n\n        del validation_index, X_validation, y_validation\n        gc.collect()\n\n    y_predicted_lgb /= n_folds\n    oof_score = round(metrics.log_loss(train_Y, y_oof_lgb), 5)\n    avg_cv_scores = round(sum(cv_scores) / len(cv_scores), 5)\n    std_cv_scores = round(np.array(cv_scores).std(), 5)\n    return y_predicted_lgb,models,y_oof_lgb,oof_score,features_importance\ndef train_catbo(train_X, train_Y,test_X,params,seed_cat,shuffle_cat):\n# model.fit(train_pool,plot=True,eval_set=test_pool)\n    kf = KFold(random_state=seed_cat,n_splits=K_FOLDS, shuffle=shuffle_cat)\n    y_oof = np.zeros(shape=(len(train_X), NUM_CLASSES))\n    y_predicted = np.zeros(shape=(len(test_X), NUM_CLASSES))\n    cv_scores = []\n    models = []\n    fold = 0\n    n_folds = kf.get_n_splits()\n    for train_index, validation_index in kf.split(X=train_X, y=train_Y):\n        fold += 1\n        print(f\"fold {fold} of {n_folds}\")\n\n        X_train, X_validation, y_train, y_validation = _get_X_Y_DF_from_CV(\n            train_X, train_Y, train_index, validation_index\n        )\n\n        train_pool = Pool(data=X_train, label=y_train)\n        eval_pool = Pool(data=X_validation, label=y_validation.values) \n        model = CatBoostClassifier(**params)\n        model.fit(train_pool,plot=True,eval_set=eval_pool)\n        del train_index, X_train, y_train\n        gc.collect()\n        models.append(model)\n        y_oof[validation_index] = model.predict_proba(\n            X_validation )\n\n        y_predicted += model.predict_proba(\n            test_X.values\n        )\n\n    #     best_iteration = model.best_iteration\n    #     print(f\"Best number of iterations for fold {fold} is: {best_iteration}\")\n\n        cv_oof_score = metrics.log_loss(y_validation, y_oof[validation_index])\n        cv_scores.append(cv_oof_score)\n        print(f\"CV OOF Score for fold {fold} is {cv_oof_score}\")\n\n        del validation_index, X_validation, y_validation\n        gc.collect()\n\n    y_predicted /= n_folds\n    oof_score = round(metrics.log_loss(train_Y, y_oof), 5)\n    avg_cv_scores = round(sum(cv_scores) / len(cv_scores), 5)\n    std_cv_scores = round(np.array(cv_scores).std(), 5)\n    return y_predicted,models,y_oof,oof_score\ndef train_xgb(X,y,test_data,params,num_iter=1500,es = 100,ve = 100,seed_xgb=42,shuffle_xgb=True):\n    features = X.columns\n    X = X.values\n    # y = train['target'].values\n    y_oof = np.zeros(shape=(len(X), NUM_CLASSES))\n    y_predicted = np.zeros(shape=(len(test_data), NUM_CLASSES))\n    cv_scores = []\n    models = []\n    kf = KFold(random_state=seed_xgb,n_splits=K_FOLDS, shuffle=shuffle_xgb)\n\n    for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n        print(' xgb kfold: {}  of  {} : '.format(i+1, K_FOLDS ))\n        X_train, X_valid = X[train_index], X[test_index]\n        y_train, y_valid = y[train_index], y[test_index]\n        d_train = xgb.DMatrix(X_train, y_train) \n        d_valid = xgb.DMatrix(X_valid, y_valid) \n        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n        xgb_model = xgb.train(params, d_train, num_iter, watchlist,\n                              early_stopping_rounds=es, \n                            verbose_eval=ve)\n        models.append(xgb_model)\n        y_oof[test_index] = xgb_model.predict(xgb.DMatrix(X_valid), \n                            ntree_limit=xgb_model.best_ntree_limit)\n        y_predicted += xgb_model.predict(xgb.DMatrix(test_data[features].values), \n                            ntree_limit=xgb_model.best_ntree_limit) \n        \n        cv_oof_score = metrics.log_loss(y_valid, y_oof[test_index])\n        cv_scores.append(cv_oof_score)\n        print(f\"CV OOF Score for fold {i+1} is {cv_oof_score}\")\n\n#         del validation_index, X_validation, y_validation\n#         gc.collect()\n\n    y_predicted /= K_FOLDS\n    oof_score = round(metrics.log_loss(y, y_oof), 5)\n    avg_cv_scores = round(sum(cv_scores) / len(cv_scores), 5)\n    std_cv_scores = round(np.array(cv_scores).std(), 5)\n    return y_predicted,models,y_oof,oof_score \ndef train_keras(X,train,test_data):\n    train ['Original_score'] = le.inverse_transform(train.Score)\n#     scaler = MinMaxScaler(feature_range=(0, 1))\n#     X_scaled = scaler.fit_transform(X)\n#     X_scaled = pd.DataFrame(X_scaled)\n    Y = pd.get_dummies(train['Original_score'])\n    X_scaled = X.values\n    Y = Y.values\n    inp = len(X.columns)\n    y_oof = np.zeros(shape=(len(X), NUM_CLASSES))\n    y_predicted = np.zeros(shape=(len(test_data), NUM_CLASSES))\n    cv_scores = []\n    models = []\n    kf = KFold(random_state=SEED,n_splits=K_FOLDS, shuffle=True)\n    for i, (train_index, test_index) in enumerate(kf.split(X_scaled, Y)):\n        print(' keras kfold: {}  of  {} : '.format(i+1, K_FOLDS ))\n        X_train, X_valid = X_scaled[train_index], X_scaled[test_index]\n        y_train, y_valid = Y[train_index], Y[test_index]\n#         np.random.seed(SEED)\n        my_model = baseline_model(inp)\n        my_model.fit(X_train, y_train,\n                     validation_data=(X_valid, y_valid),\n                     epochs=1000,\n                     callbacks=[EarlyStopping(patience=20)],\n                     verbose=0)\n        \n        models.append(my_model)\n        y_oof[test_index] = my_model.predict(X_valid)\n        y_predicted += my_model.predict(test_data.values) \n        del my_model\n        gc.collect()\n        cv_oof_score = metrics.log_loss(y_valid, y_oof[test_index])\n        cv_scores.append(cv_oof_score)\n        print(f\"CV OOF Score for fold {i+1} is {cv_oof_score}\")\n\n#         del validation_index, X_validation, y_validation\n#         gc.collect()\n\n    y_predicted /= K_FOLDS\n    oof_score = round(metrics.log_loss(y, y_oof), 5)\n    avg_cv_scores = round(sum(cv_scores) / len(cv_scores), 5)\n    std_cv_scores = round(np.array(cv_scores).std(), 5)\n    return y_predicted,models,y_oof,oof_score \ndef preds_to_sub(test,le,y_predicted,save = False):\n    Test = test.copy()\n    cols=le.inverse_transform([*range(3)])\n    Test[cols]= y_predicted\n    submit = Test[[\"Game_ID\",'Away win', 'Draw', 'Home Win']]\n    submit.drop_duplicates(subset = [\"Game_ID\"], inplace=True)\n    submit = submit.reset_index(drop=True)\n    if save:\n        submit.to_csv(\"submission_gbm15.csv\", index=False)\n    return submit   ","metadata":{"id":"S-rERS-VKgWg","execution":{"iopub.status.busy":"2022-09-04T16:21:14.460899Z","iopub.execute_input":"2022-09-04T16:21:14.461230Z","iopub.status.idle":"2022-09-04T16:21:14.803003Z","shell.execute_reply.started":"2022-09-04T16:21:14.461201Z","shell.execute_reply":"2022-09-04T16:21:14.801637Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n# Keras imports\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.callbacks import EarlyStopping\nimport os \nimport random\nimport numpy as np \n\nDEFAULT_RANDOM_SEED = 2021\n\ndef seedBasic(seed=DEFAULT_RANDOM_SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \n# tensorflow random seed \nimport tensorflow as tf \ndef seedTF(seed=DEFAULT_RANDOM_SEED):\n    tf.random.set_seed(seed)\n    \n# torch random seed\nimport torch\ndef seedTorch(seed=DEFAULT_RANDOM_SEED):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n      \n# basic + tensorflow + torch \ndef seedEverything(seed=DEFAULT_RANDOM_SEED):\n    seedBasic(seed)\n    seedTF(seed)\n    seedTorch(seed)\nseedEverything(42)\nseed = 42\n\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:10].index\n    best_features = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:50]\n    best_features.reset_index(inplace=True)\n    print(best_features.dtypes)\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"Importance\", y=\"Feature\", data=best_features)\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2022-09-04T16:21:14.804129Z","iopub.execute_input":"2022-09-04T16:21:14.804461Z","iopub.status.idle":"2022-09-04T16:21:22.665893Z","shell.execute_reply.started":"2022-09-04T16:21:14.804439Z","shell.execute_reply":"2022-09-04T16:21:22.664782Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"le=LabelEncoder()\ntrain[\"Score\"] = le.fit_transform(train[\"Score\"])\nscore_mapping = dict(zip(le.classes_, range(len(le.classes_))))","metadata":{"id":"892c51d1","execution":{"iopub.status.busy":"2022-09-04T16:21:22.668240Z","iopub.execute_input":"2022-09-04T16:21:22.669554Z","iopub.status.idle":"2022-09-04T16:21:22.685362Z","shell.execute_reply.started":"2022-09-04T16:21:22.669515Z","shell.execute_reply":"2022-09-04T16:21:22.684287Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train.sort_values(by=['Date'],inplace=True)","metadata":{"id":"0r8vE04OO2Q0","execution":{"iopub.status.busy":"2022-09-04T16:21:22.687348Z","iopub.execute_input":"2022-09-04T16:21:22.687719Z","iopub.status.idle":"2022-09-04T16:21:22.706331Z","shell.execute_reply.started":"2022-09-04T16:21:22.687686Z","shell.execute_reply":"2022-09-04T16:21:22.705463Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train.reset_index(drop = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T16:21:24.179438Z","iopub.execute_input":"2022-09-04T16:21:24.180086Z","iopub.status.idle":"2022-09-04T16:21:24.185029Z","shell.execute_reply.started":"2022-09-04T16:21:24.180040Z","shell.execute_reply":"2022-09-04T16:21:24.184145Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# X,test_data,y,_=preprocess(train,test,train_stats,test_stats,encode = False)\nX,test_data,y,_,lb=preprocess(train,test,train_stats,test_stats,encode = True)\n","metadata":{"id":"iS9dvToXJh9T","execution":{"iopub.status.busy":"2022-09-04T16:21:48.414220Z","iopub.execute_input":"2022-09-04T16:21:48.414569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X.diff_score_a\ndrop_fea = ['diff_score','diff_score_h','diff_score_h',\n            'diff_score1','diff_score_h1','diff_score_h1']","metadata":{"execution":{"iopub.status.busy":"2022-09-04T13:00:16.434573Z","iopub.execute_input":"2022-09-04T13:00:16.435006Z","iopub.status.idle":"2022-09-04T13:00:16.442462Z","shell.execute_reply.started":"2022-09-04T13:00:16.434968Z","shell.execute_reply":"2022-09-04T13:00:16.441116Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# X.select_dtypes(exclude='uint8')[X.select_dtypes(exclude='uint8').columns[[c for c in range(len(X.select_dtypes(exclude='uint8').columns)) if c not in [[list(range(9,28))]+[list(range(39,58))]] ]]]\ncols = X.select_dtypes(exclude='uint8').drop(['away_Andromeda',\n       'away_Antennae', 'away_Backward', 'away_Butterfly', 'away_Cartwheel',\n       'away_Cigar', 'away_Circinus', 'away_Coma Pinwheel', 'away_Comet',\n       'away_Cosmos Redshift 7', 'away_Eye of Sauron', 'away_Fireworks',\n       'away_Medusa Merger', 'away_Milky Way', 'away_Sculptor',\n       'away_Sombrero', 'away_Sunflower', 'away_Tadpole', 'away_Triangulum','home_Andromeda',\n       'home_Antennae', 'home_Backward', 'home_Butterfly', 'home_Cartwheel',\n       'home_Cigar', 'home_Circinus', 'home_Coma Pinwheel', 'home_Comet',\n       'home_Cosmos Redshift 7', 'home_Eye of Sauron', 'home_Fireworks',\n       'home_Medusa Merger', 'home_Milky Way', 'home_Sculptor',\n       'home_Sombrero', 'home_Sunflower', 'home_Tadpole', 'home_Triangulum'],axis = 1).columns\n","metadata":{"execution":{"iopub.status.busy":"2022-09-04T13:50:12.857749Z","iopub.execute_input":"2022-09-04T13:50:12.858187Z","iopub.status.idle":"2022-09-04T13:50:12.867862Z","shell.execute_reply.started":"2022-09-04T13:50:12.858152Z","shell.execute_reply":"2022-09-04T13:50:12.866999Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"# X.select_dtypes(include = 'float').describe()\nscale = ['mean_X_away','mean_X_home','change_mean_min_home','change_mean_min_away','change_mean_X_away','change_mean_X_home']","metadata":{"execution":{"iopub.status.busy":"2022-09-04T13:05:26.011998Z","iopub.execute_input":"2022-09-04T13:05:26.012467Z","iopub.status.idle":"2022-09-04T13:05:26.018918Z","shell.execute_reply.started":"2022-09-04T13:05:26.012429Z","shell.execute_reply":"2022-09-04T13:05:26.017556Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# sns.distplot(X[scale[3]])\nsca = StandardScaler()\nX_scaled = X.copy()\ntest_data_scaled = test_data.copy()\nX_scaled[scale] = sca.fit_transform(X_scaled[scale])\ntest_data_scaled[scale] = sca.transform(test_data_scaled[scale])","metadata":{"execution":{"iopub.status.busy":"2022-09-04T13:09:13.545189Z","iopub.execute_input":"2022-09-04T13:09:13.545875Z","iopub.status.idle":"2022-09-04T13:09:13.566393Z","shell.execute_reply.started":"2022-09-04T13:09:13.545828Z","shell.execute_reply":"2022-09-04T13:09:13.564715Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"\nSEED = 42\nNUM_CLASSES = 3\nEARLY_STOPPING_ROUNDS = 200\nN_ESTIMATORS = 10000\nK_FOLDS = 4\n# Define Parameters for LGBM\nlgb_params = {\n    \"objective\": \"multiclass\",\n    \"boosting_type\": \"gbdt\",\n    \"learning_rate\": 0.01,\n    \"num_class\": NUM_CLASSES,\n    \"num_leaves\": 42,\n    \"tree_learner\": \"feature\",\n    \"n_jobs\": 4,\n    \"seed\": SEED,\n    \"max_depth\": -1,\n#     \"max_bin\": 255,\n#     'reg_lambda': 0.1,  # L1 regularization term on weights\n#     'reg_lambda': 1,\n    \"metric\": \"multi_logloss\",\n    \"verbose\": -1,\n}\ny_predicted_lgb,models_lgb,y_oof_lgb,oof_score_lgb,features_importance_lgb = train_lgb(X_scaled[cols],\n                                                                                       y,test_data_scaled[cols],\n                                                                                       lgb_params,42,True)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T13:50:36.145421Z","iopub.execute_input":"2022-09-04T13:50:36.146089Z","iopub.status.idle":"2022-09-04T13:52:29.013337Z","shell.execute_reply.started":"2022-09-04T13:50:36.146050Z","shell.execute_reply":"2022-09-04T13:52:29.011752Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RepeatedKFold\nimport optuna.integration.lightgbm as lgb\nimport optuna\n\nrkf = RepeatedKFold(n_splits=4, n_repeats=10, random_state=42)\n\nparams = {\n        \"objective\": \"multiclass\",\n        \"metric\": \"multi_logloss\",\n        \"num_class\": NUM_CLASSES,\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",                \n        \"seed\": 42\n    }\n\n# X = np.array( train[discrete_features + continuous_features] )    \n# y = np.array( train['Survived'] ).flatten()\n\nstudy_tuner = optuna.create_study(direction='minimize')\ndtrain = lgb.Dataset(X_scaled, label=y)\n\n# Suppress information only outputs - otherwise optuna is \n# quite verbose, which can be nice, but takes up a lot of space\noptuna.logging.set_verbosity(optuna.logging.WARNING) \n\n# Run optuna LightGBMTunerCV tuning of LightGBM with cross-validation\ntuner = lgb.LightGBMTunerCV(params, \n                            dtrain, \n#                             categorical_feature=ids_of_categorical,\n                            study=study_tuner,\n                            verbose_eval=500,                            \n                            early_stopping_rounds=250,\n                            time_budget=300, # Time budget of 5 hours, we will not really need it\n                            seed = 42,\n                            folds=rkf,\n                            num_boost_round=10000,\n                            callbacks=[lgb.reset_parameter(learning_rate = [0.005]*200 + [0.001]*9800) ] #[0.1]*5 + [0.05]*15 + [0.01]*45 + \n                           )\n\ntuner.run()","metadata":{"execution":{"iopub.status.busy":"2022-09-04T14:12:28.877199Z","iopub.execute_input":"2022-09-04T14:12:28.877749Z","iopub.status.idle":"2022-09-04T14:22:13.650225Z","shell.execute_reply.started":"2022-09-04T14:12:28.877701Z","shell.execute_reply":"2022-09-04T14:22:13.648870Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"tuner.best_params","metadata":{"execution":{"iopub.status.busy":"2022-09-04T14:04:18.735434Z","iopub.execute_input":"2022-09-04T14:04:18.736188Z","iopub.status.idle":"2022-09-04T14:04:18.744847Z","shell.execute_reply.started":"2022-09-04T14:04:18.736131Z","shell.execute_reply":"2022-09-04T14:04:18.743867Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"# y_predicted_lgb\ndisplay_importances(features_importance_lgb)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T13:27:12.491267Z","iopub.execute_input":"2022-09-04T13:27:12.491721Z","iopub.status.idle":"2022-09-04T13:27:13.873897Z","shell.execute_reply.started":"2022-09-04T13:27:12.491681Z","shell.execute_reply":"2022-09-04T13:27:13.872630Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"from catboost import Pool, CatBoostClassifier\nparams_cat = {'iterations':5000,\n        'learning_rate':0.01,\n        'random_strength':0.1,\n        'depth':8,\n        'loss_function':'MultiClass',\n        'eval_metric':'MultiClass',\n        'verbose' : 100,\n        'leaf_estimation_method':'Newton'}\ny_predicted_cat,models_cat,y_oof_cat,oof_score_cat =train_catbo(X.drop(drop_fea,axis = 1),\n                                                                y,test_data.drop(drop_fea,axis = 1),\n                                                                params_cat)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:39:05.203837Z","iopub.execute_input":"2022-09-04T11:39:05.205083Z","iopub.status.idle":"2022-09-04T11:39:27.827130Z","shell.execute_reply.started":"2022-09-04T11:39:05.205029Z","shell.execute_reply":"2022-09-04T11:39:27.825278Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"params_xgb = {\"objective\":\"multi:softprob\",'learning_rate': 0.01,\n          'num_class' :3, 'max_depth': 16}#, 'subsample': 0.9,\n#           'colsample_bytree': 0.9}\n\ny_predicted_xgb,models_xgb,y_oof_xgb,oof_score_xgb=train_xgb(X,\n                                                             y.values,test_data,\n                                                             params_xgb,num_iter=1500,es = 100,ve = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def baseline_model(inp):\n    # Create model here\n    model = Sequential()\n    model.add(Dense(100, input_dim = inp, activation = 'relu')) # Rectified Linear Unit Activation Function\n    model.add(Dense(32, activation = 'relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(20, activation = 'relu'))\n    \n    model.add(Dense(3, activation = 'softmax')) # Softmax for multi-class classification\n    # Compile model here\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',\n                  metrics = ['accuracy'])\n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted_keras,models_keras,y_oof_keras,oof_score_keras = train_keras(X,\n                                                                         train,test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Y.sum(axis = 0)\n# y_predicted_keras\n# train\nlr = LogisticRegression()\nlr.fit(np.hstack([y_oof_keras,y_oof_xgb,y_oof_cat,y_oof_lgb]),y)\n# X\npreds = lr.predict_proba(np.hstack([y_predicted_keras,y_predicted_xgb,y_predicted_cat,y_predicted_lgb]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds\n# y_predicted_lgb","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:39:50.277998Z","iopub.execute_input":"2022-09-04T11:39:50.278410Z","iopub.status.idle":"2022-09-04T11:39:50.283115Z","shell.execute_reply.started":"2022-09-04T11:39:50.278376Z","shell.execute_reply":"2022-09-04T11:39:50.281890Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# y_oof_xgb\n\nsub = preds_to_sub(test,le,y_predicted_lgb,save = False)\n# y_predicted_lgb\n# (y_predicted_xgb + y_predicted_cat + y_predicted_lgb)/3","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:43:48.143114Z","iopub.execute_input":"2022-09-04T11:43:48.143537Z","iopub.status.idle":"2022-09-04T11:43:48.154843Z","shell.execute_reply.started":"2022-09-04T11:43:48.143500Z","shell.execute_reply":"2022-09-04T11:43:48.153709Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:43:49.669281Z","iopub.execute_input":"2022-09-04T11:43:49.670237Z","iopub.status.idle":"2022-09-04T11:43:49.687269Z","shell.execute_reply.started":"2022-09-04T11:43:49.670179Z","shell.execute_reply":"2022-09-04T11:43:49.685872Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('blend_uniqueid2.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:44:00.328761Z","iopub.execute_input":"2022-09-04T11:44:00.329236Z","iopub.status.idle":"2022-09-04T11:44:00.337530Z","shell.execute_reply.started":"2022-09-04T11:44:00.329199Z","shell.execute_reply":"2022-09-04T11:44:00.336305Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"sub.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub\n# sub.drop('Game_ID',axis = 1).round() +\n# sub.groupby('Game_ID').apply(lambda x : np.where(x[['Away win', 'Draw', 'Home Win']].max()>=0.5,x[['Away win', 'Draw', 'Home Win']].round()))\nsub[sub.max(axis = 1)>0.5] = sub[sub.max(axis = 1)>0.5].round()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('blend_fi_clipped.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = train_stats.corr()['Goals_scored']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a.sort_values(ascending = False,key = abs)\nX['Score'] = train['Score'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub.to_csv('lgb.csv',index = False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (test_X ==test_data).all()[((test_X ==test_data).all() == False)]\n# test_X['change_mean_X_home']\ntest_data['change_mean_X_home']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# X_train\n# model.feature_importance()\n# train_stats.groupby(['Game_ID','Team','Player_ID'])[['X','Y','Start_minutes','End_minutes']].shift(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n\n\n# define data_dmatrix\ndata_dmatrix = xgb.DMatrix(data=X,label=y)\nfrom xgboost import cv\n\n\n\nxgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=5,\n                num_boost_round=1500, early_stopping_rounds=30, metrics=\"mlogloss\", as_pandas=True, seed=123)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb_cv\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\n    #     best_iteration = model.best_iteration\n    #     print(f\"Best number of iterations for fold {fold} is: {best_iteration}\")\n\n ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_predictions\n# X['target'] = y\n# test_data\n# y_predicted\n# X['h_cent']\n# X['score'] = y\n# train_all = X.copy()\n# train_all['score'] = y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ((train_all.loc[train_all.score ==2,'h_cent'] - train_all.loc[train_all.score ==2,'a_cent'])<0).sum()# .apply(lambda x: x.a_cent - x.h_cent)\n# sns.distplot(train_all.loc[train_all.score ==2,'mean_X_home'])\n# sns.distplot(train_all.loc[train_all.score ==2,'mean_X_away'])\n\n# train_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X.corr()['target'].sort_values(ascending = False,key = abs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test = test.copy()\ncols=le.inverse_transform([*range(3)])\nTest[cols]= y_predicted\n","metadata":{"id":"7a035863","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = Test[[\"Game_ID\",'Away win', 'Draw', 'Home Win']]\nsubmit.drop_duplicates(subset = [\"Game_ID\"], inplace=True)\nsubmit = submit.reset_index(drop=True)\nsubmit.to_csv(\"submission_gbm13.csv\", index=False)","metadata":{"id":"225ef7d5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test\n# submit\n# ids = ['ID_QKQ00O16',\n# 'ID_172V2IXW',\n# 'ID_2ZK5TE39',\n# 'ID_IS54QGW9',\n# 'ID_YG9IONLS']\n# X.Train\n# ids\n# test_stats[test_stats.Game_ID == ids[4]]\n# X.shape\nX.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.iloc[0][['Away win', 'Draw', 'Home Win']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit2 = submit.copy()\nsubmit2[['Away win', 'Draw', 'Home Win']] = submit2[['Away win', 'Draw', 'Home Win']].round()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = submit2[['Away win', 'Draw', 'Home Win']].sum(axis = 1) == 0\nsubmit2.loc[a,['Away win', 'Draw', 'Home Win']] = submit.loc[a,['Away win', 'Draw', 'Home Win']] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submit2.max(axis = 1).idxmin()\nsubmit2.to_csv(\"submission_lr5.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.max(axis =1).max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}