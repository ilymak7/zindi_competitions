{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d5221cf58859cd6496cf4294414a3bc37d4c95f"
   },
   "source": [
    "In this kernel, I have implemented the encoder part of the transformer architecture as mentioned in the famous paper: Attention is all you need.(https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "Many of other codes are adopted from other kernels. For example, loading the embeddings,  load the training and test data and preprocessing, etc. I really appreciate their contributions.\n",
    "\n",
    "p.s. When I run this locally, I get validation f1-score around 0.688.\n",
    "\n",
    "Happy transforming!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a947373c706a15ed71a686d92703b9677561894"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.layers import BatchNormalization, InputSpec, add\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, activations\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b37e0d09f42f5bc5ad73a366580f6b778c9aad5a"
   },
   "source": [
    "## Some pre-configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "c7498e1cc6e3dd7e7c58f24e10fd5ad1b06b4489"
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 45000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 400 # max number of words in a question to use\n",
    "n_heads = 4 # Number of heads as in Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_uuid": "05385c91a5e5603c346bfe53010aa4cb0f3ddd4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1436, 3)\n",
      "Test shape :  (620, 2)\n"
     ]
    }
   ],
   "source": [
    "# def load_and_prec():\n",
    "train_df = pd.read_csv(\"../Translated/cleaned/train.csv\")\n",
    "test_df = pd.read_csv(\"../Translated/cleaned/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "cols_target = train_df.Label.unique().tolist()\n",
    "\n",
    "## split to train and val\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=0,shuffle = True) # hahaha\n",
    "# train_X, val_X, train_y , val_y = train_test_split(train_df, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])\n",
    "\n",
    "# trn_idx = train_y.index.tolist()\n",
    "# val_idx = val_y.index.tolist()\n",
    "\n",
    "\n",
    "## fill up the missing values\n",
    "# train_X = train_X[\"Text\"].fillna(\"_##_\").values\n",
    "# val_X = val_X[\"Text\"].fillna(\"_##_\").values\n",
    "# test_X = test_df[\"Text\"].fillna(\"_##_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_df.Text)\n",
    "# train_X = tokenizer.texts_to_sequences(train_X)\n",
    "# val_X = tokenizer.texts_to_sequences(val_X)\n",
    "# test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "# ## Pad the sentences \n",
    "# train_X = pad_sequences(train_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "# val_X = pad_sequences(val_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "# test_X = pad_sequences(test_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "\n",
    "# ## Get the target values\n",
    "# train_y = train_y.values\n",
    "# val_y = val_y.values  \n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "#shuffling the data\n",
    "# np.random.seed(2018)\n",
    "# trn_idx = np.random.permutation(len(train_X))\n",
    "# val_idx = np.random.permutation(len(val_X))\n",
    "\n",
    "# train_X = train_X[trn_idx]\n",
    "# val_X = val_X[val_idx]\n",
    "# train_y = train_y[trn_idx]\n",
    "# val_y = val_y[val_idx]    \n",
    "\n",
    "#     return train_X, val_X, test_X, train_y, val_y, tokenizer.word_index,val_idx , trn_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20682431e22eab3cbf634777cb0d2bc2730ab754"
   },
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "cf6dc22b3b2a9f2ec94f70e2aa5dfe36f6f142d3"
   },
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.005838499,0.48782197\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix \n",
    "    \n",
    "def load_fasttext(word_index):    \n",
    "    EMBEDDING_FILE = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "def load_para(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.0053247833,0.49346462\n",
    "    embed_size = all_embs.shape[1]\n",
    "    print(emb_mean,emb_std,\"para\")\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a35ee76c0f926bcdf817fcb91dbd20ee90007f06"
   },
   "source": [
    "## Scaled Dot-product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "92c050cb313508d5c88b288dd1561493bcfacbed"
   },
   "outputs": [],
   "source": [
    "class DotProdSelfAttention(Layer):\n",
    "    \"\"\"The self-attention layer as in 'Attention is all you need'.\n",
    "    paper reference: https://arxiv.org/abs/1706.03762\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, units,\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(DotProdSelfAttention, self).__init__(*kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        input_dim = input_shape[-1]\n",
    "        # We assume the output-dim of Q, K, V are the same\n",
    "        self.kernels = dict.fromkeys(['Q', 'K', 'V'])\n",
    "        for key, _ in self.kernels.items():\n",
    "            self.kernels[key] = self.add_weight(shape=(input_dim, self.units),\n",
    "                                                initializer=self.kernel_initializer,\n",
    "                                                name='kernel_{}'.format(key),\n",
    "                                                regularizer=self.kernel_regularizer,\n",
    "                                                constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            raise NotImplementedError\n",
    "        super(DotProdSelfAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        Q = K.dot(x, self.kernels['Q'])\n",
    "        K_mat = K.dot(x, self.kernels['K'])\n",
    "        V = K.dot(x, self.kernels['V'])\n",
    "        attention = K.batch_dot(Q, K.permute_dimensions(K_mat, [0, 2, 1]))\n",
    "        d_k = K.constant(self.units, dtype=K.floatx())\n",
    "        attention = attention / K.sqrt(d_k)\n",
    "        attention = K.batch_dot(K.softmax(attention, axis=-1), V)\n",
    "        return attention\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) >= 2\n",
    "        assert input_shape[-1]\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d931bd69e53756c2f8aa8cf63d07d4c7eb02a8d9"
   },
   "source": [
    "## The Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "399ddb0b7367ac0f6bd4121396b24ac3a6d1edfe"
   },
   "outputs": [],
   "source": [
    "def encoder(input_tensor):\n",
    "    \"\"\"One encoder as in Attention Is All You Need\n",
    "    \"\"\"\n",
    "    # Sub-layer 1\n",
    "    # Multi-Head Attention\n",
    "    multiheads = []\n",
    "    d_v = embed_size // n_heads\n",
    "    for i in range(n_heads):\n",
    "        multiheads.append(DotProdSelfAttention(d_v)(input_tensor))\n",
    "    multiheads = concatenate(multiheads, axis=-1)\n",
    "    multiheads = Dense(embed_size)(multiheads)\n",
    "    multiheads = Dropout(0.1)(multiheads)\n",
    "    \n",
    "    # Residual Connection\n",
    "    res_con = add([input_tensor, multiheads])\n",
    "    # Didn't use layer normalization, use Batch Normalization instead here\n",
    "    res_con = BatchNormalization(axis=-1)(res_con)\n",
    "    \n",
    "    # Sub-layer 2\n",
    "    # 2 Feed forward layer\n",
    "    ff1 = Dense(64, activation='relu')(res_con)\n",
    "    ff2 = Dense(embed_size)(ff1)\n",
    "    output = add([res_con, ff2])\n",
    "    output = BatchNormalization(axis=-1)(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8740be2622e8195ed3f0c7d9568a06ddb64cd98b"
   },
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "8bd0cd11b96080f965195da697ba34c865f5b7e2"
   },
   "outputs": [],
   "source": [
    "# https://github.com/kpot/keras-transformer/blob/master/keras_transformer/position.py\n",
    "def positional_signal(hidden_size: int, length: int,\n",
    "                      min_timescale: float = 1.0, max_timescale: float = 1e4):\n",
    "    \"\"\"\n",
    "    Helper function, constructing basic positional encoding.\n",
    "    The code is partially based on implementation from Tensor2Tensor library\n",
    "    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py\n",
    "    \"\"\"\n",
    "\n",
    "    if hidden_size % 2 != 0:\n",
    "        raise ValueError(\n",
    "            f\"The hidden dimension of the model must be divisible by 2.\"\n",
    "            f\"Currently it is {hidden_size}\")\n",
    "    position = K.arange(0, length, dtype=K.floatx())\n",
    "    num_timescales = hidden_size // 2\n",
    "    log_timescale_increment = K.constant(\n",
    "        (np.log(float(max_timescale) / float(min_timescale)) /\n",
    "         (num_timescales - 1)),\n",
    "        dtype=K.floatx())\n",
    "    inv_timescales = (\n",
    "            min_timescale *\n",
    "            K.exp(K.arange(num_timescales, dtype=K.floatx()) *\n",
    "                  -log_timescale_increment))\n",
    "    scaled_time = K.expand_dims(position, 1) * K.expand_dims(inv_timescales, 0)\n",
    "    signal = K.concatenate([K.sin(scaled_time), K.cos(scaled_time)], axis=1)\n",
    "    return K.expand_dims(signal, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "309135be6416acde8d5088af910eee3597e25d4e"
   },
   "outputs": [],
   "source": [
    "# https://github.com/kpot/keras-transformer/blob/master/keras_transformer/position.py\n",
    "class AddPositionalEncoding(Layer):\n",
    "    \"\"\"\n",
    "    Injects positional encoding signal described in section 3.5 of the original\n",
    "    paper \"Attention is all you need\". Also a base class for more complex\n",
    "    coordinate encoding described in \"Universal Transformers\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_timescale: float = 1.0,\n",
    "                 max_timescale: float = 1.0e4, **kwargs):\n",
    "        self.min_timescale = min_timescale\n",
    "        self.max_timescale = max_timescale\n",
    "        self.signal = None\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['min_timescale'] = self.min_timescale\n",
    "        config['max_timescale'] = self.max_timescale\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, length, hidden_size = input_shape\n",
    "        self.signal = positional_signal(\n",
    "            hidden_size, length, self.min_timescale, self.max_timescale)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return inputs + self.signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "312bd7b8472de749134273fead7f939a234c551c"
   },
   "source": [
    "## Transformer Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "235ae9ecb6873475900b1ad88e3a07a161195370"
   },
   "outputs": [],
   "source": [
    "def model_transformer( n_encoder=3):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, trainable=True)(inp)\n",
    "    # Add positional encoding\n",
    "    x = AddPositionalEncoding()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    for i in range(n_encoder):\n",
    "        x = encoder(x)\n",
    "    # These are my own experiments\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "#     conc = Dense(512, activation=\"relu\")(conc)\n",
    "#     conc = Dropout(0.1)(conc)\n",
    "    outp = Dense(20, activation=\"softmax\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.recurrent_v2.LSTM"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "e2f42600ff37e6c286215562afc11a1be28f0981"
   },
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class BaseDataGenerator(Sequence):\n",
    "    \"\"\"A data generator\"\"\"\n",
    "    def __init__(self, list_IDs, batch_size=64, shuffle=True):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"number of steps in one epoch\"\"\"\n",
    "        # Here is the trick\n",
    "        return len(self.list_IDs) // (self.batch_size * 2**2)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size: (index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' \n",
    "        X = train_X[list_IDs_temp, :]\n",
    "        y = train_y[list_IDs_temp]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee0611a48264188ec3063bc6c6ce221eb3724d8e"
   },
   "source": [
    "### Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c9d6121293c82701f3c07ae00f396564d8aa2c9"
   },
   "source": [
    "Here I used early stopping and model checkpoint to load the best_val model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "5f90446889d864f0a318d305eca2d3a04d1baa55"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
    "def train_pred(n_encoder = n_encoder, epochs=2):\n",
    "    # learning schedule callback\n",
    "#     loss_history = LossHistory()\n",
    "#     lrate = BatchLRScheduler(step_decay)\n",
    "#     callbacks_list = [loss_history, lrate]\n",
    "#     es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
    "#     model_path = 'keras_models.h5'\n",
    "#     mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True)\n",
    "#     callbacks = [es, mc]\n",
    "#     train_generator = BaseDataGenerator(list(np.arange(train_X.shape[0])), batch_size=512)\n",
    "#     model.fit_generator(train_generator,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(val_X, val_y),)\n",
    "#                         callbacks=callbacks)\n",
    "#     model = load_model(model_path)\n",
    "    skf = StratifiedKFold(n_splits=7, random_state=0)\n",
    "    models, preds, scores = [], [],[]\n",
    "#     vectorizer = vect(max_df = 0.5)\n",
    "    for train, test in skf.split(train_df.Text, train_df.Label):\n",
    "#     print(train, test)\n",
    "#     clf = LogisticRegression(penalty='l1')\n",
    "#         clf.fit(vectorizer.transform(), data_train.Label.loc[data_train.index.intersection(train)])\n",
    "#         K.clear_session()\n",
    "#         clf = build_base_model()\n",
    "        model = model_transformer(n_encoder=n_encoder)\n",
    "        X_train = train_df.Text.loc[train_df.index.intersection(train)]\n",
    "        X_val = train_df.Text.loc[train_df.index.intersection(test)]\n",
    "        y_train = train_df[cols_target].loc[train_df.index.intersection(train)]\n",
    "        y_val = train_df[cols_target].loc[train_df.index.intersection(test)]\n",
    "        X_train = tokenizer.texts_to_sequences(X_train)\n",
    "        X_val = tokenizer.texts_to_sequences(X_val)\n",
    "        X_test = tokenizer.texts_to_sequences(test_df.Text)\n",
    "\n",
    "        ## Pad the sentences \n",
    "        X_train = pad_sequences(X_train, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        X_val = pad_sequences(X_val, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        X_test = pad_sequences(X_test, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "\n",
    "#         X_test = vect.transform(test_df.Text).toarray()\n",
    "        model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                   validation_data = (X_val,y_val),\n",
    "                   callbacks=[\n",
    "#               RocAucEvaluation(verbose=True),\n",
    "              ModelCheckpoint(file_path,    monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "              EarlyStopping(patience=10,    monitor=\"val_accuracy\", mode=\"max\"),\n",
    "              ReduceLROnPlateau(patience=4, monitor='val_accuracy', mode='max', cooldown=2, min_lr=1e-7, factor=0.3)])\n",
    "        preds.append(model.predict(X_test))\n",
    "        models.append(model)\n",
    "        scores.append(model.evaluate(X_val,y_val))\n",
    "#         coefs.append(clf.coef_[0])\n",
    "#         clf.fit(X_train, y_train)\n",
    "#     train_time = time() - t0\n",
    "#     print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "#     t0 = time()\n",
    "#     pred = clf.predict(X_test)\n",
    "#     test_time = time() - t0\n",
    "#     print(\"test time:  %0.3fs\" % test_time)\n",
    "    pred = np.mean(preds,axis = 0)\n",
    "#     model.fit(train_X, train_y, batch_size=64,\n",
    "#               epochs=epochs,\n",
    "#               validation_data=(val_X, val_y),)\n",
    "\n",
    "#     pred_val_y = model.predict([val_X], batch_size=64, verbose=0)\n",
    "#     pred_test_y = model.predict([test_X], batch_size=64, verbose=0)\n",
    "    return models, preds, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9b632c9bea6c5e8c7e111fc97474fc9d8b099c4"
   },
   "source": [
    "### Main part: load, train, pred and blend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "6ddf2ae0c374759ef040db80346faaf609850e58"
   },
   "outputs": [],
   "source": [
    "# train_X, val_X, test_X, train_y, val_y, word_index,val_idx,trn_idx = load_and_prec()\n",
    "vocab = []\n",
    "for w,k in word_index.items():\n",
    "    vocab.append(w)\n",
    "    if k >= max_features:\n",
    "        break\n",
    "# embedding_matrix_1 = load_glove(word_index)\n",
    "# embedding_matrix_2 = load_fasttext(word_index)\n",
    "# embedding_matrix_3 = load_para(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ffc83124a9f220b31e698b922cad56d59f8c83e5"
   },
   "source": [
    "### Create New Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "622e0a2f777d15a9f74b3d1d56a0e5ad60ee90bc"
   },
   "outputs": [],
   "source": [
    "## Simple average: http://aclweb.org/anthology/N18-2031\n",
    "\n",
    "# We have presented an argument for averaging as\n",
    "# a valid meta-embedding technique, and found experimental\n",
    "# performance to be close to, or in some cases \n",
    "# better than that of concatenation, with the\n",
    "# additional benefit of reduced dimensionality  \n",
    "\n",
    "\n",
    "## Unweighted DME in https://arxiv.org/pdf/1804.07983.pdf\n",
    "\n",
    "# “The downside of concatenating embeddings and \n",
    "#  giving that as input to an RNN encoder, however,\n",
    "#  is that the network then quickly becomes inefficient\n",
    "#  as we combine more and more embeddings.”\n",
    "  \n",
    "# embedding_matrix = np.mean([embedding_matrix_1, embedding_matrix_2, embedding_matrix_3], axis = 0)\n",
    "# embedding_matrix = np.mean([embedding_matrix_1, embedding_matrix_3], axis = 0)\n",
    "# np.shape(embedding_matrix)\n",
    "# model.evaluate(val_X,val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52627f8490364ed29f81e574c49af644726701e1"
   },
   "source": [
    "## Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3270c045c747a7c5da32704e6db44c18f470646"
   },
   "source": [
    "Here I am experimenting with 2 encoders, it's not guaranteed to be optimal, you can try out other numbers. Notice that I used epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "573d8e65c007aefd1fb4a0deef16e73894327486"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "# outputs[0][1]\n",
    "# type(train_X[0][0])\n",
    "# val_X\n",
    "# train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(train_X,train_y)\n",
    "# train_X.shape\n",
    "# train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "091d7915c8c00d088d60c09c306298950cd2afe6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "39/39 [==============================] - 18s 473ms/step - loss: 2.7733 - accuracy: 0.1545 - val_loss: 2.5872 - val_accuracy: 0.1942\n",
      "Epoch 2/42\n",
      "39/39 [==============================] - 16s 423ms/step - loss: 2.5449 - accuracy: 0.2276 - val_loss: 2.5424 - val_accuracy: 0.2039\n",
      "Epoch 3/42\n",
      "39/39 [==============================] - 17s 428ms/step - loss: 2.4540 - accuracy: 0.2260 - val_loss: 2.5027 - val_accuracy: 0.3107\n",
      "Epoch 4/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 2.3477 - accuracy: 0.2634 - val_loss: 2.4617 - val_accuracy: 0.2379\n",
      "Epoch 5/42\n",
      "39/39 [==============================] - 15s 396ms/step - loss: 2.2581 - accuracy: 0.3016 - val_loss: 2.3466 - val_accuracy: 0.2670\n",
      "Epoch 6/42\n",
      "39/39 [==============================] - 15s 397ms/step - loss: 2.0976 - accuracy: 0.3829 - val_loss: 2.2929 - val_accuracy: 0.2670\n",
      "Epoch 7/42\n",
      "39/39 [==============================] - 16s 418ms/step - loss: 1.9965 - accuracy: 0.4293 - val_loss: 2.2423 - val_accuracy: 0.3107\n",
      "Epoch 8/42\n",
      "39/39 [==============================] - 18s 452ms/step - loss: 1.8531 - accuracy: 0.5390 - val_loss: 2.1691 - val_accuracy: 0.3738\n",
      "Epoch 9/42\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 1.7913 - accuracy: 0.5789 - val_loss: 2.1555 - val_accuracy: 0.3738\n",
      "Epoch 10/42\n",
      "39/39 [==============================] - 18s 467ms/step - loss: 1.7520 - accuracy: 0.5894 - val_loss: 2.1329 - val_accuracy: 0.4417\n",
      "Epoch 11/42\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 1.7195 - accuracy: 0.6187 - val_loss: 2.1201 - val_accuracy: 0.4078\n",
      "Epoch 12/42\n",
      "39/39 [==============================] - 18s 449ms/step - loss: 1.6648 - accuracy: 0.6675 - val_loss: 2.0983 - val_accuracy: 0.4078\n",
      "Epoch 13/42\n",
      "39/39 [==============================] - 18s 452ms/step - loss: 1.6267 - accuracy: 0.6569 - val_loss: 2.0818 - val_accuracy: 0.4612\n",
      "Epoch 14/42\n",
      "39/39 [==============================] - 17s 428ms/step - loss: 1.5905 - accuracy: 0.6886 - val_loss: 2.0634 - val_accuracy: 0.4806\n",
      "Epoch 15/42\n",
      "39/39 [==============================] - 16s 421ms/step - loss: 1.5494 - accuracy: 0.7187 - val_loss: 2.0458 - val_accuracy: 0.4515\n",
      "Epoch 16/42\n",
      "39/39 [==============================] - 16s 422ms/step - loss: 1.5105 - accuracy: 0.7098 - val_loss: 2.0324 - val_accuracy: 0.4369\n",
      "Epoch 17/42\n",
      "39/39 [==============================] - 16s 422ms/step - loss: 1.4725 - accuracy: 0.7163 - val_loss: 2.0297 - val_accuracy: 0.4563\n",
      "Epoch 18/42\n",
      "39/39 [==============================] - 16s 421ms/step - loss: 1.4352 - accuracy: 0.7041 - val_loss: 2.0090 - val_accuracy: 0.5097\n",
      "Epoch 19/42\n",
      "39/39 [==============================] - 15s 396ms/step - loss: 1.3951 - accuracy: 0.7366 - val_loss: 1.9909 - val_accuracy: 0.4903\n",
      "Epoch 20/42\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 1.3570 - accuracy: 0.7537 - val_loss: 1.9708 - val_accuracy: 0.4951\n",
      "Epoch 21/42\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 1.3195 - accuracy: 0.7602 - val_loss: 1.9478 - val_accuracy: 0.5146\n",
      "Epoch 22/42\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 1.2829 - accuracy: 0.7667 - val_loss: 1.9390 - val_accuracy: 0.5000\n",
      "Epoch 23/42\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 1.2474 - accuracy: 0.7707 - val_loss: 1.9232 - val_accuracy: 0.4951\n",
      "Epoch 24/42\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 1.2070 - accuracy: 0.7886 - val_loss: 1.9081 - val_accuracy: 0.5049\n",
      "Epoch 25/42\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 1.1775 - accuracy: 0.7846 - val_loss: 1.8949 - val_accuracy: 0.4903\n",
      "Epoch 26/42\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 1.1378 - accuracy: 0.8008 - val_loss: 1.8871 - val_accuracy: 0.5243\n",
      "Epoch 27/42\n",
      "39/39 [==============================] - 16s 423ms/step - loss: 1.1230 - accuracy: 0.8163 - val_loss: 1.8831 - val_accuracy: 0.5194\n",
      "Epoch 28/42\n",
      "39/39 [==============================] - 17s 448ms/step - loss: 1.1144 - accuracy: 0.8114 - val_loss: 1.8788 - val_accuracy: 0.5291\n",
      "Epoch 29/42\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 1.1004 - accuracy: 0.8122 - val_loss: 1.8738 - val_accuracy: 0.5243\n",
      "Epoch 30/42\n",
      "39/39 [==============================] - 18s 460ms/step - loss: 1.0922 - accuracy: 0.8130 - val_loss: 1.8698 - val_accuracy: 0.5340\n",
      "Epoch 31/42\n",
      "39/39 [==============================] - 15s 386ms/step - loss: 1.0817 - accuracy: 0.8187 - val_loss: 1.8656 - val_accuracy: 0.5194\n",
      "Epoch 32/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 1.0710 - accuracy: 0.8171 - val_loss: 1.8608 - val_accuracy: 0.5194\n",
      "Epoch 33/42\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 1.0616 - accuracy: 0.8203 - val_loss: 1.8589 - val_accuracy: 0.5243\n",
      "Epoch 34/42\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 1.0532 - accuracy: 0.8268 - val_loss: 1.8561 - val_accuracy: 0.5291\n",
      "Epoch 35/42\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 1.0398 - accuracy: 0.8309 - val_loss: 1.8538 - val_accuracy: 0.5291\n",
      "Epoch 36/42\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 1.0384 - accuracy: 0.8252 - val_loss: 1.8527 - val_accuracy: 0.5243\n",
      "Epoch 37/42\n",
      "39/39 [==============================] - 16s 398ms/step - loss: 1.0349 - accuracy: 0.8276 - val_loss: 1.8508 - val_accuracy: 0.5243\n",
      "Epoch 38/42\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 1.0315 - accuracy: 0.8276 - val_loss: 1.8495 - val_accuracy: 0.5243\n",
      "Epoch 39/42\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 1.0289 - accuracy: 0.8293 - val_loss: 1.8484 - val_accuracy: 0.5243\n",
      "Epoch 40/42\n",
      "39/39 [==============================] - 15s 392ms/step - loss: 1.0253 - accuracy: 0.8276 - val_loss: 1.8481 - val_accuracy: 0.5243\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.8481 - accuracy: 0.5243\n",
      "Epoch 1/42\n",
      "39/39 [==============================] - 18s 467ms/step - loss: 2.6821 - accuracy: 0.1917 - val_loss: 2.5732 - val_accuracy: 0.2293\n",
      "Epoch 2/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 2.5424 - accuracy: 0.2177 - val_loss: 2.5196 - val_accuracy: 0.2049\n",
      "Epoch 3/42\n",
      "39/39 [==============================] - 17s 447ms/step - loss: 2.4401 - accuracy: 0.2486 - val_loss: 2.4804 - val_accuracy: 0.2341\n",
      "Epoch 4/42\n",
      "39/39 [==============================] - 15s 395ms/step - loss: 2.3604 - accuracy: 0.2811 - val_loss: 2.4130 - val_accuracy: 0.2439\n",
      "Epoch 5/42\n",
      "39/39 [==============================] - 16s 419ms/step - loss: 2.2328 - accuracy: 0.3517 - val_loss: 2.3614 - val_accuracy: 0.2683\n",
      "Epoch 6/42\n",
      "39/39 [==============================] - 17s 425ms/step - loss: 2.0989 - accuracy: 0.4110 - val_loss: 2.2762 - val_accuracy: 0.3024\n",
      "Epoch 7/42\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 1.9618 - accuracy: 0.4403 - val_loss: 2.2158 - val_accuracy: 0.4537\n",
      "Epoch 8/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 1.8176 - accuracy: 0.5711 - val_loss: 2.1402 - val_accuracy: 0.4049\n",
      "Epoch 9/42\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 1.6920 - accuracy: 0.5938 - val_loss: 2.0437 - val_accuracy: 0.3854\n",
      "Epoch 10/42\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 1.5555 - accuracy: 0.6458 - val_loss: 2.0158 - val_accuracy: 0.4878\n",
      "Epoch 11/42\n",
      "39/39 [==============================] - 15s 395ms/step - loss: 1.4222 - accuracy: 0.7002 - val_loss: 1.9016 - val_accuracy: 0.4829\n",
      "Epoch 12/42\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 1.2866 - accuracy: 0.7417 - val_loss: 1.8665 - val_accuracy: 0.4976\n",
      "Epoch 13/42\n",
      "39/39 [==============================] - 17s 426ms/step - loss: 1.1618 - accuracy: 0.7709 - val_loss: 1.8357 - val_accuracy: 0.4585\n",
      "Epoch 14/42\n",
      "39/39 [==============================] - 16s 420ms/step - loss: 1.0436 - accuracy: 0.8058 - val_loss: 1.7721 - val_accuracy: 0.5415\n",
      "Epoch 15/42\n",
      "39/39 [==============================] - 17s 433ms/step - loss: 0.9359 - accuracy: 0.8351 - val_loss: 1.7156 - val_accuracy: 0.5220\n",
      "Epoch 16/42\n",
      "39/39 [==============================] - 15s 396ms/step - loss: 0.8377 - accuracy: 0.8505 - val_loss: 1.6918 - val_accuracy: 0.5268\n",
      "Epoch 17/42\n",
      "39/39 [==============================] - 15s 390ms/step - loss: 0.7445 - accuracy: 0.8741 - val_loss: 1.6530 - val_accuracy: 0.5366\n",
      "Epoch 18/42\n",
      "39/39 [==============================] - 17s 428ms/step - loss: 0.6444 - accuracy: 0.9001 - val_loss: 1.6370 - val_accuracy: 0.5317\n",
      "Epoch 19/42\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.5773 - accuracy: 0.9236 - val_loss: 1.5962 - val_accuracy: 0.5805\n",
      "Epoch 20/42\n",
      "39/39 [==============================] - 15s 383ms/step - loss: 0.5482 - accuracy: 0.9301 - val_loss: 1.5836 - val_accuracy: 0.5805\n",
      "Epoch 21/42\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.5263 - accuracy: 0.9358 - val_loss: 1.5825 - val_accuracy: 0.5659\n",
      "Epoch 22/42\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 0.5039 - accuracy: 0.9472 - val_loss: 1.5694 - val_accuracy: 0.5854\n",
      "Epoch 23/42\n",
      "39/39 [==============================] - 15s 392ms/step - loss: 0.4844 - accuracy: 0.9464 - val_loss: 1.5693 - val_accuracy: 0.5561\n",
      "Epoch 24/42\n",
      "39/39 [==============================] - 17s 444ms/step - loss: 0.4645 - accuracy: 0.9513 - val_loss: 1.5597 - val_accuracy: 0.5756\n",
      "Epoch 25/42\n",
      "39/39 [==============================] - 16s 421ms/step - loss: 0.4463 - accuracy: 0.9553 - val_loss: 1.5586 - val_accuracy: 0.5659\n",
      "Epoch 26/42\n",
      "39/39 [==============================] - 17s 443ms/step - loss: 0.4302 - accuracy: 0.9561 - val_loss: 1.5466 - val_accuracy: 0.5805\n",
      "Epoch 27/42\n",
      "39/39 [==============================] - 17s 427ms/step - loss: 0.4125 - accuracy: 0.9618 - val_loss: 1.5450 - val_accuracy: 0.5805\n",
      "Epoch 28/42\n",
      "39/39 [==============================] - 16s 421ms/step - loss: 0.4071 - accuracy: 0.9618 - val_loss: 1.5425 - val_accuracy: 0.5854\n",
      "Epoch 29/42\n",
      "39/39 [==============================] - 17s 432ms/step - loss: 0.4013 - accuracy: 0.9667 - val_loss: 1.5396 - val_accuracy: 0.5902\n",
      "Epoch 30/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.3961 - accuracy: 0.9651 - val_loss: 1.5380 - val_accuracy: 0.5854\n",
      "Epoch 31/42\n",
      "39/39 [==============================] - 17s 427ms/step - loss: 0.3914 - accuracy: 0.9675 - val_loss: 1.5360 - val_accuracy: 0.5902\n",
      "Epoch 32/42\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.3869 - accuracy: 0.9675 - val_loss: 1.5359 - val_accuracy: 0.5902\n",
      "Epoch 33/42\n",
      "39/39 [==============================] - 18s 449ms/step - loss: 0.3833 - accuracy: 0.9708 - val_loss: 1.5322 - val_accuracy: 0.5951\n",
      "Epoch 34/42\n",
      "39/39 [==============================] - 15s 397ms/step - loss: 0.3771 - accuracy: 0.9691 - val_loss: 1.5344 - val_accuracy: 0.5854\n",
      "Epoch 35/42\n",
      "39/39 [==============================] - 17s 434ms/step - loss: 0.3738 - accuracy: 0.9699 - val_loss: 1.5296 - val_accuracy: 0.5902\n",
      "Epoch 36/42\n",
      "39/39 [==============================] - 18s 456ms/step - loss: 0.3690 - accuracy: 0.9699 - val_loss: 1.5266 - val_accuracy: 0.5951\n",
      "Epoch 37/42\n",
      "39/39 [==============================] - 17s 426ms/step - loss: 0.3646 - accuracy: 0.9691 - val_loss: 1.5246 - val_accuracy: 0.5902\n",
      "Epoch 38/42\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.3581 - accuracy: 0.9716 - val_loss: 1.5244 - val_accuracy: 0.5902\n",
      "Epoch 39/42\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 0.3577 - accuracy: 0.9699 - val_loss: 1.5245 - val_accuracy: 0.5902\n",
      "Epoch 40/42\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.3554 - accuracy: 0.9716 - val_loss: 1.5238 - val_accuracy: 0.5951\n",
      "Epoch 41/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.3541 - accuracy: 0.9708 - val_loss: 1.5240 - val_accuracy: 0.5902\n",
      "Epoch 42/42\n",
      "39/39 [==============================] - 16s 420ms/step - loss: 0.3530 - accuracy: 0.9724 - val_loss: 1.5226 - val_accuracy: 0.5902\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.5226 - accuracy: 0.5902\n",
      "Epoch 1/42\n",
      "39/39 [==============================] - 17s 443ms/step - loss: 2.7593 - accuracy: 0.1487 - val_loss: 2.6128 - val_accuracy: 0.0878\n",
      "Epoch 2/42\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 2.5630 - accuracy: 0.1909 - val_loss: 2.5231 - val_accuracy: 0.2390\n",
      "Epoch 3/42\n",
      "39/39 [==============================] - 17s 443ms/step - loss: 2.4441 - accuracy: 0.2340 - val_loss: 2.4830 - val_accuracy: 0.2537\n",
      "Epoch 4/42\n",
      "39/39 [==============================] - 17s 427ms/step - loss: 2.3514 - accuracy: 0.2486 - val_loss: 2.3810 - val_accuracy: 0.2634\n",
      "Epoch 5/42\n",
      "39/39 [==============================] - 17s 432ms/step - loss: 2.2432 - accuracy: 0.3387 - val_loss: 2.3037 - val_accuracy: 0.2878\n",
      "Epoch 6/42\n",
      "39/39 [==============================] - 17s 439ms/step - loss: 2.1081 - accuracy: 0.3834 - val_loss: 2.2310 - val_accuracy: 0.3024\n",
      "Epoch 7/42\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 1.9758 - accuracy: 0.4346 - val_loss: 2.1669 - val_accuracy: 0.3902\n",
      "Epoch 8/42\n",
      "39/39 [==============================] - 17s 428ms/step - loss: 1.8370 - accuracy: 0.5345 - val_loss: 2.0894 - val_accuracy: 0.4634\n",
      "Epoch 9/42\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 1.6993 - accuracy: 0.6125 - val_loss: 2.0023 - val_accuracy: 0.4390\n",
      "Epoch 10/42\n",
      "39/39 [==============================] - 18s 452ms/step - loss: 1.5573 - accuracy: 0.6491 - val_loss: 1.9549 - val_accuracy: 0.5073\n",
      "Epoch 11/42\n",
      "39/39 [==============================] - 15s 397ms/step - loss: 1.4367 - accuracy: 0.7076 - val_loss: 1.8612 - val_accuracy: 0.4878\n",
      "Epoch 12/42\n",
      "39/39 [==============================] - 17s 448ms/step - loss: 1.3058 - accuracy: 0.7352 - val_loss: 1.7980 - val_accuracy: 0.5659\n",
      "Epoch 13/42\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 1.1749 - accuracy: 0.7839 - val_loss: 1.7549 - val_accuracy: 0.4878\n",
      "Epoch 14/42\n",
      "39/39 [==============================] - 16s 418ms/step - loss: 1.0470 - accuracy: 0.8091 - val_loss: 1.6688 - val_accuracy: 0.5805\n",
      "Epoch 15/42\n",
      "39/39 [==============================] - 15s 393ms/step - loss: 0.9414 - accuracy: 0.8392 - val_loss: 1.6220 - val_accuracy: 0.5707\n",
      "Epoch 16/42\n",
      "39/39 [==============================] - 17s 429ms/step - loss: 0.8469 - accuracy: 0.8505 - val_loss: 1.6093 - val_accuracy: 0.6000\n",
      "Epoch 17/42\n",
      "39/39 [==============================] - 17s 439ms/step - loss: 0.7564 - accuracy: 0.8652 - val_loss: 1.5646 - val_accuracy: 0.6049\n",
      "Epoch 18/42\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.6603 - accuracy: 0.8960 - val_loss: 1.5139 - val_accuracy: 0.6146\n",
      "Epoch 19/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.5844 - accuracy: 0.9155 - val_loss: 1.4943 - val_accuracy: 0.6390\n",
      "Epoch 20/42\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.5143 - accuracy: 0.9301 - val_loss: 1.4432 - val_accuracy: 0.6537\n",
      "Epoch 21/42\n",
      "39/39 [==============================] - 17s 437ms/step - loss: 0.4557 - accuracy: 0.9472 - val_loss: 1.4342 - val_accuracy: 0.6585\n",
      "Epoch 22/42\n",
      "39/39 [==============================] - 15s 396ms/step - loss: 0.3935 - accuracy: 0.9610 - val_loss: 1.4190 - val_accuracy: 0.6585\n",
      "Epoch 23/42\n",
      "39/39 [==============================] - 17s 427ms/step - loss: 0.3514 - accuracy: 0.9691 - val_loss: 1.4175 - val_accuracy: 0.6537\n",
      "Epoch 24/42\n",
      "39/39 [==============================] - 15s 391ms/step - loss: 0.3083 - accuracy: 0.9789 - val_loss: 1.3777 - val_accuracy: 0.6390\n",
      "Epoch 25/42\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.2701 - accuracy: 0.9862 - val_loss: 1.3614 - val_accuracy: 0.6341\n",
      "Epoch 26/42\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.2344 - accuracy: 0.9903 - val_loss: 1.3424 - val_accuracy: 0.6488\n",
      "Epoch 27/42\n",
      "39/39 [==============================] - 15s 383ms/step - loss: 0.2223 - accuracy: 0.9935 - val_loss: 1.3411 - val_accuracy: 0.6488\n",
      "Epoch 28/42\n",
      "39/39 [==============================] - 15s 393ms/step - loss: 0.2122 - accuracy: 0.9927 - val_loss: 1.3352 - val_accuracy: 0.6537\n",
      "Epoch 29/42\n",
      "39/39 [==============================] - 15s 392ms/step - loss: 0.2041 - accuracy: 0.9951 - val_loss: 1.3323 - val_accuracy: 0.6488\n",
      "Epoch 30/42\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.1972 - accuracy: 0.9951 - val_loss: 1.3275 - val_accuracy: 0.6439\n",
      "Epoch 31/42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 16s 400ms/step - loss: 0.1889 - accuracy: 0.9951 - val_loss: 1.3273 - val_accuracy: 0.6488\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3273 - accuracy: 0.6488\n",
      "Epoch 1/42\n",
      "39/39 [==============================] - 17s 445ms/step - loss: 2.7306 - accuracy: 0.1568 - val_loss: 2.5804 - val_accuracy: 0.1951\n",
      "Epoch 2/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 2.5487 - accuracy: 0.2145 - val_loss: 2.5284 - val_accuracy: 0.2195\n",
      "Epoch 3/42\n",
      "39/39 [==============================] - 17s 425ms/step - loss: 2.4578 - accuracy: 0.2283 - val_loss: 2.4338 - val_accuracy: 0.2439\n",
      "Epoch 4/42\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 2.3633 - accuracy: 0.2632 - val_loss: 2.3770 - val_accuracy: 0.3268\n",
      "Epoch 5/42\n",
      "39/39 [==============================] - 15s 393ms/step - loss: 2.2446 - accuracy: 0.3412 - val_loss: 2.3014 - val_accuracy: 0.2732\n",
      "Epoch 6/42\n",
      "39/39 [==============================] - 16s 419ms/step - loss: 2.1184 - accuracy: 0.3972 - val_loss: 2.2097 - val_accuracy: 0.3951\n",
      "Epoch 7/42\n",
      "39/39 [==============================] - 15s 391ms/step - loss: 1.9899 - accuracy: 0.4468 - val_loss: 2.1358 - val_accuracy: 0.3561\n",
      "Epoch 8/42\n",
      "39/39 [==============================] - 17s 423ms/step - loss: 1.8570 - accuracy: 0.5207 - val_loss: 2.0616 - val_accuracy: 0.4244\n",
      "Epoch 9/42\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 1.7117 - accuracy: 0.6076 - val_loss: 1.9702 - val_accuracy: 0.4585\n",
      "Epoch 10/42\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 1.5646 - accuracy: 0.6637 - val_loss: 1.9212 - val_accuracy: 0.4683\n",
      "Epoch 11/42\n",
      "39/39 [==============================] - 15s 391ms/step - loss: 1.4401 - accuracy: 0.6742 - val_loss: 1.8466 - val_accuracy: 0.4439\n",
      "Epoch 12/42\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 1.2779 - accuracy: 0.7563 - val_loss: 1.7530 - val_accuracy: 0.4927\n",
      "Epoch 13/42\n",
      "39/39 [==============================] - 17s 427ms/step - loss: 1.1644 - accuracy: 0.7831 - val_loss: 1.7482 - val_accuracy: 0.5854\n",
      "Epoch 14/42\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 1.0368 - accuracy: 0.8172 - val_loss: 1.6540 - val_accuracy: 0.5707\n",
      "Epoch 15/42\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.9373 - accuracy: 0.8432 - val_loss: 1.5999 - val_accuracy: 0.5951\n",
      "Epoch 16/42\n",
      "39/39 [==============================] - 18s 454ms/step - loss: 0.8441 - accuracy: 0.8513 - val_loss: 1.5996 - val_accuracy: 0.5951\n",
      "Epoch 17/42\n",
      "39/39 [==============================] - 17s 438ms/step - loss: 0.7349 - accuracy: 0.8838 - val_loss: 1.5510 - val_accuracy: 0.5805\n",
      "Epoch 18/42\n",
      "39/39 [==============================] - 17s 448ms/step - loss: 0.6512 - accuracy: 0.9033 - val_loss: 1.5313 - val_accuracy: 0.6341\n",
      "Epoch 19/42\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.5748 - accuracy: 0.9253 - val_loss: 1.4911 - val_accuracy: 0.6293\n",
      "Epoch 20/42\n",
      "39/39 [==============================] - 17s 434ms/step - loss: 0.5052 - accuracy: 0.9366 - val_loss: 1.4452 - val_accuracy: 0.6195\n",
      "Epoch 21/42\n",
      "39/39 [==============================] - 17s 431ms/step - loss: 0.4354 - accuracy: 0.9529 - val_loss: 1.4284 - val_accuracy: 0.6195\n",
      "Epoch 22/42\n",
      "39/39 [==============================] - 17s 438ms/step - loss: 0.3851 - accuracy: 0.9578 - val_loss: 1.4268 - val_accuracy: 0.6439\n",
      "Epoch 23/42\n",
      "39/39 [==============================] - 16s 422ms/step - loss: 0.3405 - accuracy: 0.9675 - val_loss: 1.4026 - val_accuracy: 0.6293\n",
      "Epoch 24/42\n",
      "39/39 [==============================] - 16s 423ms/step - loss: 0.3024 - accuracy: 0.9773 - val_loss: 1.3732 - val_accuracy: 0.6146\n",
      "Epoch 25/42\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.2585 - accuracy: 0.9838 - val_loss: 1.4151 - val_accuracy: 0.6341\n",
      "Epoch 26/42\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.2331 - accuracy: 0.9903 - val_loss: 1.3551 - val_accuracy: 0.6293\n",
      "Epoch 27/42\n",
      "39/39 [==============================] - 17s 427ms/step - loss: 0.2005 - accuracy: 0.9927 - val_loss: 1.3526 - val_accuracy: 0.6439\n",
      "Epoch 28/42\n",
      "39/39 [==============================] - 17s 428ms/step - loss: 0.1913 - accuracy: 0.9951 - val_loss: 1.3515 - val_accuracy: 0.6488\n",
      "Epoch 29/42\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 0.1824 - accuracy: 0.9943 - val_loss: 1.3495 - val_accuracy: 0.6488\n",
      "Epoch 30/42\n",
      "39/39 [==============================] - 15s 380ms/step - loss: 0.1761 - accuracy: 0.9959 - val_loss: 1.3463 - val_accuracy: 0.6390\n",
      "Epoch 31/42\n",
      "39/39 [==============================] - 17s 428ms/step - loss: 0.1704 - accuracy: 0.9959 - val_loss: 1.3388 - val_accuracy: 0.6537\n",
      "Epoch 32/42\n",
      "39/39 [==============================] - 15s 380ms/step - loss: 0.1626 - accuracy: 0.9992 - val_loss: 1.3425 - val_accuracy: 0.6488\n",
      "Epoch 33/42\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.1574 - accuracy: 0.9968 - val_loss: 1.3391 - val_accuracy: 0.6488\n",
      "Epoch 34/42\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.1509 - accuracy: 0.9992 - val_loss: 1.3324 - val_accuracy: 0.6488\n",
      "Epoch 35/42\n",
      "39/39 [==============================] - 15s 396ms/step - loss: 0.1468 - accuracy: 0.9959 - val_loss: 1.3353 - val_accuracy: 0.6341\n",
      "Epoch 36/42\n",
      "39/39 [==============================] - 15s 392ms/step - loss: 0.1400 - accuracy: 0.9984 - val_loss: 1.3288 - val_accuracy: 0.6488\n",
      "Epoch 37/42\n",
      "39/39 [==============================] - 15s 395ms/step - loss: 0.1383 - accuracy: 0.9984 - val_loss: 1.3300 - val_accuracy: 0.6488\n",
      "Epoch 38/42\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.1366 - accuracy: 0.9984 - val_loss: 1.3282 - val_accuracy: 0.6488\n",
      "Epoch 39/42\n",
      "39/39 [==============================] - 15s 394ms/step - loss: 0.1348 - accuracy: 0.9992 - val_loss: 1.3276 - val_accuracy: 0.6488\n",
      "Epoch 40/42\n",
      "39/39 [==============================] - 16s 398ms/step - loss: 0.1324 - accuracy: 0.9992 - val_loss: 1.3279 - val_accuracy: 0.6488\n",
      "Epoch 41/42\n",
      "39/39 [==============================] - 16s 398ms/step - loss: 0.1313 - accuracy: 0.9992 - val_loss: 1.3271 - val_accuracy: 0.6488\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.3271 - accuracy: 0.6488\n",
      "Epoch 1/42\n",
      "39/39 [==============================] - 18s 458ms/step - loss: 2.7328 - accuracy: 0.1649 - val_loss: 2.6167 - val_accuracy: 0.0878\n",
      "Epoch 2/42\n",
      "39/39 [==============================] - 17s 432ms/step - loss: 2.5532 - accuracy: 0.2145 - val_loss: 2.5454 - val_accuracy: 0.2537\n",
      "Epoch 3/42\n",
      "39/39 [==============================] - 17s 431ms/step - loss: 2.4677 - accuracy: 0.2388 - val_loss: 2.4415 - val_accuracy: 0.2829\n",
      "Epoch 4/42\n",
      "39/39 [==============================] - 16s 418ms/step - loss: 2.3541 - accuracy: 0.2941 - val_loss: 2.3577 - val_accuracy: 0.3463\n",
      "Epoch 5/42\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 2.2410 - accuracy: 0.3396 - val_loss: 2.2979 - val_accuracy: 0.4390\n",
      "Epoch 6/42\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 2.1035 - accuracy: 0.3907 - val_loss: 2.1922 - val_accuracy: 0.3659\n",
      "Epoch 7/42\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 1.9835 - accuracy: 0.4525 - val_loss: 2.1328 - val_accuracy: 0.3805\n",
      "Epoch 8/42\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 1.8486 - accuracy: 0.5264 - val_loss: 2.0892 - val_accuracy: 0.4195\n",
      "Epoch 9/42\n",
      "39/39 [==============================] - 17s 434ms/step - loss: 1.7151 - accuracy: 0.6117 - val_loss: 1.9561 - val_accuracy: 0.4732\n",
      "Epoch 10/42\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 1.5533 - accuracy: 0.6483 - val_loss: 1.9202 - val_accuracy: 0.5122\n",
      "Epoch 11/42\n",
      "39/39 [==============================] - 17s 442ms/step - loss: 1.4301 - accuracy: 0.7189 - val_loss: 1.8117 - val_accuracy: 0.5707\n",
      "Epoch 12/42\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 1.2735 - accuracy: 0.7392 - val_loss: 1.7316 - val_accuracy: 0.5707\n",
      "Epoch 13/42\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 1.1608 - accuracy: 0.7742 - val_loss: 1.7279 - val_accuracy: 0.4976\n",
      "Epoch 14/42\n",
      "39/39 [==============================] - 15s 380ms/step - loss: 1.0549 - accuracy: 0.8010 - val_loss: 1.6225 - val_accuracy: 0.5463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/42\n",
      "39/39 [==============================] - 17s 438ms/step - loss: 0.9327 - accuracy: 0.8327 - val_loss: 1.5896 - val_accuracy: 0.6098\n",
      "Epoch 16/42\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.8242 - accuracy: 0.8603 - val_loss: 1.5750 - val_accuracy: 0.5610\n",
      "Epoch 17/42\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 0.7456 - accuracy: 0.8716 - val_loss: 1.5116 - val_accuracy: 0.6195\n",
      "Epoch 18/42\n",
      "39/39 [==============================] - 15s 385ms/step - loss: 0.6594 - accuracy: 0.8985 - val_loss: 1.4926 - val_accuracy: 0.6146\n",
      "Epoch 19/42\n",
      "39/39 [==============================] - 15s 388ms/step - loss: 0.5727 - accuracy: 0.9245 - val_loss: 1.4420 - val_accuracy: 0.6146\n",
      "Epoch 20/42\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.5049 - accuracy: 0.9342 - val_loss: 1.4069 - val_accuracy: 0.6098\n",
      "Epoch 21/42\n",
      "39/39 [==============================] - 15s 394ms/step - loss: 0.4425 - accuracy: 0.9537 - val_loss: 1.3999 - val_accuracy: 0.6000\n",
      "Epoch 22/42\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.3887 - accuracy: 0.9610 - val_loss: 1.3649 - val_accuracy: 0.6146\n",
      "Epoch 23/42\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.3700 - accuracy: 0.9643 - val_loss: 1.3592 - val_accuracy: 0.6098\n",
      "Epoch 24/42\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 0.3561 - accuracy: 0.9691 - val_loss: 1.3564 - val_accuracy: 0.6049\n",
      "Epoch 25/42\n",
      "39/39 [==============================] - 15s 377ms/step - loss: 0.3393 - accuracy: 0.9740 - val_loss: 1.3541 - val_accuracy: 0.6146\n",
      "Epoch 26/42\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.3264 - accuracy: 0.9748 - val_loss: 1.3432 - val_accuracy: 0.6000\n",
      "Epoch 27/42\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 0.3126 - accuracy: 0.9773 - val_loss: 1.3435 - val_accuracy: 0.6098\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3435 - accuracy: 0.6098\n",
      "Epoch 1/42\n",
      "39/39 [==============================] - 12s 310ms/step - loss: 2.6860 - accuracy: 0.1665 - val_loss: 2.5955 - val_accuracy: 0.1951\n",
      "Epoch 2/42\n",
      "39/39 [==============================] - 13s 324ms/step - loss: 2.5490 - accuracy: 0.2201 - val_loss: 2.5600 - val_accuracy: 0.1951\n",
      "Epoch 3/42\n",
      "39/39 [==============================] - 13s 345ms/step - loss: 2.4656 - accuracy: 0.2307 - val_loss: 2.4849 - val_accuracy: 0.2195\n",
      "Epoch 4/42\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 2.3400 - accuracy: 0.2908 - val_loss: 2.4200 - val_accuracy: 0.2098\n",
      "Epoch 5/42\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 2.2252 - accuracy: 0.3355 - val_loss: 2.3512 - val_accuracy: 0.2780\n",
      "Epoch 6/42\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 2.1173 - accuracy: 0.3412 - val_loss: 2.2776 - val_accuracy: 0.3366\n",
      "Epoch 7/42\n",
      "39/39 [==============================] - 17s 434ms/step - loss: 1.9748 - accuracy: 0.4809 - val_loss: 2.2314 - val_accuracy: 0.3902\n",
      "Epoch 8/42\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 1.8409 - accuracy: 0.5556 - val_loss: 2.1665 - val_accuracy: 0.4049\n",
      "Epoch 9/42\n",
      "39/39 [==============================] - 17s 423ms/step - loss: 1.6999 - accuracy: 0.6149 - val_loss: 2.0647 - val_accuracy: 0.4000\n",
      "Epoch 10/42\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 1.5496 - accuracy: 0.6637 - val_loss: 2.0074 - val_accuracy: 0.4683\n",
      "Epoch 11/42\n",
      "39/39 [==============================] - 17s 444ms/step - loss: 1.4118 - accuracy: 0.7067 - val_loss: 1.9151 - val_accuracy: 0.5024\n",
      "Epoch 12/42\n",
      "39/39 [==============================] - 16s 419ms/step - loss: 1.2730 - accuracy: 0.7571 - val_loss: 1.8521 - val_accuracy: 0.4878\n",
      "Epoch 13/42\n",
      "39/39 [==============================] - 21s 546ms/step - loss: 1.1455 - accuracy: 0.7872 - val_loss: 1.8368 - val_accuracy: 0.4146\n",
      "Epoch 14/42\n",
      "39/39 [==============================] - 19s 495ms/step - loss: 1.0387 - accuracy: 0.8067 - val_loss: 1.7716 - val_accuracy: 0.4634\n",
      "Epoch 15/42\n",
      "39/39 [==============================] - 18s 469ms/step - loss: 0.9308 - accuracy: 0.8416 - val_loss: 1.7134 - val_accuracy: 0.5268\n",
      "Epoch 16/42\n",
      "39/39 [==============================] - 17s 439ms/step - loss: 0.8105 - accuracy: 0.8692 - val_loss: 1.6710 - val_accuracy: 0.5463\n",
      "Epoch 17/42\n",
      "39/39 [==============================] - 16s 420ms/step - loss: 0.7289 - accuracy: 0.8830 - val_loss: 1.6322 - val_accuracy: 0.5415\n",
      "Epoch 18/42\n",
      "39/39 [==============================] - 20s 510ms/step - loss: 0.6400 - accuracy: 0.9017 - val_loss: 1.6290 - val_accuracy: 0.5707\n",
      "Epoch 19/42\n",
      "39/39 [==============================] - 17s 435ms/step - loss: 0.5664 - accuracy: 0.9171 - val_loss: 1.5651 - val_accuracy: 0.5561\n",
      "Epoch 20/42\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 0.4998 - accuracy: 0.9236 - val_loss: 1.5475 - val_accuracy: 0.5805\n",
      "Epoch 21/42\n",
      "39/39 [==============================] - 19s 477ms/step - loss: 0.4333 - accuracy: 0.9504 - val_loss: 1.5131 - val_accuracy: 0.5659\n",
      "Epoch 22/42\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.3888 - accuracy: 0.9618 - val_loss: 1.5052 - val_accuracy: 0.5805\n",
      "Epoch 23/42\n",
      "39/39 [==============================] - 16s 398ms/step - loss: 0.3371 - accuracy: 0.9667 - val_loss: 1.5133 - val_accuracy: 0.5902\n",
      "Epoch 24/42\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 0.2943 - accuracy: 0.9740 - val_loss: 1.4647 - val_accuracy: 0.5902\n",
      "Epoch 25/42\n",
      "39/39 [==============================] - 15s 377ms/step - loss: 0.2586 - accuracy: 0.9846 - val_loss: 1.4603 - val_accuracy: 0.6049\n",
      "Epoch 26/42\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.2237 - accuracy: 0.9894 - val_loss: 1.4474 - val_accuracy: 0.5854\n",
      "Epoch 27/42\n",
      "39/39 [==============================] - 17s 438ms/step - loss: 0.1979 - accuracy: 0.9903 - val_loss: 1.4534 - val_accuracy: 0.5756\n",
      "Epoch 28/42\n",
      "39/39 [==============================] - 17s 425ms/step - loss: 0.1751 - accuracy: 0.9959 - val_loss: 1.4348 - val_accuracy: 0.5854\n",
      "Epoch 29/42\n",
      "39/39 [==============================] - 17s 445ms/step - loss: 0.1576 - accuracy: 0.9951 - val_loss: 1.4282 - val_accuracy: 0.6049\n",
      "Epoch 30/42\n",
      "39/39 [==============================] - 15s 392ms/step - loss: 0.1380 - accuracy: 0.9976 - val_loss: 1.4078 - val_accuracy: 0.6098\n",
      "Epoch 31/42\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 0.1295 - accuracy: 0.9976 - val_loss: 1.4056 - val_accuracy: 0.6000\n",
      "Epoch 32/42\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 0.1256 - accuracy: 0.9984 - val_loss: 1.4065 - val_accuracy: 0.5951\n",
      "Epoch 33/42\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 0.1214 - accuracy: 0.9976 - val_loss: 1.4011 - val_accuracy: 0.6049\n",
      "Epoch 34/42\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 0.1170 - accuracy: 0.9992 - val_loss: 1.3993 - val_accuracy: 0.6098\n",
      "Epoch 35/42\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 0.1124 - accuracy: 0.9992 - val_loss: 1.4000 - val_accuracy: 0.6146\n",
      "Epoch 36/42\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 0.1114 - accuracy: 0.9984 - val_loss: 1.3973 - val_accuracy: 0.6146\n",
      "Epoch 37/42\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 0.1098 - accuracy: 0.9992 - val_loss: 1.3985 - val_accuracy: 0.6146\n",
      "Epoch 38/42\n",
      "39/39 [==============================] - 14s 353ms/step - loss: 0.1083 - accuracy: 0.9992 - val_loss: 1.3958 - val_accuracy: 0.6146\n",
      "Epoch 39/42\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 0.1073 - accuracy: 0.9992 - val_loss: 1.3962 - val_accuracy: 0.6098\n",
      "Epoch 40/42\n",
      "39/39 [==============================] - 14s 348ms/step - loss: 0.1061 - accuracy: 1.0000 - val_loss: 1.3958 - val_accuracy: 0.6146\n",
      "Epoch 41/42\n",
      "39/39 [==============================] - 13s 331ms/step - loss: 0.1060 - accuracy: 0.9992 - val_loss: 1.3947 - val_accuracy: 0.6146\n",
      "Epoch 42/42\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 0.1051 - accuracy: 0.9992 - val_loss: 1.3955 - val_accuracy: 0.6146\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.3955 - accuracy: 0.6146\n",
      "Epoch 1/42\n",
      "39/39 [==============================] - 15s 394ms/step - loss: 2.6978 - accuracy: 0.1909 - val_loss: 2.5950 - val_accuracy: 0.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/42\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 2.5456 - accuracy: 0.2323 - val_loss: 2.5606 - val_accuracy: 0.2439\n",
      "Epoch 3/42\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 2.4381 - accuracy: 0.2283 - val_loss: 2.4901 - val_accuracy: 0.2293\n",
      "Epoch 4/42\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 2.3439 - accuracy: 0.3022 - val_loss: 2.4162 - val_accuracy: 0.2341\n",
      "Epoch 5/42\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 2.2289 - accuracy: 0.3119 - val_loss: 2.3264 - val_accuracy: 0.3073\n",
      "Epoch 6/42\n",
      "39/39 [==============================] - 15s 387ms/step - loss: 2.0942 - accuracy: 0.4151 - val_loss: 2.2584 - val_accuracy: 0.3268\n",
      "Epoch 7/42\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 1.9602 - accuracy: 0.4639 - val_loss: 2.2041 - val_accuracy: 0.3659\n",
      "Epoch 8/42\n",
      "39/39 [==============================] - 14s 365ms/step - loss: 1.8231 - accuracy: 0.5337 - val_loss: 2.1465 - val_accuracy: 0.3951\n",
      "Epoch 9/42\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 1.6791 - accuracy: 0.5881 - val_loss: 2.0580 - val_accuracy: 0.4049\n",
      "Epoch 10/42\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 1.5275 - accuracy: 0.6466 - val_loss: 2.0085 - val_accuracy: 0.4585\n",
      "Epoch 11/42\n",
      "39/39 [==============================] - 14s 363ms/step - loss: 1.4065 - accuracy: 0.7019 - val_loss: 1.9312 - val_accuracy: 0.4634\n",
      "Epoch 12/42\n",
      "39/39 [==============================] - 15s 372ms/step - loss: 1.2686 - accuracy: 0.7384 - val_loss: 1.8681 - val_accuracy: 0.4829\n",
      "Epoch 13/42\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 1.1545 - accuracy: 0.7766 - val_loss: 1.8589 - val_accuracy: 0.4439\n",
      "Epoch 14/42\n",
      "39/39 [==============================] - 13s 344ms/step - loss: 1.0298 - accuracy: 0.8050 - val_loss: 1.7859 - val_accuracy: 0.4829\n",
      "Epoch 15/42\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 0.9299 - accuracy: 0.8343 - val_loss: 1.7371 - val_accuracy: 0.5268\n",
      "Epoch 16/42\n",
      "39/39 [==============================] - 15s 374ms/step - loss: 0.8105 - accuracy: 0.8668 - val_loss: 1.7107 - val_accuracy: 0.5610\n",
      "Epoch 17/42\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 0.7317 - accuracy: 0.8790 - val_loss: 1.6729 - val_accuracy: 0.5951\n",
      "Epoch 18/42\n",
      "39/39 [==============================] - 14s 349ms/step - loss: 0.6428 - accuracy: 0.9106 - val_loss: 1.6508 - val_accuracy: 0.5659\n",
      "Epoch 19/42\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 0.5656 - accuracy: 0.9245 - val_loss: 1.6158 - val_accuracy: 0.5707\n",
      "Epoch 20/42\n",
      "39/39 [==============================] - 13s 342ms/step - loss: 0.4974 - accuracy: 0.9448 - val_loss: 1.5824 - val_accuracy: 0.5902\n",
      "Epoch 21/42\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 0.4341 - accuracy: 0.9561 - val_loss: 1.5613 - val_accuracy: 0.5854\n",
      "Epoch 22/42\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 0.3851 - accuracy: 0.9602 - val_loss: 1.5462 - val_accuracy: 0.6098\n",
      "Epoch 23/42\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 0.3617 - accuracy: 0.9683 - val_loss: 1.5388 - val_accuracy: 0.5805\n",
      "Epoch 24/42\n",
      "39/39 [==============================] - 14s 371ms/step - loss: 0.3460 - accuracy: 0.9683 - val_loss: 1.5418 - val_accuracy: 0.5854\n",
      "Epoch 25/42\n",
      "39/39 [==============================] - 14s 356ms/step - loss: 0.3322 - accuracy: 0.9716 - val_loss: 1.5341 - val_accuracy: 0.5902\n",
      "Epoch 26/42\n",
      "39/39 [==============================] - 14s 347ms/step - loss: 0.3196 - accuracy: 0.9740 - val_loss: 1.5270 - val_accuracy: 0.5951\n",
      "Epoch 27/42\n",
      "39/39 [==============================] - 13s 335ms/step - loss: 0.3058 - accuracy: 0.9813 - val_loss: 1.5268 - val_accuracy: 0.6000\n",
      "Epoch 28/42\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 0.3007 - accuracy: 0.9797 - val_loss: 1.5249 - val_accuracy: 0.5951\n",
      "Epoch 29/42\n",
      "39/39 [==============================] - 14s 351ms/step - loss: 0.2987 - accuracy: 0.9764 - val_loss: 1.5232 - val_accuracy: 0.6000\n",
      "Epoch 30/42\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 0.2947 - accuracy: 0.9813 - val_loss: 1.5220 - val_accuracy: 0.6049\n",
      "Epoch 31/42\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 0.2899 - accuracy: 0.9838 - val_loss: 1.5198 - val_accuracy: 0.6000\n",
      "Epoch 32/42\n",
      "39/39 [==============================] - 14s 362ms/step - loss: 0.2867 - accuracy: 0.9862 - val_loss: 1.5199 - val_accuracy: 0.6000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5199 - accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "n_encoder = 0\n",
    "models, preds, scores = train_pred(n_encoder = 0,epochs = 42)\n",
    "# outputs.append([pred_val_y, pred_test_y, 'transformer_enc{}'.format(n_encoder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_uuid": "e3dc6e5362fa13e00b291986b94ea9d6e5acdebf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for thresh in np.arange(0.1, 0.51, 0.01):\n",
    "#     thresh = np.round(thresh, 2)\n",
    "#     print(\"F1 score at threshold {0:.2f} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))\n",
    "# models_trans = models\n",
    "# scores\n",
    "# preds\n",
    "# np.mean(preds,axis = 0)\n",
    "# models == models_trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "43e0969fd3af4b65decfbba8cce0a8a36d552176"
   },
   "outputs": [],
   "source": [
    "# pred_test_y = (pred_test_y > 0.42).astype(int)\n",
    "# test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"qid\"])\n",
    "# out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "# out_df['prediction'] = pred_test_y\n",
    "# out_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "c378fe1cfd53529831f3928fb9866329eb7a9184"
   },
   "outputs": [],
   "source": [
    "# idx = (pred_test_y > 0.42).astype(int)\n",
    "# test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"qid\"])\n",
    "# out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "# out_df['prediction'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "c378fe1cfd53529831f3928fb9866329eb7a9184"
   },
   "outputs": [],
   "source": [
    "# mylist = out_df[out_df.prediction == 1].index\n",
    "# for i in mylist:\n",
    "#     print(i, end=',')\n",
    "\n",
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a3b5a15d3745fa2ffb2e0bfd1c98ba890e27550"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model)\n",
    "train_df = pd.read_csv(\"../Translated/cleaned/train.csv\")\n",
    "test_df = pd.read_csv(\"../Translated/cleaned/test.csv\")\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "#     text = re.sub(r\"what's\", \"what is \", text)\n",
    "#     text = re.sub(r\"\\'s\", \" \", text)\n",
    "#     text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(r\"can't\", \"cannot \", text)\n",
    "#     text = re.sub(r\"n't\", \" not \", text)\n",
    "#     text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#     text = re.sub(r\"\\'re\", \" are \", text)\n",
    "#     text = re.sub(r\"\\'d\", \" would \", text)\n",
    "#     text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "#     text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "#     text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub(r\",\", \" \", text) \n",
    "    text = re.sub(r\"!\", \" \", text) \n",
    "    text = re.sub(r\"\\(\", \" \", text) \n",
    "    text = re.sub(r\"\\)\", \" \", text) \n",
    "    text = re.sub(r\"\\?\", \" \", text) \n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)  \n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "# removing stop words\n",
    "# other_stop_w = pd.read_csv('../Downloaded_notebooks/words_shared_by_all.csv')\n",
    "# stopw = [item for sublist in other_stop_w.values.tolist() for item in sublist]\n",
    "# train_df['Text'].apply(lambda x: [item for item in x.split() if item not in stopw])\n",
    "# test_df['Text'].apply(lambda x: [item for item in x.split() if item not in stopw])\n",
    "\n",
    "train_df['Text'] = train_df['Text'].map(lambda com : clean_text(com))\n",
    "test_df['Text'] = test_df['Text'].map(lambda com : clean_text(com))\n",
    "X_tfidf = train_df.Text\n",
    "test_X_tfidf = test_df.Text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [base_m.trainable = False ]\n",
    "for base_m in base_models:\n",
    "    base_m.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect\n",
    "# base_models[0].trainable\n",
    "for base_m in models_trans:\n",
    "    base_m.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features=45000,sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "\n",
    "X_dtm = vect.fit_transform(X_tfidf).toarray()\n",
    "\n",
    "test_X_dtm = vect.transform(test_X_tfidf).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "# # y_train\n",
    "cols_target = train_df['Label'].unique().tolist()\n",
    "train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "# # train_df\n",
    "\n",
    "# x_train, x_val, y_train, y_val = train_test_split(X_dtm, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx = list(set(X_tfidf.index.tolist()) - set(val_idx.tolist()))\n",
    "# base_model.evaluate(X_dtm[val_idx],train_df.loc[val_idx,cols_target])\n",
    "# (y_val == val_y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y.shape\n",
    "# len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "# Build the model\n",
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "# K.clear_session()\n",
    "# seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "# os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "# random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "# np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "# tf.random.set_seed(seed_value)\n",
    "def build_base_model():\n",
    "    K.clear_session()\n",
    "    seed_value = 0\n",
    "    tf.random.set_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    base_model = models.Sequential()\n",
    "    base_model.add(layers.Dense(1000, input_shape=(45000,)))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    base_model.add(layers.Activation('linear'))\n",
    "    base_model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Dense(2048))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.Activation('relu'))\n",
    "    # model.add(layers.Dense(512))\n",
    "    # # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.Activation('relu'))\n",
    "    # model.add(layers.Dense(128))\n",
    "    # # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.Activation('relu'))\n",
    "\n",
    "    # model.add(layers.Dropout(drop_ratio))\n",
    "    base_model.add(layers.Dense(20))\n",
    "    base_model.add(layers.Activation('softmax'))\n",
    "\n",
    "    base_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dtm[train_idx].shape\n",
    "# base_model\n",
    "# history = base_model.fit(x_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=10,\n",
    "#                     verbose=1,\n",
    "#                    validation_split = 0.1)\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback, ReduceLROnPlateau\n",
    "file_path = \"weights_base.best.hdf5\"\n",
    "def benchmark():\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "#     print(clf)\n",
    "#     t0 = time()\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "    models, preds, scores = [], [],[]\n",
    "#     vectorizer = vect(max_df = 0.5)\n",
    "    for train, test in skf.split(train_df.Text, train_df.Label):\n",
    "#     print(train, test)\n",
    "#     clf = LogisticRegression(penalty='l1')\n",
    "#         clf.fit(vectorizer.transform(), data_train.Label.loc[data_train.index.intersection(train)])\n",
    "#         K.clear_session()\n",
    "        clf = build_base_model()\n",
    "        X_train = train_df.Text.loc[train_df.index.intersection(train)]\n",
    "        X_val = train_df.Text.loc[train_df.index.intersection(test)]\n",
    "        y_train = train_df[cols_target].loc[train_df.index.intersection(train)]\n",
    "        y_val = train_df[cols_target].loc[train_df.index.intersection(test)]\n",
    "        X_train = vect.transform(X_train).toarray()\n",
    "        X_val = vect.transform(X_val).toarray()\n",
    "        X_test = vect.transform(test_df.Text).toarray()\n",
    "        \n",
    "        \n",
    "        \n",
    "        clf.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                   validation_data = (X_val,y_val),\n",
    "                   callbacks=[\n",
    "#               RocAucEvaluation(verbose=True),\n",
    "              ModelCheckpoint(file_path,    monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "              EarlyStopping(patience=10,    monitor=\"val_accuracy\", mode=\"max\"),\n",
    "              ReduceLROnPlateau(patience=4, monitor='val_accuracy', mode='max', cooldown=2, min_lr=1e-7, factor=0.3)])\n",
    "        preds.append(clf.predict(X_test))\n",
    "        models.append(clf)\n",
    "        scores.append(clf.evaluate(X_val,y_val))\n",
    "#         coefs.append(clf.coef_[0])\n",
    "#         clf.fit(X_train, y_train)\n",
    "#     train_time = time() - t0\n",
    "#     print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "#     t0 = time()\n",
    "#     pred = clf.predict(X_test)\n",
    "#     test_time = time() - t0\n",
    "#     print(\"test time:  %0.3fs\" % test_time)\n",
    "    pred = np.mean(preds,axis = 0)\n",
    "#     score = metrics.accuracy_score(data_test.Label, pred)\n",
    "#     print(\"accuracy:   %0.3f\" % score)\n",
    "    return models, pred,scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 17s 485ms/step - loss: 2.4265 - accuracy: 0.2570 - val_loss: 2.0137 - val_accuracy: 0.4965\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 16s 441ms/step - loss: 0.9121 - accuracy: 0.8476 - val_loss: 1.5483 - val_accuracy: 0.5660\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 16s 445ms/step - loss: 0.2105 - accuracy: 0.9852 - val_loss: 1.4089 - val_accuracy: 0.6042\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 16s 453ms/step - loss: 0.0562 - accuracy: 0.9965 - val_loss: 1.3679 - val_accuracy: 0.6111\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 13s 354ms/step - loss: 0.0271 - accuracy: 0.9974 - val_loss: 1.3533 - val_accuracy: 0.6076\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0207 - accuracy: 0.9983 - val_loss: 1.3456 - val_accuracy: 0.6146\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.0137 - accuracy: 0.9991 - val_loss: 1.3410 - val_accuracy: 0.6146\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 13s 349ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 1.3376 - val_accuracy: 0.6146\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 13s 356ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 1.3373 - val_accuracy: 0.6146\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 12s 346ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 1.3357 - val_accuracy: 0.6146\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.3357 - accuracy: 0.6146\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 17s 460ms/step - loss: 2.4225 - accuracy: 0.2594 - val_loss: 1.9056 - val_accuracy: 0.4843\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 16s 438ms/step - loss: 0.8867 - accuracy: 0.8503 - val_loss: 1.4251 - val_accuracy: 0.6272\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 17s 470ms/step - loss: 0.1887 - accuracy: 0.9878 - val_loss: 1.3182 - val_accuracy: 0.6481\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 16s 450ms/step - loss: 0.0454 - accuracy: 0.9991 - val_loss: 1.2889 - val_accuracy: 0.6516\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 14s 382ms/step - loss: 0.0233 - accuracy: 0.9991 - val_loss: 1.2741 - val_accuracy: 0.6411\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 12s 343ms/step - loss: 0.0156 - accuracy: 0.9991 - val_loss: 1.2667 - val_accuracy: 0.6376\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 12s 337ms/step - loss: 0.0131 - accuracy: 0.9983 - val_loss: 1.2649 - val_accuracy: 0.6376\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 1.2637 - val_accuracy: 0.6376\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 12s 345ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2627 - val_accuracy: 0.6376\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 12s 337ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2624 - val_accuracy: 0.6376\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.2624 - accuracy: 0.6376\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 16s 447ms/step - loss: 2.4322 - accuracy: 0.2681 - val_loss: 1.8922 - val_accuracy: 0.5122\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 16s 438ms/step - loss: 0.9213 - accuracy: 0.8268 - val_loss: 1.3763 - val_accuracy: 0.6411\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 15s 417ms/step - loss: 0.1967 - accuracy: 0.9896 - val_loss: 1.2398 - val_accuracy: 0.6585\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 15s 414ms/step - loss: 0.0491 - accuracy: 0.9983 - val_loss: 1.1999 - val_accuracy: 0.6760\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 12s 322ms/step - loss: 0.0257 - accuracy: 0.9974 - val_loss: 1.1837 - val_accuracy: 0.6725\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 12s 339ms/step - loss: 0.0186 - accuracy: 0.9983 - val_loss: 1.1760 - val_accuracy: 0.6690\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 12s 338ms/step - loss: 0.0160 - accuracy: 0.9983 - val_loss: 1.1692 - val_accuracy: 0.6690\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 13s 350ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 1.1655 - val_accuracy: 0.6690\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 13s 369ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 1.1643 - val_accuracy: 0.6690\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 1.1638 - val_accuracy: 0.6690\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.1638 - accuracy: 0.6690\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 18s 502ms/step - loss: 2.4094 - accuracy: 0.2611 - val_loss: 1.9011 - val_accuracy: 0.5087\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 16s 450ms/step - loss: 0.9175 - accuracy: 0.8303 - val_loss: 1.4163 - val_accuracy: 0.6063\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.2097 - accuracy: 0.9904 - val_loss: 1.2714 - val_accuracy: 0.6237\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 13s 353ms/step - loss: 0.0543 - accuracy: 0.9983 - val_loss: 1.2259 - val_accuracy: 0.6237\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 12s 340ms/step - loss: 0.0282 - accuracy: 0.9974 - val_loss: 1.2057 - val_accuracy: 0.6237\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 12s 323ms/step - loss: 0.0178 - accuracy: 0.9983 - val_loss: 1.1931 - val_accuracy: 0.6202\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 13s 360ms/step - loss: 0.0182 - accuracy: 0.9983 - val_loss: 1.1895 - val_accuracy: 0.6202\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 13s 369ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 1.1858 - val_accuracy: 0.6202\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 12s 337ms/step - loss: 0.0105 - accuracy: 0.9991 - val_loss: 1.1827 - val_accuracy: 0.6202\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 14s 380ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 1.1813 - val_accuracy: 0.6237\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.1813 - accuracy: 0.6237\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 16s 452ms/step - loss: 2.4147 - accuracy: 0.2628 - val_loss: 1.9662 - val_accuracy: 0.4948\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 17s 460ms/step - loss: 0.9217 - accuracy: 0.8259 - val_loss: 1.5137 - val_accuracy: 0.5784\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.2096 - accuracy: 0.9896 - val_loss: 1.3826 - val_accuracy: 0.6063\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 17s 469ms/step - loss: 0.0534 - accuracy: 0.9974 - val_loss: 1.3487 - val_accuracy: 0.6098\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 13s 365ms/step - loss: 0.0285 - accuracy: 0.9965 - val_loss: 1.3365 - val_accuracy: 0.6098\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 13s 358ms/step - loss: 0.0178 - accuracy: 0.9991 - val_loss: 1.3306 - val_accuracy: 0.6098\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 13s 357ms/step - loss: 0.0180 - accuracy: 0.9983 - val_loss: 1.3294 - val_accuracy: 0.6098\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 17s 471ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 1.3240 - val_accuracy: 0.6132\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 13s 368ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.3238 - val_accuracy: 0.6132\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 13s 354ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 1.3278 - val_accuracy: 0.6098\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.3278 - accuracy: 0.6098\n"
     ]
    }
   ],
   "source": [
    "# base_model.evaluate(x_val,y_val)\n",
    "# train_X.shape\n",
    "# (y_train == train_y).all()\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,cross_val_score,train_test_split,StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron,LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "base_models, pred,scores = benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.335684061050415, 0.6145833134651184],\n",
       " [1.2624201774597168, 0.6376306414604187],\n",
       " [1.1637887954711914, 0.6689895391464233],\n",
       " [1.1812516450881958, 0.6236934065818787],\n",
       " [1.3277735710144043, 0.6097561120986938]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x1dd41b4b608>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1dd41d2e608>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1dd423f9388>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1dd441a9508>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1dd479cafc8>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1dd49cc5148>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1dd39ecad48>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base_model.trainable = False\n",
    "# model.trainable = False\n",
    "base_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_ADHEtjTi</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AHfJktdQ</td>\n",
       "      <td>RELIGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AUJIHpZr</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AUKYBbIM</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AZnsVPEi</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ID_zdpOUWyJ</td>\n",
       "      <td>SOCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ID_zhnOomuu</td>\n",
       "      <td>RELATIONSHIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ID_zmWHvBJb</td>\n",
       "      <td>LAW/ORDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>ID_zphjdFIb</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ID_ztdtrNxt</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID          Label\n",
       "0    ID_ADHEtjTi  SOCIAL ISSUES\n",
       "1    ID_AHfJktdQ       RELIGION\n",
       "2    ID_AUJIHpZr  SOCIAL ISSUES\n",
       "3    ID_AUKYBbIM  SOCIAL ISSUES\n",
       "4    ID_AZnsVPEi  SOCIAL ISSUES\n",
       "..           ...            ...\n",
       "615  ID_zdpOUWyJ         SOCIAL\n",
       "616  ID_zhnOomuu  RELATIONSHIPS\n",
       "617  ID_zmWHvBJb      LAW/ORDER\n",
       "618  ID_zphjdFIb  SOCIAL ISSUES\n",
       "619  ID_ztdtrNxt       POLITICS\n",
       "\n",
       "[620 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train.shape\n",
    "# X_dtm\n",
    "# lb.inverse_transform(pred)\n",
    "# lb.inverse_transform(pd.DataFrame(pred,columns = cols_target)[lb.classes_].values)\n",
    "pred = np.mean(preds,axis = 0)\n",
    "\n",
    "test_df['Label']= lb.inverse_transform(pd.DataFrame(pred,columns = cols_target)[lb.classes_].values)\n",
    "sub = test_df[['ID', 'Label']]\n",
    "sub.to_csv('cross_enc_001.csv', index = False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"../Translated/cleaned/train.csv\")\n",
    "# test_df = pd.read_csv(\"../Translated/cleaned/test.csv\")\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_supermodel():\n",
    "    K.clear_session()\n",
    "\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "    random.seed(seed_value)\n",
    "\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "    input_trans = layers.Input(shape=(maxlen,))\n",
    "    input_tf = layers.Input(shape=(45000,))\n",
    "    output1 = []\n",
    "    for i, base_model in enumerate(base_models) : \n",
    "        base_model._name = 'base_model_'+str(i)\n",
    "        output1.append(base_model)\n",
    "    output_1 = [base_model(input_tf,training = False) for base_model in output1]\n",
    "\n",
    "    output_2 = [model(input_trans,training = False) for model in models_trans]\n",
    "\n",
    "    y = layers.Concatenate( name = 'output_1')(output_1)\n",
    "    x = layers.Concatenate()(output_2)\n",
    "    x = layers.Concatenate()([x,y])\n",
    "    # x = layers.Dense(1024, activation = 'linear')(x)\n",
    "    x = layers.Dense(512, activation = 'linear')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation = 'sigmoid')(x)\n",
    "    x = layers.Dense(128, activation = 'linear',kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    outputs = layers.Dense(20, activation=\"softmax\")(x)\n",
    "    super_model = keras.Model(inputs=[input_trans, input_tf], outputs=outputs)\n",
    "    super_model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return super_model\n",
    "# history = super_model.fit(\n",
    "#     [train_X,x_train], y_train, batch_size=32, epochs=19, validation_split = 0.1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_stack():\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "#     print(clf)\n",
    "#     t0 = time()\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "    models, preds, scores = [], [],[]\n",
    "#     vectorizer = vect(max_df = 0.5)\n",
    "    for train, test in skf.split(train_df.Text, train_df.Label):\n",
    "#     print(train, test)\n",
    "#     clf = LogisticRegression(penalty='l1')\n",
    "#         clf.fit(vectorizer.transform(), data_train.Label.loc[data_train.index.intersection(train)])\n",
    "#         K.clear_session()\n",
    "        clf = build_supermodel()\n",
    "        X_train = train_df.Text.loc[train_df.index.intersection(train)]\n",
    "        X_val = train_df.Text.loc[train_df.index.intersection(test)]\n",
    "        y_train = train_df[cols_target].loc[train_df.index.intersection(train)]\n",
    "        y_val = train_df[cols_target].loc[train_df.index.intersection(test)]\n",
    "        \n",
    "        X_train_ker = tokenizer.texts_to_sequences(X_train)\n",
    "        X_val_ker = tokenizer.texts_to_sequences(X_val)\n",
    "        X_test_ker = tokenizer.texts_to_sequences(test_df.Text)\n",
    "\n",
    "        ## Pad the sentences \n",
    "        X_train_ker = pad_sequences(X_train_ker, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        X_val_ker = pad_sequences(X_val_ker, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        X_test_ker = pad_sequences(X_test_ker, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        \n",
    "        X_train_tfidf = vect.transform(X_train).toarray()\n",
    "        X_val_tfidf = vect.transform(X_val).toarray()\n",
    "        X_test_tfidf = vect.transform(test_df.Text).toarray()\n",
    "        \n",
    "        \n",
    "        clf.fit([X_train_ker, X_train_tfidf], y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                   validation_data = ([X_val_ker, X_val_tfidf],y_val),\n",
    "                   callbacks=[\n",
    "#               RocAucEvaluation(verbose=True),\n",
    "              ModelCheckpoint(file_path,    monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "              EarlyStopping(patience=10,    monitor=\"val_accuracy\", mode=\"max\"),\n",
    "              ReduceLROnPlateau(patience=4, monitor='val_accuracy', mode='max', cooldown=2, min_lr=1e-7, factor=0.3)])\n",
    "        preds.append(clf.predict([X_test_ker,X_test_tfidf]))\n",
    "        models.append(clf)\n",
    "        scores.append(clf.evaluate([X_val_ker, X_val_tfidf],y_val))\n",
    "#         coefs.append(clf.coef_[0])\n",
    "#         clf.fit(X_train, y_train)\n",
    "#     train_time = time() - t0\n",
    "#     print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "#     t0 = time()\n",
    "#     pred = clf.predict(X_test)\n",
    "#     test_time = time() - t0\n",
    "#     print(\"test time:  %0.3fs\" % test_time)\n",
    "    pred = np.mean(preds,axis = 0)\n",
    "#     score = metrics.accuracy_score(data_test.Label, pred)\n",
    "#     print(\"accuracy:   %0.3f\" % score)\n",
    "    return models, pred,scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.9455 - accuracy: 0.7535"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 172. MiB for an array with shape (45000, 1000) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-ac160b531ac1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbenchmark_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-170-0d84fff91d45>\u001b[0m in \u001b[0;36mbenchmark_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m               \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m               \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"max\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m               ReduceLROnPlateau(patience=4, monitor='val_accuracy', mode='max', cooldown=2, min_lr=1e-7, factor=0.3)])\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_ker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[0;32m   1300\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \"\"\"\n\u001b[0;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1979\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m   def save_weights(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    129\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m    130\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 131\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mmodel_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# TODO(b/128683857): Add integration tests between tf.keras and external\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m     \u001b[0mweight_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[0mweight_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[0msave_attributes_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m   3516\u001b[0m   \"\"\"\n\u001b[0;32m   3517\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3518\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3519\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3520\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3516\u001b[0m   \"\"\"\n\u001b[0;32m   3517\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3518\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3519\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3520\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    606\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    610\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 172. MiB for an array with shape (45000, 1000) and data type float32"
     ]
    }
   ],
   "source": [
    "\n",
    "models, pred,scores = benchmark_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super_model.evaluate([val_X,x_val], y_val)\n",
    "# gsh = output_1[0]\n",
    "# x\n",
    "# gsh.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (y_val.values == val_y).all()\n",
    "# y_val.columns == lb.classes_\n",
    "# preds  = super_model.predict([test_X, test_X_dtm])\n",
    "# lb.inverse_transform(pd.DataFrame(preds,columns = cols_target)[lb.classes_].values)\n",
    "test_df['Label'] = lb.inverse_transform(pd.DataFrame(pred,columns = cols_target)[lb.classes_].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_ADHEtjTi</td>\n",
       "      <td>Abambo odzikhweza akuchuluka Kafukufuku wa ap...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AHfJktdQ</td>\n",
       "      <td>Ambuye Ziyaye Ayamikira Aphunzitsi a Tilitonse...</td>\n",
       "      <td>RELIGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AUJIHpZr</td>\n",
       "      <td>Anatcheleza: Akundiopseza a gogo wanga Akundi...</td>\n",
       "      <td>RELATIONSHIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AUKYBbIM</td>\n",
       "      <td>Ulova wafika posauzana Adatenga digiri ya uph...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AZnsVPEi</td>\n",
       "      <td>Dzombe kukoma, koma Kuyambira makedzana, pant...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ID_zdpOUWyJ</td>\n",
       "      <td>Kanyongolo Wapempha Oyimira Milandu Kuti Atsat...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ID_zhnOomuu</td>\n",
       "      <td>Amandimenya\\nZikomo gogo,\\nNdine mtsikana wa z...</td>\n",
       "      <td>RELATIONSHIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ID_zmWHvBJb</td>\n",
       "      <td>Apolisi athotha gulu la MYP Asilikali 56 a gu...</td>\n",
       "      <td>LAW/ORDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>ID_zphjdFIb</td>\n",
       "      <td>Mwambo wa ukwati wa Chitonga Mtundu wina uliw...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ID_ztdtrNxt</td>\n",
       "      <td>Mwapasa autsa mapiri Pamene pali kusamvana pa...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text  \\\n",
       "0    ID_ADHEtjTi   Abambo odzikhweza akuchuluka Kafukufuku wa ap...   \n",
       "1    ID_AHfJktdQ  Ambuye Ziyaye Ayamikira Aphunzitsi a Tilitonse...   \n",
       "2    ID_AUJIHpZr   Anatcheleza: Akundiopseza a gogo wanga Akundi...   \n",
       "3    ID_AUKYBbIM   Ulova wafika posauzana Adatenga digiri ya uph...   \n",
       "4    ID_AZnsVPEi   Dzombe kukoma, koma Kuyambira makedzana, pant...   \n",
       "..           ...                                                ...   \n",
       "615  ID_zdpOUWyJ  Kanyongolo Wapempha Oyimira Milandu Kuti Atsat...   \n",
       "616  ID_zhnOomuu  Amandimenya\\nZikomo gogo,\\nNdine mtsikana wa z...   \n",
       "617  ID_zmWHvBJb   Apolisi athotha gulu la MYP Asilikali 56 a gu...   \n",
       "618  ID_zphjdFIb   Mwambo wa ukwati wa Chitonga Mtundu wina uliw...   \n",
       "619  ID_ztdtrNxt   Mwapasa autsa mapiri Pamene pali kusamvana pa...   \n",
       "\n",
       "             Label  \n",
       "0    SOCIAL ISSUES  \n",
       "1         RELIGION  \n",
       "2    RELATIONSHIPS  \n",
       "3    SOCIAL ISSUES  \n",
       "4    SOCIAL ISSUES  \n",
       "..             ...  \n",
       "615       POLITICS  \n",
       "616  RELATIONSHIPS  \n",
       "617      LAW/ORDER  \n",
       "618  SOCIAL ISSUES  \n",
       "619       POLITICS  \n",
       "\n",
       "[620 rows x 3 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_X.shape\n",
    "sub = test_df[['ID','Label']]\n",
    "sub.to_csv('submission_keras_stack003A_reg3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub.Label == pd.read_csv('submission_keras_stack002.csv').Label).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
