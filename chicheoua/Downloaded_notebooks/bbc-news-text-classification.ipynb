{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification - BBC News Data\n",
    "\n",
    "## Overview\n",
    "\n",
    "The following notebook is created out of inspiration from the source [here](https://colab.research.google.com/github/srushtidhope/bbc-text-classification/blob/master/bbc_text_classification.ipynb#scrollTo=22L7TrqYtFiz) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/kaggle/input/bbc-fulltext-and-category/bbc-text.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# NLTK modules\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.models import Word2Vec # Word2Vec module\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_csv('/kaggle/input/bbc-fulltext-and-category/bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (2225, 2), \n",
      "\n",
      "Columns: Index(['category', 'text'], dtype='object'), \n",
      "\n",
      "Categories: ['tech' 'business' 'sport' 'entertainment' 'politics']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>business</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>politics</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>politics</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>sport</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "0              tech  tv future in the hands of viewers with home th...\n",
       "1          business  worldcom boss  left books alone  former worldc...\n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3             sport  yeading face newcastle in fa cup premiership s...\n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "2220       business  cars pull down us retail figures us retail sal...\n",
       "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
       "2223       politics  how political squabbles snowball it s become c...\n",
       "2224          sport  souness delight at euro progress boss graeme s..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Shape : {news_data.shape}, \\n\\nColumns: {news_data.columns}, \\n\\nCategories: {news_data.category.unique()}\")\n",
    "\n",
    "# print sample data\n",
    "news_data.head().append(news_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot category data\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(news_data.category)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    def __init__(self, data, column='text'):\n",
    "        self.df = data\n",
    "        self.column = column\n",
    "    \n",
    "    def preprocess(self):\n",
    "        self.tokenize()\n",
    "        self.remove_stopwords()\n",
    "        self.remove_non_words()\n",
    "        self.lemmatize_words()\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def tokenize(self):\n",
    "        self.df['clean_text'] = self.df[self.column].apply(nltk.word_tokenize)\n",
    "        print(\"Tokenization is done.\")\n",
    "    \n",
    "    def remove_stopwords(self):\n",
    "        stopword_set = set(nltk.corpus.stopwords.words('english'))\n",
    "        \n",
    "        rem_stopword = lambda words: [item for item in words if item not in stopword_set]\n",
    "        \n",
    "        self.df['clean_text'] = self.df['clean_text'].apply(rem_stopword)\n",
    "        print(\"Remove stopwords done.\")\n",
    "    \n",
    "    def remove_non_words(self):\n",
    "        \"\"\"\n",
    "            Remove all non alpha characters from the text data\n",
    "            :numbers: 0-9\n",
    "            :punctuation: All english punctuations\n",
    "            :special characters: All english special characters\n",
    "        \"\"\"\n",
    "        regpatrn = '[a-z]+'\n",
    "        rem_special_chars = lambda x: [item for item in x if re.match(regpatrn, item)]\n",
    "        self.df['clean_text'] = self.df['clean_text'].apply(rem_special_chars)\n",
    "        print(\"Removed non english characters is done.\")\n",
    "        \n",
    "    def lemmatize_words(self):\n",
    "        lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        \n",
    "        on_word_lemma = lambda x: [lemma.lemmatize(w, pos='v') for w in x]\n",
    "        \n",
    "        self.df['clean_text'] = self.df['clean_text'].apply(on_word_lemma)\n",
    "        print(\"Lemmatization on the words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization is done.\n",
      "Remove stopwords done.\n",
      "Removed non english characters is done.\n",
      "Lemmatization on the words.\n"
     ]
    }
   ],
   "source": [
    "data_prep = DataPreparation(news_data)\n",
    "\n",
    "cleanse_df = data_prep.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [tv, future, hand, viewers, home, theatre, sys...\n",
       "1       [worldcom, boss, leave, book, alone, former, w...\n",
       "2       [tigers, wary, farrell, gamble, leicester, say...\n",
       "3       [yeading, face, newcastle, fa, cup, premiershi...\n",
       "4       [ocean, twelve, raid, box, office, ocean, twel...\n",
       "                              ...                        \n",
       "2220    [cars, pull, us, retail, figure, us, retail, s...\n",
       "2221    [kilroy, unveil, immigration, policy, ex-chats...\n",
       "2222    [rem, announce, new, glasgow, concert, us, ban...\n",
       "2223    [political, squabble, snowball, become, common...\n",
       "2224    [souness, delight, euro, progress, boss, graem...\n",
       "Name: clean_text, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanse_df['clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_model = Word2Vec(cleanse_df['clean_text'])\n",
    "\n",
    "w2v = dict(zip(vec_model.wv.index2word, vec_model.wv.syn0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Custom Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    def __init__(self, vec):\n",
    "        self.vec = vec\n",
    "        self.dim = len(vec.values())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.vec[w] for w in words if w in self.vec] or [np.zeros(self.dim)], axis=0) for words in X])\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Classifier class\n",
    "class Classifier(object):\n",
    "    def __init__(self, model, param):\n",
    "        self.model = model\n",
    "        self.param = param\n",
    "        self.gsearch = GridSearchCV(self.model, self.param, cv=5, error_score=0, refit=True)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self.gsearch.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.gsearch.predict(X)\n",
    "\n",
    "clf_models = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'SVC': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SGD Classifier': SGDClassifier(),\n",
    "    'Perceptron': MLPClassifier()\n",
    "}\n",
    "\n",
    "clf_params = {\n",
    "    'Naive Bayes': {},\n",
    "    'SVC' : {'kernel': ['linear', 'rbf']},\n",
    "    'Decision Tree': {'min_samples_split': [2, 5]},\n",
    "    'SGD Classifier': { 'penalty': ['l2', 'l1', 'elasticnet'] },\n",
    "    'Perceptron': {'activation': ['tanh', 'relu']}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(cleanse_df['clean_text'], cleanse_df['category'], test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes :\n",
      "Accuracy: 0.919 \tPrecision: 0.920 \tRecall: 0.921 \tF1-Score: 0.920\n",
      "\n",
      "SVC :\n",
      "Accuracy: 0.915 \tPrecision: 0.914 \tRecall: 0.913 \tF1-Score: 0.912\n",
      "\n",
      "Decision Tree :\n",
      "Accuracy: 0.906 \tPrecision: 0.905 \tRecall: 0.906 \tF1-Score: 0.905\n",
      "\n",
      "SGD Classifier :\n",
      "Accuracy: 0.915 \tPrecision: 0.922 \tRecall: 0.910 \tF1-Score: 0.912\n",
      "\n",
      "Perceptron :\n",
      "Accuracy: 0.937 \tPrecision: 0.937 \tRecall: 0.937 \tF1-Score: 0.936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the model names\n",
    "for key in clf_models.keys():\n",
    "    \n",
    "    clf = Pipeline([('Word2Vec', Vectorizer(w2v)), ('Classifier', Classifier(clf_models[key], clf_params[key]))])\n",
    "    \n",
    "    # Fitting the data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_preds = clf.predict(X_valid)\n",
    "    \n",
    "    \n",
    "    print(key, \":\")\n",
    "    print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\tF1-Score: %1.3f\\n\" % (accuracy_score(y_valid, y_preds),\n",
    "                                                                                     precision_score(y_valid, y_preds, average='macro'),\n",
    "                                                                                     recall_score(y_valid, y_preds, average='macro'),\n",
    "                                                                                     f1_score(y_valid, y_preds, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(vector, X_train, X_test):\n",
    "    vector_fit = vector.fit(X_train)\n",
    "    \n",
    "    X_train_vec = vector_fit.transform(X_train)\n",
    "    X_test_vec = vector_fit.transform(X_test)\n",
    "    \n",
    "    print(\"Vectorization is completed.\")\n",
    "    return X_train_vec, X_test_vec\n",
    "\n",
    "def label_encoding(y_train):\n",
    "    \"\"\"\n",
    "        Encode the given list of class labels\n",
    "        :y_train_enc: returns list of encoded classes\n",
    "        :labels: actual class labels\n",
    "    \"\"\"\n",
    "    lbl_enc = LabelEncoder()\n",
    "    \n",
    "    y_train_enc = lbl_enc.fit_transform(y_train)\n",
    "    labels = lbl_enc.classes_\n",
    "    \n",
    "    return y_train_enc, labels\n",
    "\n",
    "def algorithm_stack(models, params, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('Keys do not match')\n",
    "        \n",
    "    for key in models.keys():\n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        \n",
    "        gs = GridSearchCV(model, param, cv=5, error_score=0, refit=True)\n",
    "        gs.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        print(key, \":\")\n",
    "        print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\tF1-Score: %1.3f\\n\" % (accuracy_score(y_test, y_pred),\n",
    "                                                                                     precision_score(y_test, y_pred, average='macro'),\n",
    "                                                                                     recall_score(y_test, y_pred, average='macro'),\n",
    "                                                                                     f1_score(y_test, y_pred, average='macro')))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization is completed.\n",
      "(1780, 26955) (445, 26955)\n"
     ]
    }
   ],
   "source": [
    "# Encode the class labels\n",
    "y_enc_train, labels = label_encoding(news_data['category'])\n",
    "\n",
    "# Split from the loaded dataset\n",
    "X_train, X_valid, y_train, y_test = train_test_split(news_data['text'], y_enc_train, test_size=0.2, shuffle=True)\n",
    "\n",
    "# TFIDFVectorizer \n",
    "X_train_vec, X_valid_vec = vectorize(TfidfVectorizer(), X_train, X_valid)\n",
    "\n",
    "print(X_train_vec.shape, X_valid_vec.shape)\n",
    "\n",
    "clf_models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVC': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SGD Classifier': SGDClassifier(),\n",
    "    'Perceptron': MLPClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "# Modified parameters\n",
    "clf_params = {\n",
    "    'Naive Bayes': {'alpha': [0.5, 1], 'fit_prior': [True, False] },\n",
    "    'SVC' : {'kernel': ['linear', 'rbf']},\n",
    "    'Decision Tree': {'min_samples_split': [1, 2, 5]},\n",
    "    'SGD Classifier': { 'penalty': ['l2', 'l1', 'elasticnet'] },\n",
    "    'Perceptron': {'alpha': [0.0001, 0.001], 'activation': ['tanh', 'relu']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 4, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes :\n",
      "Accuracy: 0.973 \tPrecision: 0.974 \tRecall: 0.970 \tF1-Score: 0.971\n",
      "\n",
      "SVC :\n",
      "Accuracy: 0.989 \tPrecision: 0.989 \tRecall: 0.988 \tF1-Score: 0.988\n",
      "\n",
      "Decision Tree :\n",
      "Accuracy: 0.834 \tPrecision: 0.833 \tRecall: 0.828 \tF1-Score: 0.830\n",
      "\n",
      "SGD Classifier :\n",
      "Accuracy: 0.984 \tPrecision: 0.984 \tRecall: 0.983 \tF1-Score: 0.984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithm_stack(clf_models, clf_params, X_train_vec, X_valid_vec, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
