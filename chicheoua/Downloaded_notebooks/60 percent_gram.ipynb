{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# \n",
    "# vect\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_df = pd.read_csv('../Translated/cleaned/train.csv')\n",
    "test_df = pd.read_csv('../Translated/cleaned/test.csv')\n",
    "cols_target = train_df.Label.unique().tolist()\n",
    "le = LabelEncoder()\n",
    "# y_train = lb.fit_transform(train_df['Label'])\n",
    "train_df['label'] = le.fit_transform(train_df['Label'])\n",
    "# y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "# y_train\n",
    "\n",
    "# train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "train_df\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "#     text = re.sub(r\"what's\", \"what is \", text)\n",
    "#     text = re.sub(r\"\\'s\", \" \", text)\n",
    "#     text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(r\"can't\", \"cannot \", text)\n",
    "#     text = re.sub(r\"n't\", \" not \", text)\n",
    "#     text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#     text = re.sub(r\"\\'re\", \" are \", text)\n",
    "#     text = re.sub(r\"\\'d\", \" would \", text)\n",
    "#     text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "#     text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "#     text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "train_df['Text'] = train_df['Text'].map(lambda com : clean_text(com))\n",
    "test_df['Text'] = test_df['Text'].map(lambda com : clean_text(com))\n",
    "X = train_df.Text\n",
    "test_X = test_df.Text\n",
    "# import and instantiate TfidfVectorizer\n",
    "other_stop_w = pd.read_csv('words_shared_by_all.csv')\n",
    "stopw = [item for sublist in other_stop_w.values.tolist() for item in sublist]\n",
    "tfidf_vect = TfidfVectorizer(max_features=15000,stop_words=stopw,ngram_range=(1, 3), max_df=0.8, min_df=1)\n",
    "count_vect = CountVectorizer(stop_words = stopw)\n",
    "\n",
    "X_tfidf = tfidf_vect.fit_transform(X)\n",
    "test_X_tfidf = tfidf_vect.transform(test_X)\n",
    "\n",
    "X_count = count_vect.fit_transform(X)\n",
    "test_X_count = count_vect.transform(test_X)\n",
    "\n",
    "# vectorizer\n",
    "\n",
    "# X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(X_tfidf, train_df['label'], test_size=0.2, random_state = 0,stratify = train_df['Label'])\n",
    "\n",
    "# X_count_train, X_count_test, y_count_train, y_count_test = train_test_split(X_count, train_df['label'], test_size=0.2, random_state = 0,stratify = train_df['Label'])\n",
    "\n",
    "# logreg_tfidf = LogisticRegression(C=12.0,max_iter = 1000,random_state = 0, multi_class = 'ovr', solver = 'liblinear')\n",
    "\n",
    "# logreg_count = LogisticRegression(C=12.0,max_iter = 1000,random_state = 0, multi_class = 'ovr', solver = 'liblinear')\n",
    "\n",
    "\n",
    "# logreg_tfidf.fit(X_tfidf_train,y_tfidf_train)\n",
    "\n",
    "# logreg_count.fit(X_count_train,y_count_train)\n",
    "\n",
    "# # precision_score(logreg_tfidf.predict(X_tfidf_test),y_tfidf_test, average=None)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['label']\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'label' : lb.classes_,\n",
    "#               'precision' : precision_score(logreg_tfidf.predict(X_tfidf_test),y_tfidf_test, average=None),\n",
    "#               'recall' : recall_score(logreg_tfidf.predict(X_tfidf_test),y_tfidf_test,average = None),\n",
    "#              'accuracy' : accuracy_score(logreg_tfidf.predict(X_tfidf_test),y_tfidf_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model_vect(count_vect, train_df,model,lb):\n",
    "# #     lb = LabelEncoder()\n",
    "#     y = lb.fit_transform(train_df['Label'])\n",
    "#     X = train_df.Text\n",
    "#     X_count = count_vect.fit_transform(X)\n",
    "#     X_count_train, X_count_test, y_count_train, y_count_test = train_test_split(X_count, y, test_size=0.2, random_state = 0,stratify = train_df['Label'])\n",
    "#     model.fit(X_count_train,y_count_train)\n",
    "#     results = pd.DataFrame({'label' : lb.classes_,\n",
    "#               'precision' : precision_score(model.predict(X_count_test),y_count_test, average=None),\n",
    "#               'recall' : recall_score(model.predict(X_count_test),y_count_test,average = None),\n",
    "#              'accuracy' : accuracy_score(model.predict(X_count_test),y_count_test)})\n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model_vect(tfidf_vect, train_df,logreg_tfidf,LabelEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_tfidf = LogisticRegression(C=12.0,max_iter = 1000,random_state = 0, solver = 'liblinear')\n",
    "# count_vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vectorizer = HashingVectorizer(n_features=10000,norm=None,alternate_sign=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model_vect(hash_vectorizer, train_df,logreg_tfidf,LabelEncoder())\n",
    "\n",
    "X_hash = hash_vectorizer.fit_transform(X)\n",
    "test_hash = hash_vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1436x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 260379 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "# Build the model\n",
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1000, input_shape=(15000,)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('linear'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(2048))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(512))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(128))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "\n",
    "# model.add(layers.Dropout(drop_ratio))\n",
    "model.add(layers.Dense(20))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_target = train_df.Label.unique().tolist()\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "# y_train\n",
    "\n",
    "train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "# train_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "19/19 [==============================] - 2s 111ms/step - loss: 2.6114 - accuracy: 0.2608 - val_loss: 2.2606 - val_accuracy: 0.2538\n",
      "Epoch 2/6\n",
      "19/19 [==============================] - 2s 105ms/step - loss: 1.6586 - accuracy: 0.5654 - val_loss: 1.7344 - val_accuracy: 0.5615\n",
      "Epoch 3/6\n",
      "19/19 [==============================] - 2s 105ms/step - loss: 1.0182 - accuracy: 0.7883 - val_loss: 1.4238 - val_accuracy: 0.6308\n",
      "Epoch 4/6\n",
      "19/19 [==============================] - 2s 105ms/step - loss: 0.5952 - accuracy: 0.8804 - val_loss: 1.2495 - val_accuracy: 0.6769\n",
      "Epoch 5/6\n",
      "19/19 [==============================] - 2s 104ms/step - loss: 0.3261 - accuracy: 0.9673 - val_loss: 1.1633 - val_accuracy: 0.6923\n",
      "Epoch 6/6\n",
      "19/19 [==============================] - 2s 106ms/step - loss: 0.1705 - accuracy: 0.9931 - val_loss: 1.1237 - val_accuracy: 0.6923\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.toarray(), y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=6,\n",
    "                    verbose=1,\n",
    "                   validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2355 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2354817390441895, 0.6666666865348816]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_X_tfidf.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SOCIAL ISSUES', 'RELIGION', 'RELATIONSHIPS', 'SOCIAL ISSUES',\n",
       "       'SOCIAL ISSUES', 'RELIGION', 'POLITICS', 'ECONOMY', 'POLITICS',\n",
       "       'POLITICS', 'SPORTS', 'SOCIAL', 'RELIGION', 'SOCIAL ISSUES',\n",
       "       'LAW/ORDER', 'POLITICS', 'HEALTH', 'ECONOMY', 'RELIGION', 'HEALTH',\n",
       "       'RELIGION', 'POLITICS', 'SOCIAL ISSUES', 'ECONOMY',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'RELIGION', 'RELIGION', 'FARMING',\n",
       "       'FARMING', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'SPORTS',\n",
       "       'WILDLIFE/ENVIRONMENT', 'HEALTH', 'POLITICS', 'POLITICS', 'HEALTH',\n",
       "       'SOCIAL ISSUES', 'SPORTS', 'POLITICS', 'SOCIAL', 'SOCIAL',\n",
       "       'RELIGION', 'CULTURE', 'WILDLIFE/ENVIRONMENT', 'LAW/ORDER',\n",
       "       'EDUCATION', 'RELATIONSHIPS', 'SOCIAL ISSUES', 'SOCIAL ISSUES',\n",
       "       'RELIGION', 'POLITICS', 'EDUCATION', 'POLITICS', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'SOCIAL ISSUES', 'POLITICS', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'HEALTH', 'POLITICS', 'LAW/ORDER',\n",
       "       'RELATIONSHIPS', 'HEALTH', 'ECONOMY', 'HEALTH', 'LAW/ORDER',\n",
       "       'MUSIC', 'HEALTH', 'LAW/ORDER', 'SOCIAL', 'SOCIAL ISSUES',\n",
       "       'FARMING', 'SPORTS', 'POLITICS', 'EDUCATION', 'ECONOMY',\n",
       "       'RELIGION', 'POLITICS', 'SOCIAL ISSUES', 'EDUCATION', 'POLITICS',\n",
       "       'POLITICS', 'SOCIAL', 'RELIGION', 'HEALTH', 'LOCALCHIEFS',\n",
       "       'SOCIAL', 'RELATIONSHIPS', 'SOCIAL ISSUES', 'SOCIAL ISSUES',\n",
       "       'LAW/ORDER', 'SOCIAL ISSUES', 'POLITICS', 'RELIGION', 'RELIGION',\n",
       "       'RELATIONSHIPS', 'SPORTS', 'LOCALCHIEFS', 'LAW/ORDER', 'SOCIAL',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'ECONOMY', 'LAW/ORDER', 'ECONOMY',\n",
       "       'POLITICS', 'EDUCATION', 'ECONOMY', 'POLITICS', 'HEALTH',\n",
       "       'RELIGION', 'SOCIAL ISSUES', 'RELIGION', 'RELIGION', 'LAW/ORDER',\n",
       "       'RELIGION', 'FARMING', 'ECONOMY', 'HEALTH', 'POLITICS',\n",
       "       'LAW/ORDER', 'POLITICS', 'LAW/ORDER', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'RELIGION', 'HEALTH', 'ECONOMY', 'POLITICS', 'ECONOMY',\n",
       "       'EDUCATION', 'SOCIAL ISSUES', 'SOCIAL', 'POLITICS', 'SOCIAL',\n",
       "       'RELIGION', 'SOCIAL ISSUES', 'FARMING', 'SOCIAL ISSUES',\n",
       "       'RELIGION', 'RELIGION', 'POLITICS', 'RELIGION', 'FARMING',\n",
       "       'POLITICS', 'POLITICS', 'SOCIAL ISSUES', 'POLITICS', 'POLITICS',\n",
       "       'POLITICS', 'SOCIAL', 'SOCIAL ISSUES', 'HEALTH', 'LAW/ORDER',\n",
       "       'POLITICS', 'POLITICS', 'LAW/ORDER', 'ECONOMY', 'ECONOMY',\n",
       "       'LOCALCHIEFS', 'RELIGION', 'SPORTS', 'SOCIAL', 'SPORTS',\n",
       "       'SOCIAL ISSUES', 'ECONOMY', 'LAW/ORDER', 'POLITICS', 'FARMING',\n",
       "       'RELIGION', 'SOCIAL ISSUES', 'HEALTH', 'SOCIAL', 'POLITICS',\n",
       "       'POLITICS', 'RELIGION', 'SOCIAL', 'ECONOMY', 'SOCIAL',\n",
       "       'SOCIAL ISSUES', 'RELIGION', 'FARMING', 'SOCIAL',\n",
       "       'WILDLIFE/ENVIRONMENT', 'POLITICS', 'ECONOMY', 'HEALTH',\n",
       "       'POLITICS', 'HEALTH', 'EDUCATION', 'HEALTH', 'SPORTS', 'SOCIAL',\n",
       "       'SOCIAL', 'SPORTS', 'POLITICS', 'POLITICS', 'SOCIAL', 'POLITICS',\n",
       "       'HEALTH', 'POLITICS', 'SOCIAL', 'RELATIONSHIPS', 'LAW/ORDER',\n",
       "       'SOCIAL', 'HEALTH', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'EDUCATION',\n",
       "       'POLITICS', 'HEALTH', 'SOCIAL', 'LAW/ORDER', 'SOCIAL',\n",
       "       'SOCIAL ISSUES', 'HEALTH', 'RELATIONSHIPS', 'LAW/ORDER', 'HEALTH',\n",
       "       'HEALTH', 'SPORTS', 'SOCIAL', 'POLITICS', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'HEALTH', 'ECONOMY', 'RELATIONSHIPS',\n",
       "       'POLITICS', 'SOCIAL', 'LAW/ORDER', 'SOCIAL', 'SOCIAL', 'LAW/ORDER',\n",
       "       'ECONOMY', 'RELATIONSHIPS', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'POLITICS', 'SPORTS', 'SOCIAL ISSUES', 'POLITICS', 'SOCIAL',\n",
       "       'POLITICS', 'RELIGION', 'HEALTH', 'SOCIAL ISSUES', 'SOCIAL',\n",
       "       'SOCIAL', 'POLITICS', 'SOCIAL ISSUES', 'LOCALCHIEFS', 'HEALTH',\n",
       "       'SPORTS', 'SOCIAL ISSUES', 'POLITICS', 'HEALTH', 'POLITICS',\n",
       "       'HEALTH', 'RELIGION', 'ECONOMY', 'SOCIAL ISSUES', 'LAW/ORDER',\n",
       "       'POLITICS', 'SOCIAL', 'RELIGION', 'POLITICS', 'OPINION/ESSAY',\n",
       "       'SOCIAL', 'POLITICS', 'POLITICS', 'WILDLIFE/ENVIRONMENT', 'HEALTH',\n",
       "       'RELATIONSHIPS', 'POLITICS', 'LAW/ORDER', 'POLITICS', 'SOCIAL',\n",
       "       'SOCIAL ISSUES', 'RELATIONSHIPS', 'ECONOMY', 'RELIGION',\n",
       "       'LAW/ORDER', 'LAW/ORDER', 'FARMING', 'POLITICS', 'LAW/ORDER',\n",
       "       'CULTURE', 'POLITICS', 'SOCIAL ISSUES', 'POLITICS', 'POLITICS',\n",
       "       'POLITICS', 'HEALTH', 'POLITICS', 'LAW/ORDER', 'SOCIAL ISSUES',\n",
       "       'HEALTH', 'SOCIAL', 'HEALTH', 'LAW/ORDER', 'FARMING', 'LAW/ORDER',\n",
       "       'WILDLIFE/ENVIRONMENT', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'SPORTS',\n",
       "       'POLITICS', 'RELIGION', 'POLITICS', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'ECONOMY', 'ECONOMY', 'LAW/ORDER', 'FARMING', 'POLITICS', 'HEALTH',\n",
       "       'FARMING', 'SOCIAL', 'POLITICS', 'FARMING', 'SOCIAL ISSUES',\n",
       "       'RELIGION', 'SOCIAL ISSUES', 'RELIGION', 'RELIGION', 'CULTURE',\n",
       "       'SOCIAL', 'EDUCATION', 'SOCIAL ISSUES', 'ECONOMY', 'SOCIAL ISSUES',\n",
       "       'ECONOMY', 'MUSIC', 'POLITICS', 'HEALTH', 'HEALTH', 'HEALTH',\n",
       "       'RELIGION', 'POLITICS', 'POLITICS', 'SOCIAL', 'RELIGION',\n",
       "       'SOCIAL ISSUES', 'ECONOMY', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'LAW/ORDER', 'ECONOMY', 'SOCIAL ISSUES', 'ECONOMY',\n",
       "       'SOCIAL ISSUES', 'HEALTH', 'POLITICS', 'RELIGION', 'POLITICS',\n",
       "       'FARMING', 'POLITICS', 'RELIGION', 'RELIGION', 'FARMING',\n",
       "       'FARMING', 'FARMING', 'SOCIAL ISSUES', 'SOCIAL', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'LAW/ORDER', 'RELIGION', 'SOCIAL', 'HEALTH',\n",
       "       'POLITICS', 'POLITICS', 'POLITICS', 'POLITICS', 'SPORTS',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'ECONOMY', 'HEALTH', 'LAW/ORDER',\n",
       "       'LAW/ORDER', 'SOCIAL', 'POLITICS', 'WILDLIFE/ENVIRONMENT',\n",
       "       'POLITICS', 'SOCIAL ISSUES', 'LAW/ORDER', 'LAW/ORDER', 'POLITICS',\n",
       "       'HEALTH', 'HEALTH', 'ECONOMY', 'POLITICS', 'LAW/ORDER',\n",
       "       'WILDLIFE/ENVIRONMENT', 'RELATIONSHIPS', 'EDUCATION', 'SOCIAL',\n",
       "       'POLITICS', 'POLITICS', 'FARMING', 'SOCIAL', 'SOCIAL ISSUES',\n",
       "       'POLITICS', 'SOCIAL', 'RELIGION', 'POLITICS', 'HEALTH', 'RELIGION',\n",
       "       'RELIGION', 'LAW/ORDER', 'RELIGION', 'POLITICS', 'POLITICS',\n",
       "       'LAW/ORDER', 'LAW/ORDER', 'POLITICS', 'LAW/ORDER', 'ECONOMY',\n",
       "       'LAW/ORDER', 'ECONOMY', 'RELIGION', 'RELIGION', 'POLITICS',\n",
       "       'HEALTH', 'POLITICS', 'LAW/ORDER', 'RELIGION', 'HEALTH',\n",
       "       'POLITICS', 'HEALTH', 'FARMING', 'RELIGION', 'HEALTH', 'ECONOMY',\n",
       "       'LAW/ORDER', 'SPORTS', 'POLITICS', 'SOCIAL ISSUES', 'SOCIAL',\n",
       "       'POLITICS', 'POLITICS', 'POLITICS', 'SPORTS',\n",
       "       'WILDLIFE/ENVIRONMENT', 'RELIGION', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'SPORTS', 'POLITICS', 'POLITICS', 'SOCIAL ISSUES', 'SOCIAL ISSUES',\n",
       "       'SOCIAL', 'LAW/ORDER', 'POLITICS', 'LOCALCHIEFS', 'SOCIAL ISSUES',\n",
       "       'POLITICS', 'LAW/ORDER', 'HEALTH', 'HEALTH', 'EDUCATION',\n",
       "       'POLITICS', 'HEALTH', 'POLITICS', 'FARMING', 'POLITICS',\n",
       "       'POLITICS', 'SOCIAL', 'ECONOMY', 'RELATIONSHIPS', 'SOCIAL',\n",
       "       'SOCIAL', 'POLITICS', 'POLITICS', 'LAW/ORDER', 'SOCIAL ISSUES',\n",
       "       'ECONOMY', 'POLITICS', 'RELIGION', 'SOCIAL', 'SOCIAL', 'HEALTH',\n",
       "       'EDUCATION', 'EDUCATION', 'SOCIAL ISSUES', 'RELIGION', 'RELIGION',\n",
       "       'SOCIAL', 'LAW/ORDER', 'LAW/ORDER', 'FARMING', 'LAW/ORDER',\n",
       "       'SPORTS', 'POLITICS', 'SOCIAL ISSUES', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'ECONOMY', 'FARMING', 'HEALTH', 'SOCIAL', 'WILDLIFE/ENVIRONMENT',\n",
       "       'FARMING', 'LAW/ORDER', 'RELIGION', 'FARMING', 'POLITICS',\n",
       "       'RELIGION', 'WILDLIFE/ENVIRONMENT', 'POLITICS', 'HEALTH',\n",
       "       'RELATIONSHIPS', 'SOCIAL', 'SPORTS', 'LAW/ORDER', 'RELIGION',\n",
       "       'LAW/ORDER', 'POLITICS', 'POLITICS', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'HEALTH', 'ECONOMY', 'FARMING', 'LAW/ORDER', 'SOCIAL', 'SOCIAL',\n",
       "       'POLITICS', 'RELIGION', 'SOCIAL', 'FARMING', 'SOCIAL', 'POLITICS',\n",
       "       'LOCALCHIEFS', 'POLITICS', 'RELIGION', 'POLITICS',\n",
       "       'WILDLIFE/ENVIRONMENT', 'WILDLIFE/ENVIRONMENT', 'FARMING',\n",
       "       'SOCIAL ISSUES', 'LAW/ORDER', 'HEALTH', 'ECONOMY', 'RELIGION',\n",
       "       'SOCIAL', 'ECONOMY', 'RELIGION', 'SOCIAL', 'HEALTH', 'SPORTS',\n",
       "       'RELIGION', 'RELATIONSHIPS', 'RELATIONSHIPS', 'POLITICS',\n",
       "       'LOCALCHIEFS', 'POLITICS', 'POLITICS', 'SOCIAL ISSUES', 'RELIGION',\n",
       "       'POLITICS', 'POLITICS', 'ECONOMY', 'RELIGION', 'POLITICS',\n",
       "       'RELIGION', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'SOCIAL', 'SOCIAL',\n",
       "       'ECONOMY', 'SOCIAL', 'POLITICS', 'RELIGION', 'SOCIAL', 'POLITICS',\n",
       "       'FARMING', 'LAW/ORDER', 'SPORTS', 'POLITICS', 'SOCIAL', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'SPORTS', 'LAW/ORDER', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'ECONOMY', 'RELIGION', 'LAW/ORDER', 'ECONOMY',\n",
       "       'SPORTS', 'POLITICS', 'RELIGION', 'FARMING', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'SOCIAL', 'SPORTS', 'SOCIAL ISSUES', 'ECONOMY',\n",
       "       'SOCIAL ISSUES', 'LOCALCHIEFS', 'ECONOMY', 'POLITICS', 'LAW/ORDER',\n",
       "       'SOCIAL', 'RELATIONSHIPS', 'LAW/ORDER', 'SOCIAL ISSUES',\n",
       "       'POLITICS'], dtype='<U20')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.inverse_transform(pd.DataFrame(preds,columns = cols_target)[lb.classes_].values)\n",
    "# lb.classes_\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Label'] = lb.inverse_transform(pd.DataFrame(preds,columns = cols_target)[lb.classes_].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test_df[['ID','Label']]\n",
    "sub.to_csv('submission_keras_gram.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
