{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d5221cf58859cd6496cf4294414a3bc37d4c95f"
   },
   "source": [
    "In this kernel, I have implemented the encoder part of the transformer architecture as mentioned in the famous paper: Attention is all you need.(https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "Many of other codes are adopted from other kernels. For example, loading the embeddings,  load the training and test data and preprocessing, etc. I really appreciate their contributions.\n",
    "\n",
    "p.s. When I run this locally, I get validation f1-score around 0.688.\n",
    "\n",
    "Happy transforming!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a947373c706a15ed71a686d92703b9677561894"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.layers import BatchNormalization, InputSpec, add\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, activations\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b37e0d09f42f5bc5ad73a366580f6b778c9aad5a"
   },
   "source": [
    "## Some pre-configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c7498e1cc6e3dd7e7c58f24e10fd5ad1b06b4489"
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 45000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 400 # max number of words in a question to use\n",
    "n_heads = 4 # Number of heads as in Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "05385c91a5e5603c346bfe53010aa4cb0f3ddd4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1436, 3)\n",
      "Test shape :  (620, 2)\n"
     ]
    }
   ],
   "source": [
    "# def load_and_prec():\n",
    "train_df = pd.read_csv(\"../Translated/cleaned/train.csv\")\n",
    "test_df = pd.read_csv(\"../Translated/cleaned/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "cols_target = train_df.Label.unique().tolist()\n",
    "\n",
    "## split to train and val\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=0,shuffle = True) # hahaha\n",
    "train_X, val_X, train_y , val_y = train_test_split(train_df, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])\n",
    "\n",
    "trn_idx = train_y.index.tolist()\n",
    "val_idx = val_y.index.tolist()\n",
    "\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_X[\"Text\"].fillna(\"_##_\").values\n",
    "val_X = val_X[\"Text\"].fillna(\"_##_\").values\n",
    "test_X = test_df[\"Text\"].fillna(\"_##_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_y.values\n",
    "val_y = val_y.values  \n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "#shuffling the data\n",
    "# np.random.seed(2018)\n",
    "# trn_idx = np.random.permutation(len(train_X))\n",
    "# val_idx = np.random.permutation(len(val_X))\n",
    "\n",
    "# train_X = train_X[trn_idx]\n",
    "# val_X = val_X[val_idx]\n",
    "# train_y = train_y[trn_idx]\n",
    "# val_y = val_y[val_idx]    \n",
    "\n",
    "#     return train_X, val_X, test_X, train_y, val_y, tokenizer.word_index,val_idx , trn_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20682431e22eab3cbf634777cb0d2bc2730ab754"
   },
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "cf6dc22b3b2a9f2ec94f70e2aa5dfe36f6f142d3"
   },
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.005838499,0.48782197\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix \n",
    "    \n",
    "def load_fasttext(word_index):    \n",
    "    EMBEDDING_FILE = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "def load_para(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.0053247833,0.49346462\n",
    "    embed_size = all_embs.shape[1]\n",
    "    print(emb_mean,emb_std,\"para\")\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a35ee76c0f926bcdf817fcb91dbd20ee90007f06"
   },
   "source": [
    "## Scaled Dot-product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "92c050cb313508d5c88b288dd1561493bcfacbed"
   },
   "outputs": [],
   "source": [
    "class DotProdSelfAttention(Layer):\n",
    "    \"\"\"The self-attention layer as in 'Attention is all you need'.\n",
    "    paper reference: https://arxiv.org/abs/1706.03762\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, units,\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(DotProdSelfAttention, self).__init__(*kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        input_dim = input_shape[-1]\n",
    "        # We assume the output-dim of Q, K, V are the same\n",
    "        self.kernels = dict.fromkeys(['Q', 'K', 'V'])\n",
    "        for key, _ in self.kernels.items():\n",
    "            self.kernels[key] = self.add_weight(shape=(input_dim, self.units),\n",
    "                                                initializer=self.kernel_initializer,\n",
    "                                                name='kernel_{}'.format(key),\n",
    "                                                regularizer=self.kernel_regularizer,\n",
    "                                                constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            raise NotImplementedError\n",
    "        super(DotProdSelfAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        Q = K.dot(x, self.kernels['Q'])\n",
    "        K_mat = K.dot(x, self.kernels['K'])\n",
    "        V = K.dot(x, self.kernels['V'])\n",
    "        attention = K.batch_dot(Q, K.permute_dimensions(K_mat, [0, 2, 1]))\n",
    "        d_k = K.constant(self.units, dtype=K.floatx())\n",
    "        attention = attention / K.sqrt(d_k)\n",
    "        attention = K.batch_dot(K.softmax(attention, axis=-1), V)\n",
    "        return attention\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) >= 2\n",
    "        assert input_shape[-1]\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d931bd69e53756c2f8aa8cf63d07d4c7eb02a8d9"
   },
   "source": [
    "## The Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "399ddb0b7367ac0f6bd4121396b24ac3a6d1edfe"
   },
   "outputs": [],
   "source": [
    "def encoder(input_tensor):\n",
    "    \"\"\"One encoder as in Attention Is All You Need\n",
    "    \"\"\"\n",
    "    # Sub-layer 1\n",
    "    # Multi-Head Attention\n",
    "    multiheads = []\n",
    "    d_v = embed_size // n_heads\n",
    "    for i in range(n_heads):\n",
    "        multiheads.append(DotProdSelfAttention(d_v)(input_tensor))\n",
    "    multiheads = concatenate(multiheads, axis=-1)\n",
    "    multiheads = Dense(embed_size)(multiheads)\n",
    "    multiheads = Dropout(0.5)(multiheads)\n",
    "    \n",
    "    # Residual Connection\n",
    "    res_con = add([input_tensor, multiheads])\n",
    "    # Didn't use layer normalization, use Batch Normalization instead here\n",
    "#     res_con = BatchNormalization(axis=-1)(res_con)\n",
    "    \n",
    "    # Sub-layer 2\n",
    "    # 2 Feed forward layer\n",
    "    ff1 = Dense(400, activation='relu')(res_con)\n",
    "    ff2 = Dense(embed_size)(ff1)\n",
    "    output = add([res_con, ff2])\n",
    "#     output = BatchNormalization(axis=-1)(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8740be2622e8195ed3f0c7d9568a06ddb64cd98b"
   },
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "8bd0cd11b96080f965195da697ba34c865f5b7e2"
   },
   "outputs": [],
   "source": [
    "# https://github.com/kpot/keras-transformer/blob/master/keras_transformer/position.py\n",
    "def positional_signal(hidden_size: int, length: int,\n",
    "                      min_timescale: float = 1.0, max_timescale: float = 1e4):\n",
    "    \"\"\"\n",
    "    Helper function, constructing basic positional encoding.\n",
    "    The code is partially based on implementation from Tensor2Tensor library\n",
    "    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py\n",
    "    \"\"\"\n",
    "\n",
    "    if hidden_size % 2 != 0:\n",
    "        raise ValueError(\n",
    "            f\"The hidden dimension of the model must be divisible by 2.\"\n",
    "            f\"Currently it is {hidden_size}\")\n",
    "    position = K.arange(0, length, dtype=K.floatx())\n",
    "    num_timescales = hidden_size // 2\n",
    "    log_timescale_increment = K.constant(\n",
    "        (np.log(float(max_timescale) / float(min_timescale)) /\n",
    "         (num_timescales - 1)),\n",
    "        dtype=K.floatx())\n",
    "    inv_timescales = (\n",
    "            min_timescale *\n",
    "            K.exp(K.arange(num_timescales, dtype=K.floatx()) *\n",
    "                  -log_timescale_increment))\n",
    "    scaled_time = K.expand_dims(position, 1) * K.expand_dims(inv_timescales, 0)\n",
    "    signal = K.concatenate([K.sin(scaled_time), K.cos(scaled_time)], axis=1)\n",
    "    return K.expand_dims(signal, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "309135be6416acde8d5088af910eee3597e25d4e"
   },
   "outputs": [],
   "source": [
    "# https://github.com/kpot/keras-transformer/blob/master/keras_transformer/position.py\n",
    "class AddPositionalEncoding(Layer):\n",
    "    \"\"\"\n",
    "    Injects positional encoding signal described in section 3.5 of the original\n",
    "    paper \"Attention is all you need\". Also a base class for more complex\n",
    "    coordinate encoding described in \"Universal Transformers\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_timescale: float = 1.0,\n",
    "                 max_timescale: float = 1.0e4, **kwargs):\n",
    "        self.min_timescale = min_timescale\n",
    "        self.max_timescale = max_timescale\n",
    "        self.signal = None\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['min_timescale'] = self.min_timescale\n",
    "        config['max_timescale'] = self.max_timescale\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, length, hidden_size = input_shape\n",
    "        self.signal = positional_signal(\n",
    "            hidden_size, length, self.min_timescale, self.max_timescale)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return inputs + self.signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "312bd7b8472de749134273fead7f939a234c551c"
   },
   "source": [
    "## Transformer Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "235ae9ecb6873475900b1ad88e3a07a161195370"
   },
   "outputs": [],
   "source": [
    "def model_transformer( n_encoder=3):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, trainable=True)(inp)\n",
    "    # Add positional encoding\n",
    "    x = AddPositionalEncoding()(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "    for i in range(n_encoder):\n",
    "        x = encoder(x)\n",
    "    # These are my own experiments\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "#     conc = Dense(512, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.9)(conc)\n",
    "    outp = Dense(20, activation=\"softmax\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.recurrent_v2.LSTM"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "e2f42600ff37e6c286215562afc11a1be28f0981"
   },
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class BaseDataGenerator(Sequence):\n",
    "    \"\"\"A data generator\"\"\"\n",
    "    def __init__(self, list_IDs, batch_size=64, shuffle=True):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"number of steps in one epoch\"\"\"\n",
    "        # Here is the trick\n",
    "        return len(self.list_IDs) // (self.batch_size * 2**2)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size: (index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' \n",
    "        X = train_X[list_IDs_temp, :]\n",
    "        y = train_y[list_IDs_temp]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee0611a48264188ec3063bc6c6ce221eb3724d8e"
   },
   "source": [
    "### Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c9d6121293c82701f3c07ae00f396564d8aa2c9"
   },
   "source": [
    "Here I used early stopping and model checkpoint to load the best_val model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "5f90446889d864f0a318d305eca2d3a04d1baa55"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
    "def train_pred(model, epochs=2):\n",
    "    # learning schedule callback\n",
    "#     loss_history = LossHistory()\n",
    "#     lrate = BatchLRScheduler(step_decay)\n",
    "#     callbacks_list = [loss_history, lrate]\n",
    "#     es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
    "#     model_path = 'keras_models.h5'\n",
    "#     mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True)\n",
    "#     callbacks = [es, mc]\n",
    "#     train_generator = BaseDataGenerator(list(np.arange(train_X.shape[0])), batch_size=512)\n",
    "#     model.fit_generator(train_generator,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(val_X, val_y),)\n",
    "#                         callbacks=callbacks)\n",
    "#     model = load_model(model_path)\n",
    "    model.fit(train_X, train_y, batch_size=64,\n",
    "              epochs=epochs,\n",
    "              validation_data=(val_X, val_y),)\n",
    "\n",
    "    pred_val_y = model.predict([val_X], batch_size=64, verbose=0)\n",
    "    pred_test_y = model.predict([test_X], batch_size=64, verbose=0)\n",
    "    return pred_val_y, pred_test_y, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9b632c9bea6c5e8c7e111fc97474fc9d8b099c4"
   },
   "source": [
    "### Main part: load, train, pred and blend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_uuid": "6ddf2ae0c374759ef040db80346faaf609850e58"
   },
   "outputs": [],
   "source": [
    "# train_X, val_X, test_X, train_y, val_y, word_index,val_idx,trn_idx = load_and_prec()\n",
    "vocab = []\n",
    "for w,k in word_index.items():\n",
    "    vocab.append(w)\n",
    "    if k >= max_features:\n",
    "        break\n",
    "# embedding_matrix_1 = load_glove(word_index)\n",
    "# embedding_matrix_2 = load_fasttext(word_index)\n",
    "# embedding_matrix_3 = load_para(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ffc83124a9f220b31e698b922cad56d59f8c83e5"
   },
   "source": [
    "### Create New Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "622e0a2f777d15a9f74b3d1d56a0e5ad60ee90bc"
   },
   "outputs": [],
   "source": [
    "## Simple average: http://aclweb.org/anthology/N18-2031\n",
    "\n",
    "# We have presented an argument for averaging as\n",
    "# a valid meta-embedding technique, and found experimental\n",
    "# performance to be close to, or in some cases \n",
    "# better than that of concatenation, with the\n",
    "# additional benefit of reduced dimensionality  \n",
    "\n",
    "\n",
    "## Unweighted DME in https://arxiv.org/pdf/1804.07983.pdf\n",
    "\n",
    "# “The downside of concatenating embeddings and \n",
    "#  giving that as input to an RNN encoder, however,\n",
    "#  is that the network then quickly becomes inefficient\n",
    "#  as we combine more and more embeddings.”\n",
    "  \n",
    "# embedding_matrix = np.mean([embedding_matrix_1, embedding_matrix_2, embedding_matrix_3], axis = 0)\n",
    "# embedding_matrix = np.mean([embedding_matrix_1, embedding_matrix_3], axis = 0)\n",
    "# np.shape(embedding_matrix)\n",
    "# model.evaluate(val_X,val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52627f8490364ed29f81e574c49af644726701e1"
   },
   "source": [
    "## Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3270c045c747a7c5da32704e6db44c18f470646"
   },
   "source": [
    "Here I am experimenting with 2 encoders, it's not guaranteed to be optimal, you can try out other numbers. Notice that I used epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "573d8e65c007aefd1fb4a0deef16e73894327486"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "# outputs[0][1]\n",
    "# type(train_X[0][0])\n",
    "# val_X\n",
    "# train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(train_X,train_y)\n",
    "# train_X.shape\n",
    "# train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "091d7915c8c00d088d60c09c306298950cd2afe6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 8.7639 - accuracy: 0.0890 - val_loss: 3.3834 - val_accuracy: 0.1944\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 5.4486 - accuracy: 0.1084 - val_loss: 2.6550 - val_accuracy: 0.1944\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 4.6336 - accuracy: 0.1122 - val_loss: 2.5991 - val_accuracy: 0.2361\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 4.1545 - accuracy: 0.1161 - val_loss: 2.5915 - val_accuracy: 0.1875\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.9720 - accuracy: 0.0975 - val_loss: 2.5809 - val_accuracy: 0.2292\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 3.6905 - accuracy: 0.1169 - val_loss: 2.5537 - val_accuracy: 0.1944\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.6317 - accuracy: 0.1045 - val_loss: 2.5422 - val_accuracy: 0.2431\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.5936 - accuracy: 0.1176 - val_loss: 2.5162 - val_accuracy: 0.2569\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.3932 - accuracy: 0.1424 - val_loss: 2.5140 - val_accuracy: 0.1944\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.3794 - accuracy: 0.1122 - val_loss: 2.5217 - val_accuracy: 0.2431\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.2293 - accuracy: 0.1293 - val_loss: 2.4981 - val_accuracy: 0.2569\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.1867 - accuracy: 0.1533 - val_loss: 2.4704 - val_accuracy: 0.2431\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.1099 - accuracy: 0.1354 - val_loss: 2.4588 - val_accuracy: 0.2708\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 3.0407 - accuracy: 0.1703 - val_loss: 2.4408 - val_accuracy: 0.2361\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.9285 - accuracy: 0.1641 - val_loss: 2.4977 - val_accuracy: 0.2500\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.9493 - accuracy: 0.1594 - val_loss: 2.3980 - val_accuracy: 0.2708\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.8567 - accuracy: 0.1749 - val_loss: 2.3726 - val_accuracy: 0.2639\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.8337 - accuracy: 0.1943 - val_loss: 2.3699 - val_accuracy: 0.2569\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.7064 - accuracy: 0.1997 - val_loss: 2.2677 - val_accuracy: 0.2847\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.5748 - accuracy: 0.2546 - val_loss: 2.1897 - val_accuracy: 0.2778\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.4056 - accuracy: 0.2964 - val_loss: 2.1168 - val_accuracy: 0.3125\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 30845s 1469s/step - loss: 2.1951 - accuracy: 0.3382 - val_loss: 2.0833 - val_accuracy: 0.4167\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 34s 2s/step - loss: 1.9767 - accuracy: 0.3731 - val_loss: 2.2229 - val_accuracy: 0.3125\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 34s 2s/step - loss: 1.9556 - accuracy: 0.4149 - val_loss: 2.1206 - val_accuracy: 0.3889\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.6777 - accuracy: 0.4768 - val_loss: 2.0974 - val_accuracy: 0.4167\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.5012 - accuracy: 0.5379 - val_loss: 2.2303 - val_accuracy: 0.4792\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.2938 - accuracy: 0.5975 - val_loss: 2.3036 - val_accuracy: 0.4722\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 1.0725 - accuracy: 0.6796 - val_loss: 2.4845 - val_accuracy: 0.4097\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.9852 - accuracy: 0.7152 - val_loss: 2.6429 - val_accuracy: 0.4722\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.7821 - accuracy: 0.7786 - val_loss: 2.7806 - val_accuracy: 0.4583\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.6279 - accuracy: 0.8243 - val_loss: 3.0853 - val_accuracy: 0.4653\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.5145 - accuracy: 0.8483 - val_loss: 3.1521 - val_accuracy: 0.4931\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.4503 - accuracy: 0.8715 - val_loss: 3.1535 - val_accuracy: 0.4653\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.3247 - accuracy: 0.9048 - val_loss: 3.5954 - val_accuracy: 0.4653\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.3045 - accuracy: 0.9149 - val_loss: 3.6057 - val_accuracy: 0.4653\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.2306 - accuracy: 0.9334 - val_loss: 3.9547 - val_accuracy: 0.4653\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.2010 - accuracy: 0.9435 - val_loss: 4.1607 - val_accuracy: 0.4583\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1650 - accuracy: 0.9497 - val_loss: 4.2376 - val_accuracy: 0.4653\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1625 - accuracy: 0.9481 - val_loss: 4.9109 - val_accuracy: 0.4514\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.1243 - accuracy: 0.9613 - val_loss: 4.8606 - val_accuracy: 0.4306\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.1052 - accuracy: 0.9652 - val_loss: 5.2603 - val_accuracy: 0.4028\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.1127 - accuracy: 0.9659 - val_loss: 4.6917 - val_accuracy: 0.4444\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.1145 - accuracy: 0.9644 - val_loss: 5.0767 - val_accuracy: 0.4236\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.1636 - accuracy: 0.9567 - val_loss: 5.3634 - val_accuracy: 0.4306\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.1051 - accuracy: 0.9667 - val_loss: 4.7153 - val_accuracy: 0.3958\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.1068 - accuracy: 0.9714 - val_loss: 5.2291 - val_accuracy: 0.4444\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.0650 - accuracy: 0.9822 - val_loss: 5.4342 - val_accuracy: 0.3958\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0441 - accuracy: 0.9845 - val_loss: 5.3720 - val_accuracy: 0.4306\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0374 - accuracy: 0.9845 - val_loss: 6.0868 - val_accuracy: 0.4028\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0463 - accuracy: 0.9837 - val_loss: 5.7171 - val_accuracy: 0.4306\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 5.8156 - val_accuracy: 0.4375\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 6.1301 - val_accuracy: 0.4583\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 37s 2s/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 6.1946 - val_accuracy: 0.4583\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0374 - accuracy: 0.9892 - val_loss: 6.2362 - val_accuracy: 0.4722\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 5.8025 - val_accuracy: 0.4097\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0354 - accuracy: 0.9876 - val_loss: 7.5285 - val_accuracy: 0.4167\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0599 - accuracy: 0.9830 - val_loss: 6.8732 - val_accuracy: 0.4306\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0799 - accuracy: 0.9776 - val_loss: 6.8281 - val_accuracy: 0.3889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0764 - accuracy: 0.9768 - val_loss: 7.1893 - val_accuracy: 0.4306\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0444 - accuracy: 0.9899 - val_loss: 6.7761 - val_accuracy: 0.4375\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 6.7755 - val_accuracy: 0.4444\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0402 - accuracy: 0.9845 - val_loss: 6.8021 - val_accuracy: 0.4792\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0234 - accuracy: 0.9915 - val_loss: 7.5617 - val_accuracy: 0.4444\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 5.7041 - val_accuracy: 0.4444\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 6.9855 - val_accuracy: 0.4444\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 7.1801 - val_accuracy: 0.4514\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0398 - accuracy: 0.9907 - val_loss: 6.4843 - val_accuracy: 0.4375\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0343 - accuracy: 0.9899 - val_loss: 8.1551 - val_accuracy: 0.4167\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 8.1490 - val_accuracy: 0.4653\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 8.7432 - val_accuracy: 0.4236\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 7.6865 - val_accuracy: 0.3889\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0507 - accuracy: 0.9899 - val_loss: 7.4064 - val_accuracy: 0.4792\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0467 - accuracy: 0.9899 - val_loss: 6.3273 - val_accuracy: 0.4514\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0827 - accuracy: 0.9830 - val_loss: 9.2589 - val_accuracy: 0.4028\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1380 - accuracy: 0.9729 - val_loss: 6.5733 - val_accuracy: 0.4444\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0896 - accuracy: 0.9745 - val_loss: 6.8795 - val_accuracy: 0.4167\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1889 - accuracy: 0.9706 - val_loss: 7.9842 - val_accuracy: 0.3889\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.2815 - accuracy: 0.9528 - val_loss: 7.8359 - val_accuracy: 0.3958\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1838 - accuracy: 0.9698 - val_loss: 9.6225 - val_accuracy: 0.4514\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1841 - accuracy: 0.9605 - val_loss: 9.2991 - val_accuracy: 0.3819\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.2114 - accuracy: 0.9628 - val_loss: 9.8592 - val_accuracy: 0.3611\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.2091 - accuracy: 0.9613 - val_loss: 12.0192 - val_accuracy: 0.4167\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1949 - accuracy: 0.9706 - val_loss: 8.7071 - val_accuracy: 0.4722\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1618 - accuracy: 0.9706 - val_loss: 11.4006 - val_accuracy: 0.3750\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1891 - accuracy: 0.9644 - val_loss: 9.5896 - val_accuracy: 0.3889\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1900 - accuracy: 0.9714 - val_loss: 11.2902 - val_accuracy: 0.3681\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.2958 - accuracy: 0.9675 - val_loss: 14.1318 - val_accuracy: 0.3611\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1725 - accuracy: 0.9667 - val_loss: 13.1171 - val_accuracy: 0.3958\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.2312 - accuracy: 0.9621 - val_loss: 12.1192 - val_accuracy: 0.4028\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0548 - accuracy: 0.9907 - val_loss: 12.2895 - val_accuracy: 0.5139\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0625 - accuracy: 0.9884 - val_loss: 11.6161 - val_accuracy: 0.4792\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0551 - accuracy: 0.9876 - val_loss: 13.7872 - val_accuracy: 0.3889\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0978 - accuracy: 0.9814 - val_loss: 15.3371 - val_accuracy: 0.3958\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1362 - accuracy: 0.9822 - val_loss: 11.9303 - val_accuracy: 0.3611\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1559 - accuracy: 0.9768 - val_loss: 11.8604 - val_accuracy: 0.3819\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1599 - accuracy: 0.9791 - val_loss: 14.7858 - val_accuracy: 0.3889\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0899 - accuracy: 0.9853 - val_loss: 14.7358 - val_accuracy: 0.4028\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1137 - accuracy: 0.9845 - val_loss: 17.1700 - val_accuracy: 0.4167\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.1094 - accuracy: 0.9876 - val_loss: 14.2747 - val_accuracy: 0.4028\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 36s 2s/step - loss: 0.0926 - accuracy: 0.9853 - val_loss: 16.4822 - val_accuracy: 0.4306\n"
     ]
    }
   ],
   "source": [
    "n_encoder = 1\n",
    "pred_val_y, pred_test_y, model = train_pred(model_transformer(n_encoder=n_encoder), epochs = 100)\n",
    "outputs.append([pred_val_y, pred_test_y, 'transformer_enc{}'.format(n_encoder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "e3dc6e5362fa13e00b291986b94ea9d6e5acdebf"
   },
   "outputs": [],
   "source": [
    "# for thresh in np.arange(0.1, 0.51, 0.01):\n",
    "#     thresh = np.round(thresh, 2)\n",
    "#     print(\"F1 score at threshold {0:.2f} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "43e0969fd3af4b65decfbba8cce0a8a36d552176"
   },
   "outputs": [],
   "source": [
    "# pred_test_y = (pred_test_y > 0.42).astype(int)\n",
    "# test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"qid\"])\n",
    "# out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "# out_df['prediction'] = pred_test_y\n",
    "# out_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "c378fe1cfd53529831f3928fb9866329eb7a9184"
   },
   "outputs": [],
   "source": [
    "# idx = (pred_test_y > 0.42).astype(int)\n",
    "# test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"qid\"])\n",
    "# out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "# out_df['prediction'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "c378fe1cfd53529831f3928fb9866329eb7a9184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2607 - accuracy: 0.6389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2606784105300903, 0.6388888955116272]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mylist = out_df[out_df.prediction == 1].index\n",
    "# for i in mylist:\n",
    "#     print(i, end=',')\n",
    "\n",
    "# Stacking\n",
    "model.evaluate(val_X,val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a3b5a15d3745fa2ffb2e0bfd1c98ba890e27550"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model)\n",
    "# train_df = pd.read_csv(\"../Translated/cleaned/train.csv\")\n",
    "# test_df = pd.read_csv(\"../Translated/cleaned/test.csv\")\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "#     text = re.sub(r\"what's\", \"what is \", text)\n",
    "#     text = re.sub(r\"\\'s\", \" \", text)\n",
    "#     text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(r\"can't\", \"cannot \", text)\n",
    "#     text = re.sub(r\"n't\", \" not \", text)\n",
    "#     text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#     text = re.sub(r\"\\'re\", \" are \", text)\n",
    "#     text = re.sub(r\"\\'d\", \" would \", text)\n",
    "#     text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "#     text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "#     text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub(r\",\", \" \", text) \n",
    "    text = re.sub(r\"!\", \" \", text) \n",
    "    text = re.sub(r\"\\(\", \" \", text) \n",
    "    text = re.sub(r\"\\)\", \" \", text) \n",
    "    text = re.sub(r\"\\?\", \" \", text) \n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)  \n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "# removing stop words\n",
    "# other_stop_w = pd.read_csv('../Downloaded_notebooks/words_shared_by_all.csv')\n",
    "# stopw = [item for sublist in other_stop_w.values.tolist() for item in sublist]\n",
    "# train_df['Text'].apply(lambda x: [item for item in x.split() if item not in stopw])\n",
    "# test_df['Text'].apply(lambda x: [item for item in x.split() if item not in stopw])\n",
    "\n",
    "train_df['Text'] = train_df['Text'].map(lambda com : clean_text(com))\n",
    "test_df['Text'] = test_df['Text'].map(lambda com : clean_text(com))\n",
    "X_tfidf = train_df.Text\n",
    "test_X_tfidf = test_df.Text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features=45000,max_df = 0.7)\n",
    "\n",
    "X_dtm = vect.fit_transform(X_tfidf).toarray()\n",
    "\n",
    "test_X_dtm = vect.transform(test_X_tfidf).toarray()\n",
    "\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# lb = LabelBinarizer()\n",
    "# y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "# y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "# # y_train\n",
    "# cols_target = train_df['Label'].unique().tolist()\n",
    "# train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "# # train_df\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_dtm, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS                True\n",
       "HEALTH                  True\n",
       "LAW/ORDER               True\n",
       "RELIGION                True\n",
       "FARMING                 True\n",
       "WILDLIFE/ENVIRONMENT    True\n",
       "SOCIAL ISSUES           True\n",
       "SOCIAL                  True\n",
       "OPINION/ESSAY           True\n",
       "LOCALCHIEFS             True\n",
       "WITCHCRAFT              True\n",
       "ECONOMY                 True\n",
       "SPORTS                  True\n",
       "RELATIONSHIPS           True\n",
       "TRANSPORT               True\n",
       "CULTURE                 True\n",
       "EDUCATION               True\n",
       "MUSIC                   True\n",
       "ARTS AND CRAFTS         True\n",
       "FLOODING                True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_idx = list(set(X_tfidf.index.tolist()) - set(val_idx.tolist()))\n",
    "# base_model.evaluate(X_dtm[val_idx],train_df.loc[val_idx,cols_target])\n",
    "(y_val == val_y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y.shape\n",
    "# len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "# Build the model\n",
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(1000, input_shape=(45000,)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "base_model.add(layers.Activation('linear'))\n",
    "base_model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(2048))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(512))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(128))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "\n",
    "# model.add(layers.Dropout(drop_ratio))\n",
    "base_model.add(layers.Dense(20))\n",
    "base_model.add(layers.Activation('softmax'))\n",
    "\n",
    "base_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 6s 298ms/step - loss: 2.5904 - accuracy: 0.2134 - val_loss: 2.2687 - val_accuracy: 0.2077\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 5s 263ms/step - loss: 1.4264 - accuracy: 0.6842 - val_loss: 1.7228 - val_accuracy: 0.5692\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 5s 263ms/step - loss: 0.6325 - accuracy: 0.9088 - val_loss: 1.4262 - val_accuracy: 0.6385\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 5s 262ms/step - loss: 0.2310 - accuracy: 0.9845 - val_loss: 1.2858 - val_accuracy: 0.6538\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 5s 263ms/step - loss: 0.0898 - accuracy: 0.9966 - val_loss: 1.2228 - val_accuracy: 0.6462\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 5s 264ms/step - loss: 0.0457 - accuracy: 0.9966 - val_loss: 1.2045 - val_accuracy: 0.6538\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 5s 265ms/step - loss: 0.0301 - accuracy: 0.9966 - val_loss: 1.1900 - val_accuracy: 0.6462\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 5s 288ms/step - loss: 0.0239 - accuracy: 0.9966 - val_loss: 1.1784 - val_accuracy: 0.6538\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 5s 263ms/step - loss: 0.0179 - accuracy: 0.9983 - val_loss: 1.1692 - val_accuracy: 0.6462\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 5s 262ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 1.1611 - val_accuracy: 0.6538\n"
     ]
    }
   ],
   "source": [
    "# X_dtm[train_idx].shape\n",
    "history = base_model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                   validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.evaluate(x_val,y_val)\n",
    "# train_X.shape\n",
    "# (y_train == train_y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292, 45000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "37/37 [==============================] - 2s 64ms/step - loss: 1.7874 - accuracy: 0.5818 - val_loss: 1.2212 - val_accuracy: 0.7923\n",
      "Epoch 2/19\n",
      "37/37 [==============================] - 2s 59ms/step - loss: 0.4061 - accuracy: 0.9484 - val_loss: 0.5617 - val_accuracy: 0.9000\n",
      "Epoch 3/19\n",
      "37/37 [==============================] - 2s 61ms/step - loss: 0.1155 - accuracy: 0.9888 - val_loss: 0.3947 - val_accuracy: 0.9385\n",
      "Epoch 4/19\n",
      "37/37 [==============================] - 3s 73ms/step - loss: 0.0444 - accuracy: 0.9991 - val_loss: 0.3312 - val_accuracy: 0.9231\n",
      "Epoch 5/19\n",
      "37/37 [==============================] - 2s 59ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9462\n",
      "Epoch 6/19\n",
      "37/37 [==============================] - 2s 61ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 0.2640 - val_accuracy: 0.9308\n",
      "Epoch 7/19\n",
      "37/37 [==============================] - 2s 67ms/step - loss: 0.0094 - accuracy: 0.9991 - val_loss: 0.2433 - val_accuracy: 0.9308\n",
      "Epoch 8/19\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.2346 - val_accuracy: 0.9308\n",
      "Epoch 9/19\n",
      "37/37 [==============================] - 2s 60ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.2222 - val_accuracy: 0.9308\n",
      "Epoch 10/19\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9462\n",
      "Epoch 11/19\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.2150 - val_accuracy: 0.9308\n",
      "Epoch 12/19\n",
      "37/37 [==============================] - 2s 60ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9385\n",
      "Epoch 13/19\n",
      "37/37 [==============================] - 2s 59ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1982 - val_accuracy: 0.9385\n",
      "Epoch 14/19\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.1941 - val_accuracy: 0.9385\n",
      "Epoch 15/19\n",
      "37/37 [==============================] - 2s 60ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1962 - val_accuracy: 0.9308\n",
      "Epoch 16/19\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.1869 - val_accuracy: 0.9538\n",
      "Epoch 17/19\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.2008 - val_accuracy: 0.9308\n",
      "Epoch 18/19\n",
      "37/37 [==============================] - 2s 58ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.1837 - val_accuracy: 0.9538\n",
      "Epoch 19/19\n",
      "37/37 [==============================] - 2s 67ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.1806 - val_accuracy: 0.9538\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"../Translated/cleaned/train.csv\")\n",
    "# test_df = pd.read_csv(\"../Translated/cleaned/test.csv\")\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "input_trans = layers.Input(shape=(maxlen,))\n",
    "input_tf = layers.Input(shape=(45000,))\n",
    "output_1 = base_model(input_tf,training = False)\n",
    "output_2 = model(input_trans,training = False)\n",
    "x = layers.Concatenate()([output_1,output_2])\n",
    "# x = layers.Dense(1024, activation = 'linear')(x)\n",
    "x = layers.Dense(512, activation = 'linear')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "x = layers.Dense(256, activation = 'sigmoid')(x)\n",
    "x = layers.Dense(128, activation = 'linear')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "outputs = layers.Dense(20, activation=\"softmax\")(x)\n",
    "super_model = keras.Model(inputs=[input_trans, input_tf], outputs=outputs)\n",
    "super_model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = super_model.fit(\n",
    "    [train_X,x_train], y_train, batch_size=32, epochs=19, validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 38ms/step - loss: 1.8374 - accuracy: 0.6806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8373671770095825, 0.6805555820465088]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_model.evaluate([val_X,x_val], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (y_val.values == val_y).all()\n",
    "# y_val.columns == lb.classes_\n",
    "preds  = super_model.predict([test_X, test_X_dtm])\n",
    "# lb.inverse_transform(pd.DataFrame(preds,columns = cols_target)[lb.classes_].values)\n",
    "test_df['Label'] = lb.inverse_transform(pd.DataFrame(preds,columns = cols_target)[lb.classes_].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_X.shape\n",
    "sub = test_df[['ID','Label']]\n",
    "sub.to_csv('submission_keras_stack003.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub.Label == pd.read_csv('submission_keras_stack002.csv').Label).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
