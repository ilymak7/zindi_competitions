{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "train_df = pd.read_csv('../Translated/cleaned/train.csv')\n",
    "test_df = pd.read_csv('../Translated/cleaned/test.csv')\n",
    "cols_target = train_df.Label.unique().tolist()\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "y_train\n",
    "\n",
    "train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "train_df\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "#     text = re.sub(r\"what's\", \"what is \", text)\n",
    "#     text = re.sub(r\"\\'s\", \" \", text)\n",
    "#     text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(r\"can't\", \"cannot \", text)\n",
    "#     text = re.sub(r\"n't\", \" not \", text)\n",
    "#     text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#     text = re.sub(r\"\\'re\", \" are \", text)\n",
    "#     text = re.sub(r\"\\'d\", \" would \", text)\n",
    "#     text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "#     text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "#     text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "train_df['Text'] = train_df['Text'].map(lambda com : clean_text(com))\n",
    "test_df['Text'] = test_df['Text'].map(lambda com : clean_text(com))\n",
    "X = train_df.Text\n",
    "test_X = test_df.Text\n",
    "# import and instantiate TfidfVectorizer\n",
    "other_stop_w = pd.read_csv('words_shared_by_all.csv')\n",
    "stopw = [item for sublist in other_stop_w.values.tolist() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[cols_target] = 0\n",
    "# pd.DataFrame(y_train, columns= lb.classes_)\n",
    "s = pd.DataFrame(0, index=np.arange(test_df.shape[0]), columns=lb.classes_)\n",
    "s['ID'] = test_df['ID']\n",
    "s['Text'] = test_df['Text']\n",
    "s = s[['ID', 'Text']+list(lb.classes_)]\n",
    "# pd.concat([test_df, ],ignore_index = True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing POLITICS\n",
      "Validation accuracy is 0.9305555555555556\n",
      "... Processing HEALTH\n",
      "Validation accuracy is 0.9409722222222222\n",
      "... Processing LAW/ORDER\n",
      "Validation accuracy is 0.9236111111111112\n",
      "... Processing RELIGION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is 0.9340277777777778\n",
      "... Processing FARMING\n",
      "Validation accuracy is 0.9791666666666666\n",
      "... Processing WILDLIFE/ENVIRONMENT\n",
      "Validation accuracy is 0.9652777777777778\n",
      "... Processing SOCIAL ISSUES\n",
      "Validation accuracy is 0.9131944444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing SOCIAL\n",
      "Validation accuracy is 0.8715277777777778\n",
      "... Processing OPINION/ESSAY\n",
      "Validation accuracy is 0.9930555555555556\n",
      "... Processing LOCALCHIEFS\n",
      "Validation accuracy is 0.9965277777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing WITCHCRAFT\n",
      "Validation accuracy is 0.9895833333333334\n",
      "... Processing ECONOMY\n",
      "Validation accuracy is 0.9305555555555556\n",
      "... Processing SPORTS\n",
      "Validation accuracy is 0.9861111111111112\n",
      "... Processing RELATIONSHIPS\n",
      "Validation accuracy is 0.9895833333333334\n",
      "... Processing TRANSPORT\n",
      "Validation accuracy is 0.9930555555555556\n",
      "... Processing CULTURE\n",
      "Validation accuracy is 0.9826388888888888\n",
      "... Processing EDUCATION\n",
      "Validation accuracy is 0.9861111111111112\n",
      "... Processing MUSIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is 0.9930555555555556\n",
      "... Processing ARTS AND CRAFTS\n",
      "Validation accuracy is 0.9930555555555556\n",
      "... Processing FLOODING\n",
      "Validation accuracy is 0.9930555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features=5000,stop_words=stopw)\n",
    "# vect\n",
    "\n",
    "X_dtm = vect.fit_transform(X)\n",
    "# examine the document-term matrix created from X_train\n",
    "# X_dtm\n",
    "\n",
    "test_X_dtm = vect.transform(test_X)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection, naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dtm, train_df[cols_target], test_size=0.2, random_state = 0,shuffle = True)\n",
    "\n",
    "logreg = LogisticRegression(C=12.0,random_state = 0)\n",
    "# logreg = SVC(C = 12.0,probability = True, random_state = 0)\n",
    "\n",
    "# create submission file\n",
    "submission_binary_train = train_df[['ID']+cols_target]\n",
    "\n",
    "for label in cols_target:\n",
    "    print('... Processing {}'.format(label))\n",
    "    y = y_train[label]\n",
    "    # train the model using X_dtm & y\n",
    "    logreg.fit(X_train, y)\n",
    "    # compute the training accuracy\n",
    "    y_pred_X = logreg.predict(X_test)\n",
    "    print('Validation accuracy is {}'.format(accuracy_score(y_test[label], y_pred_X)))\n",
    "    # compute the predicted probabilities for X_test_dtm\n",
    "    test_y_prob = logreg.predict_proba(X_dtm)[:,1]\n",
    "    submission_binary_train[label] = test_y_prob\n",
    "#     test_y_prob = logreg.predict_proba(X_dtm)[:,1]\n",
    "    test_y_prob2 = logreg.predict_proba(test_X_dtm)[:,1]\n",
    "    s[label] = test_y_prob2\n",
    "#   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_nb = le.fit_transform(train_df['Label'])\n",
    "X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X_dtm, y_train_nb, test_size=0.2, random_state = 0,shuffle = True)\n",
    "nb = naive_bayes.ComplementNB()\n",
    "nb.fit(X_train_nb,y_train_nb)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb.score(X_test_nb, y_test_nb)\n",
    "X_train_nb = nb.predict_proba(X_dtm)\n",
    "X_test_nb = nb.predict_proba(test_X_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s['SOCIAL ISSUES']\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Concatenate,Bidirectional,BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Build the model\n",
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "%matplotlib inline\n",
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,300,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "#     layer = Dense(20,name='lstm_layer')(layer)\n",
    "#     layer = Activation('linear')(layer)\n",
    "    lin_reg = Input(name='lin_reg',shape=[20])\n",
    "    naive_ba = Input(name='naive_ba',shape=[20])\n",
    "#     conc1 = Concatenate()([naive_ba, lin_reg])\n",
    "#     layer = Concatenate()([layer, conc1])\n",
    "    layer = Dense(512,name='FC1')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('selu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(100,name='FC2')(layer)\n",
    "    layer = Activation('selu')(layer)\n",
    "    \n",
    "    layer = Dense(20,name='out_layer')(layer)\n",
    "    layer = Activation('softmax')(layer)\n",
    "    model = Model(inputs=[inputs, lin_reg,naive_ba],outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 300\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 300, 300)     1500000     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FC1 (Dense)                     (None, 512)          33280       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        FC1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "FC2 (Dense)                     (None, 100)          51300       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100)          0           FC2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "out_layer (Dense)               (None, 20)           2020        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lin_reg (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "naive_ba (InputLayer)           [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20)           0           out_layer[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,682,088\n",
      "Trainable params: 1,681,064\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 12s 2s/step - loss: 2.9733 - accuracy: 0.1142 - val_loss: 2.8239 - val_accuracy: 0.1992\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 13s 2s/step - loss: 1.5802 - accuracy: 0.5487 - val_loss: 2.7429 - val_accuracy: 0.2270\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.6565 - accuracy: 0.8189 - val_loss: 2.7573 - val_accuracy: 0.2563\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.2356 - accuracy: 0.9526 - val_loss: 2.7859 - val_accuracy: 0.1964\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0964 - accuracy: 0.9903 - val_loss: 2.8146 - val_accuracy: 0.2019\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0464 - accuracy: 0.9958 - val_loss: 2.8458 - val_accuracy: 0.1741\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0297 - accuracy: 0.9986 - val_loss: 2.8577 - val_accuracy: 0.1769\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.0227 - accuracy: 0.9986 - val_loss: 2.9382 - val_accuracy: 0.1086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b5ffacf88>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([sequences_matrix, submission_binary_train[cols_target].values, X_train_nb],train_df[cols_target],batch_size=128,epochs=50,\n",
    "          validation_split=0.5,callbacks=[EarlyStopping(monitor='val_accuracy',min_delta=0.0001,patience = 5),\n",
    "                                          ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_accuracy', mode='max')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tok.texts_to_sequences(test_X)\n",
    "sequences_matrix_test = sequence.pad_sequences(sequences_test,maxlen=max_len)\n",
    "preds = model.predict([sequences_matrix_test, s[cols_target].values, X_test_nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 8s 183ms/step - loss: 2.3475 - accuracy: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3475162982940674, 0.8913649320602417]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test\n",
    "# X\n",
    "# \n",
    "# ss = pd.read_csv('../data/SampleSubmission.csv')\n",
    "model.evaluate([sequences_matrix, submission_binary_train[cols_target].values, X_train_nb],train_df[cols_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['Label'] = lb.inverse_transform((pd.DataFrame(preds,columns = cols_target))[lb.classes_].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('submissionstack2.csv', index = False)\n",
    "# ss.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_ADHEtjTi</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AHfJktdQ</td>\n",
       "      <td>RELIGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AUJIHpZr</td>\n",
       "      <td>RELATIONSHIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AUKYBbIM</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AZnsVPEi</td>\n",
       "      <td>HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ID_zdpOUWyJ</td>\n",
       "      <td>HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ID_zhnOomuu</td>\n",
       "      <td>RELATIONSHIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ID_zmWHvBJb</td>\n",
       "      <td>HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>ID_zphjdFIb</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ID_ztdtrNxt</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID          Label\n",
       "0    ID_ADHEtjTi  SOCIAL ISSUES\n",
       "1    ID_AHfJktdQ       RELIGION\n",
       "2    ID_AUJIHpZr  RELATIONSHIPS\n",
       "3    ID_AUKYBbIM  SOCIAL ISSUES\n",
       "4    ID_AZnsVPEi         HEALTH\n",
       "..           ...            ...\n",
       "615  ID_zdpOUWyJ         HEALTH\n",
       "616  ID_zhnOomuu  RELATIONSHIPS\n",
       "617  ID_zmWHvBJb         HEALTH\n",
       "618  ID_zphjdFIb  SOCIAL ISSUES\n",
       "619  ID_ztdtrNxt       POLITICS\n",
       "\n",
       "[620 rows x 2 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
