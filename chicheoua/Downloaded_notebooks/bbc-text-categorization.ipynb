{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "_uuid": "6e33d72836cf1df501fe5c7d4df38f8131b72b80",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1529968185252,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "ZCXNyqFq7vY8",
    "outputId": "ec7dfb3c-88e1-478b-ec4a-08a667fa5698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have TensorFlow version 2.3.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "\n",
    "\n",
    "# This code was tested with TensorFlow v1.8\n",
    "print(\"You have TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a068e9906a1b8c0fc8fc3145b064467135a212f",
    "colab_type": "text",
    "id": "m6si-xluXrW6"
   },
   "source": [
    "## Get the data\n",
    "The data has been exported from BigQuery and is stored on GCS, and can be access directly via \n",
    "\n",
    "  `!gsutil cp gs://dataset-uploader/bbc/bbc-text.csv .`\n",
    "\n",
    "It can also be accessed via https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "_uuid": "3def70f0527177e1e6fdfd024b79804402e9c088",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1529968248939,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "PBJ8CTYL7vZD",
    "outputId": "f0cb9078-369b-4f39-d1b5-a2bb4936a392"
   },
   "outputs": [],
   "source": [
    "TRAIN_FILEPATH = \"../Translated/cleaned/train.csv\"\n",
    "TEST_FILEPATH = \"../Translated/cleaned/test.csv\"\n",
    "SS_FILEPATH = \"../data/SampleSubmission.csv\"\n",
    "VECTORS_FILEPATH = \"\"\n",
    "data = pd.read_csv(TRAIN_FILEPATH)\n",
    "test = pd.read_csv(TEST_FILEPATH)\n",
    "ss = pd.read_csv(SS_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "_uuid": "6e09deecd8c20bb3bd2bb792b0622f6d128410d0",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1529968252342,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "CBtXsyqr7vZG",
    "outputId": "91407087-b090-414d-8c18-acae82d9a26e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AASHwXxg</td>\n",
       "      <td>Mwangonde: Khansala wachinyamata Akamati achi...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AGoFySzn</td>\n",
       "      <td>MCP siidakhutire ndi kalembera Chipani cha Ma...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AGrrkBGP</td>\n",
       "      <td>Bungwe la MANEPO Lapempha Boma Liganizire Anth...</td>\n",
       "      <td>HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AIJeigeG</td>\n",
       "      <td>Ndale zogawanitsa miyambo zanyanya Si zachile...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_APMprMbV</td>\n",
       "      <td>Nanga wapolisi ataphofomoka? Masiku ano sichi...</td>\n",
       "      <td>LAW/ORDER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text      Label\n",
       "0  ID_AASHwXxg   Mwangonde: Khansala wachinyamata Akamati achi...   POLITICS\n",
       "1  ID_AGoFySzn   MCP siidakhutire ndi kalembera Chipani cha Ma...   POLITICS\n",
       "2  ID_AGrrkBGP  Bungwe la MANEPO Lapempha Boma Liganizire Anth...     HEALTH\n",
       "3  ID_AIJeigeG   Ndale zogawanitsa miyambo zanyanya Si zachile...   POLITICS\n",
       "4  ID_APMprMbV   Nanga wapolisi ataphofomoka? Masiku ano sichi...  LAW/ORDER"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "_uuid": "483f40036cdc496a43796b88046874c12c19cb76",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1529968259350,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "CUw2hqtv7vZK",
    "outputId": "609cf652-d7d3-4d3c-bd0b-3457a1d891c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS                279\n",
       "SOCIAL                  152\n",
       "RELIGION                147\n",
       "LAW/ORDER               136\n",
       "SOCIAL ISSUES           134\n",
       "HEALTH                  127\n",
       "ECONOMY                  86\n",
       "FARMING                  78\n",
       "SPORTS                   49\n",
       "EDUCATION                43\n",
       "RELATIONSHIPS            39\n",
       "WILDLIFE/ENVIRONMENT     36\n",
       "OPINION/ESSAY            26\n",
       "LOCALCHIEFS              25\n",
       "CULTURE                  23\n",
       "WITCHCRAFT               16\n",
       "MUSIC                    15\n",
       "TRANSPORT                11\n",
       "ARTS AND CRAFTS           7\n",
       "FLOODING                  7\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "_uuid": "bda23ce14c9e6cc07d459ce4f3295dcacfeb88a9",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1529968288460,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "Ilatvz9j7vZN",
    "outputId": "44f66230-f029-4008-c1fb-c9c705a6e0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1292\n",
      "Test size: 144\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * .9)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "_uuid": "6073c1614a697e0bc09c64e8140228d8e9ccd07c",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1529968332817,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "_WiJBv3E7vZQ",
    "outputId": "0b13b71e-f63b-4211-d5c4-d8b99a4b0d01"
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size):\n",
    "    train = data[:train_size]\n",
    "    test = data[train_size:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58e07108e5cb00de0e0a274b2225aa8834c43393",
    "colab_type": "text",
    "id": "5u6HXfm_ciaR"
   },
   "source": [
    "## Data preparation\n",
    "There's some work to be done in order for our data to be ready for training.\n",
    "1. First we'll split the data into training and test sets.\n",
    "1. Then we'll tokenize the words (text), and then convert them to a numbered index. \n",
    "1. Next we'll do the same for the labels (categories), by using the `LabelEncoder` utility.\n",
    "1. Finally, we'll convert the labels to a one-hot representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "_uuid": "4e83f69f4762d5b64929e06c071989456572ee21",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1529968339164,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "7gs0Skc67vZU",
    "outputId": "36190a1a-8fc5-4dc0-fe28-a8c230372625"
   },
   "outputs": [],
   "source": [
    "train_cat, test_cat = train_test_split(data['Label'], train_size)\n",
    "train_text, test_text = train_test_split(data['Text'], train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "_uuid": "6dc3604d80e5eccadba1e8a9f54d779bf915015f",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1529968392523,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "ujAGiFCy7vZW",
    "outputId": "5a276274-4fd6-4812-b417-f50747c1060a"
   },
   "outputs": [],
   "source": [
    "max_words = 1500\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=max_words, \n",
    "                                              char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "_uuid": "c6f639eb0d6196ea9b1f0c5605913a47206a4f1e",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1734,
     "status": "ok",
     "timestamp": 1529968412683,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "Fc384gXv7vZY",
    "outputId": "a2644f11-121b-4287-be3b-58e8d4b79448"
   },
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_text) # fit tokenizer to our training text data\n",
    "x_train = tokenize.texts_to_matrix(train_text)\n",
    "x_test = tokenize.texts_to_matrix(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "_uuid": "da89fd94cb271dbe37b2deaf020a1992b15173f3",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1529968421345,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "lwVzFlWb7vZb",
    "outputId": "40c75810-86da-4cde-dc41-ee74df6f1057"
   },
   "outputs": [],
   "source": [
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_cat)\n",
    "y_train = encoder.transform(train_cat)\n",
    "y_test = encoder.transform(test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "_uuid": "7086e7934f8adeabc505aafa8a745f2fb00f2c7c",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1529968446804,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "3bFkgysv7vZf",
    "outputId": "524bd41b-9f55-43f8-9f63-f5d2ba3d4e3e"
   },
   "outputs": [],
   "source": [
    "# Converts the labels to a one-hot representation\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "_uuid": "76a85d88ebadf911ad3b8acbadea12b6feb8d943",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1529968467789,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "nbgyZpkn7vZi",
    "outputId": "c2aaa800-ae4f-4b5f-d86a-8a1782808527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1292, 1500)\n",
      "x_test shape: (144, 1500)\n",
      "y_train shape: (1292, 20)\n",
      "y_test shape: (144, 20)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the dimenstions of our training and test data (this is helpful to debug)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5838e4d6eb5f04b731d73507ad74c424cbc61e89",
    "colab_type": "text",
    "id": "ms0L4rJidWRh"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Build the model using Keras layers and hyperparameters of your choosing. Then call `model.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "_uuid": "337b7d1e899297a868bb9b5a1eae4c4fb246c623",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1529968784862,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "Z3MmdGtx7vZl",
    "outputId": "d6a745be-61fb-46ee-c791-29ca80140bca"
   },
   "outputs": [],
   "source": [
    "# This model trains very quickly and 2 epochs are already more than enough\n",
    "# Training for more epochs will likely lead to overfitting on this dataset\n",
    "# You can try tweaking these hyperparamaters when using this model with your own data\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "drop_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "_uuid": "a1bbb4b632904850c9028433065f18825ab35d40",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1529968787034,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "VT6WEGF-7vZq",
    "outputId": "9af614ad-0dd9-43c3-c3a1-225a7cbab986"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(4048, input_shape=(max_words,)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(drop_ratio))\n",
    "model.add(layers.Dense(1024))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(512))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(128))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "\n",
    "# model.add(layers.Dropout(drop_ratio))\n",
    "model.add(layers.Dense(num_classes))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "_uuid": "7e47a98aa3fb3fac7d1a66f226dfdbd73f0200af",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1436,
     "status": "ok",
     "timestamp": 1529968901259,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "aZi3ZHVn7vZt",
    "outputId": "2a284ea1-dde6-45a0-842c-823d826a2f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37/37 [==============================] - 3s 88ms/step - loss: 1.9934 - accuracy: 0.4071 - val_loss: 1.5738 - val_accuracy: 0.5385\n",
      "Epoch 2/5\n",
      "37/37 [==============================] - 3s 83ms/step - loss: 0.7092 - accuracy: 0.8003 - val_loss: 1.7786 - val_accuracy: 0.5385\n",
      "Epoch 3/5\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 0.2496 - accuracy: 0.9243 - val_loss: 2.2500 - val_accuracy: 0.5077\n",
      "Epoch 4/5\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 0.1132 - accuracy: 0.9699 - val_loss: 1.8958 - val_accuracy: 0.5615\n",
      "Epoch 5/5\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 0.0644 - accuracy: 0.9785 - val_loss: 2.1894 - val_accuracy: 0.5385\n"
     ]
    }
   ],
   "source": [
    "# model.fit trains the model\n",
    "# The validation_split param tells Keras what % of our training data should be used in the validation set\n",
    "# You can see the validation loss decreasing slowly when you run this\n",
    "# Because val_loss is no longer decreasing we stop training to prevent overfitting\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "43061a58c33a5d5b9a7667cf2dc07e776362cac9",
    "colab_type": "text",
    "id": "KZ-IXqRtdip6"
   },
   "source": [
    "## Evaluate the model\n",
    "Evaluation is easy. Just call `model.evaluate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "_uuid": "cbc23de6b6ff62f33a9174dd64a941097672f3be",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1529968989028,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "Rp7qGXOI7vZx",
    "outputId": "3f97957f-3961-4342-a76b-112069b139ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3718 - accuracy: 0.5486\n",
      "Test loss: 2.371751546859741\n",
      "Test accuracy: 0.5486111044883728\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of our trained model\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f2b44f49bbcdaabad53a3fadb12a92722d65aaf",
    "colab_type": "text",
    "id": "28xNG3mVeFIT"
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e57f531af533325c1184bd0bcf1ff6cf4edc4d0",
    "colab_type": "text",
    "id": "YxoYLyHzeHPu"
   },
   "source": [
    "This is a good time to go back and tweak some parameters such as `epoch`, `batch size`, `dropout ratio`, network structure, activation function, and others, to see if you can improve the accuracy.\n",
    "\n",
    "In this particular case, to make it more challenging, I recommend reducing the max words of the call to `keras.preprocessing.text.Tokenizer`. This will reduce the number of words for each input sample, thus making it more challenging to accurately predict the category. (Notice that not all hyperparameters are necessarily inside the model. This is one such example.)\n",
    "\n",
    "The default was up to 1000 words per article. See what happens when you reduce that number to 200 words, or 50 words, or even fewer. As the evaluation accuracy drops, the effects of your hyperparameter tuning will be more pronounced, with successful adjustments making meaningful improvements to the model performance.\n",
    "\n",
    "To make this process easier to manage, I've encapulated the model definition and training and evaluation calls into one function call. You can add additional parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "bccfaad25ec2a6db799d5276bcdbc7993a1179ad",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QaOlQpLteGr8"
   },
   "outputs": [],
   "source": [
    "def run_experiment(batch_size, epochs, drop_ratio):\n",
    "  print('batch size: {}, epochs: {}, drop_ratio: {}'.format(\n",
    "      batch_size, epochs, drop_ratio))\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(2512, input_shape=(max_words,)))\n",
    "  model.add(layers.Activation('relu'))\n",
    "#   model.add(layers.Dropout(drop_ratio))\n",
    "#   model.add(layers.Dense(512))\n",
    "#   model.add(layers.Activation('relu'))\n",
    "#   model.add(layers.Dropout(drop_ratio))\n",
    "  model.add(layers.Dense(num_classes))\n",
    "  model.add(layers.Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "  history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    validation_split=0.1)\n",
    "  score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=0)\n",
    "  print('\\tTest loss:', score[0])\n",
    "  print('\\tTest accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "f75ddec1c39edbd391edc2be623361c6b45fc48d",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3431,
     "status": "ok",
     "timestamp": 1528446977868,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "pf1q6A6RfUOA",
    "outputId": "f116fdb9-27fa-4a59-dcb4-2c40f77dbc34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 32, epochs: 2, drop_ratio: 0.2\n",
      "\tTest loss: 1.5001728534698486\n",
      "\tTest accuracy: 0.5902777910232544\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "drop_ratio = 0.2\n",
    "run_experiment(batch_size, epochs, drop_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e0aa1e7f4e713903b23dbf567c3d035511924e8",
    "colab_type": "text",
    "id": "7X5sF8ZtgFRY"
   },
   "source": [
    "###Hyperparameter Search\n",
    "\n",
    "You can also automate this process using for-loops and more sophiscated methods of deciding which combinations of hyperparameter values to try out.\n",
    "\n",
    "Exhaustive search is generally not the most elegant way, this is mostly just for illustrative purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7cd75fbb89b5c79cc7dea56dc8499ce25604b9a0",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1378
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 148484,
     "status": "ok",
     "timestamp": 1528447417461,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "fM6eCxpDf-hO",
    "outputId": "1eb2d479-9e5b-47c5-d0fe-59afc41d1eb6"
   },
   "outputs": [],
   "source": [
    "# Note: The data processed for this output had the max text length set to 400.\n",
    "# for batch_size in range(10,31,10):\n",
    "#   for epochs in range(3,15,5):\n",
    "#     for drop_ratio in np.linspace(0.1, 0.5, 3):\n",
    "#       run_experiment(batch_size, epochs, drop_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ebd9f0d1120bb2ac6a65b9239f84431bdc1b181",
    "colab_type": "text",
    "id": "5Kwg1HISdvbJ"
   },
   "source": [
    "## Make some predictions\n",
    "Take some samples from the test dataset and inspect some individual predictions, to ensure that things are sensible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92df624844b469e2464738e1538ec2688c29c8b8",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1528444366463,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "cZX08a8b7vZz",
    "outputId": "a424c2e3-7d17-4bc8-9d66-45e5b5e55c25"
   },
   "outputs": [],
   "source": [
    "# Here's how to generate a prediction on individual examples\n",
    "text_labels = encoder.classes_ \n",
    "\n",
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([x_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    print(test_text.iloc[i][:50], \"...\")\n",
    "    print('Actual label:' + test_cat.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label + \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cffc52f2cf377c9e3b446e8b60c9f1616f5859df",
    "colab_type": "text",
    "id": "9fVPKqatd4wT"
   },
   "source": [
    "## (optional) Extra extra! Visualize the confusion matrix\n",
    "This can help identify which areas were a challenge to get right, if the model is performing poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0ac86d025cc57f48849d33f664bc6f355f196a2",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5iwjnls-7vZ6"
   },
   "outputs": [],
   "source": [
    "y_softmax = model.predict(x_test)\n",
    "\n",
    "y_test_1d = []\n",
    "y_pred_1d = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    probs = y_test[i]\n",
    "    index_arr = np.nonzero(probs)\n",
    "    one_hot_index = index_arr[0].item(0)\n",
    "    y_test_1d.append(one_hot_index)\n",
    "\n",
    "for i in range(0, len(y_softmax)):\n",
    "    probs = y_softmax[i]\n",
    "    predicted_index = np.argmax(probs)\n",
    "    y_pred_1d.append(predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a289402f4815e8bc322b12194c1b1b3acdd80931",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7ljbbrdu7vZ9"
   },
   "outputs": [],
   "source": [
    "# This utility function is from the sklearn docs: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e0238c7efd8b90aa654f67c258c6513c99fc9ef",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1528444377842,
     "user": {
      "displayName": "Yufeng Guo",
      "photoUrl": "//lh3.googleusercontent.com/-yh4ovY5HFlY/AAAAAAAAAAI/AAAAAAAAACk/ySd8O1k5o5s/s50-c-k-no/photo.jpg",
      "userId": "112030861868146149303"
     },
     "user_tz": 240
    },
    "id": "53JHPfCB7vZ_",
    "outputId": "9a940bfd-04a2-4ed2-cd7a-9ae4d2521941"
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "plt.figure(figsize=(24,20))\n",
    "plot_confusion_matrix(cnf_matrix, classes=text_labels, title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c286179093db65f3c0638a92bb5823f46544098",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0H1KIsy77vaC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Published BBC text BOW",
   "provenance": [
    {
     "file_id": "1IlP-4XDM1_5NRdR5g_6DbIT-YvdwKGvn",
     "timestamp": 1528444855450
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
