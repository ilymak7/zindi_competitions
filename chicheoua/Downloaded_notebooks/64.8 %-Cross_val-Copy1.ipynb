{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d5221cf58859cd6496cf4294414a3bc37d4c95f"
   },
   "source": [
    "In this kernel, I have implemented the encoder part of the transformer architecture as mentioned in the famous paper: Attention is all you need.(https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "Many of other codes are adopted from other kernels. For example, loading the embeddings,  load the training and test data and preprocessing, etc. I really appreciate their contributions.\n",
    "\n",
    "p.s. When I run this locally, I get validation f1-score around 0.688.\n",
    "\n",
    "Happy transforming!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a947373c706a15ed71a686d92703b9677561894"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.layers import BatchNormalization, InputSpec, add\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, activations\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "# Build the model\n",
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "# K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "# os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "# random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "# np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b37e0d09f42f5bc5ad73a366580f6b778c9aad5a"
   },
   "source": [
    "## Some pre-configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c7498e1cc6e3dd7e7c58f24e10fd5ad1b06b4489"
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 45000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 400 # max number of words in a question to use\n",
    "n_heads = 4 # Number of heads as in Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "05385c91a5e5603c346bfe53010aa4cb0f3ddd4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1436, 3)\n",
      "Test shape :  (620, 2)\n"
     ]
    }
   ],
   "source": [
    "# def load_and_prec():\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "cols_target = train_df.Label.unique().tolist()\n",
    "\n",
    "## split to train and val\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=0,shuffle = True) # hahaha\n",
    "# train_X, val_X, train_y , val_y = train_test_split(train_df, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])\n",
    "\n",
    "# trn_idx = train_y.index.tolist()\n",
    "# val_idx = val_y.index.tolist()\n",
    "\n",
    "\n",
    "## fill up the missing values\n",
    "# train_X = train_X[\"Text\"].fillna(\"_##_\").values\n",
    "# val_X = val_X[\"Text\"].fillna(\"_##_\").values\n",
    "# test_X = test_df[\"Text\"].fillna(\"_##_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_df.Text)\n",
    "# train_X = tokenizer.texts_to_sequences(train_X)\n",
    "# val_X = tokenizer.texts_to_sequences(val_X)\n",
    "# test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "# ## Pad the sentences \n",
    "# train_X = pad_sequences(train_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "# val_X = pad_sequences(val_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "# test_X = pad_sequences(test_X, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "\n",
    "# ## Get the target values\n",
    "# train_y = train_y.values\n",
    "# val_y = val_y.values  \n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "#shuffling the data\n",
    "# np.random.seed(2018)\n",
    "# trn_idx = np.random.permutation(len(train_X))\n",
    "# val_idx = np.random.permutation(len(val_X))\n",
    "\n",
    "# train_X = train_X[trn_idx]\n",
    "# val_X = val_X[val_idx]\n",
    "# train_y = train_y[trn_idx]\n",
    "# val_y = val_y[val_idx]    \n",
    "\n",
    "#     return train_X, val_X, test_X, train_y, val_y, tokenizer.word_index,val_idx , trn_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20682431e22eab3cbf634777cb0d2bc2730ab754"
   },
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "cf6dc22b3b2a9f2ec94f70e2aa5dfe36f6f142d3"
   },
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.005838499,0.48782197\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix \n",
    "    \n",
    "def load_fasttext(word_index):    \n",
    "    EMBEDDING_FILE = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "def load_para(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.0053247833,0.49346462\n",
    "    embed_size = all_embs.shape[1]\n",
    "    print(emb_mean,emb_std,\"para\")\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a35ee76c0f926bcdf817fcb91dbd20ee90007f06"
   },
   "source": [
    "## Scaled Dot-product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "92c050cb313508d5c88b288dd1561493bcfacbed"
   },
   "outputs": [],
   "source": [
    "class DotProdSelfAttention(Layer):\n",
    "    \"\"\"The self-attention layer as in 'Attention is all you need'.\n",
    "    paper reference: https://arxiv.org/abs/1706.03762\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, units,\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(DotProdSelfAttention, self).__init__(*kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        input_dim = input_shape[-1]\n",
    "        # We assume the output-dim of Q, K, V are the same\n",
    "        self.kernels = dict.fromkeys(['Q', 'K', 'V'])\n",
    "        for key, _ in self.kernels.items():\n",
    "            self.kernels[key] = self.add_weight(shape=(input_dim, self.units),\n",
    "                                                initializer=self.kernel_initializer,\n",
    "                                                name='kernel_{}'.format(key),\n",
    "                                                regularizer=self.kernel_regularizer,\n",
    "                                                constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            raise NotImplementedError\n",
    "        super(DotProdSelfAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        Q = K.dot(x, self.kernels['Q'])\n",
    "        K_mat = K.dot(x, self.kernels['K'])\n",
    "        V = K.dot(x, self.kernels['V'])\n",
    "        attention = K.batch_dot(Q, K.permute_dimensions(K_mat, [0, 2, 1]))\n",
    "        d_k = K.constant(self.units, dtype=K.floatx())\n",
    "        attention = attention / K.sqrt(d_k)\n",
    "        attention = K.batch_dot(K.softmax(attention, axis=-1), V)\n",
    "        return attention\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) >= 2\n",
    "        assert input_shape[-1]\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d931bd69e53756c2f8aa8cf63d07d4c7eb02a8d9"
   },
   "source": [
    "## The Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "399ddb0b7367ac0f6bd4121396b24ac3a6d1edfe"
   },
   "outputs": [],
   "source": [
    "def encoder(input_tensor):\n",
    "    \"\"\"One encoder as in Attention Is All You Need\n",
    "    \"\"\"\n",
    "    # Sub-layer 1\n",
    "    # Multi-Head Attention\n",
    "    multiheads = []\n",
    "    d_v = embed_size // n_heads\n",
    "    for i in range(n_heads):\n",
    "        multiheads.append(DotProdSelfAttention(d_v)(input_tensor))\n",
    "    multiheads = concatenate(multiheads, axis=-1)\n",
    "    multiheads = Dense(embed_size)(multiheads)\n",
    "    multiheads = Dropout(0.1)(multiheads)\n",
    "    \n",
    "    # Residual Connection\n",
    "    res_con = add([input_tensor, multiheads])\n",
    "    # Didn't use layer normalization, use Batch Normalization instead here\n",
    "    res_con = BatchNormalization(axis=-1)(res_con)\n",
    "    \n",
    "    # Sub-layer 2\n",
    "    # 2 Feed forward layer\n",
    "    ff1 = Dense(64, activation='relu')(res_con)\n",
    "    ff2 = Dense(embed_size)(ff1)\n",
    "    output = add([res_con, ff2])\n",
    "    output = BatchNormalization(axis=-1)(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8740be2622e8195ed3f0c7d9568a06ddb64cd98b"
   },
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8bd0cd11b96080f965195da697ba34c865f5b7e2"
   },
   "outputs": [],
   "source": [
    "# https://github.com/kpot/keras-transformer/blob/master/keras_transformer/position.py\n",
    "def positional_signal(hidden_size: int, length: int,\n",
    "                      min_timescale: float = 1.0, max_timescale: float = 1e4):\n",
    "    \"\"\"\n",
    "    Helper function, constructing basic positional encoding.\n",
    "    The code is partially based on implementation from Tensor2Tensor library\n",
    "    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py\n",
    "    \"\"\"\n",
    "\n",
    "    if hidden_size % 2 != 0:\n",
    "        raise ValueError(\n",
    "            f\"The hidden dimension of the model must be divisible by 2.\"\n",
    "            f\"Currently it is {hidden_size}\")\n",
    "    position = K.arange(0, length, dtype=K.floatx())\n",
    "    num_timescales = hidden_size // 2\n",
    "    log_timescale_increment = K.constant(\n",
    "        (np.log(float(max_timescale) / float(min_timescale)) /\n",
    "         (num_timescales - 1)),\n",
    "        dtype=K.floatx())\n",
    "    inv_timescales = (\n",
    "            min_timescale *\n",
    "            K.exp(K.arange(num_timescales, dtype=K.floatx()) *\n",
    "                  -log_timescale_increment))\n",
    "    scaled_time = K.expand_dims(position, 1) * K.expand_dims(inv_timescales, 0)\n",
    "    signal = K.concatenate([K.sin(scaled_time), K.cos(scaled_time)], axis=1)\n",
    "    return K.expand_dims(signal, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "309135be6416acde8d5088af910eee3597e25d4e"
   },
   "outputs": [],
   "source": [
    "# https://github.com/kpot/keras-transformer/blob/master/keras_transformer/position.py\n",
    "class AddPositionalEncoding(Layer):\n",
    "    \"\"\"\n",
    "    Injects positional encoding signal described in section 3.5 of the original\n",
    "    paper \"Attention is all you need\". Also a base class for more complex\n",
    "    coordinate encoding described in \"Universal Transformers\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_timescale: float = 1.0,\n",
    "                 max_timescale: float = 1.0e4, **kwargs):\n",
    "        self.min_timescale = min_timescale\n",
    "        self.max_timescale = max_timescale\n",
    "        self.signal = None\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['min_timescale'] = self.min_timescale\n",
    "        config['max_timescale'] = self.max_timescale\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, length, hidden_size = input_shape\n",
    "        self.signal = positional_signal(\n",
    "            hidden_size, length, self.min_timescale, self.max_timescale)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return inputs + self.signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "312bd7b8472de749134273fead7f939a234c551c"
   },
   "source": [
    "## Transformer Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "235ae9ecb6873475900b1ad88e3a07a161195370"
   },
   "outputs": [],
   "source": [
    "def model_transformer( n_encoder=3):\n",
    "    K.clear_session()\n",
    "    seed_value = 0\n",
    "    tf.random.set_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, trainable=True)(inp)\n",
    "    # Add positional encoding\n",
    "    x = AddPositionalEncoding()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    for i in range(n_encoder):\n",
    "        x = encoder(x)\n",
    "    # These are my own experiments\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "#     conc = Dense(512, activation=\"relu\")(conc)\n",
    "#     conc = Dropout(0.1)(conc)\n",
    "    outp = Dense(20, activation=\"softmax\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.recurrent_v2.LSTM"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "e2f42600ff37e6c286215562afc11a1be28f0981"
   },
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class BaseDataGenerator(Sequence):\n",
    "    \"\"\"A data generator\"\"\"\n",
    "    def __init__(self, list_IDs, batch_size=64, shuffle=True):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"number of steps in one epoch\"\"\"\n",
    "        # Here is the trick\n",
    "        return len(self.list_IDs) // (self.batch_size * 2**2)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size: (index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' \n",
    "        X = train_X[list_IDs_temp, :]\n",
    "        y = train_y[list_IDs_temp]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee0611a48264188ec3063bc6c6ce221eb3724d8e"
   },
   "source": [
    "### Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c9d6121293c82701f3c07ae00f396564d8aa2c9"
   },
   "source": [
    "Here I used early stopping and model checkpoint to load the best_val model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "5f90446889d864f0a318d305eca2d3a04d1baa55"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
    "def train_pred(n_encoder = 1, epochs=2):\n",
    "    # learning schedule callback\n",
    "#     loss_history = LossHistory()\n",
    "#     lrate = BatchLRScheduler(step_decay)\n",
    "#     callbacks_list = [loss_history, lrate]\n",
    "#     es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
    "#     model_path = 'keras_models.h5'\n",
    "#     mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True)\n",
    "#     callbacks = [es, mc]\n",
    "#     train_generator = BaseDataGenerator(list(np.arange(train_X.shape[0])), batch_size=512)\n",
    "#     model.fit_generator(train_generator,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(val_X, val_y),)\n",
    "#                         callbacks=callbacks)\n",
    "#     model = load_model(model_path)\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "    models, preds, scores = [], [],[]\n",
    "#     vectorizer = vect(max_df = 0.5)\n",
    "    for train, test in skf.split(train_df.Text, train_df.Label):\n",
    "#     print(train, test)\n",
    "#     clf = LogisticRegression(penalty='l1')\n",
    "#         clf.fit(vectorizer.transform(), data_train.Label.loc[data_train.index.intersection(train)])\n",
    "#         K.clear_session()\n",
    "#         clf = build_base_model()\n",
    "        model = model_transformer(n_encoder=n_encoder)\n",
    "        X_train = train_df.Text.loc[train_df.index.intersection(train)]\n",
    "        X_val = train_df.Text.loc[train_df.index.intersection(test)]\n",
    "        y_train = train_df[cols_target].loc[train_df.index.intersection(train)]\n",
    "        y_val = train_df[cols_target].loc[train_df.index.intersection(test)]\n",
    "        X_train = tokenizer.texts_to_sequences(X_train)\n",
    "        X_val = tokenizer.texts_to_sequences(X_val)\n",
    "        X_test = tokenizer.texts_to_sequences(test_df.Text)\n",
    "\n",
    "        ## Pad the sentences \n",
    "        X_train = pad_sequences(X_train, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        X_val = pad_sequences(X_val, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        X_test = pad_sequences(X_test, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "\n",
    "#         X_test = vect.transform(test_df.Text).toarray()\n",
    "        model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                   validation_data = (X_val,y_val),\n",
    "                   callbacks=[\n",
    "#               RocAucEvaluation(verbose=True),\n",
    "              ModelCheckpoint(file_path,    monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "              EarlyStopping(patience=6,    monitor=\"val_accuracy\", mode=\"max\"),\n",
    "              ReduceLROnPlateau(patience=4, monitor='val_accuracy', mode='max', cooldown=2, min_lr=1e-7, factor=0.3)])\n",
    "        preds.append(model.predict(X_test))\n",
    "        models.append(model)\n",
    "        scores.append(model.evaluate(X_val,y_val))\n",
    "#         coefs.append(clf.coef_[0])\n",
    "#         clf.fit(X_train, y_train)\n",
    "#     train_time = time() - t0\n",
    "#     print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "#     t0 = time()\n",
    "#     pred = clf.predict(X_test)\n",
    "#     test_time = time() - t0\n",
    "#     print(\"test time:  %0.3fs\" % test_time)\n",
    "    pred = np.mean(preds,axis = 0)\n",
    "#     model.fit(train_X, train_y, batch_size=64,\n",
    "#               epochs=epochs,\n",
    "#               validation_data=(val_X, val_y),)\n",
    "\n",
    "#     pred_val_y = model.predict([val_X], batch_size=64, verbose=0)\n",
    "#     pred_test_y = model.predict([test_X], batch_size=64, verbose=0)\n",
    "    return models, preds, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9b632c9bea6c5e8c7e111fc97474fc9d8b099c4"
   },
   "source": [
    "### Main part: load, train, pred and blend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "6ddf2ae0c374759ef040db80346faaf609850e58"
   },
   "outputs": [],
   "source": [
    "# train_X, val_X, test_X, train_y, val_y, word_index,val_idx,trn_idx = load_and_prec()\n",
    "vocab = []\n",
    "for w,k in word_index.items():\n",
    "    vocab.append(w)\n",
    "    if k >= max_features:\n",
    "        break\n",
    "# embedding_matrix_1 = load_glove(word_index)\n",
    "# embedding_matrix_2 = load_fasttext(word_index)\n",
    "# embedding_matrix_3 = load_para(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ffc83124a9f220b31e698b922cad56d59f8c83e5"
   },
   "source": [
    "### Create New Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "622e0a2f777d15a9f74b3d1d56a0e5ad60ee90bc"
   },
   "outputs": [],
   "source": [
    "## Simple average: http://aclweb.org/anthology/N18-2031\n",
    "\n",
    "# We have presented an argument for averaging as\n",
    "# a valid meta-embedding technique, and found experimental\n",
    "# performance to be close to, or in some cases \n",
    "# better than that of concatenation, with the\n",
    "# additional benefit of reduced dimensionality  \n",
    "\n",
    "\n",
    "## Unweighted DME in https://arxiv.org/pdf/1804.07983.pdf\n",
    "\n",
    "# “The downside of concatenating embeddings and \n",
    "#  giving that as input to an RNN encoder, however,\n",
    "#  is that the network then quickly becomes inefficient\n",
    "#  as we combine more and more embeddings.”\n",
    "  \n",
    "# embedding_matrix = np.mean([embedding_matrix_1, embedding_matrix_2, embedding_matrix_3], axis = 0)\n",
    "# embedding_matrix = np.mean([embedding_matrix_1, embedding_matrix_3], axis = 0)\n",
    "# np.shape(embedding_matrix)\n",
    "# model.evaluate(val_X,val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52627f8490364ed29f81e574c49af644726701e1"
   },
   "source": [
    "## Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3270c045c747a7c5da32704e6db44c18f470646"
   },
   "source": [
    "Here I am experimenting with 2 encoders, it's not guaranteed to be optimal, you can try out other numbers. Notice that I used epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "573d8e65c007aefd1fb4a0deef16e73894327486"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "# outputs[0][1]\n",
    "# type(train_X[0][0])\n",
    "# val_X\n",
    "# train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(train_X,train_y)\n",
    "# train_X.shape\n",
    "# train_idx\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback, ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,cross_val_score,train_test_split,StratifiedShuffleSplit\n",
    "\n",
    "file_path = \"weights_trans.best.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "091d7915c8c00d088d60c09c306298950cd2afe6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "36/36 [==============================] - 13s 359ms/step - loss: 2.7464 - accuracy: 0.1655 - val_loss: 2.6785 - val_accuracy: 0.2083\n",
      "Epoch 2/42\n",
      "36/36 [==============================] - 12s 337ms/step - loss: 2.5844 - accuracy: 0.2152 - val_loss: 2.5690 - val_accuracy: 0.1944\n",
      "Epoch 3/42\n",
      "36/36 [==============================] - 13s 351ms/step - loss: 2.4791 - accuracy: 0.2448 - val_loss: 2.5291 - val_accuracy: 0.2535\n",
      "Epoch 4/42\n",
      "36/36 [==============================] - 13s 362ms/step - loss: 2.3846 - accuracy: 0.2770 - val_loss: 2.4642 - val_accuracy: 0.2674\n",
      "Epoch 5/42\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 2.2591 - accuracy: 0.2770 - val_loss: 2.4223 - val_accuracy: 0.2778\n",
      "Epoch 6/42\n",
      "36/36 [==============================] - 15s 414ms/step - loss: 2.1715 - accuracy: 0.3772 - val_loss: 2.3844 - val_accuracy: 0.2188\n",
      "Epoch 7/42\n",
      "36/36 [==============================] - 15s 419ms/step - loss: 2.0420 - accuracy: 0.4059 - val_loss: 2.2946 - val_accuracy: 0.3021\n",
      "Epoch 8/42\n",
      "36/36 [==============================] - 15s 409ms/step - loss: 1.9005 - accuracy: 0.4948 - val_loss: 2.2096 - val_accuracy: 0.3264\n",
      "Epoch 9/42\n",
      "36/36 [==============================] - 14s 378ms/step - loss: 1.7793 - accuracy: 0.5627 - val_loss: 2.1915 - val_accuracy: 0.4132\n",
      "Epoch 10/42\n",
      "36/36 [==============================] - 13s 366ms/step - loss: 1.6475 - accuracy: 0.5967 - val_loss: 2.1127 - val_accuracy: 0.4132\n",
      "Epoch 11/42\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 1.5199 - accuracy: 0.6681 - val_loss: 2.0575 - val_accuracy: 0.4306\n",
      "Epoch 12/42\n",
      "36/36 [==============================] - 14s 392ms/step - loss: 1.3901 - accuracy: 0.7012 - val_loss: 2.0083 - val_accuracy: 0.5000\n",
      "Epoch 13/42\n",
      "36/36 [==============================] - 13s 364ms/step - loss: 1.2670 - accuracy: 0.7448 - val_loss: 1.9568 - val_accuracy: 0.5000\n",
      "Epoch 14/42\n",
      "36/36 [==============================] - 13s 375ms/step - loss: 1.1627 - accuracy: 0.7674 - val_loss: 1.9037 - val_accuracy: 0.5104\n",
      "Epoch 15/42\n",
      "36/36 [==============================] - 14s 393ms/step - loss: 1.0543 - accuracy: 0.7918 - val_loss: 1.8518 - val_accuracy: 0.5139\n",
      "Epoch 16/42\n",
      "36/36 [==============================] - 14s 383ms/step - loss: 0.9251 - accuracy: 0.8319 - val_loss: 1.8628 - val_accuracy: 0.5417\n",
      "Epoch 17/42\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 0.8482 - accuracy: 0.8423 - val_loss: 1.7917 - val_accuracy: 0.5417\n",
      "Epoch 18/42\n",
      "36/36 [==============================] - 15s 413ms/step - loss: 0.7599 - accuracy: 0.8746 - val_loss: 1.7733 - val_accuracy: 0.5694\n",
      "Epoch 19/42\n",
      "36/36 [==============================] - 13s 367ms/step - loss: 0.6770 - accuracy: 0.9059 - val_loss: 1.7264 - val_accuracy: 0.5417\n",
      "Epoch 20/42\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 0.6128 - accuracy: 0.9094 - val_loss: 1.7242 - val_accuracy: 0.5660\n",
      "Epoch 21/42\n",
      "36/36 [==============================] - 13s 363ms/step - loss: 0.5437 - accuracy: 0.9286 - val_loss: 1.7457 - val_accuracy: 0.5486\n",
      "Epoch 22/42\n",
      "36/36 [==============================] - 14s 377ms/step - loss: 0.4853 - accuracy: 0.9408 - val_loss: 1.6672 - val_accuracy: 0.5590\n",
      "Epoch 23/42\n",
      "36/36 [==============================] - 14s 395ms/step - loss: 0.4274 - accuracy: 0.9408 - val_loss: 1.6556 - val_accuracy: 0.5729\n",
      "Epoch 24/42\n",
      "36/36 [==============================] - 13s 363ms/step - loss: 0.4040 - accuracy: 0.9608 - val_loss: 1.6572 - val_accuracy: 0.5694\n",
      "Epoch 25/42\n",
      "36/36 [==============================] - 14s 403ms/step - loss: 0.3844 - accuracy: 0.9695 - val_loss: 1.6453 - val_accuracy: 0.5799\n",
      "Epoch 26/42\n",
      "36/36 [==============================] - 13s 365ms/step - loss: 0.3722 - accuracy: 0.9669 - val_loss: 1.6361 - val_accuracy: 0.5694\n",
      "Epoch 27/42\n",
      "36/36 [==============================] - 15s 409ms/step - loss: 0.3557 - accuracy: 0.9678 - val_loss: 1.6435 - val_accuracy: 0.5868\n",
      "Epoch 28/42\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 0.3438 - accuracy: 0.9704 - val_loss: 1.6349 - val_accuracy: 0.5764\n",
      "Epoch 29/42\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 0.3317 - accuracy: 0.9747 - val_loss: 1.6252 - val_accuracy: 0.5868\n",
      "Epoch 30/42\n",
      "36/36 [==============================] - 13s 369ms/step - loss: 0.3205 - accuracy: 0.9739 - val_loss: 1.6092 - val_accuracy: 0.5799\n",
      "Epoch 31/42\n",
      "36/36 [==============================] - 13s 366ms/step - loss: 0.3084 - accuracy: 0.9756 - val_loss: 1.6217 - val_accuracy: 0.5868\n",
      "Epoch 32/42\n",
      "36/36 [==============================] - 13s 371ms/step - loss: 0.2962 - accuracy: 0.9800 - val_loss: 1.6152 - val_accuracy: 0.5868\n",
      "Epoch 33/42\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 0.2925 - accuracy: 0.9817 - val_loss: 1.6107 - val_accuracy: 0.5833\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.6107 - accuracy: 0.5833\n",
      "Epoch 1/42\n",
      "36/36 [==============================] - 15s 409ms/step - loss: 2.7733 - accuracy: 0.1680 - val_loss: 2.6186 - val_accuracy: 0.1951\n",
      "Epoch 2/42\n",
      "36/36 [==============================] - 13s 354ms/step - loss: 2.5618 - accuracy: 0.1984 - val_loss: 2.5600 - val_accuracy: 0.1951\n",
      "Epoch 3/42\n",
      "36/36 [==============================] - 14s 400ms/step - loss: 2.4922 - accuracy: 0.2324 - val_loss: 2.5316 - val_accuracy: 0.2857\n",
      "Epoch 4/42\n",
      "36/36 [==============================] - 13s 371ms/step - loss: 2.3824 - accuracy: 0.2515 - val_loss: 2.4741 - val_accuracy: 0.2334\n",
      "Epoch 5/42\n",
      "36/36 [==============================] - 14s 377ms/step - loss: 2.2806 - accuracy: 0.3133 - val_loss: 2.3764 - val_accuracy: 0.2509\n",
      "Epoch 6/42\n",
      "36/36 [==============================] - 14s 394ms/step - loss: 2.1641 - accuracy: 0.3621 - val_loss: 2.3061 - val_accuracy: 0.3484\n",
      "Epoch 7/42\n",
      "36/36 [==============================] - 14s 385ms/step - loss: 2.0546 - accuracy: 0.4186 - val_loss: 2.2598 - val_accuracy: 0.3206\n",
      "Epoch 8/42\n",
      "36/36 [==============================] - 14s 397ms/step - loss: 1.9200 - accuracy: 0.5048 - val_loss: 2.2018 - val_accuracy: 0.4216\n",
      "Epoch 9/42\n",
      "36/36 [==============================] - 14s 377ms/step - loss: 1.7943 - accuracy: 0.5500 - val_loss: 2.1377 - val_accuracy: 0.4042\n",
      "Epoch 10/42\n",
      "36/36 [==============================] - 14s 399ms/step - loss: 1.6741 - accuracy: 0.6205 - val_loss: 2.0689 - val_accuracy: 0.4251\n",
      "Epoch 11/42\n",
      "36/36 [==============================] - 13s 353ms/step - loss: 1.5544 - accuracy: 0.6136 - val_loss: 2.0321 - val_accuracy: 0.4355\n",
      "Epoch 12/42\n",
      "36/36 [==============================] - 14s 396ms/step - loss: 1.4082 - accuracy: 0.7180 - val_loss: 1.9942 - val_accuracy: 0.4564\n",
      "Epoch 13/42\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 1.2872 - accuracy: 0.7511 - val_loss: 1.9338 - val_accuracy: 0.5017\n",
      "Epoch 14/42\n",
      "36/36 [==============================] - 13s 358ms/step - loss: 1.1714 - accuracy: 0.7702 - val_loss: 1.8373 - val_accuracy: 0.5052\n",
      "Epoch 15/42\n",
      "36/36 [==============================] - 14s 385ms/step - loss: 1.0476 - accuracy: 0.7937 - val_loss: 1.8176 - val_accuracy: 0.5331\n",
      "Epoch 16/42\n",
      "36/36 [==============================] - 13s 355ms/step - loss: 0.9680 - accuracy: 0.8190 - val_loss: 1.7990 - val_accuracy: 0.5331\n",
      "Epoch 17/42\n",
      "36/36 [==============================] - 12s 340ms/step - loss: 0.8733 - accuracy: 0.8364 - val_loss: 1.7382 - val_accuracy: 0.5470\n",
      "Epoch 18/42\n",
      "36/36 [==============================] - 13s 369ms/step - loss: 0.7717 - accuracy: 0.8729 - val_loss: 1.7213 - val_accuracy: 0.5505\n",
      "Epoch 19/42\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.7008 - accuracy: 0.8808 - val_loss: 1.6850 - val_accuracy: 0.5889\n",
      "Epoch 20/42\n",
      "36/36 [==============================] - 14s 398ms/step - loss: 0.6228 - accuracy: 0.9060 - val_loss: 1.6569 - val_accuracy: 0.5575\n",
      "Epoch 21/42\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 0.5560 - accuracy: 0.9191 - val_loss: 1.6355 - val_accuracy: 0.5679\n",
      "Epoch 22/42\n",
      "36/36 [==============================] - 15s 416ms/step - loss: 0.4891 - accuracy: 0.9365 - val_loss: 1.6311 - val_accuracy: 0.5889\n",
      "Epoch 23/42\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 0.4347 - accuracy: 0.9513 - val_loss: 1.6196 - val_accuracy: 0.5889\n",
      "Epoch 24/42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 14s 397ms/step - loss: 0.3832 - accuracy: 0.9643 - val_loss: 1.5715 - val_accuracy: 0.6028\n",
      "Epoch 25/42\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 0.3646 - accuracy: 0.9713 - val_loss: 1.5720 - val_accuracy: 0.5993\n",
      "Epoch 26/42\n",
      "36/36 [==============================] - 14s 398ms/step - loss: 0.3516 - accuracy: 0.9652 - val_loss: 1.5669 - val_accuracy: 0.6063\n",
      "Epoch 27/42\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.3365 - accuracy: 0.9782 - val_loss: 1.5623 - val_accuracy: 0.5819\n",
      "Epoch 28/42\n",
      "36/36 [==============================] - 14s 380ms/step - loss: 0.3218 - accuracy: 0.9765 - val_loss: 1.5532 - val_accuracy: 0.5993\n",
      "Epoch 29/42\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 0.3101 - accuracy: 0.9809 - val_loss: 1.5564 - val_accuracy: 0.6028\n",
      "Epoch 30/42\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 0.2988 - accuracy: 0.9809 - val_loss: 1.5509 - val_accuracy: 0.5958\n",
      "Epoch 31/42\n",
      "36/36 [==============================] - 13s 370ms/step - loss: 0.2902 - accuracy: 0.9826 - val_loss: 1.5466 - val_accuracy: 0.6028\n",
      "Epoch 32/42\n",
      "36/36 [==============================] - 13s 364ms/step - loss: 0.2856 - accuracy: 0.9835 - val_loss: 1.5429 - val_accuracy: 0.6028\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.5429 - accuracy: 0.6028\n",
      "Epoch 1/42\n",
      "36/36 [==============================] - 14s 390ms/step - loss: 2.7426 - accuracy: 0.1619 - val_loss: 2.6315 - val_accuracy: 0.1951\n",
      "Epoch 2/42\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 2.5621 - accuracy: 0.2080 - val_loss: 2.5192 - val_accuracy: 0.1951\n",
      "Epoch 3/42\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 2.4846 - accuracy: 0.2559 - val_loss: 2.5037 - val_accuracy: 0.2021\n",
      "Epoch 4/42\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 2.3874 - accuracy: 0.2463 - val_loss: 2.4347 - val_accuracy: 0.2613\n",
      "Epoch 5/42\n",
      "36/36 [==============================] - 13s 370ms/step - loss: 2.3204 - accuracy: 0.2811 - val_loss: 2.3773 - val_accuracy: 0.2997\n",
      "Epoch 6/42\n",
      "36/36 [==============================] - 14s 389ms/step - loss: 2.1955 - accuracy: 0.3594 - val_loss: 2.2857 - val_accuracy: 0.3240\n",
      "Epoch 7/42\n",
      "36/36 [==============================] - 14s 402ms/step - loss: 2.0725 - accuracy: 0.4212 - val_loss: 2.2609 - val_accuracy: 0.3415\n",
      "Epoch 8/42\n",
      "36/36 [==============================] - 14s 401ms/step - loss: 1.9356 - accuracy: 0.4987 - val_loss: 2.1647 - val_accuracy: 0.4460\n",
      "Epoch 9/42\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 1.8200 - accuracy: 0.5413 - val_loss: 2.0759 - val_accuracy: 0.4007\n",
      "Epoch 10/42\n",
      "36/36 [==============================] - 13s 350ms/step - loss: 1.6914 - accuracy: 0.6162 - val_loss: 2.0255 - val_accuracy: 0.4111\n",
      "Epoch 11/42\n",
      "36/36 [==============================] - 14s 384ms/step - loss: 1.5587 - accuracy: 0.6362 - val_loss: 1.9517 - val_accuracy: 0.5122\n",
      "Epoch 12/42\n",
      "36/36 [==============================] - 14s 384ms/step - loss: 1.4336 - accuracy: 0.6771 - val_loss: 1.9128 - val_accuracy: 0.5679\n",
      "Epoch 13/42\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 1.2840 - accuracy: 0.7728 - val_loss: 1.8230 - val_accuracy: 0.4948\n",
      "Epoch 14/42\n",
      "36/36 [==============================] - 13s 368ms/step - loss: 1.1800 - accuracy: 0.7815 - val_loss: 1.7941 - val_accuracy: 0.5470\n",
      "Epoch 15/42\n",
      "36/36 [==============================] - 14s 395ms/step - loss: 1.0673 - accuracy: 0.7981 - val_loss: 1.7521 - val_accuracy: 0.6028\n",
      "Epoch 16/42\n",
      "36/36 [==============================] - 13s 365ms/step - loss: 0.9818 - accuracy: 0.8259 - val_loss: 1.7254 - val_accuracy: 0.5923\n",
      "Epoch 17/42\n",
      "36/36 [==============================] - 12s 332ms/step - loss: 0.8982 - accuracy: 0.8320 - val_loss: 1.6472 - val_accuracy: 0.5645\n",
      "Epoch 18/42\n",
      "36/36 [==============================] - 15s 407ms/step - loss: 0.7972 - accuracy: 0.8651 - val_loss: 1.6522 - val_accuracy: 0.6098\n",
      "Epoch 19/42\n",
      "36/36 [==============================] - 15s 417ms/step - loss: 0.7023 - accuracy: 0.8930 - val_loss: 1.5918 - val_accuracy: 0.6202\n",
      "Epoch 20/42\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 0.6236 - accuracy: 0.9086 - val_loss: 1.5596 - val_accuracy: 0.5889\n",
      "Epoch 21/42\n",
      "36/36 [==============================] - 14s 393ms/step - loss: 0.5743 - accuracy: 0.9147 - val_loss: 1.5385 - val_accuracy: 0.6341\n",
      "Epoch 22/42\n",
      "36/36 [==============================] - 13s 369ms/step - loss: 0.4990 - accuracy: 0.9339 - val_loss: 1.5767 - val_accuracy: 0.6237\n",
      "Epoch 23/42\n",
      "36/36 [==============================] - 14s 390ms/step - loss: 0.4448 - accuracy: 0.9513 - val_loss: 1.5830 - val_accuracy: 0.6307\n",
      "Epoch 24/42\n",
      "36/36 [==============================] - 14s 401ms/step - loss: 0.3940 - accuracy: 0.9678 - val_loss: 1.4903 - val_accuracy: 0.6516\n",
      "Epoch 25/42\n",
      "36/36 [==============================] - 14s 389ms/step - loss: 0.3461 - accuracy: 0.9704 - val_loss: 1.4640 - val_accuracy: 0.6620\n",
      "Epoch 26/42\n",
      "36/36 [==============================] - 13s 368ms/step - loss: 0.3026 - accuracy: 0.9800 - val_loss: 1.4704 - val_accuracy: 0.6481\n",
      "Epoch 27/42\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 0.2701 - accuracy: 0.9835 - val_loss: 1.4385 - val_accuracy: 0.6516\n",
      "Epoch 28/42\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 0.2329 - accuracy: 0.9896 - val_loss: 1.4259 - val_accuracy: 0.6516\n",
      "Epoch 29/42\n",
      "36/36 [==============================] - 14s 396ms/step - loss: 0.2099 - accuracy: 0.9913 - val_loss: 1.4287 - val_accuracy: 0.6655\n",
      "Epoch 30/42\n",
      "36/36 [==============================] - 14s 389ms/step - loss: 0.1865 - accuracy: 0.9948 - val_loss: 1.4310 - val_accuracy: 0.6725\n",
      "Epoch 31/42\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.1656 - accuracy: 0.9965 - val_loss: 1.4202 - val_accuracy: 0.6620\n",
      "Epoch 32/42\n",
      "36/36 [==============================] - 13s 371ms/step - loss: 0.1495 - accuracy: 0.9974 - val_loss: 1.3850 - val_accuracy: 0.6690\n",
      "Epoch 33/42\n",
      "36/36 [==============================] - 14s 400ms/step - loss: 0.1345 - accuracy: 0.9965 - val_loss: 1.3842 - val_accuracy: 0.6794\n",
      "Epoch 34/42\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 0.1187 - accuracy: 0.9983 - val_loss: 1.3787 - val_accuracy: 0.6481\n",
      "Epoch 35/42\n",
      "36/36 [==============================] - 15s 413ms/step - loss: 0.1071 - accuracy: 0.9983 - val_loss: 1.3806 - val_accuracy: 0.6864\n",
      "Epoch 36/42\n",
      "36/36 [==============================] - 14s 382ms/step - loss: 0.0985 - accuracy: 0.9974 - val_loss: 1.3609 - val_accuracy: 0.6725\n",
      "Epoch 37/42\n",
      "36/36 [==============================] - 13s 365ms/step - loss: 0.0876 - accuracy: 0.9991 - val_loss: 1.3571 - val_accuracy: 0.6655\n",
      "Epoch 38/42\n",
      "36/36 [==============================] - 13s 359ms/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 1.3574 - val_accuracy: 0.6829\n",
      "Epoch 39/42\n",
      "36/36 [==============================] - 12s 341ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 1.3321 - val_accuracy: 0.6655\n",
      "Epoch 40/42\n",
      "36/36 [==============================] - 13s 354ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 1.3307 - val_accuracy: 0.6794\n",
      "Epoch 41/42\n",
      "36/36 [==============================] - 13s 354ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 1.3279 - val_accuracy: 0.6760\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.3279 - accuracy: 0.6760\n",
      "Epoch 1/42\n",
      "36/36 [==============================] - 13s 366ms/step - loss: 2.7408 - accuracy: 0.1802 - val_loss: 2.6017 - val_accuracy: 0.1951\n",
      "Epoch 2/42\n",
      "36/36 [==============================] - 12s 342ms/step - loss: 2.5472 - accuracy: 0.2141 - val_loss: 2.5514 - val_accuracy: 0.1951\n",
      "Epoch 3/42\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 2.4778 - accuracy: 0.2324 - val_loss: 2.4772 - val_accuracy: 0.2125\n",
      "Epoch 4/42\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 2.3711 - accuracy: 0.2602 - val_loss: 2.4187 - val_accuracy: 0.2474\n",
      "Epoch 5/42\n",
      "36/36 [==============================] - 12s 344ms/step - loss: 2.3064 - accuracy: 0.3229 - val_loss: 2.3909 - val_accuracy: 0.2962\n",
      "Epoch 6/42\n",
      "36/36 [==============================] - 12s 333ms/step - loss: 2.1977 - accuracy: 0.3969 - val_loss: 2.3236 - val_accuracy: 0.2753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/42\n",
      "36/36 [==============================] - 14s 375ms/step - loss: 2.0481 - accuracy: 0.4378 - val_loss: 2.2649 - val_accuracy: 0.3833\n",
      "Epoch 8/42\n",
      "36/36 [==============================] - 14s 380ms/step - loss: 1.9173 - accuracy: 0.5109 - val_loss: 2.1689 - val_accuracy: 0.4181\n",
      "Epoch 9/42\n",
      "36/36 [==============================] - 12s 338ms/step - loss: 1.7997 - accuracy: 0.5683 - val_loss: 2.1296 - val_accuracy: 0.3902\n",
      "Epoch 10/42\n",
      "36/36 [==============================] - 13s 359ms/step - loss: 1.6740 - accuracy: 0.6153 - val_loss: 2.0358 - val_accuracy: 0.4216\n",
      "Epoch 11/42\n",
      "36/36 [==============================] - 12s 337ms/step - loss: 1.5600 - accuracy: 0.6545 - val_loss: 1.9978 - val_accuracy: 0.4495\n",
      "Epoch 12/42\n",
      "36/36 [==============================] - 13s 359ms/step - loss: 1.4401 - accuracy: 0.6667 - val_loss: 1.9601 - val_accuracy: 0.4913\n",
      "Epoch 13/42\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 1.3060 - accuracy: 0.7415 - val_loss: 1.8722 - val_accuracy: 0.5122\n",
      "Epoch 14/42\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 1.1848 - accuracy: 0.7711 - val_loss: 1.8132 - val_accuracy: 0.4843\n",
      "Epoch 15/42\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 1.0789 - accuracy: 0.7920 - val_loss: 1.7873 - val_accuracy: 0.5296\n",
      "Epoch 16/42\n",
      "36/36 [==============================] - 12s 342ms/step - loss: 0.9673 - accuracy: 0.8216 - val_loss: 1.7814 - val_accuracy: 0.5052\n",
      "Epoch 17/42\n",
      "36/36 [==============================] - 12s 346ms/step - loss: 0.8775 - accuracy: 0.8477 - val_loss: 1.7217 - val_accuracy: 0.5540\n",
      "Epoch 18/42\n",
      "36/36 [==============================] - 13s 353ms/step - loss: 0.7807 - accuracy: 0.8729 - val_loss: 1.7009 - val_accuracy: 0.5645\n",
      "Epoch 19/42\n",
      "36/36 [==============================] - 13s 364ms/step - loss: 0.7032 - accuracy: 0.8842 - val_loss: 1.6545 - val_accuracy: 0.5784\n",
      "Epoch 20/42\n",
      "36/36 [==============================] - 12s 338ms/step - loss: 0.6251 - accuracy: 0.9043 - val_loss: 1.6258 - val_accuracy: 0.5645\n",
      "Epoch 21/42\n",
      "36/36 [==============================] - 13s 367ms/step - loss: 0.5598 - accuracy: 0.9191 - val_loss: 1.6340 - val_accuracy: 0.5923\n",
      "Epoch 22/42\n",
      "36/36 [==============================] - 12s 341ms/step - loss: 0.5017 - accuracy: 0.9347 - val_loss: 1.5752 - val_accuracy: 0.6028\n",
      "Epoch 23/42\n",
      "36/36 [==============================] - 12s 337ms/step - loss: 0.4366 - accuracy: 0.9487 - val_loss: 1.5686 - val_accuracy: 0.5784\n",
      "Epoch 24/42\n",
      "36/36 [==============================] - 12s 323ms/step - loss: 0.3928 - accuracy: 0.9617 - val_loss: 1.5573 - val_accuracy: 0.5958\n",
      "Epoch 25/42\n",
      "36/36 [==============================] - 13s 353ms/step - loss: 0.3458 - accuracy: 0.9704 - val_loss: 1.5517 - val_accuracy: 0.5993\n",
      "Epoch 26/42\n",
      "36/36 [==============================] - 13s 359ms/step - loss: 0.2991 - accuracy: 0.9791 - val_loss: 1.5505 - val_accuracy: 0.6132\n",
      "Epoch 27/42\n",
      "36/36 [==============================] - 13s 363ms/step - loss: 0.2688 - accuracy: 0.9843 - val_loss: 1.5203 - val_accuracy: 0.6132\n",
      "Epoch 28/42\n",
      "36/36 [==============================] - 14s 381ms/step - loss: 0.2405 - accuracy: 0.9878 - val_loss: 1.5206 - val_accuracy: 0.5819\n",
      "Epoch 29/42\n",
      "36/36 [==============================] - 12s 322ms/step - loss: 0.2185 - accuracy: 0.9887 - val_loss: 1.5113 - val_accuracy: 0.6132\n",
      "Epoch 30/42\n",
      "36/36 [==============================] - 12s 341ms/step - loss: 0.1881 - accuracy: 0.9913 - val_loss: 1.4999 - val_accuracy: 0.6063\n",
      "Epoch 31/42\n",
      "36/36 [==============================] - 11s 318ms/step - loss: 0.1676 - accuracy: 0.9956 - val_loss: 1.4723 - val_accuracy: 0.6098\n",
      "Epoch 32/42\n",
      "36/36 [==============================] - 12s 322ms/step - loss: 0.1580 - accuracy: 0.9965 - val_loss: 1.4654 - val_accuracy: 0.6098\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.4654 - accuracy: 0.6098\n",
      "Epoch 1/42\n",
      "36/36 [==============================] - 13s 356ms/step - loss: 2.7776 - accuracy: 0.1427 - val_loss: 2.6260 - val_accuracy: 0.1916\n",
      "Epoch 2/42\n",
      "36/36 [==============================] - 12s 331ms/step - loss: 2.5447 - accuracy: 0.2089 - val_loss: 2.5705 - val_accuracy: 0.1916\n",
      "Epoch 3/42\n",
      "36/36 [==============================] - 13s 364ms/step - loss: 2.4871 - accuracy: 0.2193 - val_loss: 2.5045 - val_accuracy: 0.1916\n",
      "Epoch 4/42\n",
      "36/36 [==============================] - 14s 398ms/step - loss: 2.3638 - accuracy: 0.2863 - val_loss: 2.4673 - val_accuracy: 0.2300\n",
      "Epoch 5/42\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 2.2842 - accuracy: 0.3168 - val_loss: 2.4214 - val_accuracy: 0.2578\n",
      "Epoch 6/42\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 2.1712 - accuracy: 0.3890 - val_loss: 2.3649 - val_accuracy: 0.2683\n",
      "Epoch 7/42\n",
      "36/36 [==============================] - 13s 351ms/step - loss: 2.0331 - accuracy: 0.4508 - val_loss: 2.3083 - val_accuracy: 0.3031\n",
      "Epoch 8/42\n",
      "36/36 [==============================] - 13s 355ms/step - loss: 1.8987 - accuracy: 0.5030 - val_loss: 2.2507 - val_accuracy: 0.3345\n",
      "Epoch 9/42\n",
      "36/36 [==============================] - 13s 374ms/step - loss: 1.7920 - accuracy: 0.5500 - val_loss: 2.1869 - val_accuracy: 0.3624\n",
      "Epoch 10/42\n",
      "36/36 [==============================] - 14s 397ms/step - loss: 1.6557 - accuracy: 0.5901 - val_loss: 2.0988 - val_accuracy: 0.3902\n",
      "Epoch 11/42\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 1.5340 - accuracy: 0.6371 - val_loss: 2.0686 - val_accuracy: 0.4460\n",
      "Epoch 12/42\n",
      "36/36 [==============================] - 15s 417ms/step - loss: 1.3978 - accuracy: 0.6980 - val_loss: 1.9873 - val_accuracy: 0.5017\n",
      "Epoch 13/42\n",
      "36/36 [==============================] - 14s 378ms/step - loss: 1.2794 - accuracy: 0.7433 - val_loss: 1.9252 - val_accuracy: 0.4948\n",
      "Epoch 14/42\n",
      "36/36 [==============================] - 13s 351ms/step - loss: 1.1631 - accuracy: 0.7772 - val_loss: 1.8799 - val_accuracy: 0.4878\n",
      "Epoch 15/42\n",
      "36/36 [==============================] - 13s 357ms/step - loss: 1.0461 - accuracy: 0.7911 - val_loss: 1.8826 - val_accuracy: 0.5401\n",
      "Epoch 16/42\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 0.9434 - accuracy: 0.8399 - val_loss: 1.8468 - val_accuracy: 0.5261\n",
      "Epoch 17/42\n",
      "36/36 [==============================] - 13s 351ms/step - loss: 0.8600 - accuracy: 0.8486 - val_loss: 1.7953 - val_accuracy: 0.5505\n",
      "Epoch 18/42\n",
      "36/36 [==============================] - 13s 354ms/step - loss: 0.7620 - accuracy: 0.8834 - val_loss: 1.7828 - val_accuracy: 0.5470\n",
      "Epoch 19/42\n",
      "36/36 [==============================] - 14s 377ms/step - loss: 0.6847 - accuracy: 0.9008 - val_loss: 1.7377 - val_accuracy: 0.5889\n",
      "Epoch 20/42\n",
      "36/36 [==============================] - 13s 350ms/step - loss: 0.6057 - accuracy: 0.9191 - val_loss: 1.7178 - val_accuracy: 0.5575\n",
      "Epoch 21/42\n",
      "36/36 [==============================] - 14s 393ms/step - loss: 0.5493 - accuracy: 0.9295 - val_loss: 1.6961 - val_accuracy: 0.5749\n",
      "Epoch 22/42\n",
      "36/36 [==============================] - 14s 377ms/step - loss: 0.4775 - accuracy: 0.9452 - val_loss: 1.6552 - val_accuracy: 0.5854\n",
      "Epoch 23/42\n",
      "36/36 [==============================] - 12s 345ms/step - loss: 0.4288 - accuracy: 0.9582 - val_loss: 1.6347 - val_accuracy: 0.5610\n",
      "Epoch 24/42\n",
      "36/36 [==============================] - 13s 362ms/step - loss: 0.3735 - accuracy: 0.9661 - val_loss: 1.6294 - val_accuracy: 0.5819\n",
      "Epoch 25/42\n",
      "36/36 [==============================] - 15s 404ms/step - loss: 0.3567 - accuracy: 0.9678 - val_loss: 1.6273 - val_accuracy: 0.5958\n",
      "Epoch 26/42\n",
      "36/36 [==============================] - 14s 384ms/step - loss: 0.3395 - accuracy: 0.9721 - val_loss: 1.6151 - val_accuracy: 0.5854\n",
      "Epoch 27/42\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.3279 - accuracy: 0.9756 - val_loss: 1.6085 - val_accuracy: 0.5784\n",
      "Epoch 28/42\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 0.3146 - accuracy: 0.9765 - val_loss: 1.6164 - val_accuracy: 0.5923\n",
      "Epoch 29/42\n",
      "36/36 [==============================] - 14s 375ms/step - loss: 0.3041 - accuracy: 0.9782 - val_loss: 1.6094 - val_accuracy: 0.5784\n",
      "Epoch 30/42\n",
      "36/36 [==============================] - 14s 392ms/step - loss: 0.2920 - accuracy: 0.9835 - val_loss: 1.6053 - val_accuracy: 0.5889\n",
      "Epoch 31/42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 12s 337ms/step - loss: 0.2844 - accuracy: 0.9843 - val_loss: 1.6042 - val_accuracy: 0.5923\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6042 - accuracy: 0.5923\n"
     ]
    }
   ],
   "source": [
    "n_encoder = 0\n",
    "models_trans, preds, scores_trans = train_pred(n_encoder = 0,epochs = 42)\n",
    "# outputs.append([pred_val_y, pred_test_y, 'transformer_enc{}'.format(n_encoder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "e3dc6e5362fa13e00b291986b94ea9d6e5acdebf"
   },
   "outputs": [],
   "source": [
    "# for thresh in np.arange(0.1, 0.51, 0.01):\n",
    "#     thresh = np.round(thresh, 2)\n",
    "#     print(\"F1 score at threshold {0:.2f} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))\n",
    "# models_trans = models\n",
    "# scores\n",
    "# preds\n",
    "# np.mean(preds,axis = 0)\n",
    "# models == models_trans\n",
    "scores_trans = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.6107128858566284, 0.5833333134651184],\n",
       " [1.5429130792617798, 0.602787435054779],\n",
       " [1.3278847932815552, 0.6759582161903381],\n",
       " [1.4654251337051392, 0.6097561120986938],\n",
       " [1.6041935682296753, 0.592334508895874]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores[1]\n",
    "scores_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "43e0969fd3af4b65decfbba8cce0a8a36d552176"
   },
   "outputs": [],
   "source": [
    "# pred_test_y = (pred_test_y > 0.42).astype(int)\n",
    "# test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"qid\"])\n",
    "# out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "# out_df['prediction'] = pred_test_y\n",
    "# out_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "c378fe1cfd53529831f3928fb9866329eb7a9184"
   },
   "outputs": [],
   "source": [
    "# idx = (pred_test_y > 0.42).astype(int)\n",
    "# test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"qid\"])\n",
    "# out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "# out_df['prediction'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "c378fe1cfd53529831f3928fb9866329eb7a9184"
   },
   "outputs": [],
   "source": [
    "# mylist = out_df[out_df.prediction == 1].index\n",
    "# for i in mylist:\n",
    "#     print(i, end=',')\n",
    "\n",
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a3b5a15d3745fa2ffb2e0bfd1c98ba890e27550"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model)\n",
    "train_df = pd.read_csv(\"../data/Train.csv\")\n",
    "test_df = pd.read_csv(\"../data/Test.csv\")\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "#     text = re.sub(r\"what's\", \"what is \", text)\n",
    "#     text = re.sub(r\"\\'s\", \" \", text)\n",
    "#     text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(r\"can't\", \"cannot \", text)\n",
    "#     text = re.sub(r\"n't\", \" not \", text)\n",
    "#     text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#     text = re.sub(r\"\\'re\", \" are \", text)\n",
    "#     text = re.sub(r\"\\'d\", \" would \", text)\n",
    "#     text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "#     text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "#     text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub(r\",\", \" \", text) \n",
    "    text = re.sub(r\"!\", \" \", text) \n",
    "    text = re.sub(r\"\\(\", \" \", text) \n",
    "    text = re.sub(r\"\\)\", \" \", text) \n",
    "    text = re.sub(r\"\\?\", \" \", text) \n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)  \n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "# removing stop words\n",
    "# other_stop_w = pd.read_csv('../Downloaded_notebooks/words_shared_by_all.csv')\n",
    "# stopw = [item for sublist in other_stop_w.values.tolist() for item in sublist]\n",
    "# train_df['Text'].apply(lambda x: [item for item in x.split() if item not in stopw])\n",
    "# test_df['Text'].apply(lambda x: [item for item in x.split() if item not in stopw])\n",
    "\n",
    "train_df['Text'] = train_df['Text'].map(lambda com : clean_text(com))\n",
    "test_df['Text'] = test_df['Text'].map(lambda com : clean_text(com))\n",
    "X_tfidf = train_df.Text\n",
    "test_X_tfidf = test_df.Text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [base_m.trainable = False ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features=45000,sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "\n",
    "X_dtm = vect.fit_transform(X_tfidf).toarray()\n",
    "\n",
    "test_X_dtm = vect.transform(test_X_tfidf).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "# # y_train\n",
    "cols_target = train_df['Label'].unique().tolist()\n",
    "train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "# # train_df\n",
    "\n",
    "# x_train, x_val, y_train, y_val = train_test_split(X_dtm, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx = list(set(X_tfidf.index.tolist()) - set(val_idx.tolist()))\n",
    "# base_model.evaluate(X_dtm[val_idx],train_df.loc[val_idx,cols_target])\n",
    "# (y_val == val_y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y.shape\n",
    "# len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "# Build the model\n",
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "# K.clear_session()\n",
    "# seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "# os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "# random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "# np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "# tf.random.set_seed(seed_value)\n",
    "def build_base_model():\n",
    "    K.clear_session()\n",
    "    seed_value = 0\n",
    "    tf.random.set_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    base_model = models.Sequential()\n",
    "    base_model.add(layers.Dense(1000, input_shape=(45000,)))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    base_model.add(layers.Activation('linear'))\n",
    "    base_model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Dense(2048))\n",
    "    # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.Activation('relu'))\n",
    "    # model.add(layers.Dense(512))\n",
    "    # # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.Activation('relu'))\n",
    "    # model.add(layers.Dense(128))\n",
    "    # # model.add(layers.BatchNormalization())\n",
    "    # model.add(layers.Activation('relu'))\n",
    "\n",
    "    # model.add(layers.Dropout(drop_ratio))\n",
    "    base_model.add(layers.Dense(20))\n",
    "    base_model.add(layers.Activation('softmax'))\n",
    "\n",
    "    base_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dtm[train_idx].shape\n",
    "# base_model\n",
    "# history = base_model.fit(x_train, y_train,\n",
    "#                     batch_size=64,\n",
    "#                     epochs=10,\n",
    "#                     verbose=1,\n",
    "#                    validation_split = 0.1)\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback, ReduceLROnPlateau\n",
    "file_path = \"weights_base.best.hdf5\"\n",
    "def benchmark():\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "#     print(clf)\n",
    "#     t0 = time()\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "    models, preds, scores = [], [],[]\n",
    "#     vectorizer = vect(max_df = 0.5)\n",
    "    for train, test in skf.split(train_df.Text, train_df.Label):\n",
    "#     print(train, test)\n",
    "#     clf = LogisticRegression(penalty='l1')\n",
    "#         clf.fit(vectorizer.transform(), data_train.Label.loc[data_train.index.intersection(train)])\n",
    "#         K.clear_session()\n",
    "        clf = build_base_model()\n",
    "        X_train = train_df.Text.loc[train_df.index.intersection(train)]\n",
    "        X_val = train_df.Text.loc[train_df.index.intersection(test)]\n",
    "        y_train = train_df[cols_target].loc[train_df.index.intersection(train)]\n",
    "        y_val = train_df[cols_target].loc[train_df.index.intersection(test)]\n",
    "        X_train = vect.transform(X_train).toarray()\n",
    "        X_val = vect.transform(X_val).toarray()\n",
    "        X_test = vect.transform(test_df.Text).toarray()\n",
    "        \n",
    "        \n",
    "        \n",
    "        clf.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                   validation_data = (X_val,y_val),\n",
    "                   callbacks=[\n",
    "#               RocAucEvaluation(verbose=True),\n",
    "              ModelCheckpoint(file_path,    monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "              EarlyStopping(patience=10,    monitor=\"val_accuracy\", mode=\"max\"),\n",
    "              ReduceLROnPlateau(patience=4, monitor='val_accuracy', mode='max', cooldown=2, min_lr=1e-7, factor=0.3)])\n",
    "        preds.append(clf.predict(X_test))\n",
    "        models.append(clf)\n",
    "        scores.append(clf.evaluate(X_val,y_val))\n",
    "#         coefs.append(clf.coef_[0])\n",
    "#         clf.fit(X_train, y_train)\n",
    "#     train_time = time() - t0\n",
    "#     print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "#     t0 = time()\n",
    "#     pred = clf.predict(X_test)\n",
    "#     test_time = time() - t0\n",
    "#     print(\"test time:  %0.3fs\" % test_time)\n",
    "    pred = np.mean(preds,axis = 0)\n",
    "#     score = metrics.accuracy_score(data_test.Label, pred)\n",
    "#     print(\"accuracy:   %0.3f\" % score)\n",
    "    return models, pred,scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 19s 520ms/step - loss: 2.4258 - accuracy: 0.2605 - val_loss: 2.0041 - val_accuracy: 0.4931\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 16s 450ms/step - loss: 0.9089 - accuracy: 0.8441 - val_loss: 1.5423 - val_accuracy: 0.5660\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.2080 - accuracy: 0.9878 - val_loss: 1.4053 - val_accuracy: 0.6076\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 15s 415ms/step - loss: 0.0551 - accuracy: 0.9965 - val_loss: 1.3657 - val_accuracy: 0.6146\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 14s 382ms/step - loss: 0.0267 - accuracy: 0.9974 - val_loss: 1.3525 - val_accuracy: 0.6111\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 14s 386ms/step - loss: 0.0204 - accuracy: 0.9983 - val_loss: 1.3456 - val_accuracy: 0.6076\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 13s 352ms/step - loss: 0.0135 - accuracy: 0.9991 - val_loss: 1.3414 - val_accuracy: 0.6111\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 13s 350ms/step - loss: 0.0116 - accuracy: 0.9983 - val_loss: 1.3385 - val_accuracy: 0.6076\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 0.0097 - accuracy: 0.9991 - val_loss: 1.3387 - val_accuracy: 0.6111\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 14s 395ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 1.3380 - val_accuracy: 0.6076\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.3380 - accuracy: 0.6076\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 17s 466ms/step - loss: 2.4194 - accuracy: 0.2620 - val_loss: 1.9161 - val_accuracy: 0.5052\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.8915 - accuracy: 0.8503 - val_loss: 1.4407 - val_accuracy: 0.6272\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 16s 450ms/step - loss: 0.1924 - accuracy: 0.9869 - val_loss: 1.3315 - val_accuracy: 0.6481\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 14s 395ms/step - loss: 0.0460 - accuracy: 0.9991 - val_loss: 1.3006 - val_accuracy: 0.6411\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 14s 385ms/step - loss: 0.0236 - accuracy: 0.9991 - val_loss: 1.2859 - val_accuracy: 0.6341\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 13s 354ms/step - loss: 0.0158 - accuracy: 0.9991 - val_loss: 1.2779 - val_accuracy: 0.6376\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 12s 346ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 1.2758 - val_accuracy: 0.6341\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 14s 378ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.2751 - val_accuracy: 0.6341\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 15s 405ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.2741 - val_accuracy: 0.6341\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 15s 404ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2738 - val_accuracy: 0.6341\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 1.2738 - accuracy: 0.6341\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 17s 485ms/step - loss: 2.4324 - accuracy: 0.2742 - val_loss: 1.8869 - val_accuracy: 0.5157\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 17s 462ms/step - loss: 0.9197 - accuracy: 0.8259 - val_loss: 1.3698 - val_accuracy: 0.6481\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 17s 481ms/step - loss: 0.1939 - accuracy: 0.9904 - val_loss: 1.2341 - val_accuracy: 0.6620\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 17s 472ms/step - loss: 0.0482 - accuracy: 0.9983 - val_loss: 1.1954 - val_accuracy: 0.6725\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 13s 366ms/step - loss: 0.0255 - accuracy: 0.9974 - val_loss: 1.1803 - val_accuracy: 0.6725\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 17s 461ms/step - loss: 0.0185 - accuracy: 0.9983 - val_loss: 1.1728 - val_accuracy: 0.6760\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 13s 358ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 1.1666 - val_accuracy: 0.6725\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 13s 349ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 1.1632 - val_accuracy: 0.6725\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 13s 368ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 1.1599 - val_accuracy: 0.6725\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 13s 371ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 1.1603 - val_accuracy: 0.6690\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.1603 - accuracy: 0.6690\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 18s 510ms/step - loss: 2.4084 - accuracy: 0.2576 - val_loss: 1.9020 - val_accuracy: 0.5157\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 17s 468ms/step - loss: 0.9165 - accuracy: 0.8277 - val_loss: 1.4190 - val_accuracy: 0.6098\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 17s 463ms/step - loss: 0.2072 - accuracy: 0.9913 - val_loss: 1.2764 - val_accuracy: 0.6307\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0534 - accuracy: 0.9983 - val_loss: 1.2325 - val_accuracy: 0.6307\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 13s 352ms/step - loss: 0.0279 - accuracy: 0.9974 - val_loss: 1.2136 - val_accuracy: 0.6202\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 13s 363ms/step - loss: 0.0176 - accuracy: 0.9983 - val_loss: 1.2016 - val_accuracy: 0.6202\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 13s 351ms/step - loss: 0.0181 - accuracy: 0.9983 - val_loss: 1.1989 - val_accuracy: 0.6202\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 16s 438ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 1.1953 - val_accuracy: 0.6237\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 1.1921 - val_accuracy: 0.6307\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 14s 393ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 1.1908 - val_accuracy: 0.6307\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1.1908 - accuracy: 0.6307\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 17s 486ms/step - loss: 2.4138 - accuracy: 0.2602 - val_loss: 1.9680 - val_accuracy: 0.4878\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 16s 450ms/step - loss: 0.9205 - accuracy: 0.8268 - val_loss: 1.5199 - val_accuracy: 0.5784\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.2081 - accuracy: 0.9896 - val_loss: 1.3900 - val_accuracy: 0.6028\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 14s 399ms/step - loss: 0.0528 - accuracy: 0.9974 - val_loss: 1.3567 - val_accuracy: 0.5993\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 13s 367ms/step - loss: 0.0283 - accuracy: 0.9965 - val_loss: 1.3455 - val_accuracy: 0.5958\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 13s 370ms/step - loss: 0.0178 - accuracy: 0.9983 - val_loss: 1.3394 - val_accuracy: 0.5958\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 13s 366ms/step - loss: 0.0181 - accuracy: 0.9983 - val_loss: 1.3389 - val_accuracy: 0.5958\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 14s 387ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 1.3361 - val_accuracy: 0.5993\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 14s 384ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 1.3336 - val_accuracy: 0.5993\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 13s 371ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 1.3338 - val_accuracy: 0.5993\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.3338 - accuracy: 0.5993\n"
     ]
    }
   ],
   "source": [
    "# base_model.evaluate(x_val,y_val)\n",
    "# train_X.shape\n",
    "# (y_train == train_y).all()\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,cross_val_score,train_test_split,StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron,LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "base_models, pred,scores_base = benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect\n",
    "# base_models[0].trainable\n",
    "for base_m in models_trans:\n",
    "    base_m.trainable = False\n",
    "for base_m in base_models:\n",
    "    base_m.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores\n",
    "# models_trans[2]== models_trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.trainable = False\n",
    "# model.trainable = False\n",
    "# base_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape\n",
    "# X_dtm\n",
    "# lb.inverse_transform(pred)\n",
    "# lb.inverse_transform(pd.DataFrame(pred,columns = cols_target)[lb.classes_].values)\n",
    "# pred = np.mean(preds,axis = 0)\n",
    "\n",
    "# test_df['Label']= lb.inverse_transform(pd.DataFrame(pred,columns = cols_target)[lb.classes_].values)\n",
    "# sub = test_df[['ID', 'Label']]\n",
    "# sub.to_csv('cross_enc_001.csv', index = False)\n",
    "# sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"../Translated/cleaned/train.csv\")\n",
    "# test_df = pd.read_csv(\"../Translated/cleaned/test.csv\")\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_supermodel():\n",
    "    K.clear_session()\n",
    "\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "    random.seed(seed_value)\n",
    "\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "    input_trans = layers.Input(shape=(maxlen,))\n",
    "    input_tf = layers.Input(shape=(45000,))\n",
    "    output1 = []\n",
    "    output2 = []\n",
    "    for i, base_model in enumerate(base_models) : \n",
    "        base_model._name = 'base_model_'+str(i)\n",
    "        output1.append(base_model)\n",
    "    for i, base_model in enumerate(models_trans) : \n",
    "        base_model._name = 'trans_model_'+str(i)\n",
    "        output2.append(base_model)\n",
    "    output_1 = [base_model(input_tf,training = False) for base_model in output1]\n",
    "\n",
    "    output_2 = [model(input_trans,training = False) for model in output2]\n",
    "\n",
    "    y = layers.Concatenate( name = 'output_1')(output_1)\n",
    "    x = layers.Concatenate()(output_2)\n",
    "    x = layers.Concatenate()([x,y])\n",
    "    # x = layers.Dense(1024, activation = 'linear')(x)\n",
    "    x = layers.Dense(512, activation = 'linear')(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation = 'sigmoid')(x)\n",
    "    x = layers.Dense(128, activation = 'linear',kernel_regularizer=regularizers.l2(0.02))(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    outputs = layers.Dense(20, activation=\"softmax\")(x)\n",
    "    super_model = keras.Model(inputs=[input_trans, input_tf], outputs=outputs)\n",
    "    super_model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return super_model\n",
    "# history = super_model.fit(\n",
    "#     [train_X,x_train], y_train, batch_size=32, epochs=19, validation_split = 0.1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_stack():\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "#     print(clf)\n",
    "#     t0 = time()\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "    models, preds, scores = [], [],[]\n",
    "#     vectorizer = vect(max_df = 0.5)\n",
    "    for train, test in skf.split(train_df.Text, train_df.Label):\n",
    "#     print(train, test)\n",
    "#     clf = LogisticRegression(penalty='l1')\n",
    "#         clf.fit(vectorizer.transform(), data_train.Label.loc[data_train.index.intersection(train)])\n",
    "#         K.clear_session()\n",
    "        clf = build_supermodel()\n",
    "        X_train = train_df.Text.loc[train_df.index.intersection(train)]\n",
    "        X_val = train_df.Text.loc[train_df.index.intersection(test)]\n",
    "        y_train = train_df[cols_target].loc[train_df.index.intersection(train)]\n",
    "        y_val = train_df[cols_target].loc[train_df.index.intersection(test)]\n",
    "        \n",
    "        X_train_ker = tokenizer.texts_to_sequences(X_train)\n",
    "        X_val_ker = tokenizer.texts_to_sequences(X_val)\n",
    "        X_test_ker = tokenizer.texts_to_sequences(test_df.Text)\n",
    "\n",
    "        ## Pad the sentences \n",
    "        X_train_ker = pad_sequences(X_train_ker, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        X_val_ker = pad_sequences(X_val_ker, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        X_test_ker = pad_sequences(X_test_ker, maxlen=maxlen,padding = 'post', truncating = 'post')\n",
    "        \n",
    "        X_train_tfidf = vect.transform(X_train).toarray()\n",
    "        X_val_tfidf = vect.transform(X_val).toarray()\n",
    "        X_test_tfidf = vect.transform(test_df.Text).toarray()\n",
    "        \n",
    "        \n",
    "        clf.fit([X_train_ker, X_train_tfidf], y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                   validation_data = ([X_val_ker, X_val_tfidf],y_val),\n",
    "                   callbacks=[\n",
    "#               RocAucEvaluation(verbose=True),\n",
    "              ModelCheckpoint(file_path,    monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "              EarlyStopping(patience=10,    monitor=\"val_accuracy\", mode=\"max\"),\n",
    "              ReduceLROnPlateau(patience=4, monitor='val_accuracy', mode='max', cooldown=2, min_lr=1e-7, factor=0.3)])\n",
    "        preds.append(clf.predict([X_test_ker,X_test_tfidf]))\n",
    "        models.append(clf)\n",
    "        scores.append(clf.evaluate([X_val_ker, X_val_tfidf],y_val))\n",
    "#         coefs.append(clf.coef_[0])\n",
    "#         clf.fit(X_train, y_train)\n",
    "#     train_time = time() - t0\n",
    "#     print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "#     t0 = time()\n",
    "#     pred = clf.predict(X_test)\n",
    "#     test_time = time() - t0\n",
    "#     print(\"test time:  %0.3fs\" % test_time)\n",
    "    pred = np.mean(preds,axis = 0)\n",
    "#     score = metrics.accuracy_score(data_test.Label, pred)\n",
    "#     print(\"accuracy:   %0.3f\" % score)\n",
    "    return models, pred,scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "36/36 [==============================] - 31s 872ms/step - loss: 4.2983 - accuracy: 0.7430 - val_loss: 3.0512 - val_accuracy: 0.9688\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 27s 753ms/step - loss: 2.4960 - accuracy: 0.9869 - val_loss: 2.0241 - val_accuracy: 0.9896\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 26s 711ms/step - loss: 1.6559 - accuracy: 0.9965 - val_loss: 1.3211 - val_accuracy: 1.0000\n",
      "9/9 [==============================] - 3s 364ms/step - loss: 1.3211 - accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "36/36 [==============================] - 30s 842ms/step - loss: 4.3303 - accuracy: 0.7346 - val_loss: 3.0439 - val_accuracy: 0.9826\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 29s 813ms/step - loss: 2.5364 - accuracy: 0.9869 - val_loss: 2.0564 - val_accuracy: 0.9965\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 29s 811ms/step - loss: 1.7043 - accuracy: 0.9991 - val_loss: 1.3624 - val_accuracy: 1.0000\n",
      "9/9 [==============================] - 3s 346ms/step - loss: 1.3624 - accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "36/36 [==============================] - 30s 832ms/step - loss: 4.3019 - accuracy: 0.7319 - val_loss: 3.0516 - val_accuracy: 0.9791\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 25s 707ms/step - loss: 2.5125 - accuracy: 0.9869 - val_loss: 2.0398 - val_accuracy: 0.9930\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 26s 735ms/step - loss: 1.6689 - accuracy: 0.9983 - val_loss: 1.3363 - val_accuracy: 0.9965\n",
      "9/9 [==============================] - 3s 312ms/step - loss: 1.3363 - accuracy: 0.9965\n",
      "Epoch 1/3\n",
      "36/36 [==============================] - 27s 742ms/step - loss: 4.2523 - accuracy: 0.7502 - val_loss: 3.0065 - val_accuracy: 0.9721\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 26s 719ms/step - loss: 2.4699 - accuracy: 0.9852 - val_loss: 1.9881 - val_accuracy: 0.9895\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 25s 685ms/step - loss: 1.6218 - accuracy: 0.9991 - val_loss: 1.2824 - val_accuracy: 1.0000\n",
      "9/9 [==============================] - 3s 359ms/step - loss: 1.2824 - accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "36/36 [==============================] - 28s 788ms/step - loss: 4.2427 - accuracy: 0.7537 - val_loss: 2.9926 - val_accuracy: 0.9721\n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 25s 688ms/step - loss: 2.4496 - accuracy: 0.9869 - val_loss: 1.9653 - val_accuracy: 0.9930\n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 27s 739ms/step - loss: 1.5993 - accuracy: 0.9983 - val_loss: 1.2605 - val_accuracy: 1.0000\n",
      "9/9 [==============================] - 3s 291ms/step - loss: 1.2605 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "models, pred,scores = benchmark_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(models,scores,threshold = 0.6):\n",
    "    return [models[i] for i, v in enumerate(scores) if v[1]>=threshold]\n",
    "#   return models[index]\n",
    "# \n",
    "# scores_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x141f2bf83c8>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x141f4382208>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x141f45ce148>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x141f5a93b08>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(base_models,scores_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super_model.evaluate([val_X,x_val], y_val)\n",
    "# gsh = output_1[0]\n",
    "# x\n",
    "# gsh.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (y_val.values == val_y).all()\n",
    "# y_val.columns == lb.classes_\n",
    "# preds  = super_model.predict([test_X, test_X_dtm])\n",
    "# lb.inverse_transform(pd.DataFrame(preds,columns = cols_target)[lb.classes_].values)\n",
    "test_df['Label'] = lb.inverse_transform(pd.DataFrame(pred,columns = cols_target)[lb.classes_].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_ADHEtjTi</td>\n",
       "      <td>abambo odzikhweza akuchuluka kafukufuku wa apo...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AHfJktdQ</td>\n",
       "      <td>ambuye ziyaye ayamikira aphunzitsi a tilitonse...</td>\n",
       "      <td>RELIGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AUJIHpZr</td>\n",
       "      <td>anatcheleza: akundiopseza a gogo wanga akundio...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AUKYBbIM</td>\n",
       "      <td>ulova wafika posauzana adatenga digiri ya uphu...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AZnsVPEi</td>\n",
       "      <td>dzombe kukoma koma kuyambira makedzana panthaw...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ID_zdpOUWyJ</td>\n",
       "      <td>kanyongolo wapempha oyimira milandu kuti atsat...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ID_zhnOomuu</td>\n",
       "      <td>amandimenya zikomo gogo ndine mtsikana wa zaka...</td>\n",
       "      <td>RELATIONSHIPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ID_zmWHvBJb</td>\n",
       "      <td>apolisi athotha gulu la myp asilikali 56 a gul...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>ID_zphjdFIb</td>\n",
       "      <td>mwambo wa ukwati wa chitonga mtundu wina uliwo...</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ID_ztdtrNxt</td>\n",
       "      <td>mwapasa autsa mapiri pamene pali kusamvana pak...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               Text  \\\n",
       "0    ID_ADHEtjTi  abambo odzikhweza akuchuluka kafukufuku wa apo...   \n",
       "1    ID_AHfJktdQ  ambuye ziyaye ayamikira aphunzitsi a tilitonse...   \n",
       "2    ID_AUJIHpZr  anatcheleza: akundiopseza a gogo wanga akundio...   \n",
       "3    ID_AUKYBbIM  ulova wafika posauzana adatenga digiri ya uphu...   \n",
       "4    ID_AZnsVPEi  dzombe kukoma koma kuyambira makedzana panthaw...   \n",
       "..           ...                                                ...   \n",
       "615  ID_zdpOUWyJ  kanyongolo wapempha oyimira milandu kuti atsat...   \n",
       "616  ID_zhnOomuu  amandimenya zikomo gogo ndine mtsikana wa zaka...   \n",
       "617  ID_zmWHvBJb  apolisi athotha gulu la myp asilikali 56 a gul...   \n",
       "618  ID_zphjdFIb  mwambo wa ukwati wa chitonga mtundu wina uliwo...   \n",
       "619  ID_ztdtrNxt  mwapasa autsa mapiri pamene pali kusamvana pak...   \n",
       "\n",
       "             Label  \n",
       "0    SOCIAL ISSUES  \n",
       "1         RELIGION  \n",
       "2    SOCIAL ISSUES  \n",
       "3    SOCIAL ISSUES  \n",
       "4    SOCIAL ISSUES  \n",
       "..             ...  \n",
       "615       POLITICS  \n",
       "616  RELATIONSHIPS  \n",
       "617       POLITICS  \n",
       "618  SOCIAL ISSUES  \n",
       "619       POLITICS  \n",
       "\n",
       "[620 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_X.shape\n",
    "sub = test_df[['ID','Label']]\n",
    "sub.to_csv('submission_keras_stack003A_reg8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub.Label == pd.read_csv('submission_keras_stack002.csv').Label).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
