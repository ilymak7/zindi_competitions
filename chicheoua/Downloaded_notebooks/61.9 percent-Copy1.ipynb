{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# \n",
    "# vect\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_df = pd.read_csv('../Translated/cleaned/train.csv')\n",
    "test_df = pd.read_csv('../Translated/cleaned/test.csv')\n",
    "cols_target = train_df.Label.unique().tolist()\n",
    "le = LabelEncoder()\n",
    "# y_train = lb.fit_transform(train_df['Label'])\n",
    "train_df['label'] = le.fit_transform(train_df['Label'])\n",
    "# y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "# y_train\n",
    "\n",
    "# train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "train_df\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "#     text = re.sub(r\"what's\", \"what is \", text)\n",
    "#     text = re.sub(r\"\\'s\", \" \", text)\n",
    "#     text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(r\"can't\", \"cannot \", text)\n",
    "#     text = re.sub(r\"n't\", \" not \", text)\n",
    "#     text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#     text = re.sub(r\"\\'re\", \" are \", text)\n",
    "#     text = re.sub(r\"\\'d\", \" would \", text)\n",
    "#     text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "#     text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "#     text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "train_df['Text'] = train_df['Text'].map(lambda com : clean_text(com))\n",
    "test_df['Text'] = test_df['Text'].map(lambda com : clean_text(com))\n",
    "X = train_df.Text\n",
    "test_X = test_df.Text\n",
    "# import and instantiate TfidfVectorizer\n",
    "other_stop_w = pd.read_csv('words_shared_by_all.csv')\n",
    "stopw = [item for sublist in other_stop_w.values.tolist() for item in sublist]\n",
    "tfidf_vect = TfidfVectorizer(max_features=45000,ngram_range=(1, 4), max_df=0.9, min_df = 2)\n",
    "count_vect = CountVectorizer(stop_words = stopw)\n",
    "\n",
    "X_tfidf = tfidf_vect.fit_transform(X)\n",
    "test_X_tfidf = tfidf_vect.transform(test_X)\n",
    "\n",
    "X_count = count_vect.fit_transform(X)\n",
    "test_X_count = count_vect.transform(test_X)\n",
    "\n",
    "# vectorizer\n",
    "\n",
    "# X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(X_tfidf, train_df['label'], test_size=0.2, random_state = 0,stratify = train_df['Label'])\n",
    "\n",
    "# X_count_train, X_count_test, y_count_train, y_count_test = train_test_split(X_count, train_df['label'], test_size=0.2, random_state = 0,stratify = train_df['Label'])\n",
    "\n",
    "# logreg_tfidf = LogisticRegression(C=12.0,max_iter = 1000,random_state = 0, multi_class = 'ovr', solver = 'liblinear')\n",
    "\n",
    "# logreg_count = LogisticRegression(C=12.0,max_iter = 1000,random_state = 0, multi_class = 'ovr', solver = 'liblinear')\n",
    "\n",
    "\n",
    "# logreg_tfidf.fit(X_tfidf_train,y_tfidf_train)\n",
    "\n",
    "# logreg_count.fit(X_count_train,y_count_train)\n",
    "\n",
    "# # precision_score(logreg_tfidf.predict(X_tfidf_test),y_tfidf_test, average=None)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['label']\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'label' : lb.classes_,\n",
    "#               'precision' : precision_score(logreg_tfidf.predict(X_tfidf_test),y_tfidf_test, average=None),\n",
    "#               'recall' : recall_score(logreg_tfidf.predict(X_tfidf_test),y_tfidf_test,average = None),\n",
    "#              'accuracy' : accuracy_score(logreg_tfidf.predict(X_tfidf_test),y_tfidf_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model_vect(count_vect, train_df,model,lb):\n",
    "# #     lb = LabelEncoder()\n",
    "#     y = lb.fit_transform(train_df['Label'])\n",
    "#     X = train_df.Text\n",
    "#     X_count = count_vect.fit_transform(X)\n",
    "#     X_count_train, X_count_test, y_count_train, y_count_test = train_test_split(X_count, y, test_size=0.2, random_state = 0,stratify = train_df['Label'])\n",
    "#     model.fit(X_count_train,y_count_train)\n",
    "#     results = pd.DataFrame({'label' : lb.classes_,\n",
    "#               'precision' : precision_score(model.predict(X_count_test),y_count_test, average=None),\n",
    "#               'recall' : recall_score(model.predict(X_count_test),y_count_test,average = None),\n",
    "#              'accuracy' : accuracy_score(model.predict(X_count_test),y_count_test)})\n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model_vect(tfidf_vect, train_df,logreg_tfidf,LabelEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_tfidf = LogisticRegression(C=12.0,max_iter = 1000,random_state = 0, solver = 'liblinear')\n",
    "# count_vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vectorizer = HashingVectorizer(n_features=10000,norm=None,alternate_sign=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model_vect(hash_vectorizer, train_df,logreg_tfidf,LabelEncoder())\n",
    "\n",
    "X_hash = hash_vectorizer.fit_transform(X)\n",
    "test_hash = hash_vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1436x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 260379 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_target = train_df.Label.unique().tolist()\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train_df['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "# y_train\n",
    "\n",
    "train_df = pd.concat([train_df, y_train], axis = 1)\n",
    "# train_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "# Build the model\n",
    "from keras import backend as K \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1400, input_shape=(45000,)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('linear'))\n",
    "# model.add(layers.ActivityRegularization(l1=0.5, l2=0.5))\n",
    "# model.add(layers.Dropout(0.3))\n",
    "# model.add(layers.Dense(400))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('softmax'))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "\n",
    "# model.add(layers.Dense(2048))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(512))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(128))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "\n",
    "# model.add(layers.Dropout(drop_ratio))\n",
    "model.add(layers.Dense(20))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/37 [==============================] - 19s 512ms/step - loss: 2.1555 - accuracy: 0.3821 - val_loss: 1.5491 - val_accuracy: 0.6154\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 19s 512ms/step - loss: 0.4649 - accuracy: 0.9148 - val_loss: 1.2194 - val_accuracy: 0.6538\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 13s 361ms/step - loss: 0.0608 - accuracy: 0.9966 - val_loss: 1.1655 - val_accuracy: 0.6538\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 18s 479ms/step - loss: 0.0267 - accuracy: 0.9974 - val_loss: 1.1564 - val_accuracy: 0.6692\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 13s 360ms/step - loss: 0.0225 - accuracy: 0.9974 - val_loss: 1.1519 - val_accuracy: 0.6692\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 14s 368ms/step - loss: 0.0188 - accuracy: 0.9974 - val_loss: 1.1507 - val_accuracy: 0.6692\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 13s 359ms/step - loss: 0.0180 - accuracy: 0.9983 - val_loss: 1.1500 - val_accuracy: 0.6692\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 13s 365ms/step - loss: 0.0173 - accuracy: 0.9991 - val_loss: 1.1496 - val_accuracy: 0.6692\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 14s 367ms/step - loss: 0.0170 - accuracy: 0.9991 - val_loss: 1.1493 - val_accuracy: 0.6692\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 14s 373ms/step - loss: 0.0167 - accuracy: 0.9991 - val_loss: 1.1492 - val_accuracy: 0.6692\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 13s 360ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.6692\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 13s 359ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.6692\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 13s 364ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.1490 - val_accuracy: 0.6692\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 13s 363ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.1490 - val_accuracy: 0.6692\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.toarray(), y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    callbacks=[\n",
    "#               RocAucEvaluation(verbose=True),\n",
    "              ModelCheckpoint('model.chekpoint.hdf5',monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "              EarlyStopping(patience=10,    monitor=\"val_accuracy\", mode=\"max\"),\n",
    "              ReduceLROnPlateau(patience=0, monitor='val_accuracy', mode='max', cooldown=2, min_lr=1e-7, factor=0.3)],\n",
    "                   validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 46ms/step - loss: 1.2635 - accuracy: 0.6736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2635291814804077, 0.6736111044883728]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_X_tfidf.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SOCIAL ISSUES', 'RELIGION', 'RELATIONSHIPS', 'SOCIAL ISSUES',\n",
       "       'SOCIAL ISSUES', 'RELIGION', 'POLITICS', 'ECONOMY', 'POLITICS',\n",
       "       'POLITICS', 'SPORTS', 'SOCIAL', 'RELIGION', 'SOCIAL ISSUES',\n",
       "       'LAW/ORDER', 'POLITICS', 'SOCIAL', 'SOCIAL', 'RELIGION', 'HEALTH',\n",
       "       'RELIGION', 'POLITICS', 'SOCIAL ISSUES', 'ECONOMY',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'RELIGION', 'RELIGION', 'FARMING',\n",
       "       'FARMING', 'SOCIAL ISSUES', 'POLITICS', 'SPORTS',\n",
       "       'WILDLIFE/ENVIRONMENT', 'HEALTH', 'LAW/ORDER', 'POLITICS',\n",
       "       'HEALTH', 'SOCIAL ISSUES', 'SPORTS', 'POLITICS', 'SOCIAL',\n",
       "       'SOCIAL', 'RELIGION', 'CULTURE', 'WILDLIFE/ENVIRONMENT',\n",
       "       'LAW/ORDER', 'EDUCATION', 'RELATIONSHIPS', 'SOCIAL ISSUES',\n",
       "       'SOCIAL ISSUES', 'RELIGION', 'POLITICS', 'EDUCATION', 'POLITICS',\n",
       "       'POLITICS', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'POLITICS', 'SOCIAL ISSUES', 'SOCIAL', 'POLITICS', 'LAW/ORDER',\n",
       "       'RELATIONSHIPS', 'HEALTH', 'ECONOMY', 'HEALTH', 'LAW/ORDER',\n",
       "       'MUSIC', 'HEALTH', 'SOCIAL ISSUES', 'SOCIAL', 'SOCIAL ISSUES',\n",
       "       'FARMING', 'SPORTS', 'POLITICS', 'EDUCATION', 'ECONOMY',\n",
       "       'RELIGION', 'POLITICS', 'SOCIAL ISSUES', 'SOCIAL', 'POLITICS',\n",
       "       'POLITICS', 'SOCIAL', 'RELIGION', 'HEALTH', 'LOCALCHIEFS',\n",
       "       'SOCIAL', 'RELATIONSHIPS', 'SOCIAL ISSUES', 'RELATIONSHIPS',\n",
       "       'LAW/ORDER', 'SOCIAL ISSUES', 'POLITICS', 'RELIGION', 'SOCIAL',\n",
       "       'RELATIONSHIPS', 'SPORTS', 'LOCALCHIEFS', 'LAW/ORDER', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'ECONOMY', 'LAW/ORDER', 'ECONOMY',\n",
       "       'POLITICS', 'EDUCATION', 'SOCIAL ISSUES', 'POLITICS', 'HEALTH',\n",
       "       'RELIGION', 'SOCIAL ISSUES', 'RELIGION', 'RELIGION', 'LAW/ORDER',\n",
       "       'RELIGION', 'FARMING', 'ECONOMY', 'HEALTH', 'POLITICS',\n",
       "       'EDUCATION', 'POLITICS', 'LAW/ORDER', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'RELIGION', 'HEALTH', 'ECONOMY', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'LAW/ORDER', 'SOCIAL ISSUES', 'SOCIAL', 'SOCIAL ISSUES', 'SOCIAL',\n",
       "       'RELIGION', 'SOCIAL ISSUES', 'FARMING', 'SOCIAL ISSUES',\n",
       "       'RELIGION', 'RELIGION', 'POLITICS', 'RELIGION', 'FARMING',\n",
       "       'POLITICS', 'POLITICS', 'SOCIAL ISSUES', 'POLITICS', 'POLITICS',\n",
       "       'POLITICS', 'SOCIAL', 'SOCIAL ISSUES', 'HEALTH', 'LAW/ORDER',\n",
       "       'POLITICS', 'POLITICS', 'LAW/ORDER', 'ECONOMY', 'ECONOMY',\n",
       "       'LOCALCHIEFS', 'RELIGION', 'SPORTS', 'SOCIAL', 'SPORTS',\n",
       "       'SOCIAL ISSUES', 'ECONOMY', 'LAW/ORDER', 'POLITICS', 'FARMING',\n",
       "       'RELIGION', 'SOCIAL ISSUES', 'HEALTH', 'RELIGION', 'POLITICS',\n",
       "       'POLITICS', 'RELIGION', 'SOCIAL', 'POLITICS', 'SOCIAL',\n",
       "       'SOCIAL ISSUES', 'RELIGION', 'FARMING', 'SOCIAL',\n",
       "       'WILDLIFE/ENVIRONMENT', 'POLITICS', 'FARMING', 'HEALTH',\n",
       "       'POLITICS', 'HEALTH', 'EDUCATION', 'HEALTH', 'SPORTS', 'RELIGION',\n",
       "       'SOCIAL', 'SPORTS', 'POLITICS', 'POLITICS', 'SOCIAL', 'POLITICS',\n",
       "       'HEALTH', 'POLITICS', 'RELIGION', 'RELATIONSHIPS', 'LAW/ORDER',\n",
       "       'SOCIAL', 'HEALTH', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'EDUCATION',\n",
       "       'POLITICS', 'HEALTH', 'HEALTH', 'LAW/ORDER', 'RELIGION',\n",
       "       'SOCIAL ISSUES', 'HEALTH', 'RELATIONSHIPS', 'LAW/ORDER', 'HEALTH',\n",
       "       'HEALTH', 'SPORTS', 'SOCIAL', 'POLITICS', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'ECONOMY', 'HEALTH', 'ECONOMY', 'RELATIONSHIPS',\n",
       "       'POLITICS', 'SOCIAL', 'LAW/ORDER', 'SOCIAL', 'SOCIAL', 'LAW/ORDER',\n",
       "       'ECONOMY', 'RELATIONSHIPS', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'POLITICS', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'POLITICS', 'SOCIAL',\n",
       "       'POLITICS', 'RELIGION', 'ECONOMY', 'SOCIAL ISSUES', 'SOCIAL',\n",
       "       'SOCIAL', 'POLITICS', 'SOCIAL ISSUES', 'LOCALCHIEFS', 'HEALTH',\n",
       "       'SPORTS', 'SOCIAL ISSUES', 'POLITICS', 'HEALTH', 'POLITICS',\n",
       "       'HEALTH', 'RELIGION', 'SOCIAL ISSUES', 'SOCIAL ISSUES',\n",
       "       'LAW/ORDER', 'POLITICS', 'SOCIAL', 'RELIGION', 'POLITICS',\n",
       "       'OPINION/ESSAY', 'SOCIAL', 'LAW/ORDER', 'POLITICS',\n",
       "       'WILDLIFE/ENVIRONMENT', 'HEALTH', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'LAW/ORDER', 'SOCIAL ISSUES', 'SOCIAL', 'SOCIAL ISSUES',\n",
       "       'RELATIONSHIPS', 'POLITICS', 'RELIGION', 'LAW/ORDER', 'LAW/ORDER',\n",
       "       'FARMING', 'POLITICS', 'LAW/ORDER', 'RELIGION', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'POLITICS', 'POLITICS', 'HEALTH',\n",
       "       'POLITICS', 'LAW/ORDER', 'SOCIAL ISSUES', 'HEALTH', 'SOCIAL',\n",
       "       'SOCIAL', 'LAW/ORDER', 'FARMING', 'LAW/ORDER',\n",
       "       'WILDLIFE/ENVIRONMENT', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'SPORTS',\n",
       "       'POLITICS', 'RELIGION', 'POLITICS', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'POLITICS', 'ECONOMY', 'LAW/ORDER', 'FARMING', 'POLITICS',\n",
       "       'HEALTH', 'FARMING', 'SOCIAL', 'POLITICS', 'FARMING',\n",
       "       'SOCIAL ISSUES', 'RELIGION', 'SOCIAL ISSUES', 'RELIGION',\n",
       "       'RELIGION', 'CULTURE', 'SOCIAL', 'EDUCATION', 'SOCIAL ISSUES',\n",
       "       'FARMING', 'SOCIAL ISSUES', 'ECONOMY', 'MUSIC', 'POLITICS',\n",
       "       'HEALTH', 'SOCIAL', 'HEALTH', 'RELIGION', 'POLITICS', 'POLITICS',\n",
       "       'SOCIAL', 'RELIGION', 'SOCIAL ISSUES', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'LAW/ORDER', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'ECONOMY', 'SOCIAL ISSUES', 'HEALTH', 'POLITICS', 'RELIGION',\n",
       "       'POLITICS', 'FARMING', 'POLITICS', 'RELIGION', 'POLITICS',\n",
       "       'FARMING', 'FARMING', 'FARMING', 'SOCIAL ISSUES', 'LAW/ORDER',\n",
       "       'POLITICS', 'SOCIAL ISSUES', 'LAW/ORDER', 'RELIGION', 'SOCIAL',\n",
       "       'HEALTH', 'POLITICS', 'POLITICS', 'POLITICS', 'POLITICS', 'SPORTS',\n",
       "       'SOCIAL ISSUES', 'LOCALCHIEFS', 'ECONOMY', 'SOCIAL', 'LAW/ORDER',\n",
       "       'LAW/ORDER', 'SOCIAL', 'POLITICS', 'WILDLIFE/ENVIRONMENT',\n",
       "       'POLITICS', 'SOCIAL ISSUES', 'LAW/ORDER', 'LAW/ORDER', 'POLITICS',\n",
       "       'HEALTH', 'HEALTH', 'ECONOMY', 'POLITICS', 'SOCIAL',\n",
       "       'WILDLIFE/ENVIRONMENT', 'RELATIONSHIPS', 'EDUCATION', 'SOCIAL',\n",
       "       'POLITICS', 'POLITICS', 'FARMING', 'SOCIAL', 'SOCIAL ISSUES',\n",
       "       'POLITICS', 'SOCIAL', 'RELIGION', 'POLITICS', 'HEALTH', 'RELIGION',\n",
       "       'RELIGION', 'LAW/ORDER', 'RELIGION', 'POLITICS', 'POLITICS',\n",
       "       'LAW/ORDER', 'LAW/ORDER', 'POLITICS', 'LAW/ORDER', 'ECONOMY',\n",
       "       'LAW/ORDER', 'ECONOMY', 'RELIGION', 'RELIGION', 'POLITICS',\n",
       "       'LAW/ORDER', 'POLITICS', 'LAW/ORDER', 'RELIGION', 'HEALTH',\n",
       "       'POLITICS', 'HEALTH', 'FARMING', 'RELIGION', 'HEALTH', 'ECONOMY',\n",
       "       'LAW/ORDER', 'SPORTS', 'POLITICS', 'SOCIAL ISSUES', 'SOCIAL',\n",
       "       'POLITICS', 'POLITICS', 'POLITICS', 'SPORTS',\n",
       "       'WILDLIFE/ENVIRONMENT', 'SOCIAL', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'SPORTS', 'POLITICS', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'ARTS AND CRAFTS', 'SOCIAL', 'POLITICS', 'POLITICS', 'LOCALCHIEFS',\n",
       "       'SOCIAL ISSUES', 'POLITICS', 'SOCIAL ISSUES', 'HEALTH', 'HEALTH',\n",
       "       'EDUCATION', 'POLITICS', 'HEALTH', 'POLITICS', 'FARMING',\n",
       "       'POLITICS', 'POLITICS', 'SOCIAL', 'ECONOMY', 'RELATIONSHIPS',\n",
       "       'SOCIAL', 'SOCIAL', 'POLITICS', 'POLITICS', 'LAW/ORDER',\n",
       "       'SOCIAL ISSUES', 'ECONOMY', 'POLITICS', 'RELIGION', 'SOCIAL',\n",
       "       'SOCIAL', 'HEALTH', 'EDUCATION', 'EDUCATION', 'LAW/ORDER',\n",
       "       'RELIGION', 'RELIGION', 'SOCIAL', 'LAW/ORDER', 'LAW/ORDER',\n",
       "       'FARMING', 'LAW/ORDER', 'SPORTS', 'POLITICS', 'SOCIAL ISSUES',\n",
       "       'POLITICS', 'SOCIAL ISSUES', 'ECONOMY', 'FARMING', 'HEALTH',\n",
       "       'SOCIAL', 'WILDLIFE/ENVIRONMENT', 'FARMING', 'LAW/ORDER',\n",
       "       'RELIGION', 'FARMING', 'POLITICS', 'RELIGION',\n",
       "       'WILDLIFE/ENVIRONMENT', 'POLITICS', 'HEALTH', 'RELATIONSHIPS',\n",
       "       'SOCIAL', 'SPORTS', 'LAW/ORDER', 'RELIGION', 'LAW/ORDER',\n",
       "       'POLITICS', 'POLITICS', 'SOCIAL ISSUES', 'POLITICS', 'HEALTH',\n",
       "       'ECONOMY', 'FARMING', 'SOCIAL ISSUES', 'ECONOMY', 'RELIGION',\n",
       "       'POLITICS', 'RELIGION', 'SOCIAL', 'FARMING', 'SOCIAL', 'POLITICS',\n",
       "       'LOCALCHIEFS', 'POLITICS', 'RELIGION', 'POLITICS', 'SOCIAL',\n",
       "       'WILDLIFE/ENVIRONMENT', 'FARMING', 'SOCIAL ISSUES', 'LAW/ORDER',\n",
       "       'HEALTH', 'ECONOMY', 'RELIGION', 'SOCIAL', 'ECONOMY', 'RELIGION',\n",
       "       'SOCIAL', 'HEALTH', 'SPORTS', 'RELIGION', 'RELATIONSHIPS',\n",
       "       'RELATIONSHIPS', 'POLITICS', 'POLITICS', 'POLITICS', 'POLITICS',\n",
       "       'SOCIAL ISSUES', 'RELIGION', 'POLITICS', 'POLITICS', 'ECONOMY',\n",
       "       'SOCIAL', 'POLITICS', 'SOCIAL', 'SOCIAL ISSUES', 'SOCIAL ISSUES',\n",
       "       'SOCIAL', 'SOCIAL', 'ECONOMY', 'SOCIAL', 'POLITICS', 'RELIGION',\n",
       "       'LAW/ORDER', 'POLITICS', 'FARMING', 'LAW/ORDER', 'SPORTS',\n",
       "       'POLITICS', 'SOCIAL', 'POLITICS', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'SPORTS', 'SOCIAL ISSUES', 'POLITICS', 'SOCIAL ISSUES', 'POLITICS',\n",
       "       'RELIGION', 'LAW/ORDER', 'ECONOMY', 'SPORTS', 'POLITICS',\n",
       "       'RELIGION', 'FARMING', 'POLITICS', 'SOCIAL ISSUES', 'SOCIAL',\n",
       "       'SPORTS', 'SOCIAL ISSUES', 'ECONOMY', 'SOCIAL ISSUES',\n",
       "       'LOCALCHIEFS', 'ECONOMY', 'POLITICS', 'POLITICS', 'POLITICS',\n",
       "       'RELATIONSHIPS', 'LAW/ORDER', 'SOCIAL ISSUES', 'POLITICS'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.inverse_transform(pd.DataFrame(preds,columns = cols_target)[lb.classes_].values)\n",
    "# lb.classes_\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Label'] = lb.inverse_transform(pd.DataFrame(preds,columns = cols_target)[lb.classes_].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test_df[['ID','Label']]\n",
    "sub.to_csv('submission_keras_gram5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
