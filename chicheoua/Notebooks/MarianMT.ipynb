{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Helsinki-NLP/opus-mt-ny-en'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'size'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4e33d4dbc4bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hello, my dog is cute\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlast_hidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1272\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m         )\n\u001b[0;32m   1276\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1127\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             )\n\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\models\\marian\\modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    709\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "outputs = model(inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILEPATH = \"../Translated/cleaned/train.csv\"\n",
    "TEST_FILEPATH = \"../Translated/cleaned/test.csv\"\n",
    "SS_FILEPATH = \"../data/SampleSubmission.csv\"\n",
    "VECTORS_FILEPATH = \"\"\n",
    "train = pd.read_csv(TRAIN_FILEPATH)\n",
    "test = pd.read_csv(TEST_FILEPATH)\n",
    "ss = pd.read_csv(SS_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name, output_loading_info=False)\n",
    "        \n",
    "# batch2 = tokenizer.prepare_seq2seq_batch(train.Text.values.tolist()[0],\n",
    "#                                                max_length=500,\n",
    "#                                                pad_to_max_length=True,\n",
    "#                                        return_tensors = 'pt')\n",
    "# translated = model.generate(**batch)\n",
    "\n",
    "# df.loc[df['lang']==lang, 'content_english'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['input_ids']\n",
    "# import numpy as np\n",
    "# (np.array((tokenizer.encode(train.Text.values.tolist()[0],max_length = 500)))==batch['input_ids'][0].numpy()).all()\n",
    "# model.model.encoder.layers[:6]\n",
    "# layer1 = model.model.encoder.layers.state_dict()\n",
    "tokens = []\n",
    "for text in train.Text.values.tolist() : \n",
    "    tokens.append(np.array((tokenizer.encode(text,max_length = 500,padding = 'max_length',truncation = True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(layer1)\n",
    "# train['tokens'] = tokens\n",
    "# train.tokens.apply(len)\n",
    "# (tokenizer.encode.__doc__)\n",
    "# ((tokenizer.encode(train.Text.values.tolist(),max_length = 500,padding = 'max_length',truncation = True)))\n",
    "# train\n",
    "import tensorflow as tf\n",
    "\n",
    "train_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    train.tokens, maxlen=500, dtype='int32', padding='post',\n",
    "    truncating='post'\n",
    ")\n",
    "test_text = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    train.tokens, maxlen=500, dtype='int32', padding='post',\n",
    "    truncating='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # **batch\n",
    "# # output = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "# # type(translated)\n",
    "# # batch.keys()\n",
    "# # batch['input_ids'][0]\n",
    "# # train.Text.str.split(' ')[0][6]\n",
    "# # batch2 = tokenizer.prepare_seq2seq_batch(train.Text.values.tolist()[1],\n",
    "# #                                                max_length=500,\n",
    "# #                                                pad_to_max_length=True,\n",
    "# #                                        return_tensors = 'pt')\n",
    "# # batch2\n",
    "# # train.Text.values.tolist()\n",
    "# test_tokens = []\n",
    "\n",
    "# for text in test.Text.values.tolist() : \n",
    "#     test_tokens.append(np.array((tokenizer.encode(text,max_length = 500,padding = True))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.Text.values.tolist()[1]\n",
    "test['tokens'] = test_tokens\n",
    "# output\n",
    "# translated.shape\n",
    "# from transformers import pipeline\n",
    "# pipeline('zero-shot-classification', model=model_name, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['Text'],axis = 1, inplace = True)\n",
    "train.drop(['Text'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train.Text[0].split())\n",
    "# model.get_encoder().tie_weights()\n",
    "# test\n",
    "# train\n",
    "# cols_target = train.Label.unique().tolist()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(train['Label'])\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= lb.classes_)\n",
    "# y_train\n",
    "cols_target = train['Label'].unique().tolist()\n",
    "train_df = pd.concat([train, y_train], axis = 1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_text, train_df[cols_target], test_size=0.1, random_state = 0,stratify = train_df['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292, 500)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model.train())\n",
    "# type(model.get_input_embeddings())\n",
    "# train_df\n",
    "# x_train.shape\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "# Build the model\n",
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "K.clear_session()\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "num_filters = 7\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(60000, 300, input_length=500, trainable=True))\n",
    "model.add(layers.Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(40, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.5)))\n",
    "# model.add(Dense(num_classes, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
    "# base_model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(2048))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(512))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dense(128))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "\n",
    "# model.add(layers.Dropout(drop_ratio))\n",
    "model.add(layers.Dense(20))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 9s 474ms/step - loss: 8.8968 - accuracy: 0.1274 - val_loss: 8.3767 - val_accuracy: 0.2231\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 9s 465ms/step - loss: 7.9429 - accuracy: 0.2014 - val_loss: 7.4946 - val_accuracy: 0.2077\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 9s 464ms/step - loss: 7.0624 - accuracy: 0.1773 - val_loss: 6.6769 - val_accuracy: 0.2231\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 10s 505ms/step - loss: 6.2628 - accuracy: 0.1902 - val_loss: 5.9622 - val_accuracy: 0.2154\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 9s 492ms/step - loss: 5.6114 - accuracy: 0.1988 - val_loss: 5.3806 - val_accuracy: 0.1923\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 9s 493ms/step - loss: 5.0216 - accuracy: 0.2384 - val_loss: 4.9016 - val_accuracy: 0.2077\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 9s 491ms/step - loss: 4.5601 - accuracy: 0.2427 - val_loss: 4.4859 - val_accuracy: 0.2077\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 9s 499ms/step - loss: 4.1899 - accuracy: 0.2470 - val_loss: 4.1558 - val_accuracy: 0.2154\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 10s 529ms/step - loss: 3.8549 - accuracy: 0.2599 - val_loss: 3.8652 - val_accuracy: 0.2077\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 10s 534ms/step - loss: 3.5380 - accuracy: 0.2676 - val_loss: 3.6163 - val_accuracy: 0.2000\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 10s 519ms/step - loss: 3.3004 - accuracy: 0.2771 - val_loss: 3.4024 - val_accuracy: 0.2231\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 11s 562ms/step - loss: 3.0993 - accuracy: 0.2668 - val_loss: 3.2308 - val_accuracy: 0.2308\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 10s 540ms/step - loss: 2.9082 - accuracy: 0.2892 - val_loss: 3.0805 - val_accuracy: 0.2538\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 9s 482ms/step - loss: 2.7378 - accuracy: 0.3150 - val_loss: 2.9708 - val_accuracy: 0.3000\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 9s 496ms/step - loss: 2.6526 - accuracy: 0.3012 - val_loss: 2.8677 - val_accuracy: 0.2846\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 10s 507ms/step - loss: 2.5396 - accuracy: 0.3158 - val_loss: 2.7824 - val_accuracy: 0.3154\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 9s 477ms/step - loss: 2.3715 - accuracy: 0.3494 - val_loss: 2.6966 - val_accuracy: 0.3077\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 9s 465ms/step - loss: 2.2905 - accuracy: 0.3485 - val_loss: 2.6490 - val_accuracy: 0.3077\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 9s 452ms/step - loss: 2.2412 - accuracy: 0.3511 - val_loss: 2.5994 - val_accuracy: 0.3308\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 9s 484ms/step - loss: 2.1299 - accuracy: 0.3864 - val_loss: 2.5478 - val_accuracy: 0.3385\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 10s 534ms/step - loss: 2.1037 - accuracy: 0.3838 - val_loss: 2.5208 - val_accuracy: 0.3308\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 9s 498ms/step - loss: 2.0213 - accuracy: 0.3985 - val_loss: 2.4864 - val_accuracy: 0.3385\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 9s 481ms/step - loss: 1.9888 - accuracy: 0.3976 - val_loss: 2.4753 - val_accuracy: 0.3308\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 9s 481ms/step - loss: 1.9066 - accuracy: 0.4148 - val_loss: 2.4341 - val_accuracy: 0.3538\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 10s 503ms/step - loss: 1.8814 - accuracy: 0.4045 - val_loss: 2.4361 - val_accuracy: 0.3615\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 9s 470ms/step - loss: 1.8657 - accuracy: 0.4200 - val_loss: 2.4154 - val_accuracy: 0.3231\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 9s 449ms/step - loss: 1.7606 - accuracy: 0.4630 - val_loss: 2.3998 - val_accuracy: 0.3538\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 9s 451ms/step - loss: 1.7558 - accuracy: 0.4466 - val_loss: 2.3892 - val_accuracy: 0.3692\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 9s 452ms/step - loss: 1.7545 - accuracy: 0.4346 - val_loss: 2.3793 - val_accuracy: 0.3692\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 9s 452ms/step - loss: 1.7326 - accuracy: 0.4389 - val_loss: 2.3707 - val_accuracy: 0.3462\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 9s 462ms/step - loss: 1.6625 - accuracy: 0.4587 - val_loss: 2.3815 - val_accuracy: 0.3462\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 9s 469ms/step - loss: 1.6898 - accuracy: 0.4432 - val_loss: 2.3562 - val_accuracy: 0.3308\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 10s 513ms/step - loss: 1.6705 - accuracy: 0.4492 - val_loss: 2.3351 - val_accuracy: 0.3385\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 9s 487ms/step - loss: 1.6686 - accuracy: 0.4423 - val_loss: 2.3465 - val_accuracy: 0.3231\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 9s 467ms/step - loss: 1.5887 - accuracy: 0.4785 - val_loss: 2.3458 - val_accuracy: 0.3385\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 9s 495ms/step - loss: 1.5833 - accuracy: 0.4725 - val_loss: 2.3377 - val_accuracy: 0.3462\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 9s 472ms/step - loss: 1.6053 - accuracy: 0.4604 - val_loss: 2.3317 - val_accuracy: 0.3462\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 9s 494ms/step - loss: 1.5521 - accuracy: 0.4983 - val_loss: 2.3289 - val_accuracy: 0.3538\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 9s 454ms/step - loss: 1.5559 - accuracy: 0.4905 - val_loss: 2.3255 - val_accuracy: 0.3385\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 10s 503ms/step - loss: 1.5306 - accuracy: 0.4836 - val_loss: 2.2891 - val_accuracy: 0.3846\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 9s 497ms/step - loss: 1.5373 - accuracy: 0.4957 - val_loss: 2.3262 - val_accuracy: 0.3308\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 9s 457ms/step - loss: 1.4682 - accuracy: 0.5103 - val_loss: 2.3060 - val_accuracy: 0.3385\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 9s 466ms/step - loss: 1.5062 - accuracy: 0.5000 - val_loss: 2.3244 - val_accuracy: 0.3231\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 9s 457ms/step - loss: 1.4893 - accuracy: 0.4991 - val_loss: 2.3204 - val_accuracy: 0.3077\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 9s 451ms/step - loss: 1.4758 - accuracy: 0.5017 - val_loss: 2.3107 - val_accuracy: 0.3154\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 9s 451ms/step - loss: 1.4937 - accuracy: 0.4931 - val_loss: 2.3051 - val_accuracy: 0.3154\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 9s 451ms/step - loss: 1.4306 - accuracy: 0.5353 - val_loss: 2.2964 - val_accuracy: 0.3308\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 9s 453ms/step - loss: 1.4784 - accuracy: 0.5069 - val_loss: 2.3252 - val_accuracy: 0.3308\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 9s 451ms/step - loss: 1.4189 - accuracy: 0.5146 - val_loss: 2.3147 - val_accuracy: 0.3308\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 8s 446ms/step - loss: 1.3869 - accuracy: 0.5448 - val_loss: 2.3244 - val_accuracy: 0.3308\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                   validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59678"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
