{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron,LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "TRAIN_FILEPATH = \"../Translated/cleaned/train.csv\"\n",
    "TEST_FILEPATH = \"../Translated/cleaned/test.csv\"\n",
    "SS_FILEPATH = \"../data/SampleSubmission.csv\"\n",
    "VECTORS_FILEPATH = \"\"\n",
    "train_df = pd.read_csv(TRAIN_FILEPATH)\n",
    "test_df = pd.read_csv(TEST_FILEPATH)\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,cross_val_score,train_test_split,StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train_df.Label.unique().tolist()\n",
    "# data_train, data_test = train_test_split(train_df, test_size=0.1, random_state = 42, stratify = train_df['Label'])\n",
    "data_train = train_df.copy()\n",
    "data_test = test_df.copy()\n",
    "train_idx = data_train.index.tolist()\n",
    "test_idx = data_test.index.tolist()\n",
    "def vect(max_df = 0.5):\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=max_df, stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(data_train.Text)\n",
    "    return vectorizer\n",
    "# def preprocess(df\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "    models, preds, scores = [], [],[]\n",
    "    vectorizer = vect(max_df = 0.5)\n",
    "    for train, test in skf.split(data_train.Text, data_train.Label):\n",
    "#     print(train, test)\n",
    "#     clf = LogisticRegression(penalty='l1')\n",
    "        clf.fit(vectorizer.transform(data_train.Text.loc[data_train.index.intersection(train)]), data_train.Label.loc[data_train.index.intersection(train)])\n",
    "        preds.append(clf.predict_proba(vectorizer.transform(data_test.Text)))\n",
    "        models.append(clf)\n",
    "        scores.append(accuracy_score(clf.predict(vectorizer.transform(data_train.Text.loc[data_train.index.intersection(test)])),data_train.Label.loc[data_train.index.intersection(test)]))\n",
    "#         coefs.append(clf.coef_[0])\n",
    "#         clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "#     pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    pred = np.mean(preds,axis = 0)\n",
    "#     score = metrics.accuracy_score(data_test.Label, pred)\n",
    "#     print(\"accuracy:   %0.3f\" % score)\n",
    "    return models, pred,scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=20, multi_class='ovr', random_state=0, tol=1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 54.889s\n",
      "test time:  0.000s\n"
     ]
    }
   ],
   "source": [
    "models, pred, scores = benchmark(LogisticRegression(C = 20, multi_class = 'ovr' ,tol=1e-5,random_state = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6295392953929538"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "# models, preds = [], []\n",
    "# vectorizer = vect(max_df = 0.5)\n",
    "# for train, test in skf.split(data_train.Text, data_train.Label):\n",
    "#       print(test)\n",
    "# data_train.Text.loc[]\n",
    "# np.zeros(pred[1].shape)\n",
    "data_test['Label'] = models[4].classes_[np.argmax(pred,axis =1)]\n",
    "sub = data_test[['ID', 'Label']]\n",
    "sub.to_csv('cross_val.csv', index = False)\n",
    "# [np.argmax(pred,axis =1)]\n",
    "# models[4].classes_ == models[3].classes_ \n",
    "# models[4].classes_[[1,3,3]]\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00396599, 0.01250032, 0.05772551, 0.02401101, 0.05205382,\n",
       "       0.00395089, 0.09315155, 0.09812242, 0.01560303, 0.00713147,\n",
       "       0.01533163, 0.21370458, 0.02732427, 0.10318962, 0.10077275,\n",
       "       0.10486998, 0.02917927, 0.00565802, 0.02309053, 0.00866335])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.tolist()\n",
    "np.mean(pred,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004026890749123799"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (pred[0][0,0] +pred[1][0,0]+pred[2][0,0]+pred[3][0,0]+pred[4][0,0])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
