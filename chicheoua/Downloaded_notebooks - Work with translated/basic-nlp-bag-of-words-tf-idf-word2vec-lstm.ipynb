{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ef08df1c-3c94-4f63-bbc7-6cc93f46fb52",
    "_execution_state": "idle",
    "_uuid": "7b62b6d64cc54d675b18c29ee12eed7cd45a3154"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import gensim\n",
    "\n",
    "# import scikitplot.plotters as skplt\n",
    "\n",
    "import nltk\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikitplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0b39f26e-9c4c-46db-8fe5-86967734c0e5",
    "_uuid": "58b74d086e6f6f067f337470219be9fd43211c08"
   },
   "source": [
    "## Load training_text and training_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "011dde04-0160-41cd-9149-5aeac26295fb",
    "_execution_state": "idle",
    "_uuid": "1b07b556871714b93d70806d58b5225be507e716"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AASHwXxg</td>\n",
       "      <td>Mwangonde: Khansala wachinyamata Akamati achi...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AGoFySzn</td>\n",
       "      <td>MCP siidakhutire ndi kalembera Chipani cha Ma...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AGrrkBGP</td>\n",
       "      <td>Bungwe la MANEPO Lapempha Boma Liganizire Anth...</td>\n",
       "      <td>HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AIJeigeG</td>\n",
       "      <td>Ndale zogawanitsa miyambo zanyanya Si zachile...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_APMprMbV</td>\n",
       "      <td>Nanga wapolisi ataphofomoka? Masiku ano sichi...</td>\n",
       "      <td>LAW/ORDER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text      Label\n",
       "0  ID_AASHwXxg   Mwangonde: Khansala wachinyamata Akamati achi...   POLITICS\n",
       "1  ID_AGoFySzn   MCP siidakhutire ndi kalembera Chipani cha Ma...   POLITICS\n",
       "2  ID_AGrrkBGP  Bungwe la MANEPO Lapempha Boma Liganizire Anth...     HEALTH\n",
       "3  ID_AIJeigeG   Ndale zogawanitsa miyambo zanyanya Si zachile...   POLITICS\n",
       "4  ID_APMprMbV   Nanga wapolisi ataphofomoka? Masiku ano sichi...  LAW/ORDER"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_txt = pd.read_csv('../Translated/cleaned/train.csv')\n",
    "df_train_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "795f95c3-ea53-47ef-9199-4c12bc80b16f",
    "_execution_state": "idle",
    "_uuid": "0abbd8861ba31246cb57b5d660b0fdf50c64bee6"
   },
   "outputs": [],
   "source": [
    "# df_train_var = pd.read_csv('../input/training_variants')\n",
    "# df_train_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "7bf0c669-6284-4974-a996-54ad0e6941f6",
    "_execution_state": "idle",
    "_uuid": "65bb8b567ee893c6f796f2508b576e9c02e27a46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_ADHEtjTi</td>\n",
       "      <td>Abambo odzikhweza akuchuluka Kafukufuku wa ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AHfJktdQ</td>\n",
       "      <td>Ambuye Ziyaye Ayamikira Aphunzitsi a Tilitonse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AUJIHpZr</td>\n",
       "      <td>Anatcheleza: Akundiopseza a gogo wanga Akundi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AUKYBbIM</td>\n",
       "      <td>Ulova wafika posauzana Adatenga digiri ya uph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AZnsVPEi</td>\n",
       "      <td>Dzombe kukoma, koma Kuyambira makedzana, pant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text\n",
       "0  ID_ADHEtjTi   Abambo odzikhweza akuchuluka Kafukufuku wa ap...\n",
       "1  ID_AHfJktdQ  Ambuye Ziyaye Ayamikira Aphunzitsi a Tilitonse...\n",
       "2  ID_AUJIHpZr   Anatcheleza: Akundiopseza a gogo wanga Akundi...\n",
       "3  ID_AUKYBbIM   Ulova wafika posauzana Adatenga digiri ya uph...\n",
       "4  ID_AZnsVPEi   Dzombe kukoma, koma Kuyambira makedzana, pant..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_txt = pd.read_csv('../Translated/cleaned/test.csv')\n",
    "df_test_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "dfc2969d-1ef9-4e89-a236-70e17e1b1970",
    "_execution_state": "idle",
    "_uuid": "53f36fe20604e87d1f083f59448da9d6ef0e3863"
   },
   "outputs": [],
   "source": [
    "# df_test_var = pd.read_csv('../input/test_variants')\n",
    "# df_test_var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5707f8ac-85bc-40fd-9a8b-5e7912d5c8d1",
    "_uuid": "2e9d1f1157305e68bb06ae32a00f2bb4e31710c8"
   },
   "source": [
    "### Let's join them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "13b2c874-ef56-45f5-9500-aae3c77fbfaa",
    "_execution_state": "idle",
    "_uuid": "315a8b16269f0a2894c4d82642e82baa7826b30b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AASHwXxg</td>\n",
       "      <td>Mwangonde: Khansala wachinyamata Akamati achi...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AGoFySzn</td>\n",
       "      <td>MCP siidakhutire ndi kalembera Chipani cha Ma...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AGrrkBGP</td>\n",
       "      <td>Bungwe la MANEPO Lapempha Boma Liganizire Anth...</td>\n",
       "      <td>HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AIJeigeG</td>\n",
       "      <td>Ndale zogawanitsa miyambo zanyanya Si zachile...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_APMprMbV</td>\n",
       "      <td>Nanga wapolisi ataphofomoka? Masiku ano sichi...</td>\n",
       "      <td>LAW/ORDER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text      Label\n",
       "0  ID_AASHwXxg   Mwangonde: Khansala wachinyamata Akamati achi...   POLITICS\n",
       "1  ID_AGoFySzn   MCP siidakhutire ndi kalembera Chipani cha Ma...   POLITICS\n",
       "2  ID_AGrrkBGP  Bungwe la MANEPO Lapempha Boma Liganizire Anth...     HEALTH\n",
       "3  ID_AIJeigeG   Ndale zogawanitsa miyambo zanyanya Si zachile...   POLITICS\n",
       "4  ID_APMprMbV   Nanga wapolisi ataphofomoka? Masiku ano sichi...  LAW/ORDER"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train_txt.copy()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "86a5146c-f1c2-4d41-8c5a-3fc620d16695",
    "_execution_state": "idle",
    "_uuid": "7c2b09211ba02dba759bdbc4b2feea5c0928582a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_ADHEtjTi</td>\n",
       "      <td>Abambo odzikhweza akuchuluka Kafukufuku wa ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AHfJktdQ</td>\n",
       "      <td>Ambuye Ziyaye Ayamikira Aphunzitsi a Tilitonse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AUJIHpZr</td>\n",
       "      <td>Anatcheleza: Akundiopseza a gogo wanga Akundi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AUKYBbIM</td>\n",
       "      <td>Ulova wafika posauzana Adatenga digiri ya uph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AZnsVPEi</td>\n",
       "      <td>Dzombe kukoma, koma Kuyambira makedzana, pant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text\n",
       "0  ID_ADHEtjTi   Abambo odzikhweza akuchuluka Kafukufuku wa ap...\n",
       "1  ID_AHfJktdQ  Ambuye Ziyaye Ayamikira Aphunzitsi a Tilitonse...\n",
       "2  ID_AUJIHpZr   Anatcheleza: Akundiopseza a gogo wanga Akundi...\n",
       "3  ID_AUKYBbIM   Ulova wafika posauzana Adatenga digiri ya uph...\n",
       "4  ID_AZnsVPEi   Dzombe kukoma, koma Kuyambira makedzana, pant..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test_txt.copy()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6902a7ac-d631-4ae3-b80b-b5fbacc7bf11",
    "_uuid": "90c26968d60d11ac38dfdb2f3ffdd3b04acc4ba6"
   },
   "source": [
    "## Run preliminary statistics on loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "2045e414-408a-46d8-a351-1757bd9df5e9",
    "_execution_state": "idle",
    "_uuid": "cc9d844d7110e9534dc40e019d885c5bcc31e904"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1436</td>\n",
       "      <td>1436</td>\n",
       "      <td>1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1436</td>\n",
       "      <td>1436</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ID_SvJVcupC</td>\n",
       "      <td>Mutharika afika mawa Mtsogoleri wa dziko lino...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                               Text  \\\n",
       "count          1436                                               1436   \n",
       "unique         1436                                               1436   \n",
       "top     ID_SvJVcupC   Mutharika afika mawa Mtsogoleri wa dziko lino...   \n",
       "freq              1                                                  1   \n",
       "\n",
       "           Label  \n",
       "count       1436  \n",
       "unique        20  \n",
       "top     POLITICS  \n",
       "freq         279  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "db691b33-6370-4ec4-8086-77ea6528b568",
    "_execution_state": "idle",
    "_uuid": "360c0686091dbf914980ba1c398c6d5f1ad44bcd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ID_GngCDUHN</td>\n",
       "      <td>Anatchezera Anzanga sakundifunsira Ndine mtsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                               Text\n",
       "count           620                                                620\n",
       "unique          620                                                620\n",
       "top     ID_GngCDUHN   Anatchezera Anzanga sakundifunsira Ndine mtsi...\n",
       "freq              1                                                  1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "199c8014-d06f-4f14-b8fa-bf4ec2e35d21",
    "_execution_state": "idle",
    "_uuid": "3e5fcd9f545b5a80b793905fe2e562668d751536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7e34f8cc8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['Label'].value_counts().plot(kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f3c61af-91fe-4da4-9e58-cb5c050f45a7",
    "_uuid": "5d1cfc6d2e8aa7052f99bf256988df4d9c72e231"
   },
   "source": [
    "### Classes seem very imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "414fba7c-ecae-4a7e-acfe-d926df6aaec5",
    "_uuid": "fcb73d697f9b4656f5a2c728acc67cc48dd5e930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell reduces the training data for Kaggle limits. Remove this cell for real results.\n",
    "df_train, df_test1 = train_test_split(df_train, test_size=0.1, random_state=8, stratify=df_train['Label'])\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f6abf33d-337d-4be8-8d50-34d2292a4c71",
    "_uuid": "525e0ac244f14d7dbc0edfe5783c1439a3a10d3d"
   },
   "source": [
    "# The main task here is to predict the class of the mutation given the text in the literature. Our approach will then be to apply some common NLP techniques to transform the free text into features for an ML classifier and see which ones work best.\n",
    "\n",
    "### Define a helper function to evaluate the effectiveness of transformed free text. We'll use a simple logistic regression with 3-fold stratified cross-validation for fast evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "e687a44c-45f1-47c0-8c8f-3cced55cfba7",
    "_execution_state": "idle",
    "_uuid": "74e93f2f49e6399758ccda8950741f2dc3070e70"
   },
   "outputs": [],
   "source": [
    "def evaluate_features(X, y, clf=None):\n",
    "    \"\"\"General helper function for evaluating effectiveness of passed features in ML model\n",
    "    \n",
    "    Prints out Log loss, accuracy, and confusion matrix with 3-fold stratified cross-validation\n",
    "    \n",
    "    Args:\n",
    "        X (array-like): Features array. Shape (n_samples, n_features)\n",
    "        \n",
    "        y (array-like): Labels array. Shape (n_samples,)\n",
    "        \n",
    "        clf: Classifier to use. If None, default Log reg is use.\n",
    "    \"\"\"\n",
    "    if clf is None:\n",
    "        clf = LogisticRegression()\n",
    "    \n",
    "    probas = cross_val_predict(clf, X, y, cv=StratifiedKFold(random_state=8), \n",
    "                              n_jobs=-1, method='predict_proba', verbose=2)\n",
    "    pred_indices = np.argmax(probas, axis=1)\n",
    "    classes = np.unique(y)\n",
    "    preds = classes[pred_indices]\n",
    "    print('Log loss: {}'.format(log_loss(y, probas)))\n",
    "    print('Accuracy: {}'.format(accuracy_score(y, preds)))\n",
    "#     skplt.plot_confusion_matrix(y, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f123aa3e-e4a2-4bbd-82a4-deb9f9416749",
    "_uuid": "05e65e23552a5c11fedaa9e9e65ac9156a9297e0"
   },
   "source": [
    "Let's do a quick test of evaluate_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "96a33bf5-96a2-4099-8e09-a61db0c052e1",
    "_execution_state": "idle",
    "_uuid": "1795526eb77ec9281a8a18f3f01d02cc4b643a9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass return_X_y=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.13995479890942475\n",
      "Accuracy: 0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.5s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Quick test of evaluate_features\n",
    "from sklearn.datasets import load_iris\n",
    "evaluate_features(*load_iris(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "98e9cd4a-f6f4-4c5b-a151-2edf4ac179f6",
    "_uuid": "22078fdc406c13d21d1588644371edc43a553b1a"
   },
   "source": [
    "## Start with a simple baseline. Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "d3207228-9664-472e-b025-7507f10fec7c",
    "_execution_state": "idle",
    "_uuid": "5028611d6b4007f8f139b432c7909748781c3022"
   },
   "outputs": [],
   "source": [
    "other_stop_w = pd.read_csv('words_shared_by_all.csv')\n",
    "stopw = [item for sublist in other_stop_w.values.tolist() for item in sublist]\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\", tokenizer=nltk.word_tokenize,\n",
    "    preprocessor=None, stop_words=stopw, max_features=None)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "5df3c9c0-4b0b-487f-bef4-6cceb8ce0290",
    "_execution_state": "busy",
    "_uuid": "1153f8a8a0320483ce8c8f3044fe21cb860ad989"
   },
   "outputs": [],
   "source": [
    "bag_of_words = count_vectorizer.fit_transform(df_train['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "c037498b-d5d5-4c50-93a4-d37c5c8f091e",
    "_execution_state": "busy",
    "_uuid": "69e813164a0da79e98ec0895a4ce24759dbcdf79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47717"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31960f4d-efd5-4162-bf78-5780088f4d5d",
    "_uuid": "ea3d1136c7e969c8a03f6fb182885782396be325"
   },
   "source": [
    "#### 281586 unique words in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "6a5ae966-e759-4c29-96de-7d4492e93888",
    "_execution_state": "busy",
    "_uuid": "74d91589176aed1f15f991fe7e2115df4229c107"
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=25, n_iter=25, random_state=12)\n",
    "truncated_bag_of_words = svd.fit_transform(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "15b83eea-8ea0-4b4b-a055-d109f7ce814a",
    "_execution_state": "busy",
    "_uuid": "9006201fdd9c50f26229fcbafa258b3dbef94b6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 1.783472687459665\n",
      "Accuracy: 0.5464396284829721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(truncated_bag_of_words, df_train['Label'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "6abaa6b4-852b-4421-9f37-3bce113c357e",
    "_execution_state": "busy",
    "_uuid": "d78b3a8c686dbf57aadd3faf8ca1fa66e70bfa00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 1.806121254798095\n",
      "Accuracy: 0.4868421052631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    5.1s remaining:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.3s finished\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(truncated_bag_of_words, df_train['Label'].values.ravel(), \n",
    "                  RandomForestClassifier(n_estimators=1000, max_depth=5, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "27ef74f3-6be8-4f87-8a43-4974a8a776ba",
    "_uuid": "ea1c3dd8c62d52ed234d7ce20041e0df3334de46"
   },
   "source": [
    "### Bad results overall for the baseline\n",
    "\n",
    "## Let's try TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "80a12233-65b3-426c-8fab-8d15cc6c78ab",
    "_execution_state": "busy",
    "_uuid": "b9c41a68f6682de79329d161eaaa565063a13f08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47717"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"word\", tokenizer=nltk.word_tokenize,\n",
    "    preprocessor=None, stop_words=stopw, max_features=None)    \n",
    "\n",
    "tfidf = count_vectorizer.fit_transform(df_train['Text'])\n",
    "\n",
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "7befec83-dc74-48fb-97b0-c2d78b17decc",
    "_execution_state": "busy",
    "_uuid": "ef48809922c0850626803b3323585d60ff78a32f"
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=25, n_iter=25, random_state=12)\n",
    "truncated_tfidf = svd.fit_transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "91e06bc0-6ce2-4466-a8b1-66a555a94d3b",
    "_execution_state": "busy",
    "_uuid": "0bd566447e9f104b7b79bb56e8daff6cd372bebd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 1.7716298641858217\n",
      "Accuracy: 0.5456656346749226\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(truncated_tfidf, df_train['Label'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "775e52c8-d9e8-4db1-a46c-4f7416aa8a9a",
    "_execution_state": "busy",
    "_uuid": "87c8f656c58e997062d4c82df7f6b319bfa49874"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.6s remaining:    7.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 1.6265441384223702\n",
      "Accuracy: 0.5657894736842105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(truncated_tfidf, df_train['Label'].values.ravel(), \n",
    "                  RandomForestClassifier(n_estimators=1000, max_depth=5, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "8dc579fa-63ab-4919-ba78-087adcdb2043",
    "_execution_state": "busy",
    "_uuid": "dc4479f8be6d3f524ce0a086b8019035d50027b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   20.5s remaining:   30.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 1.251052284226112\n",
      "Accuracy: 0.6246130030959752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.9s finished\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(tfidf, df_train['Label'].values.ravel(), \n",
    "                  SVC(kernel='linear', probability=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "67253f68-410f-4309-bf17-2144340558c3",
    "_uuid": "62cb5aa5763d6bf912fd56abc777998175806ca2"
   },
   "source": [
    "### A little better, but still bad. You can see from the confusion matrix that it's just classifying most samples into class 7.\n",
    "\n",
    "### Also tried a linear SVM for features straight from TFIDF (did not go through Truncated SVD). Worse log loss but confusion matrix seems to show better balance among predicted classes.\n",
    "\n",
    "_____\n",
    "\n",
    "## This time, let's try the popular word2vec to get features\n",
    "\n",
    "### Define helper function get_word2vec  and helper class MySentences for training word2vec on the corpus of texts. (or loading if already trained and saved to disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "609177df-1799-4f5e-b3e7-77c820561a7c",
    "_execution_state": "busy",
    "_uuid": "d631c05ece2e126a82481fa5a262d12ec7577e38"
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    \"\"\"MySentences is a generator to produce a list of tokenized sentences \n",
    "    \n",
    "    Takes a list of numpy arrays containing documents.\n",
    "    \n",
    "    Args:\n",
    "        arrays: List of arrays, where each element in the array contains a document.\n",
    "    \"\"\"\n",
    "    def __init__(self, *arrays):\n",
    "        self.arrays = arrays\n",
    " \n",
    "    def __iter__(self):\n",
    "        for array in self.arrays:\n",
    "            for document in array:\n",
    "                for sent in nltk.sent_tokenize(document):\n",
    "                    yield nltk.word_tokenize(sent)\n",
    "\n",
    "def get_word2vec(sentences, location):\n",
    "    \"\"\"Returns trained word2vec\n",
    "    \n",
    "    Args:\n",
    "        sentences: iterator for sentences\n",
    "        \n",
    "        location (str): Path to save/load word2vec\n",
    "    \"\"\"\n",
    "    if os.path.exists(location):\n",
    "        print('Found {}'.format(location))\n",
    "        model = gensim.models.Word2Vec.load(location)\n",
    "        return model\n",
    "    \n",
    "    print('{} not found. training model'.format(location))\n",
    "    model = gensim.models.Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)\n",
    "    print('Model done training. Saving to disk')\n",
    "    model.save(location)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5782e63f-8fef-47c8-b83a-829836f1f096",
    "_uuid": "70f109950197b133cc46e2497b2248830d42a349"
   },
   "source": [
    "### Start training the word2vec model. Since word2vec training is unsupervised, you can use both training and test datasets.\n",
    "\n",
    "If training has already been done, the function will just load the word2vec to disk so you don't need to retrain if rerunning the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "e62cf926-34d9-461a-bf92-21e38e9ff2d3",
    "_execution_state": "busy",
    "_uuid": "80d89a6184209c1630976aa5bdb9a93b1290b363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found w2vmodel\n"
     ]
    }
   ],
   "source": [
    "w2vec = get_word2vec(\n",
    "    MySentences(\n",
    "        df_train['Text'].values, \n",
    "        #df_test['Text'].values  Commented for Kaggle limits\n",
    "    ),\n",
    "    'w2vmodel'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "591cc8cb-49c2-41d0-be0a-ff8ee7d4f230",
    "_uuid": "b41f276a240b388d56fb5187a5b99ac0d3b76d59"
   },
   "source": [
    "### Now that we have our word2vec model, how do we use it to transform each documents into a feature vector? In order to convert a document of multiple words into a single vector using our trained word2vec, we take the word2vec of all words in the document, then take its mean.\n",
    "\n",
    "### We'll define a transformer (with sklearn interface) to convert a document into its corresponding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "8be99804-9357-4522-a80b-aa328f5ef973",
    "_execution_state": "busy",
    "_uuid": "f188944da320461ad2e8f76a7a991454e2c0763c"
   },
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for document in X:\n",
    "            tokenized_doc = []\n",
    "            for sent in nltk.sent_tokenize(document):\n",
    "                tokenized_doc += nltk.word_tokenize(sent)\n",
    "            transformed_X.append(np.array(tokenized_doc))\n",
    "        return np.array(transformed_X)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.wv.syn0[0])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = MyTokenizer().fit_transform(X)\n",
    "        \n",
    "        return np.array([\n",
    "            np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "1a13f2ef-1fb7-462a-8e72-63608f158969",
    "_execution_state": "busy",
    "_uuid": "22e86ded9c31b7039c65ba3e46a2e58ff2b08cee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    }
   ],
   "source": [
    "mean_embedding_vectorizer = MeanEmbeddingVectorizer(w2vec)\n",
    "mean_embedded = mean_embedding_vectorizer.fit_transform(df_train['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "383b2dc5-5ba8-4a44-86cc-d6710bacc8a8",
    "_execution_state": "busy",
    "_uuid": "2f30d63d72bc0dda91f1625a399fc1a98c8e25c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 2.3906491891037938\n",
      "Accuracy: 0.24458204334365324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(mean_embedded, df_train['Label'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "33e16fc2-7172-4163-9d6e-8bab7a9e85b3",
    "_execution_state": "busy",
    "_uuid": "c0fcd434367d7a1899deda82cdfe5726c85bb41e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   12.7s remaining:   19.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 2.3692412119737694\n",
      "Accuracy: 0.326625386996904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.0s finished\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(mean_embedded, df_train['Label'].values.ravel(),\n",
    "                  RandomForestClassifier(n_estimators=1000, max_depth=15, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "ffa542a9-909c-4bd6-a59f-de71f3327d9e",
    "_execution_state": "busy",
    "_uuid": "e18fab5b47d20ff4050b7b7d1c6e44f374772abb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   20.2s remaining:   30.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 2.2555922843723475\n",
      "Accuracy: 0.3173374613003096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.7s finished\n"
     ]
    }
   ],
   "source": [
    "evaluate_features(mean_embedded, \n",
    "                  df_train['Label'].values.ravel(),\n",
    "                  XGBClassifier(max_depth=4,\n",
    "                                objective='multi:softprob',\n",
    "                                learning_rate=0.03333,\n",
    "                                )\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d59000aa-abc6-4ea8-b3f8-683f54e95761",
    "_uuid": "6ea65a9b884a0af3c31a2ca61432fa6858f9a402"
   },
   "source": [
    "### As expected, we get better results than TF-IDF. \n",
    "\n",
    "The results are still not very good though. One way to explain this is that there is a lot of information loss from just getting the mean of all word vectors of the document. This is roughly analogous to taking the entire document, summarizing it into one word, and using that word to classify the entire text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7db18b6e-d23f-412a-9f16-429082572649",
    "_uuid": "934ddee5cd73ca17ee2bd73f647290697aca997c"
   },
   "source": [
    "## Let's try a quick and dirty LSTM in Keras to take into account the sequential nature of text\n",
    "\n",
    "* We won't do any hyperparameter search \n",
    "* We'll go with 15 epochs, and save the model with the best validation loss after an epoch\n",
    "* Max sequence length is cut down to a measly 2000 (longest text has 77000+ words), to shorten training time and prevent GPU OOM\n",
    "\n",
    "Note: This takes about an hour to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "d1b0a192-ea18-419e-9ba4-bb52f12b9f78",
    "_execution_state": "busy",
    "_uuid": "8d4ee34e1e95faa8be9d93ecced116c324b61465"
   },
   "outputs": [],
   "source": [
    "# Use the Keras tokenizer\n",
    "num_words = 2000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(df_train['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "0610df13-711b-4d28-810a-2f7361cea388",
    "_execution_state": "busy",
    "_uuid": "2fba830b1fd73426d1b3b2f22bac503d91d0a923"
   },
   "outputs": [],
   "source": [
    "# Pad the data \n",
    "X = tokenizer.texts_to_sequences(df_train['Text'].values)\n",
    "X = pad_sequences(X, maxlen=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "af64e666-69b4-4fe7-a8ce-c098e640cbf9",
    "_execution_state": "busy",
    "_uuid": "6aff6b56a17d5bc0650e1bb41e60fee7be6f52ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2000, 128)         256000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                3940      \n",
      "=================================================================\n",
      "Total params: 514,740\n",
      "Trainable params: 514,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build out our simple LSTM\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "# Model saving callback\n",
    "ckpt_callback = ModelCheckpoint('keras_model', \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 mode='auto')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embed_dim, input_length = X.shape[1]))\n",
    "model.add(LSTM(lstm_out, recurrent_dropout=0.2, dropout=0.2))\n",
    "model.add(Dense(20,activation='sigmoid'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "3a3d8330-3b5e-4cb6-87c7-0f7707b48a76",
    "_execution_state": "busy",
    "_uuid": "f9a53d657ec8a6017648965ad8073627756a13bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 2000) (1033, 20)\n",
      "(259, 2000) (259, 20)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df_train['Label']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42, stratify=Y)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "d7eac40d-a8d6-47a7-9542-1a2b06f76ca8",
    "_execution_state": "busy",
    "_uuid": "a0da0f4a43684380e3dd1b6f53d03cc45384fbf9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "26/26 [==============================] - ETA: 0s - loss: 2.7848 - accuracy: 0.1864 \n",
      "Epoch 00001: val_loss improved from inf to 2.64084, saving model to keras_model\n",
      "WARNING:tensorflow:From C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: keras_model\\assets\n",
      "26/26 [==============================] - 524s 20s/step - loss: 2.7848 - accuracy: 0.1864 - val_loss: 2.6408 - val_accuracy: 0.1981\n",
      "Epoch 2/8\n",
      "26/26 [==============================] - ETA: 0s - loss: 2.6281 - accuracy: 0.1937 \n",
      "Epoch 00002: val_loss improved from 2.64084 to 2.62587, saving model to keras_model\n",
      "INFO:tensorflow:Assets written to: keras_model\\assets\n",
      "26/26 [==============================] - 480s 18s/step - loss: 2.6281 - accuracy: 0.1937 - val_loss: 2.6259 - val_accuracy: 0.1981\n",
      "Epoch 3/8\n",
      " 5/26 [====>.........................] - ETA: 5:42:16 - loss: 2.5364 - accuracy: 0.1937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-3e86abc605a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mckpt_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs=8, batch_size=batch_size, validation_split=0.2, callbacks=[ckpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72101f81-dd5a-4b27-b985-e4fa03a7d7fd",
    "_execution_state": "busy",
    "_uuid": "142200cc3855cd276bb3a9abf3526a61988fafee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "63a95326-bbb5-4513-8a0c-329f87cc1fb9",
    "_execution_state": "busy",
    "_uuid": "80eb60399aedb6f8fcb3b65e215b1340f2b679c2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da8194c1-bce5-4d3d-93a7-fbb6b832113e",
    "_execution_state": "busy",
    "_uuid": "fffe9f6d9907deabbf827f183c4cf33af917b131"
   },
   "outputs": [],
   "source": [
    "pred_indices = np.argmax(probas, axis=1)\n",
    "classes = np.array(range(1, 10))\n",
    "preds = classes[pred_indices]\n",
    "print('Log loss: {}'.format(log_loss(classes[np.argmax(Y_test, axis=1)], probas)))\n",
    "print('Accuracy: {}'.format(accuracy_score(classes[np.argmax(Y_test, axis=1)], preds)))\n",
    "skplt.plot_confusion_matrix(classes[np.argmax(Y_test, axis=1)], preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e96c819f-eea0-4079-8309-0b5233fb4a1c",
    "_uuid": "0fda6b5af213a4250ba1589b7203ffde3aaead6f"
   },
   "source": [
    "### The results of the quick LSTM are promising. \n",
    "\n",
    "On the first try with no hyperparameter search, 6th epoch, max sequence length cut down to a measly 2000 (longest text has 77000+ words), we get the best log loss so far of around 1.4. You can still see a bit of bias towards class 7 but the confusion matrix looks more balanced than anything we've seen so far.\n",
    "\n",
    "### Further tuning of the LSTM will likely produce better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "db48f4cc-a354-4f8d-9e60-a9d4462876dd",
    "_uuid": "a3689c71d2b898f2109bef73b38247999535486d"
   },
   "source": [
    "## So far, we've only used the text field to perform classification. But there is still the \"Gene\" and \"Variation\" fields.\n",
    "\n",
    "Using only the Text field is a bit flawed. Looking closer at the statistics we calculated above, \"training_text\" actually has duplicates, and the duplicates have different classes. This is part of the challenge. A lot of papers are studies of 2 or more genes. It is our job to use the other fields to figure out which parts of the text are relevant for the particular Gene and Variation.\n",
    "\n",
    "### Let's use a LabelEncoder to encode Gene and Variation and combine it with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "704fce25-86e1-48b6-8674-9843559ace23",
    "_execution_state": "busy",
    "_uuid": "80844cb882cf78f1e3e9705f14c3332a4778be48",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_le = LabelEncoder()\n",
    "gene_encoded = gene_le.fit_transform(df_train['Gene'].values.ravel()).reshape(-1, 1)\n",
    "gene_encoded = gene_encoded / np.max(gene_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ceed29c-6f13-41e7-9c85-47f39820e319",
    "_execution_state": "busy",
    "_uuid": "bf24d496955e15ff12bc583b97ed034b57adfd89",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variation_le = LabelEncoder()\n",
    "variation_encoded = variation_le.fit_transform(df_train['Variation'].values.ravel()).reshape(-1, 1)\n",
    "variation_encoded = variation_encoded / np.max(variation_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dbafc18-a824-4eb5-b8b1-c104e4b14480",
    "_execution_state": "busy",
    "_uuid": "8e98d909ca15dc9e1c756610df216f22c054d8d1"
   },
   "outputs": [],
   "source": [
    "evaluate_features(np.hstack((gene_encoded, variation_encoded, truncated_tfidf)), df_train['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14b8a51e-ab20-4791-9fc0-9d1681263f21",
    "_execution_state": "busy",
    "_uuid": "0d151795f1e0a4a5cbf42d740d3d97882c6d970d"
   },
   "outputs": [],
   "source": [
    "evaluate_features(np.hstack((gene_encoded, variation_encoded, truncated_tfidf)), df_train['Class'],\n",
    "                  RandomForestClassifier(n_estimators=1000, max_depth=5, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "772a5a7a-c978-4ce5-bfaf-0e50584b225a",
    "_uuid": "9fdfeaf538aaea6e557a95233a60d7c01def5814"
   },
   "source": [
    "### Barely any difference, let's try our  label encoded features with our word2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58ef00cc-e255-4eac-9a56-7ac0406b8230",
    "_execution_state": "busy",
    "_uuid": "e3813a8343a90bd7023055150cc7b9012885247c"
   },
   "outputs": [],
   "source": [
    "evaluate_features(np.hstack((gene_encoded, variation_encoded, mean_embedded)), df_train['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "43c00792-b741-45de-9709-4c3ad9a7eafc",
    "_execution_state": "busy",
    "_uuid": "fbcc0adde6907f7beab0de93debe310815a1156b"
   },
   "outputs": [],
   "source": [
    "evaluate_features(np.hstack((gene_encoded, variation_encoded, mean_embedded)), df_train['Class'],\n",
    "                  RandomForestClassifier(n_estimators=1000, max_depth=5, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c1780db6-c523-4a23-a5dd-84906fb0505a",
    "_uuid": "04b528db030e8e16cf0c581643bd02d95923522c"
   },
   "source": [
    "### Doesn't make a difference either. Let's try one-hot encoding + SVD the \"Gene\" and \"Variation\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "83c49101-1cbb-492e-9680-ad5f5a4995d2",
    "_execution_state": "busy",
    "_uuid": "343d08a18abfaa87e67064faf592ddbb2d92de2f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_gene = pd.get_dummies(df_train['Gene'])\n",
    "svd = TruncatedSVD(n_components=25, n_iter=25, random_state=12)\n",
    "truncated_one_hot_gene = svd.fit_transform(one_hot_gene.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0340ce68-271b-43da-92e0-a9d22528bb30",
    "_execution_state": "busy",
    "_uuid": "ab2bb2dadc7ee52b5b4e382bad56ba314f93ec7a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_variation = pd.get_dummies(df_train['Variation'])\n",
    "svd = TruncatedSVD(n_components=25, n_iter=25, random_state=12)\n",
    "truncated_one_hot_variation = svd.fit_transform(one_hot_variation.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8cb7e817-d34f-4d46-ab04-b33c445bb72a",
    "_uuid": "c4e3b7ae95ead4d81a5bc329a4df5b1016f47b2b"
   },
   "source": [
    "### Truncated one hot encoding + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3c6e9f63-b095-437a-adde-325f86bd58f2",
    "_execution_state": "busy",
    "_uuid": "94704cd2cc00bd6f33a9a2228b01392430806d48"
   },
   "outputs": [],
   "source": [
    "evaluate_features(np.hstack((truncated_one_hot_gene, truncated_one_hot_variation, truncated_tfidf)), df_train['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "69ae841b-f616-468d-980a-bbca4eb40160",
    "_execution_state": "busy",
    "_uuid": "0bc53506063033a3c991226344fc72538c8c6cc3"
   },
   "outputs": [],
   "source": [
    "evaluate_features(np.hstack((truncated_one_hot_gene, truncated_one_hot_variation, truncated_tfidf)), df_train['Class'],\n",
    "                  RandomForestClassifier(n_estimators=1000, max_depth=5, verbose=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "97164561-dca4-43fe-b37b-3a54d64dd99b",
    "_uuid": "d65b9d9324de3990985b1cc6e6b3b50bb6ad9ca2"
   },
   "source": [
    "### Truncated one hot encoding + word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e9710c6-8ad0-4462-ae86-71c09306c971",
    "_execution_state": "busy",
    "_uuid": "d8dc844e566435a95016f7dde0087a76ccc94656"
   },
   "outputs": [],
   "source": [
    "evaluate_features(np.hstack((truncated_one_hot_gene, truncated_one_hot_variation, mean_embedded)), df_train['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c5b4c744-3ff8-4d96-b80f-358a2a102155",
    "_execution_state": "busy",
    "_uuid": "d684bc32a398a92a77f3b7617dade9340dafd92e"
   },
   "outputs": [],
   "source": [
    "evaluate_features(np.hstack((truncated_one_hot_gene, truncated_one_hot_variation, mean_embedded)), df_train['Class'],\n",
    "                  RandomForestClassifier(n_estimators=1000, max_depth=5, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a69600f7-640f-4238-8484-c8c0ac40c54c",
    "_uuid": "c238870079622900d50629bcbf0f06914a1c7a87"
   },
   "source": [
    "### Interestingly, performance is actually a bit worse than simple label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e70c3e0c-3722-4ed0-943f-3909c2078f38",
    "_uuid": "2eeb0f102a078b433d0c30b9d4e5fedebc58a236"
   },
   "source": [
    "## Before going into a summary of the insights we've discovered, let's generate some submissions from our best models and see how they fare in the public leaderboard\n",
    "\n",
    "### We'll start by generating a submission from our word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "359545db-061c-428c-9863-77cc73edb2a5",
    "_execution_state": "busy",
    "_uuid": "960016c34ae2a8cc76c9624ee721e712e3e3baf5"
   },
   "outputs": [],
   "source": [
    "lr_w2vec = LogisticRegression()\n",
    "lr_w2vec.fit(mean_embedded, df_train['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b18da40c-43a0-4f3d-b2fd-65d4b5ffe13c",
    "_execution_state": "busy",
    "_uuid": "15f8696fff30dc4377efae0ebca1f47c5470df29",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_embedded_test = mean_embedding_vectorizer.transform(df_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29ef4844-4cc2-4b19-adfc-dfbdd5eb6821",
    "_execution_state": "busy",
    "_uuid": "32c10bef6437d50261d22c3f5fd61fdab46a399f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = lr_w2vec.predict_proba(mean_embedded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85f25966-0e5a-421a-a77c-5a8d75410917",
    "_execution_state": "busy",
    "_uuid": "a106e10bd7e26e6284e583a1411a66c8f1f073e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(probas, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission_df['ID'] = df_test['ID']\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9c0da856-df5c-44b6-a8ab-50ce90212974",
    "_execution_state": "busy",
    "_uuid": "f5b95449759c0052a634b624d0c5d18177aa5329",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d30f0cd2-bd38-4913-941f-2de07416dce9",
    "_uuid": "2313e8a97d9801826e7499fafbcf73abe353df28"
   },
   "source": [
    "### Test out XGB and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "366147f8-7898-4c43-8e7d-3bb9092c0914",
    "_execution_state": "busy",
    "_uuid": "936695ec044ae89260c3e191b9af9a1c84e21e67",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_w2vec = XGBClassifier(max_depth=4,\n",
    "                          objective='multi:softprob',\n",
    "                          learning_rate=0.03333)\n",
    "xgb_w2vec.fit(mean_embedded, df_train['Class'])\n",
    "probas = xgb_w2vec.predict_proba(mean_embedded_test)\n",
    "submission_df = pd.DataFrame(probas, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission_df['ID'] = df_test['ID']\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c313def8-9b81-4257-ae96-f826130c18aa",
    "_execution_state": "busy",
    "_uuid": "4dffea7a53a0953e51fe6ab353dcc24c45ec7e4a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_w2vec = SVC(kernel='linear', probability=True)\n",
    "svc_w2vec.fit(mean_embedded, df_train['Class'])\n",
    "probas = svc_w2vec.predict_proba(mean_embedded_test)\n",
    "submission_df = pd.DataFrame(probas, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission_df['ID'] = df_test['ID']\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8cfef508-e869-4971-9b84-06d3e80ae6ea",
    "_uuid": "9c2e087dd457065520e8e8d1d195dc015571925b"
   },
   "source": [
    "#### Public LB Score Log Reg: 1.032000\n",
    "\n",
    "#### Public LB Score XGB: 0.96536\n",
    "\n",
    "#### Public LB Score SVC: 0.97059\n",
    "\n",
    "### Let's try our Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56db5d32-cc80-445f-b33a-05071832dd69",
    "_execution_state": "busy",
    "_uuid": "8d65e2e32ad9d552e5f38c3667f15bfdb9915208",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = tokenizer.texts_to_sequences(df_test['Text'].values)\n",
    "Xtest = pad_sequences(Xtest, maxlen=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4d608be7-741c-462c-8a2a-39b81612000d",
    "_execution_state": "busy",
    "_uuid": "7b454ebc7996841cffcaba3a165d8b28b5c76466",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dbcb71f9-1854-44c3-b9cf-d060494887d8",
    "_execution_state": "busy",
    "_uuid": "81165d6e9870765c90fbb4624743ea49f9f6d1d8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(probas, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission_df['ID'] = df_test['ID']\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9ce11af2-21b8-47e0-a83b-55ee14c1c53c",
    "_execution_state": "busy",
    "_uuid": "7264bb21f9c0028b6be3e637c8414d543266d113",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d1aa03cb-3faf-4dfe-97a7-97dbfff856ec",
    "_uuid": "1ac56c47c3e55b3a6fde88332fe1e045e59fef9b"
   },
   "source": [
    "#### Public LB Score: 1.00234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04e8cc4c-7bcd-4951-8e8f-859a6da7e0fe",
    "_uuid": "9070256ed93261c08d7ff3c7bf43f144463263b5"
   },
   "source": [
    "## Summary\n",
    "\n",
    "The aim of this notebook was to do some quick exploration of the dataset and apply some common ML techniques to the classification task. The metric to maximize is multiclass log loss.\n",
    "\n",
    "A big part of the problem is to teach an ML model how to \"read\" medical literature and classify the given Gene and Variation into 1 out of 9 classes.\n",
    "\n",
    "Thus, the first part of this notebook focused on applying common techniques to preprocess and vectorize free text and evaluate its effectiveness by running them through vanilla Logistic Regression and Random Forest.\n",
    "\n",
    "The techniques used, from least effective to most effective, were:\n",
    "\n",
    "* Bag of Words\n",
    "* TF-IDF\n",
    "* Word2Vec\n",
    "\n",
    "Because the above approaches did not take into account the temporal patterns in free text, a quick LSTM was tried as well. This approach scored higher than the above without any tuning.\n",
    "\n",
    "In the second part of the notebook, I added the \"Gene\" and \"Variation\" features next to the free text features. I tried both label encoding and one-hot encoding, however, the results did not show much improvement.\n",
    "\n",
    "In the third part of the notebook, I generated submissions for both Word2Vec (multiple classifiers) and Keras LSTM and recorded the public leaderboard scores of each submission. The scores were better (around 1) but did not show the same relationships with each other as my own CV (they were mostly close to each other). This is a common occurrence in Kaggle competitions since the public leaderboard is scored on a smaller subset of the test data. Most Kagglers' advice is to ignore the public leaderboard and trust your own CV.\n",
    "\n",
    "## Further things to try\n",
    "\n",
    "This notebook's aim was mostly figuring out which techniques are worth exploring and was not intended to generate very competitive submissions. The following is a list of suggestions to try for further improvement.\n",
    "\n",
    "* There are tons of other techniques for free text other than the ones I listed above. Make sure to explore other techniques such as Doc2Vec, DeepIR, and Word Mover's distance\n",
    "\n",
    "* Focus more on capturing the relationship between \"Gene\" and \"Variation\" with the free text features. Since \"Text\" is sometimes duplicated (with different classes!), taking into account \"Gene\" and \"Variation\" is very important.\n",
    "\n",
    "* Explore different deep learning architectures for the data. One idea for an architecture is to combine a simple Embedding + LSTM for the free text and concatenate the input with \"Gene\" and \"Variation\" Embeddings, leading into a final fully connected layer for the classes. Hopefully, this will capture the relationship between the text and the \"Gene\" + \"Variation\" columns.\n",
    "\n",
    "* Train Word2Vec on a bigger corpus of genetic and medical data. Since Word2Vec is unsupervised, we can get better embeddings with more data, and consequently, better predictions\n",
    "\n",
    "* Don't forget to do hyperparameter optimization when you're happy with a set of features. Stacked ensembling is also an almost guaranteed way to get a small boost to your score. We skipped this entirely in this notebook as this is usually the last step in the process. Try http://xcessiv.readthedocs.io/.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "47a36edb-f857-4de7-a19d-99dbb68aab50",
    "_execution_state": "busy",
    "_uuid": "609fdc82b3b3125e3f79ea88909dfab79484b829",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1e994ded-dbfe-4117-a034-4ea3b57be80f",
    "_execution_state": "busy",
    "_uuid": "a8e5d0e66cf98fc72ec808b7f5e0e366d4a492b2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1bcacfa6-87a4-489c-aa38-5a7f88424134",
    "_execution_state": "busy",
    "_uuid": "7ee8525ea2ffedb4c8d76afeba30598f5589b2f4",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
