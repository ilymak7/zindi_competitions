{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install chart-studio\nclear_output()\nfrom sklearn.impute import KNNImputer\nimport seaborn as sns\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom datetime import datetime as dt\nimport itertools\nfrom tqdm import tqdm\nfrom scipy.stats import norm, t\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\nimport lightgbm as lgb\nfrom sklearn.linear_model import LinearRegression\nimport gc\nfrom sklearn.model_selection import StratifiedKFold,KFold\nfrom sklearn import metrics\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\npd.set_option('display.max_columns', None)\nplt.style.use('fivethirtyeight') \nfrom pylab import rcParams\nfrom plotly import tools\nimport chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport statsmodels.api as sm\nfrom numpy.random import normal, seed\nfrom statsmodels.tsa.arima_model import ARMA\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.tsa.arima_model import ARIMA\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import Pool, CatBoostRegressor\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.callbacks import EarlyStopping\nimport os \nimport random\n# import numpy as np \nfrom catboost import Pool, CatBoostRegressor\n\nDEFAULT_RANDOM_SEED = 2021\n\ndef seedBasic(seed=DEFAULT_RANDOM_SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \n# tensorflow random seed \nimport tensorflow as tf \ndef seedTF(seed=DEFAULT_RANDOM_SEED):\n    tf.random.set_seed(seed)\n    \n# torch random seed\nimport torch\ndef seedTorch(seed=DEFAULT_RANDOM_SEED):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n      \n# basic + tensorflow + torch \ndef seedEverything(seed=DEFAULT_RANDOM_SEED):\n    seedBasic(seed)\n    seedTF(seed)\n    seedTorch(seed)\nseedEverything(42)\nseed = 42\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-21T10:36:26.483371Z","iopub.execute_input":"2022-09-21T10:36:26.483807Z","iopub.status.idle":"2022-09-21T10:36:42.035901Z","shell.execute_reply.started":"2022-09-21T10:36:26.483764Z","shell.execute_reply":"2022-09-21T10:36:42.034638Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.14.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}}]},{"cell_type":"code","source":"train_ori = pd.read_csv('/kaggle/input/airquoi/train.csv',parse_dates=['date'])\ntest_ori = pd.read_csv('/kaggle/input/airquoi/test.csv',parse_dates=['date'])\nss =pd.read_csv('/kaggle/input/airquoi/SampleSubmission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:36:42.037863Z","iopub.execute_input":"2022-09-21T10:36:42.038648Z","iopub.status.idle":"2022-09-21T10:36:42.275242Z","shell.execute_reply.started":"2022-09-21T10:36:42.038609Z","shell.execute_reply":"2022-09-21T10:36:42.274245Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:36:42.276682Z","iopub.execute_input":"2022-09-21T10:36:42.277397Z","iopub.status.idle":"2022-09-21T10:36:42.282983Z","shell.execute_reply.started":"2022-09-21T10:36:42.277358Z","shell.execute_reply":"2022-09-21T10:36:42.281570Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"def cust_metric(y_pred, ds):\n    y_true = ds.get_label()\n    sq_errs = abs(y_true - y_pred)\n    avg_per_id = pd.Series(sq_errs).groupby(ds.site_code).mean()\n#     print(avg_per_id)\n    return 'avg_worst_by_id', avg_per_id.max(), False\n\ndef _get_X_Y_DF_from_CV(train_X, train_Y, train_index, validation_index):\n        X_train, X_validation = (\n            train_X.iloc[train_index],\n            train_X.iloc[validation_index],\n        )\n        y_train, y_validation = (\n            train_Y.iloc[train_index],\n            train_Y.iloc[validation_index],\n        )\n        return X_train, X_validation, y_train, y_validation\ndef cust_score(y_predicted):\n    l = []\n    a = train.site_latitude.unique()\n    for i in a:\n        y_true = train.loc[train.site_latitude == i,'pm2_5']\n        y_hat = y_predicted[y_true.index]\n        l.append(metrics.mean_absolute_error(y_true,y_hat))\n    return pd.DataFrame({'site_latitude':a,\n                        'err': np.array(l)})\ndef preds_to_sub(test,preds,name = None,log = False):\n    if log :\n        test['pm2_5'] = np.exp(preds)\n    else:\n        test['pm2_5'] = preds\n    sub = test[['ID','pm2_5']]\n    if name:\n        sub.to_csv(name+'.csv', index = False)\n    return sub\n","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:36:42.285706Z","iopub.execute_input":"2022-09-21T10:36:42.286081Z","iopub.status.idle":"2022-09-21T10:36:42.298854Z","shell.execute_reply.started":"2022-09-21T10:36:42.286050Z","shell.execute_reply":"2022-09-21T10:36:42.297512Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess(train,test,scale = True,target_encode = False,\n               include_date = True,remove_nans = True, remove_multi = True):\n    le = LabelEncoder()\n    train['Train']=1\n    test['Train']=0\n    all_data=pd.concat([train,test])\n    if include_date:\n        all_data['month'] = all_data.date.dt.month\n        all_data['year'] = all_data.date.dt.year\n        all_data['day'] = all_data.date.dt.day\n        all_data['week'] = all_data.date.dt.week\n        all_data['dow'] = all_data.date.dt.dayofweek\n        all_data['woy'] = all_data.date.dt.weekofyear\n    all_data[['site_latitude','site_longitude']] =  all_data[['site_latitude','site_longitude']] .round(5)\n    all_data['device'] = le.fit_transform(all_data['device'].values.reshape(-1,1))\n    le = LabelEncoder()\n    all_data['site_code'] = le.fit_transform(all_data.site_latitude.astype('str').values.reshape(-1,1))\n    train = all_data.loc[all_data.Train == 1].reset_index(drop = True)\n    test = all_data.loc[all_data.Train == 0].reset_index(drop = True)\n    if target_encode:\n        train,test = target_encode(train,test,target = 'pm2_5',groupss = 'site_code')\n    if remove_nans:\n        tr,te = cust_imputer(train.copy(), test.copy())\n        all_data = pd.concat([tr,te]).reset_index(drop = True)\n        s_codes = all_data.site_code.unique()\n        distances = np.zeros((s_codes.shape[0],s_codes.shape[0]))\n        for i in np.sort(s_codes):\n            for j in np.sort(s_codes):\n                distances[i,j] =  get_dist(all_data, i,j)\n        distances = pd.DataFrame(index = np.sort(s_codes), columns = np.sort(s_codes),data = distances)\n        SO2_cols = ['SulphurDioxide_SO2_column_number_density',\n                    'SulphurDioxide_SO2_column_number_density_amf',\n               'SulphurDioxide_SO2_slant_column_number_density',\n               'SulphurDioxide_cloud_fraction',\n                'SulphurDioxide_sensor_azimuth_angle',\n               'SulphurDioxide_sensor_zenith_angle',\n               'SulphurDioxide_solar_azimuth_angle',\n               'SulphurDioxide_solar_zenith_angle',\n               'SulphurDioxide_SO2_column_number_density_15km']\n        CO_cols = ['CarbonMonoxide_CO_column_number_density',\n               'CarbonMonoxide_H2O_column_number_density',\n               'CarbonMonoxide_cloud_height', 'CarbonMonoxide_sensor_altitude',\n               'CarbonMonoxide_sensor_azimuth_angle',\n               'CarbonMonoxide_sensor_zenith_angle',\n               'CarbonMonoxide_solar_azimuth_angle',\n               'CarbonMonoxide_solar_zenith_angle']\n        NO2_cols = ['NitrogenDioxide_NO2_column_number_density',\n               'NitrogenDioxide_tropospheric_NO2_column_number_density',\n               'NitrogenDioxide_stratospheric_NO2_column_number_density',\n               'NitrogenDioxide_NO2_slant_column_number_density',\n               'NitrogenDioxide_tropopause_pressure',\n               'NitrogenDioxide_absorbing_aerosol_index',\n               'NitrogenDioxide_cloud_fraction', 'NitrogenDioxide_sensor_altitude',\n               'NitrogenDioxide_sensor_azimuth_angle',\n               'NitrogenDioxide_sensor_zenith_angle',\n               'NitrogenDioxide_solar_azimuth_angle',\n               'NitrogenDioxide_solar_zenith_angle']\n        HCHO_cols = ['Formaldehyde_tropospheric_HCHO_column_number_density',\n               'Formaldehyde_tropospheric_HCHO_column_number_density_amf',\n               'Formaldehyde_HCHO_slant_column_number_density',\n               'Formaldehyde_cloud_fraction', 'Formaldehyde_solar_zenith_angle',\n               'Formaldehyde_solar_azimuth_angle', 'Formaldehyde_sensor_zenith_angle',\n               'Formaldehyde_sensor_azimuth_angle']\n        UV_cols = ['UvAerosolIndex_absorbing_aerosol_index',\n               'UvAerosolIndex_sensor_altitude', 'UvAerosolIndex_sensor_azimuth_angle',\n               'UvAerosolIndex_sensor_zenith_angle',\n               'UvAerosolIndex_solar_azimuth_angle',\n               'UvAerosolIndex_solar_zenith_angle']\n        O3_cols = ['Ozone_O3_column_number_density_amf',\n               'Ozone_O3_slant_column_number_density',\n               'Ozone_O3_effective_temperature', 'Ozone_cloud_fraction',\n               'Ozone_sensor_azimuth_angle', 'Ozone_sensor_zenith_angle',\n               'Ozone_solar_azimuth_angle', 'Ozone_solar_zenith_angle']\n        cloud_cols = ['Cloud_cloud_fraction', 'Cloud_cloud_top_pressure',\n               'Cloud_cloud_top_height', 'Cloud_cloud_base_pressure',\n               'Cloud_cloud_base_height', 'Cloud_cloud_optical_depth',\n               'Cloud_surface_albedo', 'Cloud_sensor_azimuth_angle',\n               'Cloud_sensor_zenith_angle', 'Cloud_solar_azimuth_angle',\n               'Cloud_solar_zenith_angle']\n        target = ['pm2_5']\n        all_cols = SO2_cols+cloud_cols+O3_cols+UV_cols+HCHO_cols+NO2_cols+CO_cols\n        other_cols = ['pm2_5', 'Train', 'month', 'year', 'day',\n               'week', 'dow', 'woy', 'rel_date']\n        other_cols_test = ['Train', 'month', 'year', 'day',\n               'week', 'dow', 'woy', 'rel_date']\n        for col in tqdm(all_cols):\n            for s_co in s_codes:\n                all_data = distance_w_impute(col,s_co,all_data,distances)\n        test = all_data[all_data.ID.isin(test_ori.ID)].drop_duplicates().reset_index(drop = True)\n        train = all_data[all_data.ID.isin(train_ori.ID)].drop_duplicates().reset_index(drop = True)\n        kn = KNNImputer(n_neighbors=5)\n        cols = train.drop('pm2_5',axis = 1).select_dtypes(include = ['float','int']).columns\n        train[cols] = kn.fit_transform(train[cols])\n        test[cols] = kn.transform(test[cols])\n        if scale:\n            rs= RobustScaler()\n            train[cols] = rs.fit_transform(train[cols])\n            test[cols] = rs.transform(test[cols])\n    if remove_multi:\n        cols = train.select_dtypes(include = ['int','float']).columns\n        l_drop = []\n        for col in cols:\n            df = train.pivot(index = 'date',columns = 'site_code',values = col)\n            if df.corr().mean().mean()>0.99:\n                l_drop.append(col)\n        train = train.drop([l for l  in l_drop[1:] if l not in other_cols],axis = 1 )\n        test = test.drop([l for l  in l_drop[1:] if l not in other_cols],axis = 1 )\n    return train.sort_index(), test.sort_index()\ndef get_dist(all_data, i,j):\n    return np.sqrt((all_data.loc[all_data.site_code == i,'site_latitude'].unique()[0]- all_data.loc[all_data.site_code == j,'site_latitude'].unique()[0])**2 + (all_data.loc[all_data.site_code == i,'site_longitude'].unique()[0]- all_data.loc[all_data.site_code == j,'site_longitude'].unique()[0])**2)\n\ndef distance_w_impute(col,s_co,all_data,distances):\n    ind = all_data.loc[(all_data.site_code == s_co)& (all_data[col].isna()),'date'].values\n    df3 = all_data.loc[(all_data.site_code != s_co)& (all_data.date.isin(ind)),['date',col,'site_code']]\n    df3['weights'] = df3['site_code'].map(distances[s_co]**(-1))\n    df3[col] = df3[col]*df3['weights']\n    maps = df3.groupby('date').apply(lambda x : x[col].sum()/(x['weights'].sum()))\n    all_data.loc[(all_data.site_code == s_co)& (all_data[col].isna()),col] = all_data.loc[(all_data.site_code == s_co)& (all_data[col].isna()),'date'].map(maps)\n    return all_data\ndef cust_imputer(train, test):\n    all_data = pd.concat([train,test]).reset_index(drop = True)\n    sensor_az_ang = ['SulphurDioxide_sensor_azimuth_angle','CarbonMonoxide_sensor_azimuth_angle','NitrogenDioxide_sensor_azimuth_angle',\n          'Formaldehyde_sensor_azimuth_angle','UvAerosolIndex_sensor_azimuth_angle','Ozone_sensor_azimuth_angle',\n         'Cloud_sensor_azimuth_angle']\n    sensor_zen_ang = ['SulphurDioxide_sensor_zenith_angle','CarbonMonoxide_sensor_zenith_angle','NitrogenDioxide_sensor_zenith_angle',\n          'Formaldehyde_sensor_zenith_angle','UvAerosolIndex_sensor_zenith_angle','Ozone_sensor_zenith_angle',\n         'Cloud_sensor_zenith_angle']\n    solar_az_ang = ['SulphurDioxide_solar_azimuth_angle','CarbonMonoxide_solar_azimuth_angle','NitrogenDioxide_solar_azimuth_angle',\n          'Formaldehyde_solar_azimuth_angle','UvAerosolIndex_solar_azimuth_angle','Ozone_solar_azimuth_angle',\n         'Cloud_solar_azimuth_angle']\n    solar_zen_ang = ['SulphurDioxide_solar_zenith_angle','CarbonMonoxide_solar_zenith_angle','NitrogenDioxide_solar_zenith_angle',\n          'Formaldehyde_solar_zenith_angle','UvAerosolIndex_solar_zenith_angle','Ozone_solar_zenith_angle',\n         'Cloud_solar_zenith_angle']\n    X =  all_data[sensor_az_ang]\n    imputer = KNNImputer(n_neighbors=5)\n    all_data.loc[X.isna().sum(axis = 1)<7,sensor_az_ang] = imputer.fit_transform(X[X.isna().sum(axis = 1)<7]) \n    X =  all_data[sensor_zen_ang]\n    imputer = KNNImputer(n_neighbors=5)\n    all_data.loc[X.isna().sum(axis = 1)<7,sensor_zen_ang] = imputer.fit_transform(X[X.isna().sum(axis = 1)<7])\n    X =  all_data[solar_az_ang]\n    imputer = KNNImputer(n_neighbors=5)\n    all_data.loc[X.isna().sum(axis = 1)<7,solar_az_ang] = imputer.fit_transform(X[X.isna().sum(axis = 1)<7]) \n    X =  all_data[solar_zen_ang]\n    imputer = KNNImputer(n_neighbors=5)\n    all_data.loc[X.isna().sum(axis = 1)<7,solar_zen_ang] = imputer.fit_transform(X[X.isna().sum(axis = 1)<7])\n    return all_data.loc[:train.shape[0]], all_data.loc[train.shape[0]:]\n","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:36:42.300984Z","iopub.execute_input":"2022-09-21T10:36:42.301496Z","iopub.status.idle":"2022-09-21T10:36:42.346690Z","shell.execute_reply.started":"2022-09-21T10:36:42.301447Z","shell.execute_reply":"2022-09-21T10:36:42.345372Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"def train_keras(baseline_model,train,features,target,test_data,kf,split_by):\n    inp = train[features].shape[1]\n    cats = train[split_by].values\n    X_scaled = train[features].values\n    Y = train[target].values\n    \n    y_oof = np.zeros(shape=(len(X_scaled),1))\n    y_predicted = np.zeros(shape=(len(test_data),1))\n    cv_scores = []\n    test_data = test_data[features]\n    models = []\n    for i, (train_index, test_index) in enumerate(kf.split(X_scaled, cats)):\n        print(' keras kfold: {}  of  {} : '.format(i+1, K_FOLDS ))\n        X_train, X_valid = X_scaled[train_index], X_scaled[test_index]\n        y_train, y_valid = Y[train_index], Y[test_index]\n        my_model = baseline_model(inp)\n        my_model.fit(X_train, y_train,\n                     validation_data=(X_valid, y_valid),\n                     epochs=100,\n                     batch_size = 64,\n                     callbacks=[EarlyStopping(patience=20)],\n                     verbose=0)\n        \n        models.append(my_model)\n        y_oof[test_index] = my_model.predict(X_valid)\n        y_predicted += my_model.predict(test_data.values) \n        del my_model\n        gc.collect()\n        cv_oof_score = metrics.mean_absolute_error(y_valid, y_oof[test_index])\n        cv_scores.append(cv_oof_score)\n        print(f\"CV OOF Score for fold {i+1} is {cv_oof_score}\")\n\n#         del validation_index, X_validation, y_validation\n#         gc.collect()\n\n    y_predicted /= K_FOLDS\n    oof_score = round(metrics.mean_absolute_error(Y, y_oof), 5)\n    avg_cv_scores = round(sum(cv_scores) / len(cv_scores), 5)\n    std_cv_scores = round(np.array(cv_scores).std(), 5)\n    return y_predicted,models,y_oof,oof_score \ndef train_lgb(X,features,target,test_data,params,kf,split_by):\n    features_importance= pd.DataFrame({'Feature':[], 'Importance':[]})\n    models =[]\n    train_X = X[features]\n    train_Y = X[target]\n    split_by = X[split_by]\n    test_data = test_data[features]\n    test_X = test_data.copy()\n    print(f\"Shape of train_X : {train_X.shape}, test_X: {test_X.shape}, train_Y: {train_Y.shape}\")\n    \n    predictors = list(train_X.columns)\n    # print(f\"List of features to be used {list(predictors)}\")\n\n    # Selecting n_splits to be 3, since class 42 has \n    # just 3 instances\n#     kf = KFold(random_state=seed_lgb,n_splits=K_FOLDS, shuffle=shuffle_lgb)\n#     kf = StratifiedKFold(random_state=seed_lgb,n_splits=K_FOLDS, shuffle=shuffle_lgb)\n    y_oof_lgb = np.zeros(shape=(len(train_X),))\n    y_predicted_lgb = np.zeros(shape=(len(test_X),))\n    cv_scores = []\n    fold = 0\n    n_folds = kf.get_n_splits()\n    for train_index, validation_index in kf.split(X=train_X, y=split_by):\n        fold += 1\n        print(f\"fold {fold} of {n_folds}\")\n\n        X_train, X_validation, y_train, y_validation = _get_X_Y_DF_from_CV(\n            train_X, train_Y, train_index, validation_index\n        )\n\n        lgb_train = lgb.Dataset(X_train, y_train)\n        lgb_eval = lgb.Dataset(X_validation, y_validation, reference=lgb_train)\n\n        model = lgb.train(\n            params,\n            lgb_train,\n            valid_sets=[lgb_train, lgb_eval],\n            verbose_eval=-1,\n#             early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n#             num_boost_round=N_ESTIMATORS,\n            feature_name=predictors,\n            categorical_feature=\"auto\",\n        )\n        del lgb_train, lgb_eval, train_index, X_train, y_train\n        gc.collect()\n\n        y_oof_lgb[validation_index] = model.predict(\n            X_validation, num_iteration=model.best_iteration\n        )\n\n        y_predicted_lgb += model.predict(\n            test_data.values, num_iteration=model.best_iteration\n        )\n        fold_importance_df= pd.DataFrame({'Feature':[], 'Importance':[]})\n        fold_importance_df['Feature']= predictors\n        fold_importance_df['Importance']= model.feature_importance()\n        fold_importance_df[\"fold\"] = fold + 1\n        features_importance = pd.concat([features_importance, fold_importance_df], axis=0)\n        models.append(model)\n\n        best_iteration = model.best_iteration\n        print(f\"Best number of iterations for fold {fold} is: {best_iteration}\")\n\n        cv_oof_score = metrics.mean_absolute_error(y_validation, y_oof_lgb[validation_index])\n        cv_scores.append(cv_oof_score)\n        print(f\"CV OOF Score for fold {fold} is {cv_oof_score}\")\n\n        del validation_index, X_validation, y_validation\n        gc.collect()\n\n    y_predicted_lgb /= n_folds\n    oof_score = round(metrics.mean_absolute_error(train_Y, y_oof_lgb), 5)\n    avg_cv_scores = round(sum(cv_scores) / len(cv_scores), 5)\n    std_cv_scores = round(np.array(cv_scores).std(), 5)\n    return y_predicted_lgb,models,y_oof_lgb,oof_score,features_importance\ndef train_catbo(train_X,features, target,test_X,params,kf,split_by):\n    y_oof = np.zeros(shape=(len(train_X),))\n    y_predicted = np.zeros(shape=(len(test_X),))\n    train_Y= train_X[target]\n    split_by = train_X[split_by]\n    train_X = train_X[features]\n    test_X = test_X[features]\n    cv_scores = []\n    models = []\n    fold = 0\n    n_folds = kf.get_n_splits()\n    for train_index, validation_index in kf.split(X=train_X, y=split_by):\n        fold += 1\n        print(f\"fold {fold} of {n_folds}\")\n        X_train, X_validation, y_train, y_validation = _get_X_Y_DF_from_CV(\n            train_X, train_Y, train_index, validation_index\n        )\n        train_pool = Pool(data=X_train, label=y_train)\n        eval_pool = Pool(data=X_validation, label=y_validation.values) \n        model = CatBoostRegressor(**params)\n        model.fit(train_pool,plot=True,eval_set=eval_pool)\n        del train_index, X_train, y_train\n        gc.collect()\n        models.append(model)\n        y_oof[validation_index] = model.predict(\n            X_validation )\n\n        y_predicted += model.predict(\n            test_X.values\n        )\n        cv_oof_score = metrics.mean_absolute_error(y_validation, y_oof[validation_index])\n        cv_scores.append(cv_oof_score)\n        print(f\"CV OOF Score for fold {fold} is {cv_oof_score}\")\n\n        del validation_index, X_validation, y_validation\n        gc.collect()\n\n    y_predicted /= n_folds\n    oof_score = round(metrics.mean_absolute_error(train_Y, y_oof), 5)\n    avg_cv_scores = round(sum(cv_scores) / len(cv_scores), 5)\n    std_cv_scores = round(np.array(cv_scores).std(), 5)\n    return y_predicted,models,y_oof,oof_score\ndef train_xgb(X,features,target,test_data,params,kf,split_by,num_iter=1500,es = 100,ve = 0):\n#     features = X.columns\n    y = train[target]\n    split_by = train[split_by]\n    X = X[features].values\n    y_oof = np.zeros(shape=(len(X),))\n    y_predicted = np.zeros(shape=(len(test_data), ))\n    test_data = test_data[features]\n    cv_scores = []\n    models = []\n    for i, (train_index, test_index) in enumerate(kf.split(X, split_by)):\n        print(' xgb kfold: {}  of  {} : '.format(i+1, K_FOLDS ))\n        X_train, X_valid = X[train_index], X[test_index]\n        y_train, y_valid = y[train_index], y[test_index]\n        d_train = xgb.DMatrix(X_train, y_train) \n        d_valid = xgb.DMatrix(X_valid, y_valid) \n        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n        xgb_model = xgb.train(params, d_train, num_iter, watchlist,\n                              early_stopping_rounds=es, \n                            verbose_eval=ve)\n        models.append(xgb_model)\n        y_oof[test_index] = xgb_model.predict(xgb.DMatrix(X_valid), \n                            ntree_limit=xgb_model.best_ntree_limit)\n        y_predicted += xgb_model.predict(xgb.DMatrix(test_data[features].values), \n                            ntree_limit=xgb_model.best_ntree_limit) \n        \n        cv_oof_score = metrics.mean_absolute_error(y_valid, y_oof[test_index])\n        cv_scores.append(cv_oof_score)\n        print(f\"CV OOF Score for fold {i+1} is {cv_oof_score}\")\n\n    y_predicted /= K_FOLDS\n    oof_score = round(metrics.mean_absolute_error(y, y_oof), 5)\n    avg_cv_scores = round(sum(cv_scores) / len(cv_scores), 5)\n    std_cv_scores = round(np.array(cv_scores).std(), 5)\n    return y_predicted,models,y_oof,oof_score \n","metadata":{"execution":{"iopub.status.busy":"2022-09-21T15:05:24.742375Z","iopub.execute_input":"2022-09-21T15:05:24.742845Z","iopub.status.idle":"2022-09-21T15:05:24.783828Z","shell.execute_reply.started":"2022-09-21T15:05:24.742806Z","shell.execute_reply":"2022-09-21T15:05:24.782597Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# kf","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:46:28.497007Z","iopub.execute_input":"2022-09-21T10:46:28.497500Z","iopub.status.idle":"2022-09-21T10:46:28.532517Z","shell.execute_reply.started":"2022-09-21T10:46:28.497457Z","shell.execute_reply":"2022-09-21T10:46:28.531121Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1328/2302870274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'kf' is not defined"],"ename":"NameError","evalue":"name 'kf' is not defined","output_type":"error"}]},{"cell_type":"code","source":"train,test = preprocess(train_ori,test_ori)\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:36:48.614643Z","iopub.execute_input":"2022-09-21T10:36:48.615078Z","iopub.status.idle":"2022-09-21T10:39:13.805044Z","shell.execute_reply.started":"2022-09-21T10:36:48.615040Z","shell.execute_reply":"2022-09-21T10:39:13.803618Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"drop_cols = ['ID','date','Train','pm2_5','site_latitudepm2_5enc7',\n       'site_latitudepm2_5enc8', 'site_latitudepm2_5enc6',\n       'site_latitudepm2_5enc5', 'site_latitudepm2_5enc4',\n       'site_latitudepm2_5enc', 'site_latitudepm2_5enc1',\n       'site_latitudepm2_5enc2', 'site_latitudepm2_5enc3','preds']\nfeatures  = [d for d in test.columns if d  not in drop_cols]","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:39:13.808224Z","iopub.execute_input":"2022-09-21T10:39:13.808663Z","iopub.status.idle":"2022-09-21T10:39:13.816141Z","shell.execute_reply.started":"2022-09-21T10:39:13.808627Z","shell.execute_reply":"2022-09-21T10:39:13.814911Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"SEED = 42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_params = {\n        \"objective\": \"regression\",\n        \"boosting_type\": \"gbdt\",\n        \"learning_rate\": 0.1,\n        \"n_jobs\": 4,\n        \"seed\": SEED,\n        \"max_depth\": 3,\n    #     \"num_leaves\":10,\n        \"force_col_wise\":True,\n    #     'min_data_in_leaf' : 5,\n    #     'feature_fraction':0.5,\n    #     'bagging_fraction':0.8,\n    #     \"max_bin\": 255,\n    #     'reg_lambda': 0.1,  # L1 regularization term on weights\n    #     'reg_lambda': 10,\n        \"metric\": \"MAE\",\n        \"verbose\": -1,\n    }\nparams_cat = {'iterations':5000,\n        'learning_rate':0.025,\n#         'random_strength':0.1,\n        'early_stopping_rounds':30, \n        'depth':3,\n        'loss_function':'RMSE',\n        'eval_metric':'MAE',\n        'verbose' : 100,\n#         'leaf_estimation_method':'Newton'\n             }\nparams_xgb = {\"objective\":\"reg:squarederror\",'learning_rate': 0.1,\n           'max_depth': 3}#, 'subsample': 0.9,\n#           'colsample_bytree': 0.9}\n   \nparams={'params_lgb' : lgb_params,\n      'params_xgb': params_xgb,\n      'params_cat':params_cat}","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:47:40.106477Z","iopub.execute_input":"2022-09-21T10:47:40.106941Z","iopub.status.idle":"2022-09-21T10:47:40.115722Z","shell.execute_reply.started":"2022-09-21T10:47:40.106900Z","shell.execute_reply":"2022-09-21T10:47:40.114422Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"K_FOLDS = 5\nkf = KFold(n_splits = K_FOLDS, shuffle=False,random_state = None)\n\ntrain_catbo(train,features, target,test,params['params_cat'],kf,target)","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:47:41.185427Z","iopub.execute_input":"2022-09-21T10:47:41.185874Z","iopub.status.idle":"2022-09-21T10:48:04.109146Z","shell.execute_reply.started":"2022-09-21T10:47:41.185835Z","shell.execute_reply":"2022-09-21T10:48:04.107522Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"fold 1 of 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c1d9f9ab7b4882b9b8c6a096345354"}},"metadata":{}},{"name":"stdout","text":"0:\tlearn: 21.0895256\ttest: 20.6929575\tbest: 20.6929575 (0)\ttotal: 5.25ms\tremaining: 26.2s\n100:\tlearn: 16.1070486\ttest: 15.3767784\tbest: 15.3767784 (100)\ttotal: 416ms\tremaining: 20.2s\n200:\tlearn: 14.4280201\ttest: 13.7416370\tbest: 13.7416370 (200)\ttotal: 809ms\tremaining: 19.3s\n300:\tlearn: 13.3868554\ttest: 12.8201561\tbest: 12.8201561 (300)\ttotal: 1.21s\tremaining: 18.8s\n400:\tlearn: 12.5585530\ttest: 12.0897086\tbest: 12.0897086 (400)\ttotal: 1.61s\tremaining: 18.5s\n500:\tlearn: 11.9801125\ttest: 11.6084584\tbest: 11.6084584 (500)\ttotal: 2.04s\tremaining: 18.3s\n600:\tlearn: 11.5434585\ttest: 11.2332092\tbest: 11.2332092 (600)\ttotal: 2.45s\tremaining: 17.9s\n700:\tlearn: 11.1597477\ttest: 10.9095532\tbest: 10.9095532 (700)\ttotal: 2.85s\tremaining: 17.5s\n800:\tlearn: 10.7995539\ttest: 10.6143143\tbest: 10.6143143 (800)\ttotal: 3.25s\tremaining: 17.1s\n900:\tlearn: 10.4800340\ttest: 10.3496107\tbest: 10.3496107 (900)\ttotal: 3.64s\tremaining: 16.5s\n1000:\tlearn: 10.2154405\ttest: 10.1419528\tbest: 10.1419528 (1000)\ttotal: 4.05s\tremaining: 16.2s\n1100:\tlearn: 9.9756010\ttest: 9.9493403\tbest: 9.9493403 (1100)\ttotal: 4.44s\tremaining: 15.7s\n1200:\tlearn: 9.7567684\ttest: 9.7821052\tbest: 9.7821052 (1200)\ttotal: 4.82s\tremaining: 15.3s\n1300:\tlearn: 9.5650464\ttest: 9.6337681\tbest: 9.6337681 (1300)\ttotal: 5.24s\tremaining: 14.9s\n1400:\tlearn: 9.3944237\ttest: 9.5166199\tbest: 9.5166199 (1400)\ttotal: 5.62s\tremaining: 14.4s\n1500:\tlearn: 9.2353319\ttest: 9.3997239\tbest: 9.3997239 (1500)\ttotal: 6.04s\tremaining: 14.1s\n1600:\tlearn: 9.0931385\ttest: 9.3058886\tbest: 9.3055852 (1599)\ttotal: 6.43s\tremaining: 13.7s\n1700:\tlearn: 8.9649925\ttest: 9.2079772\tbest: 9.2079772 (1700)\ttotal: 6.81s\tremaining: 13.2s\n1800:\tlearn: 8.8314085\ttest: 9.1115586\tbest: 9.1115586 (1800)\ttotal: 7.25s\tremaining: 12.9s\n1900:\tlearn: 8.7098364\ttest: 9.0316201\tbest: 9.0316201 (1900)\ttotal: 7.63s\tremaining: 12.4s\n2000:\tlearn: 8.6018373\ttest: 8.9655139\tbest: 8.9655139 (2000)\ttotal: 8.07s\tremaining: 12.1s\n2100:\tlearn: 8.4951908\ttest: 8.8979539\tbest: 8.8979539 (2100)\ttotal: 8.45s\tremaining: 11.7s\n2200:\tlearn: 8.3819155\ttest: 8.8160960\tbest: 8.8160960 (2200)\ttotal: 8.84s\tremaining: 11.2s\n2300:\tlearn: 8.2722539\ttest: 8.7457938\tbest: 8.7457938 (2300)\ttotal: 9.3s\tremaining: 10.9s\n2400:\tlearn: 8.1831693\ttest: 8.6899920\tbest: 8.6899920 (2400)\ttotal: 9.69s\tremaining: 10.5s\n2500:\tlearn: 8.0946864\ttest: 8.6379311\tbest: 8.6379311 (2500)\ttotal: 10.2s\tremaining: 10.2s\n2600:\tlearn: 8.0062219\ttest: 8.5791799\tbest: 8.5791799 (2600)\ttotal: 10.6s\tremaining: 9.75s\n2700:\tlearn: 7.9186760\ttest: 8.5283925\tbest: 8.5283925 (2700)\ttotal: 11.2s\tremaining: 9.53s\n2800:\tlearn: 7.8362842\ttest: 8.4763078\tbest: 8.4763078 (2800)\ttotal: 11.7s\tremaining: 9.17s\n2900:\tlearn: 7.7593578\ttest: 8.4345114\tbest: 8.4345114 (2900)\ttotal: 12.1s\tremaining: 8.75s\n3000:\tlearn: 7.6838327\ttest: 8.3959490\tbest: 8.3959490 (3000)\ttotal: 12.6s\tremaining: 8.38s\n3100:\tlearn: 7.6023004\ttest: 8.3458656\tbest: 8.3458656 (3100)\ttotal: 13s\tremaining: 7.94s\n3200:\tlearn: 7.5285130\ttest: 8.3041973\tbest: 8.3041973 (3200)\ttotal: 13.4s\tremaining: 7.55s\n3300:\tlearn: 7.4609757\ttest: 8.2746998\tbest: 8.2746998 (3300)\ttotal: 13.8s\tremaining: 7.12s\n3400:\tlearn: 7.3945951\ttest: 8.2391682\tbest: 8.2389148 (3398)\ttotal: 14.2s\tremaining: 6.68s\n3500:\tlearn: 7.3288108\ttest: 8.2051483\tbest: 8.2048851 (3498)\ttotal: 14.7s\tremaining: 6.29s\n3600:\tlearn: 7.2670746\ttest: 8.1661812\tbest: 8.1661802 (3598)\ttotal: 15.1s\tremaining: 5.86s\n3700:\tlearn: 7.2093851\ttest: 8.1401512\tbest: 8.1401512 (3700)\ttotal: 15.6s\tremaining: 5.46s\n3800:\tlearn: 7.1571464\ttest: 8.1228412\tbest: 8.1228412 (3800)\ttotal: 16s\tremaining: 5.04s\n3900:\tlearn: 7.1029736\ttest: 8.1009518\tbest: 8.1005496 (3894)\ttotal: 16.7s\tremaining: 4.71s\n4000:\tlearn: 7.0502081\ttest: 8.0742594\tbest: 8.0742161 (3999)\ttotal: 17.1s\tremaining: 4.28s\n4100:\tlearn: 7.0006323\ttest: 8.0555808\tbest: 8.0555808 (4100)\ttotal: 17.5s\tremaining: 3.84s\n4200:\tlearn: 6.9526686\ttest: 8.0375641\tbest: 8.0375641 (4200)\ttotal: 18s\tremaining: 3.43s\n4300:\tlearn: 6.9090065\ttest: 8.0216406\tbest: 8.0214534 (4298)\ttotal: 18.4s\tremaining: 2.99s\n4400:\tlearn: 6.8620190\ttest: 8.0000098\tbest: 7.9998064 (4399)\ttotal: 18.9s\tremaining: 2.57s\n4500:\tlearn: 6.8185154\ttest: 7.9802062\tbest: 7.9802062 (4500)\ttotal: 19.3s\tremaining: 2.14s\n4600:\tlearn: 6.7777633\ttest: 7.9642774\tbest: 7.9640786 (4598)\ttotal: 19.7s\tremaining: 1.71s\n4700:\tlearn: 6.7343247\ttest: 7.9509716\tbest: 7.9508159 (4697)\ttotal: 20.2s\tremaining: 1.28s\n4800:\tlearn: 6.6861553\ttest: 7.9330382\tbest: 7.9330382 (4800)\ttotal: 20.6s\tremaining: 854ms\n4900:\tlearn: 6.6481099\ttest: 7.9182303\tbest: 7.9182303 (4900)\ttotal: 21.2s\tremaining: 427ms\n4999:\tlearn: 6.6064651\ttest: 7.9053366\tbest: 7.9051804 (4998)\ttotal: 21.6s\tremaining: 0us\n\nbestTest = 7.905180398\nbestIteration = 4998\n\nShrink model to first 4999 iterations.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNan\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Cannot convert 'b'ID_UOH62J0XHX'' to float","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1328/2635609911.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_FOLDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_catbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params_cat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_1328/1863278163.py\u001b[0m in \u001b[0;36mtrain_catbo\u001b[0;34m(train_X, features, target, test_X, params, kf, split_by)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         y_predicted += model.predict(\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         )\n\u001b[1;32m    144\u001b[0m         \u001b[0mcv_oof_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_oof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5634\u001b[0m             \u001b[0mprediction_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5635\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RawFormulaVal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2458\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_is_single_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_predict_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_method_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2459\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m                 \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_embedding_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthread_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m             )\n\u001b[1;32m   2446\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_single_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                 self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0;32m--> 791\u001b[0;31m                            group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0mfeature_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_transform_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0;32m-> 1412\u001b[0;31m                         group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_objects_order_layout_pool\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_data\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_data_from_generic_matrix\u001b[0;34m()\u001b[0m\n","\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n","\u001b[0;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"ID_UOH62J0XHX\": Cannot convert 'b'ID_UOH62J0XHX'' to float"],"ename":"CatBoostError","evalue":"Bad value for num_feature[non_default_doc_idx=0,feature_idx=0]=\"ID_UOH62J0XHX\": Cannot convert 'b'ID_UOH62J0XHX'' to float","output_type":"error"}]},{"cell_type":"code","source":"# train['pm2_5'].quantile(0.999)\n\ndef train_all(bl,features,SEED,k_folds):\n    seedEverything(SEED)\n    K_FOLDS = 5\n    kf = KFold(n_splits = K_FOLDS, shuffle=False,random_state = None)\n    y_predicted_keras,models_keras,y_oof_keras,oof_score_keras = train_keras(bl,train,features,target,test,kf,split_by)\n    EARLY_STOPPING_ROUNDS = 30\n    N_ESTIMATORS = 5000\n    K_FOLDS = 2\n    kf = KFold(n_splits = K_FOLDS, shuffle=False,random_state = None)\n    y_predicted_lgb,models_lgb,y_oof_lgb,oof_score_lgb,features_importance_lgb = train_lgb(train,features,\n                                                                                       target,test[features],\n                                                                                       params['params_lgb'],kf,'pm2_5')\n#     K_\n    kf = KFold(n_splits = K_FOLDS, shuffle=True,random_state = SEED)\n\n    y_predicted_cat,models_cat,y_oof_cat,oof_score_cat =train_catbo(train,,features,target,test,params['params_cat'],\n                                                                    kf, 'pm2_5')\n    \n    y_predicted_xgb,models_xgb,y_oof_xgb,oof_score_xgb=train_xgb(train,features,target,test,\n                                                             params['params_xgb'],kf,'pm2_5',num_iter=1000,es = 30,ve = 100)\n    train['preds_lgb'] = y_oof_lgb                                                                                 \n    train['preds_xgb'] = y_oof_xgb\n    train['preds_cat'] = y_oof_cat                                                                                 \n    train['preds_keras'] = y_oof_keras\n    test['preds_lgb'] = y_predicted_lgb                                                                                 \n    test['preds_xgb'] = y_predicted_xgb\n    test['preds_cat'] = y_predicted_cat                                                                                 \n    test['preds_keras'] = y_predicted_keras\n    \n    \n                                                                                           \n                                                                                           ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import optimizers\ndef baseline_model(inp):\n    # Create model here\n    model = Sequential()\n    model.add(Dense(100, input_dim = inp, activation = 'tanh')) # Rectified Linear Unit Activation Function\n    model.add(Dropout(0.3))\n\n#     model.add(Dense(32, activation = 'tanh'))\n    model.add(Dense(8, activation = 'linear'))\n    \n    model.add(Dense(1, activation = 'linear')) # Softmax for multi-class classification\n    # Compile model here\n    model.compile(loss = 'mse', optimizer = tf.keras.optimizers.RMSprop(lr=0.025),\n                  metrics = ['mse'],)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \nSEED = 42\nseedEverything(SEED)\nK_FOLDS = 2\nkf = KFold(n_splits = K_FOLDS, shuffle=False,random_state = None)\nsplit_by = 'pm2_5'\ny_predicted_keras,models_keras,y_oof_keras,oof_score_keras = train_keras(bl,train,features,train['pm2_5'],test,kf,split_by)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_blend,_,w = models_to_blend()\n# w","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_to_sub(test,preds_blend,'blend31')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EARLY_STOPPING_ROUNDS = 30\nN_ESTIMATORS = 5000\nK_FOLDS = 2\nlgb_params = {\n    \"objective\": \"regression\",\n    \"boosting_type\": \"gbdt\",\n    \"learning_rate\": 0.1,\n    \"n_jobs\": 4,\n    \"seed\": SEED,\n    \"max_depth\": 13,\n#     \"num_leaves\":10,\n    \"force_col_wise\":True,\n#     'min_data_in_leaf' : 5,\n#     'feature_fraction':0.5,\n#     'bagging_fraction':0.8,\n#     \"max_bin\": 255,\n#     'reg_lambda': 0.1,  # L1 regularization term on weights\n#     'reg_lambda': 10,\n    \"metric\": \"MAE\",\n    \"verbose\": -1,\n}\nkf = KFold(n_splits = K_FOLDS, shuffle=False,random_state = None)\ny_predicted_lgb,models_lgb,y_oof_lgb,oof_score_lgb,features_importance_lgb = train_lgb(train,features,\n                                                                                       target,test,\n                                                                                       lgb_params,kf,'pm2_5')","metadata":{"execution":{"iopub.status.busy":"2022-09-21T14:57:02.258752Z","iopub.execute_input":"2022-09-21T14:57:02.259223Z","iopub.status.idle":"2022-09-21T14:57:07.995933Z","shell.execute_reply.started":"2022-09-21T14:57:02.259181Z","shell.execute_reply":"2022-09-21T14:57:07.994821Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 2\nBest number of iterations for fold 1 is: 361\nCV OOF Score for fold 1 is 7.766087489477163\nfold 2 of 2\nBest number of iterations for fold 2 is: 422\nCV OOF Score for fold 2 is 8.511737588797063\n","output_type":"stream"}]},{"cell_type":"code","source":"target","metadata":{"execution":{"iopub.status.busy":"2022-09-21T14:56:38.578966Z","iopub.execute_input":"2022-09-21T14:56:38.579519Z","iopub.status.idle":"2022-09-21T14:56:38.588022Z","shell.execute_reply.started":"2022-09-21T14:56:38.579459Z","shell.execute_reply":"2022-09-21T14:56:38.586953Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'pm2_5'"},"metadata":{}}]},{"cell_type":"code","source":"from catboost import Pool, CatBoostRegressor\nparams_cat = {'iterations':5000,\n        'learning_rate':0.025,\n#         'random_strength':0.1,\n        'early_stopping_rounds':30, \n        'depth':3,\n        'loss_function':'RMSE',\n        'eval_metric':'MAE',\n        'verbose' : 100,\n#         'leaf_estimation_method':'Newton'\n             }\nkf = KFold(n_splits = K_FOLDS, shuffle=True,random_state = SEED)\n\ny_predicted_cat,models_cat,y_oof_cat,oof_score_cat =train_catbo(train[features],\n                                                                        train['pm2_5'],test[features],params_cat,\n                                                                kf, 'pm2_5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_xgb = {\"objective\":\"reg:squarederror\",'learning_rate': 0.1,\n           'max_depth': 3}#, 'subsample': 0.9,\n#           'colsample_bytree': 0.9}\n\ny_predicted_xgb,models_xgb,y_oof_xgb,oof_score_xgb=train_xgb(train[features],\n                                                                        train['pm2_5'],test[features],\n                                                             params_xgb,kf,'pm2_5',num_iter=1000,es = 30,ve = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def models_to_blend():\n    w_cat = cust_score(y_oof_cat).sort_values(by = 'err', ascending = False)['err'].iloc[:4].mean()\n    w_lgb = cust_score(y_oof_lgb).sort_values(by = 'err', ascending = False)['err'].iloc[:4].mean()\n    w_xgb = cust_score(y_oof_xgb).sort_values(by = 'err', ascending = False)['err'].iloc[:4].mean()\n    w_keras = cust_score(y_oof_keras).sort_values(by = 'err', ascending = False)['err'].iloc[:4].mean()\n    weigths = [1/w_cat,1/w_lgb,1/w_xgb,1/w_keras]\n    blend_preds = np.average(np.vstack([y_predicted_cat,y_predicted_xgb,y_predicted_cat,y_predicted_keras.squeeze()]),axis = 0,weights=weigths)\n    blend_preds_train = np.average(np.vstack([y_oof_cat,y_oof_xgb,y_oof_cat,y_oof_keras.squeeze()]),axis = 0,weights=weigths)\n    w_blend = cust_score(blend_preds_train).sort_values(by = 'err', ascending = False)['err'].iloc[:4].mean()\n    weights = [w_cat,w_lgb,w_xgb,w_keras,w_blend]\n    print(\"mae of cat : {}.-------- worst {}\".format(metrics.mean_absolute_error(train['pm2_5'],y_oof_cat).round(3),w_cat.round(3)))\n    print(\"mae of lgb : {}..-------- worst {}\".format(metrics.mean_absolute_error(train['pm2_5'],y_oof_lgb).round(3),w_lgb.round(3)))\n    print(\"mae of xgb : {}..-------- worst {}\".format(metrics.mean_absolute_error(train['pm2_5'],y_oof_xgb).round(3),w_xgb.round(3)))\n    print(\"mae of keras : {}..-------- worst {}\".format(metrics.mean_absolute_error(train['pm2_5'],y_oof_keras).round(3),w_keras.round(3)))\n    print(\"mae of blend : {}..-------- worst {}\".format(metrics.mean_absolute_error(train['pm2_5'],blend_preds_train).round(3),w_blend.round(3)))\n          \n    return blend_preds,blend_preds_train,weights\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_,w = models_to_blend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.vstack([y_predicted_lgb,y_predicted_xgb]).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_predicted_xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.average(np.vstack([y_predicted_lgb,y_predicted_xgb]),axis = 0,weights=[10,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_to_sub(test,y_predicted_lgb+,'lgb_scaled3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nSEED = 42\nK_FOLDS = 4\ntarget = 'pm2_5'\ndef objective(trial):\n    params = {\n                #'iterations' : 10000, replaced by early stopping\n                'eval_metric': 'RMSE',\n                'verbose' : 500,\n                'use_best_model': True,\n                'random_seed' : SEED,\n                'learning_rate' :trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n                \"depth\": trial.suggest_int(\"depth\", 1, 9),\n                'l2_leaf_reg' :trial.suggest_loguniform('l2_leaf_reg', 1e-8, 10),\n                'random_strength' : trial.suggest_loguniform('random_strength', 0.1, 10),\n                'grow_policy':trial.suggest_categorical ('grow_policy', ['Lossguide','SymmetricTree']),\n                'max_bin': trial.suggest_int(\"max_bin\", 20, 500),\n                'min_data_in_leaf':trial.suggest_int('min_data_in_leaf', 1, 100),\n                \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\"])\n            }\n    \n    if params['grow_policy'] == 'Lossguide':\n        params['max_leaves']:trial.suggest_int('max_leaves', 1, 20)\n    if params[\"bootstrap_type\"] == \"Bayesian\":\n        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n        \n    \n    kf = KFold(n_splits = K_FOLDS, shuffle=True,random_state = SEED)\n\n\n    y_predicted_cat,models_cat,y_oof_cat,oof_score_cat =train_catbo(train,features,target,test,params,\n                                                                    kf=kf, split_by = 'pm2_5')\n    \n        \n    return cust_score(y_oof_cat).sort_values(by = 'err', ascending = False)['err'].iloc[:4].mean()\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features\n# study.best_params\n# {'learning_rate': 0.09336356367527626,\n#  'depth': 8,\n#  'l2_leaf_reg': 0.00033354798569319656,\n#  'random_strength': 10.395143072706773,\n#  'grow_policy': 'SymmetricTree',\n#  'max_bin': 111,\n#  'min_data_in_leaf': 94,\n#  'bootstrap_type': 'Bernoulli',\n#  'subsample': 0.4351151265075187}### params with MAE, metric\ncat_b_params = {'learning_rate': 0.07574755563809993, 'depth': 6, 'l2_leaf_reg': 0.39323612155779863, 'random_strength': 0.20259568870497338, 'grow_policy': 'Lossguide', 'max_bin': 67, 'min_data_in_leaf': 10, 'bootstrap_type': 'Bernoulli', 'subsample': 0.9244602042319705}","metadata":{"execution":{"iopub.status.busy":"2022-09-21T11:40:37.870857Z","iopub.execute_input":"2022-09-21T11:40:37.871339Z","iopub.status.idle":"2022-09-21T11:40:37.880648Z","shell.execute_reply.started":"2022-09-21T11:40:37.871287Z","shell.execute_reply":"2022-09-21T11:40:37.879445Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.09336356367527626,\n 'depth': 8,\n 'l2_leaf_reg': 0.00033354798569319656,\n 'random_strength': 10.395143072706773,\n 'grow_policy': 'SymmetricTree',\n 'max_bin': 111,\n 'min_data_in_leaf': 94,\n 'bootstrap_type': 'Bernoulli',\n 'subsample': 0.4351151265075187}"},"metadata":{}}]},{"cell_type":"code","source":"# study.direction\nK_FOLDS = 5\n# kf = KFold(n_splits=N_split)\nSEED = 43\nimport optuna\n\ndef objective(trial):\n   \n    params = { 'objective': 'reg:squarederror',\n              'eval_metric': 'mae',\n#             'tree_method': 'hist',\n            'grow_policy' : trial.suggest_categorical ('grow_policy', ['lossguide','depthwise']),\n            'learning_rate':trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n            'max_depth': trial.suggest_int('max_depth', 3, 20),# a virer avec'depthwise'\n#             'reg_alpha': trial.suggest_loguniform('reg_alpha', 1, 10),\n#             'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-15, 10.0),\n            'max_delta_step':trial.suggest_int('max_delta_step', 1, 10),\n            'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n            'colsample_bytree':trial.suggest_loguniform('colsample_bytree', 0.4, 1.0),\n            'subsample': trial.suggest_loguniform('subsample', 0.4, 1.0),\n            'seed':1\n                }\n    if params['grow_policy'] == 'lossguide':\n        params['max_leaves'] = trial.suggest_int('max_leaves', 1, 100)   \n        \n    kf = KFold(n_splits = K_FOLDS, shuffle=True,random_state = SEED)\n\n    y_predicted_xgb,models_xgb,y_oof_xgb,oof_score_xgb=train_xgb(train,features,target,test,\n                                                             params,kf,'pm2_5',num_iter=1000,es = 30,ve = 500)\n        \n    return cust_score(y_oof_xgb).sort_values(by = 'err', ascending = False)['err'].iloc[:4].mean()\n\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4 folds\n# xgb_params = {'grow_policy': 'depthwise', 'learning_rate': 0.10769618165955801, 'max_depth': 14, 'max_delta_step': 2, 'min_child_weight': 132, 'colsample_bytree': 0.6353119293029151, 'subsample': 0.6254457606715289,'tree_method': 'hist'}\n# xgb_params = {'grow_policy': 'lossguide', 'learning_rate': 0.03982304720613181, 'max_depth': 12, 'max_delta_step': 10, 'min_child_weight': 133, 'colsample_bytree': 0.8709673399493595, 'subsample': 0.7129355859703879, 'max_leaves': 34}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# N_split = 2\n# kf = KFold(n_splits=N_split)\n# EARLY_STOPPING_ROUNDS = 30\nN_ESTIMATORS = 5000\nK_FOLDS = 3\nimport optuna\n\ndef objective(trial):\n    params = {\n            'objective': 'regression',\n            'metric': 'mae',\n            'n_estimators':5000,\n            'verbose':-1,\n            'learning_rate': trial.suggest_float(\"learning_rate\", 0.04,0.4),\n            'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n            'colsample_bytree':trial.suggest_float(\"colsample\", 0.1,0.3),\n            'subsample': trial.suggest_float(\"subsample\", 0.1,0.3),\n            'max_depth': trial.suggest_int('max_depth', 3, 10),\n            'min_child_samples': trial.suggest_int('min_child_samples', 3, 2000),\n            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n            'cat_smooth':trial.suggest_int('cat_smooth', 1, 100)\n            }\n    \n    kf = KFold(n_splits = K_FOLDS, shuffle=False,random_state = None)\n    y_predicted_lgb,models_lgb,y_oof_lgb,oof_score_lgb,features_importance_lgb = train_lgb(train,features,\n                                                                                  target,test,params = params,kf = kf,split_by = 'pm2_5') \n    return cust_score(y_oof_lgb).sort_values(by = 'err', ascending = False)['err'].iloc[:4].mean()\n\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=20)","metadata":{"execution":{"iopub.status.busy":"2022-09-21T15:15:11.222160Z","iopub.execute_input":"2022-09-21T15:15:11.222630Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:15:11,231]\u001b[0m A new study created in memory with name: no-name-efd03da3-7424-4b7c-be04-8354faea1eab\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 9.158008505782536\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 9.304642945031127\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 9.412341891165092\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:15:23,402]\u001b[0m Trial 0 finished with value: 15.972997253821 and parameters: {'learning_rate': 0.3939723623264472, 'num_leaves': 50, 'colsample': 0.10607282907856037, 'subsample': 0.23288542443763074, 'max_depth': 3, 'min_child_samples': 764, 'reg_alpha': 0.0028214770453633647, 'reg_lambda': 3.5201438870240126e-06, 'cat_smooth': 39}. Best is trial 0 with value: 15.972997253821.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 9.767121886379101\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 10.102051245546077\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 10.188515104275174\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:15:35,999]\u001b[0m Trial 1 finished with value: 17.120524641990993 and parameters: {'learning_rate': 0.2843324044679964, 'num_leaves': 22, 'colsample': 0.2114746501308415, 'subsample': 0.24250409880089902, 'max_depth': 3, 'min_child_samples': 1655, 'reg_alpha': 0.040621176561131116, 'reg_lambda': 3.8109214519332717e-06, 'cat_smooth': 57}. Best is trial 0 with value: 15.972997253821.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 8.95193352099599\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 9.050875030528001\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 9.118524698854\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:15:52,006]\u001b[0m Trial 2 finished with value: 16.026945072902038 and parameters: {'learning_rate': 0.13336174294158137, 'num_leaves': 98, 'colsample': 0.2725255201293416, 'subsample': 0.2866160484845921, 'max_depth': 7, 'min_child_samples': 1041, 'reg_alpha': 0.00023301383747751443, 'reg_lambda': 0.000646894805919383, 'cat_smooth': 71}. Best is trial 0 with value: 15.972997253821.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 9.453594967084777\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 9.65860904360298\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 9.848079462117878\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:16:05,084]\u001b[0m Trial 3 finished with value: 16.59387704140955 and parameters: {'learning_rate': 0.26056978505495737, 'num_leaves': 99, 'colsample': 0.20488742932870885, 'subsample': 0.10997631701571756, 'max_depth': 3, 'min_child_samples': 1500, 'reg_alpha': 0.06365425204558756, 'reg_lambda': 4.5790936124732975e-06, 'cat_smooth': 15}. Best is trial 0 with value: 15.972997253821.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 8.819932486724326\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 9.064915877649826\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 9.086311179159184\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:16:26,067]\u001b[0m Trial 4 finished with value: 15.530259555018294 and parameters: {'learning_rate': 0.3420405673839803, 'num_leaves': 48, 'colsample': 0.25675323921272286, 'subsample': 0.23757138533539016, 'max_depth': 9, 'min_child_samples': 603, 'reg_alpha': 9.314357163802371e-06, 'reg_lambda': 5.0929820407791066e-05, 'cat_smooth': 53}. Best is trial 4 with value: 15.530259555018294.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 10.46015017718621\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 11.34379820844191\nfold 3 of 3\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:16:37,942]\u001b[0m Trial 5 finished with value: 18.05540318696104 and parameters: {'learning_rate': 0.27834702521181004, 'num_leaves': 61, 'colsample': 0.20980220461244825, 'subsample': 0.2539354629139303, 'max_depth': 8, 'min_child_samples': 1948, 'reg_alpha': 0.001934397495890443, 'reg_lambda': 0.010695188464869056, 'cat_smooth': 10}. Best is trial 4 with value: 15.530259555018294.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Best number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 11.144371386120948\nShape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 9.051742225725336\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 9.132408460448092\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 9.326347242085726\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:16:52,438]\u001b[0m Trial 6 finished with value: 16.03500843532516 and parameters: {'learning_rate': 0.29326655690415054, 'num_leaves': 14, 'colsample': 0.21422133654815706, 'subsample': 0.17010932097456427, 'max_depth': 8, 'min_child_samples': 1069, 'reg_alpha': 0.05629859738822514, 'reg_lambda': 2.913014262932653e-08, 'cat_smooth': 12}. Best is trial 4 with value: 15.530259555018294.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 9.309390403354564\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 9.575734214177576\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 9.575916598127945\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:17:06,670]\u001b[0m Trial 7 finished with value: 16.410413595795493 and parameters: {'learning_rate': 0.3277246942095374, 'num_leaves': 42, 'colsample': 0.2963887387119277, 'subsample': 0.1649293708098057, 'max_depth': 8, 'min_child_samples': 1486, 'reg_alpha': 2.1466717184079975e-08, 'reg_lambda': 1.7521880763461323e-08, 'cat_smooth': 49}. Best is trial 4 with value: 15.530259555018294.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 9.833553738675661\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 10.18393504169768\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 10.274962421066267\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:17:17,590]\u001b[0m Trial 8 finished with value: 17.244288478100803 and parameters: {'learning_rate': 0.29555338633898665, 'num_leaves': 80, 'colsample': 0.15884509285008835, 'subsample': 0.12240776086447124, 'max_depth': 5, 'min_child_samples': 1653, 'reg_alpha': 2.6131513588237207, 'reg_lambda': 8.595564530069057e-06, 'cat_smooth': 15}. Best is trial 4 with value: 15.530259555018294.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 9.012711132414264\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 9.088526436082235\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 9.210290445927669\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:17:32,965]\u001b[0m Trial 9 finished with value: 16.089205092539334 and parameters: {'learning_rate': 0.15995905065811697, 'num_leaves': 47, 'colsample': 0.2320994241948466, 'subsample': 0.12743750258313752, 'max_depth': 8, 'min_child_samples': 1038, 'reg_alpha': 4.360227648447543, 'reg_lambda': 0.12375289145415123, 'cat_smooth': 22}. Best is trial 4 with value: 15.530259555018294.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 7.304105010287369\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 7.5925339260537585\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 7.627437104950614\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:18:14,625]\u001b[0m Trial 10 finished with value: 14.573589497058597 and parameters: {'learning_rate': 0.0635938724410916, 'num_leaves': 31, 'colsample': 0.2556455958822984, 'subsample': 0.29787449702328844, 'max_depth': 10, 'min_child_samples': 16, 'reg_alpha': 1.4868037975722531e-06, 'reg_lambda': 0.0005428092641970505, 'cat_smooth': 95}. Best is trial 10 with value: 14.573589497058597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 7.696649928374241\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 7.895808625136486\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 8.156181728051491\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:18:54,458]\u001b[0m Trial 11 finished with value: 14.88058585093447 and parameters: {'learning_rate': 0.05395115091898299, 'num_leaves': 30, 'colsample': 0.2526580246200434, 'subsample': 0.2979563828022361, 'max_depth': 10, 'min_child_samples': 83, 'reg_alpha': 1.5348574000128484e-06, 'reg_lambda': 0.00045158417571721367, 'cat_smooth': 97}. Best is trial 10 with value: 14.573589497058597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 7.856933598202623\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 8.037523493886896\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 8.181183394515024\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:19:30,834]\u001b[0m Trial 12 finished with value: 15.075609741340777 and parameters: {'learning_rate': 0.045380002475916115, 'num_leaves': 29, 'colsample': 0.2536434281215585, 'subsample': 0.2965316268767679, 'max_depth': 10, 'min_child_samples': 159, 'reg_alpha': 3.972800408974477e-07, 'reg_lambda': 0.0012141112185465686, 'cat_smooth': 100}. Best is trial 10 with value: 14.573589497058597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 7.6077633862177505\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 7.879519963591368\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 8.105696629308776\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:20:15,038]\u001b[0m Trial 13 finished with value: 14.7761939295781 and parameters: {'learning_rate': 0.05254142159281418, 'num_leaves': 34, 'colsample': 0.2943553030646571, 'subsample': 0.27256410305259277, 'max_depth': 10, 'min_child_samples': 77, 'reg_alpha': 4.63616411720828e-06, 'reg_lambda': 0.0179532794321232, 'cat_smooth': 98}. Best is trial 10 with value: 14.573589497058597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 8.321591217639735\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 8.451166817967477\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 8.59146847455155\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:20:44,328]\u001b[0m Trial 14 finished with value: 15.595327883453734 and parameters: {'learning_rate': 0.11010913818085803, 'num_leaves': 62, 'colsample': 0.295441165093243, 'subsample': 0.26525296791364483, 'max_depth': 10, 'min_child_samples': 370, 'reg_alpha': 8.757835168267108e-06, 'reg_lambda': 0.5140109899302303, 'cat_smooth': 79}. Best is trial 10 with value: 14.573589497058597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\nBest number of iterations for fold 1 is: 0\nCV OOF Score for fold 1 is 8.661202520083748\nfold 2 of 3\nBest number of iterations for fold 2 is: 0\nCV OOF Score for fold 2 is 8.845501984215995\nfold 3 of 3\nBest number of iterations for fold 3 is: 0\nCV OOF Score for fold 3 is 8.87614110502353\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2022-09-21 15:21:02,173]\u001b[0m Trial 15 finished with value: 15.525848036802953 and parameters: {'learning_rate': 0.19232277338990345, 'num_leaves': 10, 'colsample': 0.17281721447809675, 'subsample': 0.20784182899265688, 'max_depth': 5, 'min_child_samples': 315, 'reg_alpha': 1.3750029851930742e-08, 'reg_lambda': 0.03229045960477008, 'cat_smooth': 85}. Best is trial 10 with value: 14.573589497058597.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Shape of train_X : (9923, 69), test_X: (4254, 69), train_Y: (9923,)\nfold 1 of 3\n","output_type":"stream"}]},{"cell_type":"raw","source":"","metadata":{}}]}