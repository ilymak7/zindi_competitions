{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:02.114501Z",
     "iopub.status.busy": "2022-08-24T19:53:02.114107Z",
     "iopub.status.idle": "2022-08-24T19:53:03.541270Z",
     "shell.execute_reply": "2022-08-24T19:53:03.540298Z",
     "shell.execute_reply.started": "2022-08-24T19:53:02.114416Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgbm# .loc[df_test.sku_name == new_id_test[0]]\n",
    "from sklearn.preprocessing import LabelEncoder as LE\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:10].index\n",
    "    best_features = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:50]\n",
    "    best_features.reset_index(inplace=True)\n",
    "    print(best_features.dtypes)\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=best_features)\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:03.543618Z",
     "iopub.status.busy": "2022-08-24T19:53:03.543069Z",
     "iopub.status.idle": "2022-08-24T19:53:03.767103Z",
     "shell.execute_reply": "2022-08-24T19:53:03.766447Z",
     "shell.execute_reply.started": "2022-08-24T19:53:03.543577Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "ss = pd.read_csv('SampleSubmission.csv')\n",
    "dict_s = pd.read_csv('DataDictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:04.657482Z",
     "iopub.status.busy": "2022-08-24T19:53:04.657116Z",
     "iopub.status.idle": "2022-08-24T19:53:04.662657Z",
     "shell.execute_reply": "2022-08-24T19:53:04.661749Z",
     "shell.execute_reply.started": "2022-08-24T19:53:04.657456Z"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "import calendar\n",
    "def count_weekends(m,y):\n",
    "    day_to_count = calendar.SUNDAY\n",
    "\n",
    "    matrix = calendar.monthcalendar(y,m)\n",
    "\n",
    "    num_days = sum(1 for x in matrix if x[day_to_count] != 0)\n",
    "    return num_days%4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:06.545759Z",
     "iopub.status.busy": "2022-08-24T19:53:06.545103Z",
     "iopub.status.idle": "2022-08-24T19:53:06.549074Z",
     "shell.execute_reply": "2022-08-24T19:53:06.548229Z",
     "shell.execute_reply.started": "2022-08-24T19:53:06.545729Z"
    }
   },
   "outputs": [],
   "source": [
    "# kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "# kf.split(y, groups=X['date'].values)\n",
    "# train = train[train.sku_name.isin(test.sku_name.unique())].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:07.125335Z",
     "iopub.status.busy": "2022-08-24T19:53:07.124971Z",
     "iopub.status.idle": "2022-08-24T19:53:07.186324Z",
     "shell.execute_reply": "2022-08-24T19:53:07.185686Z",
     "shell.execute_reply.started": "2022-08-24T19:53:07.125308Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Weeks'] = test.apply(lambda x: count_weekends(x.month, x.year), axis=1)\n",
    "train['date'] = (train['year']-2016)*12 + (train['month']-1) \n",
    "test['date'] = (test['year']-2016)*12 + (test['month']-1) # train\n",
    "# train['is_test'] = 0\n",
    "ma = train.groupby('sku_name').apply(lambda x : x['price'].values[-1])\n",
    "test['price'] = test['sku_name'].map(ma)\n",
    "test['price'] = test['price'].fillna(135).astype('int')\n",
    "train['price'] = train['price'].fillna(135).astype('int')\n",
    "# test['is_test'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dat = pd.concat([train,test],axis = 0).reset_index(drop = True)\n",
    "# train.price.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dat['price'] = all_dat.groupby('sku_name')['price'].fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:08.837640Z",
     "iopub.status.busy": "2022-08-24T19:53:08.837113Z",
     "iopub.status.idle": "2022-08-24T19:53:08.841523Z",
     "shell.execute_reply": "2022-08-24T19:53:08.840809Z",
     "shell.execute_reply.started": "2022-08-24T19:53:08.837613Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "target = 'sellin'\n",
    "prediction_columns = test.columns.tolist()\n",
    "encoding_columns = [t for t in train.columns if t not in prediction_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:10.143907Z",
     "iopub.status.busy": "2022-08-24T19:53:10.143323Z",
     "iopub.status.idle": "2022-08-24T19:53:10.148527Z",
     "shell.execute_reply": "2022-08-24T19:53:10.147623Z",
     "shell.execute_reply.started": "2022-08-24T19:53:10.143878Z"
    }
   },
   "outputs": [],
   "source": [
    "sellin = ['sellin','sellin_channel_1','sellin_channel_2','sellin_channel_3','sellin_channel_4',\n",
    "         'sellin_channel_5','sellin_channel_6','sellin_channel_7','sellin_channel_8']\n",
    "sellout = ['sellout','sellout_channel_1','sellout_channel_2','sellout_channel_3','sellout_channel_4',\n",
    "         'sellout_channel_5','sellout_channel_6','sellout_channel_7','sellout_channel_8','sellout_channel_9',\n",
    "           'sellout_channel_10']\n",
    "onhand= ['onhand_inventory','onhand_inventory_channel_1','onhand_inventory_channel_2','onhand_inventory_channel_3','onhand_inventory_channel_4',\n",
    "         'onhand_inventory_channel_5','onhand_inventory_channel_6','onhand_inventory_channel_7','onhand_inventory_channel_8','onhand_inventory_channel_9',\n",
    "           'onhand_inventory_channel_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:11.557719Z",
     "iopub.status.busy": "2022-08-24T19:53:11.557332Z",
     "iopub.status.idle": "2022-08-24T19:53:11.610905Z",
     "shell.execute_reply": "2022-08-24T19:53:11.610027Z",
     "shell.execute_reply.started": "2022-08-24T19:53:11.557691Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "df_train[sellin+sellout+onhand+['leftover_inventory','starting_inventory']] = df_train[sellin+sellout+onhand+['leftover_inventory','starting_inventory']]/1013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:12.341799Z",
     "iopub.status.busy": "2022-08-24T19:53:12.341458Z",
     "iopub.status.idle": "2022-08-24T19:53:17.229546Z",
     "shell.execute_reply": "2022-08-24T19:53:17.228707Z",
     "shell.execute_reply.started": "2022-08-24T19:53:12.341772Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.columns\n",
    "pcl = df_train.groupby(['sku_name','year','month'])['product_lifecycle_stage'].apply(lambda x : x.unique()[0]).reset_index()\n",
    "pcl_test = df_train.groupby('sku_name')['product_lifecycle_stage'].apply(lambda x:x.values[-1])\n",
    "df_train.drop('product_lifecycle_stage',axis = 1,inplace = True)\n",
    "fea1 = sellin+sellout+onhand+['leftover_inventory','starting_inventory']\n",
    "fea2 = [f for f in df_train.columns.tolist() if f not in fea1]\n",
    "# new_target = df_train.groupby(['sku_name','year','month'])['sellin'].sum().reset_index()\n",
    "new_target = df_train.groupby(['sku_name','year','month'])[fea1].sum().reset_index()\n",
    "new_target2 = df_train[fea2].groupby(['sku_name','year','month']).mean().reset_index()\n",
    "df_train = new_target.merge(pcl,on = ['sku_name','year','month'],how = 'left').merge(new_target2,on = ['sku_name','year','month'],how = 'left')\n",
    "df_test['product_lifecycle_stage'] = df_test['sku_name'].map(pcl_test)\n",
    "price = df_train.groupby(['sku_name','year','month'])['price'].apply(lambda x : x.unique()[0]).reset_index()\n",
    "price_test = df_train.groupby('sku_name')['price'].apply(lambda x:x.values[-1])\n",
    "# df_test['price'] = df_test['sku_name'].map(price_test)\n",
    "\n",
    "target = 'sellin'\n",
    "prediction_columns = df_test.columns.tolist()\n",
    "encoding_columns = [t for t in df_train.columns if t not in prediction_columns]\n",
    "mao = df_train.groupby('sku_name').size()\n",
    "df_test['size'] = df_test['sku_name'].map(mao)\n",
    "df_test['size'].fillna(0,inplace = True)\n",
    "df_train['size'] = df_train['sku_name'].map(mao)\n",
    "df_train['sellin_old'] = df_train.groupby('sku_name')[['sellin']].shift(1).fillna(0)\n",
    "df_train['sellin_old2'] = df_train.groupby('sku_name')[['sellin']].shift(2).fillna(0)\n",
    "df_train['period_old'] = df_train.groupby(['sku_name'])['date'].diff().fillna(0)\n",
    "df_train['period_old2'] = df_train.groupby(['sku_name'])['date'].diff(2)\n",
    "ma_sell = df_train[df_train.sku_name.isin(df_test.sku_name)].groupby('sku_name').apply(lambda x : x['sellin'].values[-1])\n",
    "ma_date = df_train[df_train.sku_name.isin(df_test.sku_name)].groupby('sku_name').apply(lambda x : x['date'].values[-1])\n",
    "\n",
    "ma_sell2 = df_train.loc[(df_train.sku_name.isin(df_test.sku_name))& (df_train['size']>1)].groupby('sku_name').apply(lambda x : x['sellin'].values[-2])\n",
    "ma_date2 = df_train.loc[(df_train.sku_name.isin(df_test.sku_name))& (df_train['size']>1)].groupby('sku_name').apply(lambda x : x['date'].values[-2])\n",
    "df_test['sellin_old'] = df_test['sku_name'].map(ma_sell)\n",
    "df_test['period_old'] = df_test['sku_name'].map(ma_date)\n",
    "df_test['sellin_old2'] = df_test['sku_name'].map(ma_sell2)\n",
    "df_test['period_old2'] = df_test['sku_name'].map(ma_date2)\n",
    "df_test['period_old'] = df_test['date'] - df_test['period_old']\n",
    "df_test['period_old2'] = df_test['date'] - df_test['period_old2']\n",
    "first = df_train.groupby('sku_name').apply(lambda x :x['date'].values[0])\n",
    "df_train['first_appear'] = df_train['sku_name'].map(first).astype('int')\n",
    "df_test['first_appear'] = df_test['sku_name'].map(first)\n",
    "df_test['first_appear'] = df_test['first_appear'].fillna(70).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['date']\n",
    "# df_test\n",
    "# df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:17.231308Z",
     "iopub.status.busy": "2022-08-24T19:53:17.231065Z",
     "iopub.status.idle": "2022-08-24T19:53:17.240719Z",
     "shell.execute_reply": "2022-08-24T19:53:17.239875Z",
     "shell.execute_reply.started": "2022-08-24T19:53:17.231286Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['price0'] = df_train['price']//100\n",
    "df_train['price1'] = (df_train['price']//10)%10\n",
    "df_train['price2'] = df_train['price']%10\n",
    "df_train['price3'] = df_train['price']//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:17.242156Z",
     "iopub.status.busy": "2022-08-24T19:53:17.241948Z",
     "iopub.status.idle": "2022-08-24T19:53:17.250277Z",
     "shell.execute_reply": "2022-08-24T19:53:17.249497Z",
     "shell.execute_reply.started": "2022-08-24T19:53:17.242134Z"
    }
   },
   "outputs": [],
   "source": [
    "add_pivotal_sum = False\n",
    "add_pivotal_max = False\n",
    "encode_channels = False\n",
    "add_pivotal_min = False\n",
    "add_kmeans = False\n",
    "# enode_channels = False\n",
    "add_similar_month = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:53.661326Z",
     "iopub.status.busy": "2022-08-24T19:53:53.660981Z",
     "iopub.status.idle": "2022-08-24T19:53:53.709563Z",
     "shell.execute_reply": "2022-08-24T19:53:53.708480Z",
     "shell.execute_reply.started": "2022-08-24T19:53:53.661299Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.groupby('sku_name').apply(lambda x: x['sellin'].sum())\n",
    "# df_train[df_train.date == 45].describe()['sellin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T19:53:17.252458Z",
     "iopub.status.busy": "2022-08-24T19:53:17.251928Z",
     "iopub.status.idle": "2022-08-24T19:53:17.262161Z",
     "shell.execute_reply": "2022-08-24T19:53:17.261417Z",
     "shell.execute_reply.started": "2022-08-24T19:53:17.252433Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "# df_train[df_train.date==0].describe()['sellin'].index.tolist()\n",
    "# df_train.iloc[4463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:46:05.900469Z",
     "iopub.status.busy": "2022-08-24T14:46:05.899535Z",
     "iopub.status.idle": "2022-08-24T14:46:05.909078Z",
     "shell.execute_reply": "2022-08-24T14:46:05.907554Z",
     "shell.execute_reply.started": "2022-08-24T14:46:05.900421Z"
    }
   },
   "outputs": [],
   "source": [
    "# # mao.unique()[0]\n",
    "# compare = pd.DataFrame(index = range(0,df_train.date.max()+1),\n",
    "#                        columns = ['count','mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "# for i in range(0,df_train.date.max()+1):\n",
    "#     compare.loc[i] = df_train[df_train.date==i].describe()['sellin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(compare['mean'])\n",
    "# plt.plot(compare['std'])\n",
    "# compare\n",
    "# plt.plot(compare['50%'])\n",
    "# df_train = df_train[df_train.date != 45].reset_index(drop = True)\n",
    "# df_train = df_train[df_train.date != 20].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:46:14.743070Z",
     "iopub.status.busy": "2022-08-24T14:46:14.742566Z",
     "iopub.status.idle": "2022-08-24T14:46:14.755177Z",
     "shell.execute_reply": "2022-08-24T14:46:14.753657Z",
     "shell.execute_reply.started": "2022-08-24T14:46:14.743033Z"
    }
   },
   "outputs": [],
   "source": [
    "if encode_channels:\n",
    "        sku_name_channel_enc = df_train.groupby('sku_name')[sellin[1:]].max().idxmax(axis=1) # other encoding\n",
    "        sku_name_channel_enc1 = df_train.groupby('sku_name')[sellin[1:]].min().idxmin(axis=1)# train.groupby('sku_name')[sellin[1:]].min().idxmin(axis=1) # other encoding\n",
    "        df_train['sku_name_channel_enc'] = df_train['sku_name'].map(sku_name_channel_enc)\n",
    "        df_train['sku_name_channel_enc1'] = df_train['sku_name'].map(sku_name_channel_enc1)\n",
    "        df_test['sku_name_channel_enc'] = df_test['sku_name'].map(sku_name_channel_enc)\n",
    "        df_test['sku_name_channel_enc1'] = df_test['sku_name'].map(sku_name_channel_enc1)\n",
    "        df_test['sku_name_channel_enc1'].fillna('sellin_channel_1', inplace=True)\n",
    "        df_test['sku_name_channel_enc'].fillna('sellin_channel_4', inplace=True)\n",
    "        le = LE()\n",
    "        df_train['sku_name_channel_enc1'] = le.fit_transform(df_train['sku_name_channel_enc1'])\n",
    "        df_test['sku_name_channel_enc1'] = le.transform(df_test['sku_name_channel_enc1'])\n",
    "        le = LE()\n",
    "        df_train['sku_name_channel_enc'] = le.fit_transform(df_train['sku_name_channel_enc'])\n",
    "        df_test['sku_name_channel_enc'] = le.transform(df_test['sku_name_channel_enc'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:46:18.398224Z",
     "iopub.status.busy": "2022-08-24T14:46:18.397671Z",
     "iopub.status.idle": "2022-08-24T14:46:18.407680Z",
     "shell.execute_reply": "2022-08-24T14:46:18.406485Z",
     "shell.execute_reply.started": "2022-08-24T14:46:18.398184Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:46:22.084818Z",
     "iopub.status.busy": "2022-08-24T14:46:22.084344Z",
     "iopub.status.idle": "2022-08-24T14:46:22.116139Z",
     "shell.execute_reply": "2022-08-24T14:46:22.114834Z",
     "shell.execute_reply.started": "2022-08-24T14:46:22.084783Z"
    }
   },
   "outputs": [],
   "source": [
    "if add_pivotal_sum:\n",
    "        cols = ['month_'+str(i+1) for i in range(12) ]\n",
    "        exp = df_train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "        exp.columns = ['sku_name']+ cols\n",
    "        from sklearn.impute import KNNImputer\n",
    "#         imputer = KNNImputer(n_neighbors=5)\n",
    "#         exp[cols] = imputer.fit_transform(exp[cols])\n",
    "        exp.fillna(0,inplace = True)\n",
    "        exp.set_index('sku_name',inplace = True)\n",
    "        for c in cols:\n",
    "            df_test['sku_name_target_enc_sum_'+c] = df_test['sku_name'].map(exp[c])\n",
    "            tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "            kf = KFold(n_splits = 5, shuffle=True,random_state = 1991032)\n",
    "            for idx_1, idx_2 in kf.split(df_train):\n",
    "                exp2 = df_train.iloc[idx_1].groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "                exp2.columns = ['sku_name']+ cols\n",
    "                imputer = KNNImputer(n_neighbors=20)\n",
    "                exp2[cols] = imputer.fit_transform(exp2[cols])\n",
    "                exp2.set_index('sku_name',inplace = True)\n",
    "\n",
    "                tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(exp2[c])\n",
    "                df_train['sku_name_target_enc_sum_'+c] = tmp\n",
    "        imputer = KNNImputer(n_neighbors=20)\n",
    "        df_train[['sku_name_target_enc_sum_'+j for j in cols]] = imputer.fit_transform(df_train[['sku_name_target_enc_sum_'+j for j in cols]])\n",
    "if add_pivotal_min:\n",
    "        cols = ['month_'+str(i+1) for i in range(12) ]\n",
    "        exp = df_train.groupby(['sku_name','month'])[sellin[0]].min().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "        exp.columns = ['sku_name']+ cols\n",
    "        from sklearn.impute import KNNImputer\n",
    "#         imputer = KNNImputer(n_neighbors=5)\n",
    "#         exp[cols] = imputer.fit_transform(exp[cols])\n",
    "        exp.fillna(0,inplace = True)\n",
    "    \n",
    "        \n",
    "        exp.set_index('sku_name',inplace = True)\n",
    "        for c in cols:\n",
    "            df_test['sku_name_target_enc_min_'+c] = df_test['sku_name'].map(exp[c])\n",
    "            tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "            kf = KFold(n_splits = 5, shuffle=True,random_state = 1910325)\n",
    "            for idx_1, idx_2 in kf.split(df_train):\n",
    "                exp2 = df_train.iloc[idx_1].groupby(['sku_name','month'])[sellin[0]].min().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "                exp2.columns = ['sku_name']+ cols\n",
    "#                 imputer = KNNImputer(n_neighbors=5)\n",
    "#                 exp2[cols] = imputer.fit_transform(exp2[cols])\n",
    "                exp2.set_index('sku_name',inplace = True)\n",
    "\n",
    "                tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(exp2[c])\n",
    "                df_train['sku_name_target_enc_min_'+c] = tmp\n",
    "        imputer = KNNImputer(n_neighbors=20)\n",
    "        df_train[['sku_name_target_enc_min_'+j for j in cols]] = imputer.fit_transform(df_train[['sku_name_target_enc_min_'+j for j in cols]])\n",
    "if add_pivotal_max:\n",
    "        cols = ['month_'+str(i+1) for i in range(12) ]\n",
    "        exp = df_train.groupby(['sku_name','month'])[sellin[0]].max().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "        exp.columns = ['sku_name']+ cols\n",
    "        from sklearn.impute import KNNImputer\n",
    "#         imputer = KNNImputer(n_neighbors=5)\n",
    "#         exp[cols] = imputer.fit_transform(exp[cols])\n",
    "        exp.fillna(0,inplace = True)\n",
    "\n",
    "        exp.set_index('sku_name',inplace = True)\n",
    "        for c in cols:\n",
    "            df_test['sku_name_target_enc_max_'+c] = df_test['sku_name'].map(exp[c])\n",
    "            tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "            kf = KFold(n_splits = 5, shuffle=True,random_state = 9910325)\n",
    "            for idx_1, idx_2 in kf.split(df_train):\n",
    "                exp2 = df_train.iloc[idx_1].groupby(['sku_name','month'])[sellin[0]].max().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "                exp2.columns = ['sku_name']+ cols\n",
    "#                 imputer = KNNImputer(n_neighbors=5)\n",
    "#                 exp2[cols] = imputer.fit_transform(exp2[cols])\n",
    "                exp2.set_index('sku_name',inplace = True)\n",
    "\n",
    "                tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(exp2[c])\n",
    "                df_train['sku_name_target_enc_max_'+c] = tmp\n",
    "        imputer = KNNImputer(n_neighbors=20)\n",
    "        df_train[['sku_name_target_enc_max_'+j for j in cols]] = imputer.fit_transform(df_train[['sku_name_target_enc_max_'+j for j in cols]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:46:24.014060Z",
     "iopub.status.busy": "2022-08-24T14:46:24.013519Z",
     "iopub.status.idle": "2022-08-24T14:46:24.025745Z",
     "shell.execute_reply": "2022-08-24T14:46:24.024609Z",
     "shell.execute_reply.started": "2022-08-24T14:46:24.014003Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "# exp[exp.isna().sum(axis = 1)==6]\n",
    "#     .drop('sku_name',axis = 1).mean(axis = 1))\n",
    "pivotal_sum_fea = ['sku_name_target_enc_sum_month_'+str(i+1) for i in range(12) ]\n",
    "pivotal_min_fea = ['sku_name_target_enc_min_month_'+str(i+1) for i in range(12) ]\n",
    "pivotal_max_fea = ['sku_name_target_enc_max_month_'+str(i+1) for i in range(12) ]\n",
    "pivot_fea = pivotal_sum_fea + pivotal_max_fea + pivotal_min_fea\n",
    "# new_fea = [f for f in X_train.columns if f not in pivot_fea ]\n",
    "price_enc =  ['sku_namepriceenc6','sku_namepriceenc5','sku_namepriceenc4','sku_namepriceenc','sku_namepriceenc1','sku_namepriceenc2','sku_namepriceenc3']\n",
    "sellin_enc =  ['sku_namesellinenc6','sku_namesellinenc5','sku_namesellinenc4','sku_namesellinenc','sku_namesellinenc1','sku_namesellinenc2','sku_namesellinenc3']\n",
    "sellout_enc =  ['sku_nameselloutenc6','sku_nameselloutenc5','sku_nameselloutenc4','sku_nameselloutenc','sku_nameselloutenc1','sku_nameselloutenc2','sku_nameselloutenc3']\n",
    "onhand_inventory_enc =  ['sku_nameonhand_inventoryenc6','sku_nameonhand_inventoryenc5','sku_nameonhand_inventoryenc4','sku_nameonhand_inventoryenc','sku_nameonhand_inventoryenc1','sku_nameonhand_inventoryenc2','sku_nameonhand_inventoryenc3']\n",
    "starting_inventory_enc =  ['sku_namestarting_inventoryenc6','sku_namestarting_inventoryenc5','sku_namestarting_inventoryenc4','sku_namestarting_inventoryenc','sku_namestarting_inventoryenc1','sku_namestarting_inventoryenc2','sku_namestarting_inventoryenc3']\n",
    "enc_features = price_enc + sellin_enc + sellout_enc + onhand_inventory_enc + starting_inventory_enc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:46:24.819500Z",
     "iopub.status.busy": "2022-08-24T14:46:24.818956Z",
     "iopub.status.idle": "2022-08-24T14:46:24.825715Z",
     "shell.execute_reply": "2022-08-24T14:46:24.824037Z",
     "shell.execute_reply.started": "2022-08-24T14:46:24.819463Z"
    }
   },
   "outputs": [],
   "source": [
    "spliti = 'kfold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:47:44.437765Z",
     "iopub.status.busy": "2022-08-24T14:47:44.437193Z",
     "iopub.status.idle": "2022-08-24T14:47:44.596040Z",
     "shell.execute_reply": "2022-08-24T14:47:44.594202Z",
     "shell.execute_reply.started": "2022-08-24T14:47:44.437716Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train = df_train.groupby(['sku_name','year','month']).mean().reset_index()\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = len(train_array)\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
    "\n",
    "if spliti == 'kfold':\n",
    "    def target_encode(df_train,df_test,target):\n",
    "        sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "        sku_name_target_max = df_train.groupby('sku_name')[target].max()\n",
    "        sku_name_target_min = df_train.groupby('sku_name')[target].min()\n",
    "        sku_name_target_std = df_train.groupby('sku_name')[target].std()\n",
    "        sku_name_target_median = df_train.groupby('sku_name')[target].apply(lambda x : np.median(x))\n",
    "        sku_name_target_q95 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95))\n",
    "        sku_name_target_q05 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05))\n",
    "        # sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "        df_test['sku_name'+target+'enc'] = df_test['sku_name'].map(sku_name_target_mean)\n",
    "        df_test['sku_name'+target+'enc'].fillna((df_test['sku_name'+target+'enc'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc1'] = df_test['sku_name'].map(sku_name_target_max)\n",
    "        df_test['sku_name'+target+'enc1'].fillna((df_test['sku_name'+target+'enc1'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc2'] = df_test['sku_name'].map(sku_name_target_min)\n",
    "        df_test['sku_name'+target+'enc2'].fillna((df_test['sku_name'+target+'enc2'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc3'] = df_test['sku_name'].map(sku_name_target_std)\n",
    "        df_test['sku_name'+target+'enc3'].fillna((df_test['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc4'] = df_test['sku_name'].map(sku_name_target_median)\n",
    "        df_test['sku_name'+target+'enc4'].fillna((df_test['sku_name'+target+'enc4'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc5'] = df_test['sku_name'].map(sku_name_target_q95)\n",
    "        df_test['sku_name'+target+'enc5'].fillna((df_test['sku_name'+target+'enc5'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc6'] = df_test['sku_name'].map(sku_name_target_q05)\n",
    "        df_test['sku_name'+target+'enc6'].fillna((df_test['sku_name'+target+'enc6'].mean()), inplace=True)\n",
    "        tmp =np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 19910325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc6'] = tmp\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1991032)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc5'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1991035)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.median(x))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc4'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1910325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].mean()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1991025)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_max = df_train.iloc[idx_1].groupby('sku_name')[target].max()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_max)\n",
    "        df_train['sku_name'+target+'enc1'] = tmp\n",
    "        # from sklearn.model_selection import KFold/\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1990325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_min = df_train.iloc[idx_1].groupby('sku_name')[target].min()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_min)\n",
    "        df_train['sku_name'+target+'enc2'] = tmp\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 19910325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_std = df_train.iloc[idx_1].groupby('sku_name')[target].std()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_std)\n",
    "        df_train['sku_name'+target+'enc3'] = tmp\n",
    "        df_train['sku_name'+target+'enc'].fillna((df_train['sku_name'+target+'enc'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc1'].fillna((df_train['sku_name'+target+'enc1'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc2'].fillna((df_train['sku_name'+target+'enc2'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc3'].fillna((df_train['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc4'].fillna((df_train['sku_name'+target+'enc4'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc5'].fillna((df_train['sku_name'+target+'enc5'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc6'].fillna((df_train['sku_name'+target+'enc6'].mean()), inplace=True)\n",
    "        return df_train, df_test\n",
    "    # train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmax(axis = 1) # other encoding\n",
    "    # train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmin(axis = 1).reset_index() # other encoding\n",
    "\n",
    "    def target_encode_p(df_train,df_test,target):\n",
    "        sku_name_target_mean = df_train.groupby('sku_name')[target].mean().round().astype('int16')\n",
    "        sku_name_target_max = df_train.groupby('sku_name')[target].max().round().astype('int16')\n",
    "        sku_name_target_min = df_train.groupby('sku_name')[target].min().round().astype('int16')\n",
    "        sku_name_target_std = df_train.groupby('sku_name')[target].std()\n",
    "        sku_name_target_median = df_train.groupby('sku_name')[target].apply(lambda x : np.median(x).round().astype('int16'))\n",
    "        sku_name_target_q95 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95).round().astype('int16'))\n",
    "        sku_name_target_q05 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05).round().astype('int16'))\n",
    "        # sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "        df_test['sku_name'+target+'enc'] = df_test['sku_name'].map(sku_name_target_mean)\n",
    "        df_test['sku_name'+target+'enc'].fillna((df_test['sku_name'+target+'enc'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc1'] = df_test['sku_name'].map(sku_name_target_max)\n",
    "        df_test['sku_name'+target+'enc1'].fillna((df_test['sku_name'+target+'enc1'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc2'] = df_test['sku_name'].map(sku_name_target_min)\n",
    "        df_test['sku_name'+target+'enc2'].fillna((df_test['sku_name'+target+'enc2'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc3'] = df_test['sku_name'].map(sku_name_target_std)\n",
    "        df_test['sku_name'+target+'enc3'].fillna((df_test['sku_name'+target+'enc3']), inplace=True)\n",
    "        df_test['sku_name'+target+'enc4'] = df_test['sku_name'].map(sku_name_target_median)\n",
    "        df_test['sku_name'+target+'enc4'].fillna((df_test['sku_name'+target+'enc4'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc5'] = df_test['sku_name'].map(sku_name_target_q95)\n",
    "        df_test['sku_name'+target+'enc5'].fillna((df_test['sku_name'+target+'enc5'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc6'] = df_test['sku_name'].map(sku_name_target_q05)\n",
    "        df_test['sku_name'+target+'enc6'].fillna((df_test['sku_name'+target+'enc6'].mean().round().astype('int16')), inplace=True)\n",
    "        tmp =np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 19910325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05).round().astype('int16'))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc6'] = tmp\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1991032)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95).round().astype('int16'))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc5'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1991035)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.median(x).round().astype('int16'))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc4'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1910325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].mean().round().astype('int16')\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1991025)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_max = df_train.iloc[idx_1].groupby('sku_name')[target].max().round().astype('int16')\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_max)\n",
    "        df_train['sku_name'+target+'enc1'] = tmp\n",
    "        # from sklearn.model_selection import KFold/\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 1990325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_min = df_train.iloc[idx_1].groupby('sku_name')[target].min().round().astype('int16')\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_min)\n",
    "        df_train['sku_name'+target+'enc2'] = tmp\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 19910325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_std = df_train.iloc[idx_1].groupby('sku_name')[target].std()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_std)\n",
    "        df_train['sku_name'+target+'enc3'] = tmp\n",
    "        df_train['sku_name'+target+'enc'].fillna((df_train['sku_name'+target+'enc'].mean().round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc1'].fillna((df_train['sku_name'+target+'enc1'].mean().round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc2'].fillna((df_train['sku_name'+target+'enc2'].mean().round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc3'].fillna((df_train['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc4'].fillna((df_train['sku_name'+target+'enc4'].mean().round().astype('int16').round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc5'].fillna((df_train['sku_name'+target+'enc5'].mean().round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc6'].fillna((df_train['sku_name'+target+'enc6'].mean().round().astype('int16')), inplace=True)\n",
    "        return df_train, df_test\n",
    "    # train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmax(axis = 1) # other encoding\n",
    "# train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmin(axis = 1).reset_index() # other encoding\n",
    "    \n",
    "if spliti == 'purged':\n",
    "    def target_encode_p(df_train,df_test,target):\n",
    "        kfolds = 5\n",
    "        sku_name_target_mean = df_train.groupby('sku_name')[target].mean().round().astype('int16')\n",
    "        sku_name_target_max = df_train.groupby('sku_name')[target].max().round().astype('int16')\n",
    "        sku_name_target_min = df_train.groupby('sku_name')[target].min().round().astype('int16')\n",
    "        sku_name_target_std = df_train.groupby('sku_name')[target].std()\n",
    "        sku_name_target_median = df_train.groupby('sku_name')[target].apply(lambda x : np.median(x).round().astype('int16'))\n",
    "        sku_name_target_q95 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95).round().astype('int16'))\n",
    "        sku_name_target_q05 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05).round().astype('int16'))\n",
    "        # sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "        df_test['sku_name'+target+'enc'] = df_test['sku_name'].map(sku_name_target_mean)\n",
    "        df_test['sku_name'+target+'enc'].fillna((df_test['sku_name'+target+'enc'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc1'] = df_test['sku_name'].map(sku_name_target_max)\n",
    "        df_test['sku_name'+target+'enc1'].fillna((df_test['sku_name'+target+'enc1'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc2'] = df_test['sku_name'].map(sku_name_target_min)\n",
    "        df_test['sku_name'+target+'enc2'].fillna((df_test['sku_name'+target+'enc2'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc3'] = df_test['sku_name'].map(sku_name_target_std)\n",
    "        df_test['sku_name'+target+'enc3'].fillna((df_test['sku_name'+target+'enc3']), inplace=True)\n",
    "        df_test['sku_name'+target+'enc4'] = df_test['sku_name'].map(sku_name_target_median)\n",
    "        df_test['sku_name'+target+'enc4'].fillna((df_test['sku_name'+target+'enc4'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc5'] = df_test['sku_name'].map(sku_name_target_q95)\n",
    "        df_test['sku_name'+target+'enc5'].fillna((df_test['sku_name'+target+'enc5'].mean().round().astype('int16')), inplace=True)\n",
    "        df_test['sku_name'+target+'enc6'] = df_test['sku_name'].map(sku_name_target_q05)\n",
    "        df_test['sku_name'+target+'enc6'].fillna((df_test['sku_name'+target+'enc6'].mean().round().astype('int16')), inplace=True)\n",
    "        tmp =np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05).round().astype('int16'))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc6'] = tmp\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95).round().astype('int16'))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc5'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.median(x).round().astype('int16'))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc4'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].mean().round().astype('int16')\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_max = df_train.iloc[idx_1].groupby('sku_name')[target].max().round().astype('int16')\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_max)\n",
    "        df_train['sku_name'+target+'enc1'] = tmp\n",
    "        # from sklearn.model_selection import KFold/\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_min = df_train.iloc[idx_1].groupby('sku_name')[target].min().round().astype('int16')\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_min)\n",
    "        df_train['sku_name'+target+'enc2'] = tmp\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_std = df_train.iloc[idx_1].groupby('sku_name')[target].std()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_std)\n",
    "        df_train['sku_name'+target+'enc3'] = tmp\n",
    "        df_train['sku_name'+target+'enc'].fillna((df_train['sku_name'+target+'enc'].mean().round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc1'].fillna((df_train['sku_name'+target+'enc1'].mean().round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc2'].fillna((df_train['sku_name'+target+'enc2'].mean().round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc3'].fillna((df_train['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc4'].fillna((df_train['sku_name'+target+'enc4'].mean().round().astype('int16').round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc5'].fillna((df_train['sku_name'+target+'enc5'].mean().round().astype('int16')), inplace=True)\n",
    "        df_train['sku_name'+target+'enc6'].fillna((df_train['sku_name'+target+'enc6'].mean().round().astype('int16')), inplace=True)\n",
    "        return df_train, df_test\n",
    "    # train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmax(axis = 1) # other encoding\n",
    "    # train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmin(axis = 1).reset_index() # other encoding\n",
    "    def target_encode(df_train,df_test,target):\n",
    "        kfolds = 5\n",
    "        sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "        sku_name_target_max = df_train.groupby('sku_name')[target].max()\n",
    "        sku_name_target_min = df_train.groupby('sku_name')[target].min()\n",
    "        sku_name_target_std = df_train.groupby('sku_name')[target].std()\n",
    "        sku_name_target_median = df_train.groupby('sku_name')[target].apply(lambda x : np.median(x))\n",
    "        sku_name_target_q95 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95))\n",
    "        sku_name_target_q05 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05))\n",
    "        # sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "        df_test['sku_name'+target+'enc'] = df_test['sku_name'].map(sku_name_target_mean)\n",
    "        df_test['sku_name'+target+'enc'].fillna((df_test['sku_name'+target+'enc'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc1'] = df_test['sku_name'].map(sku_name_target_max)\n",
    "        df_test['sku_name'+target+'enc1'].fillna((df_test['sku_name'+target+'enc1'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc2'] = df_test['sku_name'].map(sku_name_target_min)\n",
    "        df_test['sku_name'+target+'enc2'].fillna((df_test['sku_name'+target+'enc2'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc3'] = df_test['sku_name'].map(sku_name_target_std)\n",
    "        df_test['sku_name'+target+'enc3'].fillna((df_test['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc4'] = df_test['sku_name'].map(sku_name_target_median)\n",
    "        df_test['sku_name'+target+'enc4'].fillna((df_test['sku_name'+target+'enc4'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc5'] = df_test['sku_name'].map(sku_name_target_q95)\n",
    "        df_test['sku_name'+target+'enc5'].fillna((df_test['sku_name'+target+'enc5'].mean()), inplace=True)\n",
    "        df_test['sku_name'+target+'enc6'] = df_test['sku_name'].map(sku_name_target_q05)\n",
    "        df_test['sku_name'+target+'enc6'].fillna((df_test['sku_name'+target+'enc6'].mean()), inplace=True)\n",
    "        tmp =np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc6'] = tmp\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc5'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.median(x))\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc4'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].mean()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name'+target+'enc'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_max = df_train.iloc[idx_1].groupby('sku_name')[target].max()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_max)\n",
    "        df_train['sku_name'+target+'enc1'] = tmp\n",
    "        # from sklearn.model_selection import KFold/\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_min = df_train.iloc[idx_1].groupby('sku_name')[target].min()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_min)\n",
    "        df_train['sku_name'+target+'enc2'] = tmp\n",
    "        # from sklearn.model_selection import KFold\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "        for idx_1, idx_2 in kf.split(df_train, groups=df_train['date'].values):\n",
    "            target_std = df_train.iloc[idx_1].groupby('sku_name')[target].std()\n",
    "\n",
    "            tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_std)\n",
    "        df_train['sku_name'+target+'enc3'] = tmp\n",
    "        df_train['sku_name'+target+'enc'].fillna((df_train['sku_name'+target+'enc'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc1'].fillna((df_train['sku_name'+target+'enc1'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc2'].fillna((df_train['sku_name'+target+'enc2'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc3'].fillna((df_train['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc4'].fillna((df_train['sku_name'+target+'enc4'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc5'].fillna((df_train['sku_name'+target+'enc5'].mean()), inplace=True)\n",
    "        df_train['sku_name'+target+'enc6'].fillna((df_train['sku_name'+target+'enc6'].mean()), inplace=True)\n",
    "        return df_train, df_test\n",
    "    # train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmax(axis = 1) # other encoding\n",
    "    # train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmin(axis = 1).reset_index() # other encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:48:54.026349Z",
     "iopub.status.busy": "2022-08-24T14:48:54.025792Z",
     "iopub.status.idle": "2022-08-24T14:49:34.016375Z",
     "shell.execute_reply": "2022-08-24T14:49:34.014985Z",
     "shell.execute_reply.started": "2022-08-24T14:48:54.026307Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train,df_test = target_encode(df_train,df_test,'sellin')\n",
    "df_train,df_test = target_encode(df_train,df_test,'sellout')\n",
    "# df_train,df_test = target_encode_p(df_train,df_test,'price0')\n",
    "# df_train,df_test = target_encode_p(df_train,df_test,'price1')\n",
    "# df_train,df_test = target_encode_p(df_train,df_test,'price2')\n",
    "# df_train,df_test = target_encode_p(df_train,df_test,'price3')\n",
    "df_train,df_test = target_encode(df_train,df_test,'price')\n",
    "\n",
    "df_train,df_test = target_encode(df_train,df_test,'starting_inventory')\n",
    "df_train,df_test = target_encode(df_train,df_test,'leftover_inventory')\n",
    "# pcl = df_train.groupby(['sku_name','year','month'])['product_lifecycle_stage'].apply(lambda x : x.unique()[0]).reset_index()\n",
    "# pcl_test = df_train.groupby('sku_name')['product_lifecycle_stage'].apply(lambda x:x.values[-1])\n",
    "# df_train.drop('product_lifecycle_stage',axis = 1,inplace = True)\n",
    "# new_target = df_train.groupby(['sku_name','year','month'])['sellin'].sum().reset_index()\n",
    "# df_train = df_train.merge(pcl,on = ['sku_name','year','month'],how = 'left')\n",
    "# df_test['product_lifecycle_stage'] = df_test['sku_name'].map(pcl_test)\n",
    "target = 'sellin'\n",
    "prediction_columns = df_test.columns.tolist()\n",
    "encoding_columns = [t for t in df_train.columns if t not in prediction_columns]\n",
    "# X = df_train.drop(encoding_columns+[target],axis=1)\n",
    "# y = df_train[target]\n",
    "# df_train = df_train.drop(encoding_columns+[target],axis=1).merge(new_target,on = ['sku_name','year','month'],how = 'left').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.018995Z",
     "iopub.status.busy": "2022-08-24T14:49:34.018509Z",
     "iopub.status.idle": "2022-08-24T14:49:34.068849Z",
     "shell.execute_reply": "2022-08-24T14:49:34.067220Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.018962Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([df_train[prediction_columns],df_test[prediction_columns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.070841Z",
     "iopub.status.busy": "2022-08-24T14:49:34.070437Z",
     "iopub.status.idle": "2022-08-24T14:49:34.076925Z",
     "shell.execute_reply": "2022-08-24T14:49:34.075492Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.070798Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_data.groupby(['sku_name','month','year']).size().max()\n",
    "# all_data.index.max()\n",
    "all_data['price'].fillna(all_data['price'].median(),inplace = True)\n",
    "all_data['price'] = all_data['price'].astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.081366Z",
     "iopub.status.busy": "2022-08-24T14:49:34.080923Z",
     "iopub.status.idle": "2022-08-24T14:49:34.130736Z",
     "shell.execute_reply": "2022-08-24T14:49:34.129728Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.081330Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "le = LE()\n",
    "all_data['enc_sku'] = le.fit_transform(all_data['sku_name'])\n",
    "df_train['enc_sku'] = all_data.iloc[:df_train.shape[0]]['enc_sku']\n",
    "df_test['enc_sku'] = all_data.iloc[df_train.shape[0]:]['enc_sku']\n",
    "\n",
    "# le = LE()\n",
    "# all_data['product_lifecycle_stage'] = le.fit_transform(all_data['product_lifecycle_stage'])\n",
    "# df_train['product_lifecycle_stage'] = all_data.iloc[:df_train.shape[0]]['product_lifecycle_stage']\n",
    "# df_test['product_lifecycle_stage'] = all_data.iloc[df_train.shape[0]:]['product_lifecycle_stage']\n",
    "# # df_test['enc_sku'] = le.transform(df_test['sku_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.133697Z",
     "iopub.status.busy": "2022-08-24T14:49:34.132567Z",
     "iopub.status.idle": "2022-08-24T14:49:34.145238Z",
     "shell.execute_reply": "2022-08-24T14:49:34.143985Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.133644Z"
    }
   },
   "outputs": [],
   "source": [
    "add_similar_products = True\n",
    "if add_similar_month:\n",
    "        df_train['new_index'] = df_train['sku_name']+'_'+df_train['month'].astype(str)\n",
    "        df_test['new_index'] = df_test['sku_name']+'_'+df_test['month'].astype(str)\n",
    "        new_df = df_train.groupby('new_index')['sellin'].mean()\n",
    "        df_test['sku_name_target_enc_overfit'] = df_test['new_index'].map(new_df)\n",
    "        df_test['sku_name_target_enc_overfit'].fillna((df_test['sku_name_target_enc_overfit'].mean()), inplace=True)\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 29910325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('new_index')['sellin'].mean()\n",
    "\n",
    "            tmp[idx_2] = df_train['new_index'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name_target_enc_overfit'] = tmp\n",
    "        df_train['sku_name_target_enc_overfit'].fillna((df_train['sku_name_target_enc_overfit'].mean()), inplace=True)\n",
    "        df_train.drop('new_index',axis = 1, inplace = True)\n",
    "        df_test.drop('new_index',axis = 1, inplace = True)\n",
    "# What i suppose is similar products\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.148208Z",
     "iopub.status.busy": "2022-08-24T14:49:34.147380Z",
     "iopub.status.idle": "2022-08-24T14:49:34.157864Z",
     "shell.execute_reply": "2022-08-24T14:49:34.156563Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.148162Z"
    }
   },
   "outputs": [],
   "source": [
    "price_cols = ['sku_nameprice0enc',\n",
    " 'sku_nameprice0enc1',\n",
    " 'sku_nameprice0enc2',\n",
    " 'sku_nameprice0enc3',\n",
    " 'sku_nameprice0enc4',\n",
    " 'sku_nameprice0enc5',\n",
    " 'sku_nameprice0enc6',\n",
    " 'sku_nameprice1enc',\n",
    " 'sku_nameprice1enc1',\n",
    " 'sku_nameprice1enc2',\n",
    " 'sku_nameprice1enc3',\n",
    " 'sku_nameprice1enc4',\n",
    " 'sku_nameprice1enc5',\n",
    " 'sku_nameprice1enc6',\n",
    " 'sku_nameprice2enc',\n",
    " 'sku_nameprice2enc1',\n",
    " 'sku_nameprice2enc2',\n",
    " 'sku_nameprice2enc3',\n",
    " 'sku_nameprice2enc4',\n",
    " 'sku_nameprice2enc5',\n",
    " 'sku_nameprice2enc6',\n",
    " 'sku_nameprice3enc',\n",
    " 'sku_nameprice3enc1',\n",
    " 'sku_nameprice3enc2',\n",
    " 'sku_nameprice3enc3',\n",
    " 'sku_nameprice3enc4',\n",
    " 'sku_nameprice3enc5',\n",
    " 'sku_nameprice3enc6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.price.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.160574Z",
     "iopub.status.busy": "2022-08-24T14:49:34.160156Z",
     "iopub.status.idle": "2022-08-24T14:49:34.173774Z",
     "shell.execute_reply": "2022-08-24T14:49:34.172609Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.160540Z"
    }
   },
   "outputs": [],
   "source": [
    "# train.loc[train.year == train['year'].min(),'month'].min()\n",
    "# df_train['date'] = (df_train['year']-2016)*12 + (df_train['month']-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.176143Z",
     "iopub.status.busy": "2022-08-24T14:49:34.175091Z",
     "iopub.status.idle": "2022-08-24T14:49:34.186992Z",
     "shell.execute_reply": "2022-08-24T14:49:34.185491Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.176071Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df_train['sellin']\n",
    "# train['date'] = (train['year'].astype(str)+ '-'+train['month'].astype(str)).apply(lambda _: pd.to_datetime(_,format='%Y-%m', errors='coerce'))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.189334Z",
     "iopub.status.busy": "2022-08-24T14:49:34.188655Z",
     "iopub.status.idle": "2022-08-24T14:49:34.204732Z",
     "shell.execute_reply": "2022-08-24T14:49:34.203344Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.189293Z"
    }
   },
   "outputs": [],
   "source": [
    "# # this is code slightly modified from the sklearn docs here:\n",
    "# # https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n",
    "# def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "#     \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "#     cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "#     jet = plt.cm.get_cmap('jet', 256)\n",
    "#     seq = np.linspace(0, 1, 256)\n",
    "#     _ = np.random.shuffle(seq)   # inplace\n",
    "#     cmap_data = ListedColormap(jet(seq))\n",
    "\n",
    "#     # Generate the training/testing visualizations for each CV split\n",
    "#     for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "#         # Fill in indices with the training/test groups\n",
    "#         indices = np.array([np.nan] * len(X))\n",
    "#         indices[tt] = 1\n",
    "#         indices[tr] = 0\n",
    "\n",
    "#         # Visualize the results\n",
    "#         ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "#                    c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "#                    vmin=-.2, vmax=1.2)\n",
    "\n",
    "#     # Plot the data classes and groups at the end\n",
    "#     ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "#                c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n",
    "\n",
    "#     ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "#                c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "#     # Formatting\n",
    "#     yticklabels = list(range(n_splits)) + ['target', 'day']\n",
    "#     ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "#            xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "#            ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "#     ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "#     return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T13:10:30.324026Z",
     "iopub.status.busy": "2022-08-24T13:10:30.322806Z",
     "iopub.status.idle": "2022-08-24T13:10:30.334630Z",
     "shell.execute_reply": "2022-08-24T13:10:30.333334Z",
     "shell.execute_reply.started": "2022-08-24T13:10:30.323987Z"
    }
   },
   "outputs": [],
   "source": [
    "# from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T13:10:30.336708Z",
     "iopub.status.busy": "2022-08-24T13:10:30.336075Z",
     "iopub.status.idle": "2022-08-24T13:10:30.345891Z",
     "shell.execute_reply": "2022-08-24T13:10:30.344639Z",
     "shell.execute_reply.started": "2022-08-24T13:10:30.336672Z"
    }
   },
   "outputs": [],
   "source": [
    "# # train.iloc[splits[4][0]].groupby('sku_name')['date'].max()> \n",
    "# # train.iloc[splits[4][1]].groupby('sku_name')['date'].max()\n",
    "# # %%time\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# fig, ax = plt.subplots()\n",
    "# cv = PurgedGroupTimeSeriesSplit(n_splits = 5, group_gap = 1)\n",
    "# plot_cv_indices(cv, train[train.drop('sellin',axis=1).columns].values, train['sellin'].values, train['date'].values, ax, 5, lw = 20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T13:10:30.348347Z",
     "iopub.status.busy": "2022-08-24T13:10:30.347981Z",
     "iopub.status.idle": "2022-08-24T13:10:30.364875Z",
     "shell.execute_reply": "2022-08-24T13:10:30.363983Z",
     "shell.execute_reply.started": "2022-08-24T13:10:30.348315Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def add_more(df_train,df_test):\n",
    "# #     def last_known_sellin(df_train,df_test):\n",
    "# # #     months_train = \n",
    "# #     # df_train.iloc[1:].apply(rowIndex,axis= 1)-1\n",
    "# #         ma = df_train.groupby('sku_name').apply(lambda x : np.median(x))\n",
    "# #         df_train['medians'] = df_train['sku_name'].map(ma)\n",
    "# #         a = df_train.merge(df_train.shift(1)[['sku_name','year','month','sellin']] ,left_index = True,right_index = True,suffixes = (None,'_old'))\n",
    "# #         b = df_test.merge(df_train.loc[df_train.sku_name.isin(df_test.sku_name)].groupby('sku_name').apply(lambda x:x.iloc[-1])[['year','month','sellin']].reset_index(),\n",
    "# #                      on = 'sku_name',how = 'left', suffixes = (None,'_old'))\n",
    "# #         a['sellin_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['sellin_old'] , np.nan)\n",
    "# #         a['month_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['month_old'] , np.nan)\n",
    "# #         a['year_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['year_old'] , np.nan)\n",
    "# #         a['period_old'] = np.where(a['sku_name'] == a['sku_name_old'], (a['year']-a['year_old'])*12 + (a['month']-a['month_old']) , np.nan)\n",
    "# #         b['period_old'] = (b['year']-b['year_old'])*12 + (b['month']-b['month_old'])\n",
    "# #         b['sellin_old'] = b['sellin']\n",
    "# #         a['sellin_old'] = a['sellin_old'].fillna(a['medians'])\n",
    "# #         b['sellin_old'] = b['sellin_old'].fillna(np.median(a['medians'].values))\n",
    "# #         a.drop(['sku_name_old','medians'],axis = 1,inplace = True)\n",
    "# #         b.drop(['sellin'],axis = 1,inplace = True)\n",
    "# #         return a,b\n",
    "#     def last_known_sellin(df_train,df_test):\n",
    "# #     months_train = \n",
    "# # df_train.iloc[1:].apply(rowIndex,axis= 1)-1\n",
    "#         ma = df_train.groupby('sku_name').apply(lambda x : np.median(x))\n",
    "#         df_train['medians'] = df_train['sku_name'].map(ma)\n",
    "#         a = df_train.merge(df_train.shift(1)[['sku_name','year','month','sellin']] ,left_index = True,right_index = True,suffixes = (None,'_old'))\n",
    "#         b = df_test.merge(df_train.loc[df_train.sku_name.isin(df_test.sku_name)].groupby('sku_name').apply(lambda x:x.iloc[-1])[['year','month','sellin']].reset_index(),\n",
    "#                      on = 'sku_name',how = 'left', suffixes = (None,'_old'))\n",
    "#         a['sellin_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['sellin_old'] , np.nan)\n",
    "#         a['month_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['month_old'] , np.nan)\n",
    "#         a['year_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['year_old'] , np.nan)\n",
    "#         a['period_old'] = np.where(a['sku_name'] == a['sku_name_old'], (a['year']-a['year_old'])*12 + (a['month']-a['month_old']) , np.nan)\n",
    "#         b['period_old'] = (b['year']-b['year_old'])*12 + (b['month']-b['month_old'])\n",
    "#         b['sellin_old'] = b['sellin']\n",
    "#         a['sellin_old'] = a['sellin_old'].fillna(a['medians'])\n",
    "# #         med = a.groupby('sku_name')['medians'].mean()\n",
    "#         b['medians'] = b['sku_name'].map(ma)\n",
    "#         b['sellin_old'] = b['sellin_old'].fillna(b['medians'])\n",
    "#     #     a['last_change'] = a['sellin'].diff()/a['period_old']\n",
    "#     #     b['last_change'] = b['sellin'].diff()/b['period_old']\n",
    "#         a.loc[a.period_old>1,'sellin_old'] = a.loc[a.period_old>1].groupby('sku_name').apply(lambda a : (a['sellin'].diff()/a['period_old'])).fillna(0).values + a.loc[a.period_old>1,'medians']\n",
    "#         maps = a.groupby('sku_name').apply(lambda a : ((a['sellin'].diff()/a['period_old'])).fillna(0).values[-1])\n",
    "#         b['pct_change'] = b['sku_name'].map(maps)\n",
    "#         b.loc[b.period_old>1,'sellin_old'] = b.loc[b.period_old>1,'medians'] + (b.loc[b.period_old>1,'period_old']* b.loc[b.period_old>1,'pct_change'] )\n",
    "#         a.drop(['sku_name_old','medians'],axis = 1,inplace = True)\n",
    "#         b.drop(['sellin','medians'],axis = 1,inplace = True)\n",
    "#         return a,b\n",
    "#     def interpolate(Serie,strat = 'linear',c = 0):\n",
    "#         missing_months = Serie['missing'][1]\n",
    "#         missing_years = Serie['missing'][0]\n",
    "#         flag = Serie['missing'][2]\n",
    "#         if flag:\n",
    "#             power = 1\n",
    "#         else:\n",
    "#             power = -1\n",
    "#         bm = Serie['best_month']\n",
    "#         if len(missing_years)>1:\n",
    "#             yearly_fact = (y_fact.loc[(y_fact.best_month == bm)& (y_fact.year.isin(missing_years[1:])),'pct_change_year']+1).prod()\n",
    "#         else:\n",
    "#             yearly_fact = 1\n",
    "#         if len(missing_months)>0:\n",
    "#             monthly_fact = (fact.loc[(fact.best_month == bm)& (fact.month.isin(missing_months)),'pct_change_sellin']+1).prod()\n",
    "#         else:\n",
    "#             monthly_fact = 1\n",
    "#         if strat == 'linear':\n",
    "#             return ((monthly_fact)**power)*yearly_fact*Serie['sellin_old']\n",
    "#         if strat == 'constant':\n",
    "#             return c*Serie['sellin_old']\n",
    "#     def missing_years(y,m,y_o,m_o):\n",
    "#         flag = True\n",
    "#         if (m_o>m )and not ((m_o == 12) & (m ==1 )):\n",
    "#             flag = False\n",
    "#         flag2 = False\n",
    "#         if ((m_o == 12) & (m ==1 )) & (y_o+1 == y):\n",
    "#             flag2 = True\n",
    "#         missing_y = []\n",
    "#         while y>y_o:\n",
    "#             missing_y.append(y_o)\n",
    "#             y_o=y_o+1\n",
    "#         missing_m = []\n",
    "#         if flag:\n",
    "#             while m>m_o+1:\n",
    "#                 m_o=m_o+1\n",
    "#                 missing_m.append(m_o)\n",
    "\n",
    "#         else:\n",
    "#                 while m<m_o and not ((m_o == 12) & (m ==1 )):\n",
    "#                     m_o=m_o-1\n",
    "#                     missing_m.append(m_o-1)\n",
    "#         if (len(missing_y)==0) & (len(missing_m)==0):\n",
    "#             return np.nan\n",
    "#         elif flag2:\n",
    "#             return 0\n",
    "#         else:\n",
    "#             return np.array(missing_y),np.array(missing_m),flag\n",
    "#     df_train,df_test = last_known_sellin(df_train,df_test)\n",
    "#     groups = df_train.groupby(['sku_name','month'])['sellin'].sum().reset_index().pivot(index = 'sku_name',columns = 'month', values = 'sellin').idxmax(axis = 1)\n",
    "#     df_test['best_month'] = df_test['sku_name'].map(groups)\n",
    "#     df_train['best_month'] = df_train['sku_name'].map(groups).astype('int')\n",
    "#     df_test['best_month'].fillna(10,inplace = True)\n",
    "#     df_test['best_month'] = df_test['best_month'].astype('int')\n",
    "#     df_test['period_old'] = df_test['period_old'].fillna(0).astype('int')\n",
    "#     df_train['period_old'] = df_train['period_old'].fillna(0).astype('int')\n",
    "#     df_train1 = df_train.copy()\n",
    "#     df_test1 = df_test.copy()\n",
    "#     df_train1['pct_change_sellin'] = df_train1.groupby('sku_name')['sellin'].pct_change().fillna(0)\n",
    "#     fact = df_train1[['sku_name','month','year','best_month','pct_change_sellin']].groupby(['best_month','month'])['pct_change_sellin'].mean().reset_index()\n",
    "#     strat = 'linear'\n",
    "#     for m in [11,12,1]:\n",
    "#         for bm in range(1,13):\n",
    "#             if m==12:\n",
    "#                 M = 1\n",
    "#             else:\n",
    "#                 M = m+1\n",
    "#             if strat == 'linear':\n",
    "#                 df_test.loc[(df_test.best_month == bm)& (df_test.month == M),'sellin_old' ] =\\\n",
    "#                 df_test.loc[(df_test.best_month == bm)& (df_test.month == M),'sellin_old' ] +\\\n",
    "#                 (df_test.loc[(df_test.best_month == bm)& (df_test.month == M),'sellin_old' ]* \\\n",
    "#                  (fact.loc[(fact.best_month == bm)& (fact.month == m),'pct_change_sellin'].values+1))#*(/df_train.loc[(df_train.best_month == bm)& (df_train.month == m)]))\n",
    "#             elif strat =='constant':\n",
    "#                 continue\n",
    "#     a = df_train1[df_train1.year<2021].groupby(['sku_name','year'])['sellin'].mean().reset_index()\n",
    "#     b = a.groupby('sku_name')['sellin'].pct_change().fillna(0)/a.groupby('sku_name')['year'].diff().fillna(0)\n",
    "#     a['pct_change_year'] = b.fillna(0)\n",
    "#     df_train1 = df_train1.merge(a[['sku_name','year','pct_change_year']], on = ['sku_name','year'],how = 'left')\n",
    "#     y_fact = df_train1[df_train1.year<2021].groupby(['best_month','year'])['pct_change_year'].mean().reset_index().fillna(0)\n",
    "#     c = df_train1.apply(lambda x : missing_years(x['year'],x['month'],x['year_old'],x['month_old']),axis = 1)\n",
    "#     df_train1['missing'] = c\n",
    "#     pct_ch = []\n",
    "#     for m in range(1,13):\n",
    "#         pct_ch.append(((y_fact.loc[(y_fact.best_month == m)& (y_fact.year == 2019) ,'pct_change_year'].values - y_fact.loc[(y_fact.best_month == m)& (y_fact.year == 2018) ,'pct_change_year'].values)*2 + y_fact.loc[(y_fact.best_month == m)& (y_fact.year == 2018) ,'pct_change_year'].values)[0]) \n",
    "#     new_2020 = pd.DataFrame({'best_month' : list(range(1,13)) ,\n",
    "#                              'pct_change_year' : np.array(pct_ch),\n",
    "#                             'year' : 2020})\n",
    "#     y_fact = pd.concat([new_2020,y_fact]).sort_values(by = ['best_month','year']).reset_index(drop = True)\n",
    "#     df_train1.loc[(df_train1.missing.notna())&(df_train1.missing!=0),'sellin_old'] = df_train1.loc[(df_train1.missing.notna())&(df_train1.missing!=0)].apply(lambda x : interpolate(x,strat = 'linear'),axis = 1)\n",
    "#     df_train = df_train1.drop(['year_old','month_old','pct_change_sellin','pct_change_year','missing'],axis = 1)\n",
    "#     df_test.drop(['year_old','month_old'],axis = 1,inplace= True)\n",
    "#     return df_train,df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:34.208146Z",
     "iopub.status.busy": "2022-08-24T14:49:34.207367Z",
     "iopub.status.idle": "2022-08-24T14:49:34.921018Z",
     "shell.execute_reply": "2022-08-24T14:49:34.920014Z",
     "shell.execute_reply.started": "2022-08-24T14:49:34.208067Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train = df_train_ori.copy()\n",
    "# df_test = df_test_ori.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:57.732595Z",
     "iopub.status.busy": "2022-08-24T14:49:57.732040Z",
     "iopub.status.idle": "2022-08-24T14:49:57.738328Z",
     "shell.execute_reply": "2022-08-24T14:49:57.737037Z",
     "shell.execute_reply.started": "2022-08-24T14:49:57.732555Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:59.006024Z",
     "iopub.status.busy": "2022-08-24T14:49:59.005547Z",
     "iopub.status.idle": "2022-08-24T14:49:59.020575Z",
     "shell.execute_reply": "2022-08-24T14:49:59.018919Z",
     "shell.execute_reply.started": "2022-08-24T14:49:59.005987Z"
    }
   },
   "outputs": [],
   "source": [
    "# def add_more(df_train,df_test):\n",
    "#     def missing_years(y,m,y_o,m_o):\n",
    "#         flag = True\n",
    "#         if (m_o>m )and not ((m_o == 12) & (m ==1 )):\n",
    "#             flag = False\n",
    "#         flag2 = False\n",
    "#         if ((m_o == 12) & (m ==1 )) & (y_o+1 == y):\n",
    "#             flag2 = True\n",
    "#         missing_y = []\n",
    "#         while y>y_o:\n",
    "#             missing_y.append(y_o)\n",
    "#             y_o=y_o+1\n",
    "#         missing_m = []\n",
    "#         if flag:\n",
    "#             while m>m_o+1:\n",
    "#                 m_o=m_o+1\n",
    "#                 missing_m.append(m_o)\n",
    "\n",
    "#         else:\n",
    "#                 while m<m_o and not ((m_o == 12) & (m ==1 )):\n",
    "#                     m_o=m_o-1\n",
    "#                     missing_m.append(m_o-1)\n",
    "#         if (len(missing_y)==0) & (len(missing_m)==0):\n",
    "#             return np.nan\n",
    "#         elif flag2:\n",
    "#             return 0\n",
    "#         else:\n",
    "#             return np.array(missing_y),np.array(missing_m),flag\n",
    "\n",
    "#     def last_known_sellin(df_train,df_test):\n",
    "#     #     months_train = \n",
    "#     # df_train.iloc[1:].apply(rowIndex,axis= 1)-1\n",
    "#         ma = df_train.groupby('sku_name')['sellin'].apply(lambda x : np.median(x))\n",
    "#         df_train['medians'] = df_train['sku_name'].map(ma)\n",
    "#         a = df_train.merge(df_train.shift(1)[['sku_name','year','month','sellin']] ,left_index = True,right_index = True,suffixes = (None,'_old'))\n",
    "#         b = df_test.merge(df_train.loc[df_train.sku_name.isin(df_test.sku_name)].groupby('sku_name').apply(lambda x:x.iloc[-1])[['year','month','sellin']].reset_index(),\n",
    "#                      on = 'sku_name',how = 'left', suffixes = (None,'_old'))\n",
    "#         a['sellin_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['sellin_old'] , np.nan)\n",
    "#         a['month_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['month_old'] , np.nan)\n",
    "#         a['year_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['year_old'] , np.nan)\n",
    "#         a['period_old'] = np.where(a['sku_name'] == a['sku_name_old'], (a['year']-a['year_old'])*12 + (a['month']-a['month_old']) , np.nan)\n",
    "#         b['period_old'] = (b['year']-b['year_old'])*12 + (b['month']-b['month_old'])\n",
    "#         b['sellin_old'] = b['sellin']\n",
    "#         a['sellin_old'] = a['sellin_old'].fillna(a['medians'])\n",
    "#     #         med = a.groupby('sku_name')['medians'].mean()\n",
    "#         b['medians'] = b['sku_name'].map(ma)\n",
    "#         b['sellin_old'] = b['sellin_old'].fillna(b['medians'])\n",
    "#         b.head()\n",
    "#     #     a['last_change'] = a['sellin'].diff()/a['period_old']\n",
    "#     #     b['last_change'] = b['sellin'].diff()/b['period_old']\n",
    "#         a.loc[a.period_old>1,'sellin_old'] = a.loc[a.period_old>1].groupby('sku_name').apply(lambda a : np.power(a['sellin'].pct_change()+1,1/(a['period_old']))).fillna(0).values + a.loc[a.period_old>1,'medians']\n",
    "#         maps = a.groupby('sku_name').apply(lambda a : np.power(a['sellin'].pct_change()+1,1/(a['period_old'])).fillna(0).values[-1])\n",
    "#         b['pct_change'] = b['sku_name'].map(maps)\n",
    "#         b.loc[b.period_old>1,'sellin_old'] = b.loc[b.period_old>1,'sellin_old'] + (b.loc[b.period_old>1,'period_old']* b.loc[b.period_old>1,'pct_change'] )\n",
    "#         a.drop(['sku_name_old'],axis = 1,inplace = True)\n",
    "#         b.drop(['sellin'],axis = 1,inplace = True)\n",
    "#         return a,b\n",
    "#     def interpolate(Serie,strat = 'linear',c = 0):\n",
    "#         missing_months = Serie['missing'][1]\n",
    "#         missing_years = Serie['missing'][0]\n",
    "#         flag = Serie['missing'][2]\n",
    "#         if flag:\n",
    "#             power = 1\n",
    "#         else:\n",
    "#             power = -1\n",
    "#         bm = Serie['best_month']\n",
    "#         if len(missing_years)>1:\n",
    "#             yearly_fact = (y_fact.loc[(y_fact.best_month == bm)& (y_fact.year.isin(missing_years[1:])),'pct_change_year']+1).prod()\n",
    "#         else:\n",
    "#             yearly_fact = 1\n",
    "#         if len(missing_months)>0:\n",
    "#             monthly_fact = (fact.loc[(fact.best_month == bm)& (fact.month.isin(missing_months)),'pct_change_sellin']+1).prod()\n",
    "#         else:\n",
    "#             monthly_fact = 1\n",
    "#         if strat == 'linear':\n",
    "#             return ((monthly_fact)**power)*yearly_fact*Serie['sellin_old']\n",
    "#         if strat == 'constant':\n",
    "#             return c*Serie['sellin_old']\n",
    "#     df_train,df_test = last_known_sellin(df_train,df_test)\n",
    "#     groups = df_train.groupby(['sku_name','month'])['sellin'].sum().reset_index().pivot(index = 'sku_name',columns = 'month', values = 'sellin').idxmax(axis = 1)\n",
    "#     df_test['best_month'] = df_test['sku_name'].map(groups)\n",
    "#     df_train['best_month'] = df_train['sku_name'].map(groups).astype('int')\n",
    "#     df_test['best_month'].fillna(10,inplace = True)\n",
    "#     df_test['best_month'] = df_test['best_month'].astype('int')\n",
    "#     df_test['period_old'] = df_test['period_old'].fillna(0).astype('int')\n",
    "#     df_train['period_old'] = df_train['period_old'].fillna(0).astype('int')\n",
    "#     df_train1 = df_train.copy()\n",
    "#     df_test1 = df_test.copy()\n",
    "#     df_train1['pct_change_sellin'] = df_train1.groupby('sku_name').apply(lambda a : np.power(a['sellin'].pct_change()+1,1/(a['period_old']))).fillna(0).values\n",
    "#     fact = df_train1[['sku_name','month','year','best_month','pct_change_sellin']].groupby(['best_month','month'])['pct_change_sellin'].mean().reset_index()\n",
    "#     strat = 'constant'\n",
    "#     for m in [11,12,1]:\n",
    "#         for bm in range(1,13):\n",
    "#             if m==12:\n",
    "#                 M = 1\n",
    "#             else:\n",
    "#                 M = m+1\n",
    "#             if strat == 'linear':\n",
    "#                 df_test.loc[(df_test.best_month == bm)& (df_test.month == M),'sellin_old' ] =\\\n",
    "#                 df_test.loc[(df_test.best_month == bm)& (df_test.month == m),'sellin_old' ].values +\\\n",
    "#                 ((df_test.loc[(df_test.best_month == bm)& (df_test.month == m),'medians' ]-df_test.loc[(df_test.best_month == bm)& (df_test.month == m),'sellin_old' ].values)* \\\n",
    "#                  (fact.loc[(fact.best_month == bm)& (fact.month == M),'pct_change_sellin'].values-1)).values#*(/df_train.loc[(df_train.best_month == bm)& (df_train.month == m)]))\n",
    "#             elif strat =='constant':\n",
    "#                 df_test.loc[(df_test.best_month == bm)& (df_test.month == M),'sellin_old' ] =\\\n",
    "#                 df_test.loc[(df_test.best_month == bm)& (df_test.month == m),'sellin_old' ].values\n",
    "#                 continue\n",
    "\n",
    "#     a = df_train1[df_train1.year<2021].groupby(['sku_name','year'])['sellin'].mean().reset_index()\n",
    "#     b = a.groupby('sku_name')['sellin'].pct_change().fillna(0)/a.groupby('sku_name')['year'].diff().fillna(0)\n",
    "#     a['pct_change_year'] = b.fillna(0)\n",
    "#     df_train1 = df_train1.merge(a[['sku_name','year','pct_change_year']], on = ['sku_name','year'],how = 'left')\n",
    "#     y_fact = df_train1[df_train1.year<2021].groupby(['best_month','year'])['pct_change_year'].mean().reset_index().fillna(0)\n",
    "#     c = df_train1.apply(lambda x : missing_years(x['year'],x['month'],x['year_old'],x['month_old']),axis = 1)\n",
    "#     df_train1['missing'] = c\n",
    "#     pct_ch = []\n",
    "#     for m in range(1,13):\n",
    "#         pct_ch.append(((y_fact.loc[(y_fact.best_month == m)& (y_fact.year == 2019) ,'pct_change_year'].values - y_fact.loc[(y_fact.best_month == m)& (y_fact.year == 2018) ,'pct_change_year'].values)*2 + y_fact.loc[(y_fact.best_month == m)& (y_fact.year == 2018) ,'pct_change_year'].values)[0]) \n",
    "#     new_2020 = pd.DataFrame({'best_month' : list(range(1,13)) ,\n",
    "#                              'pct_change_year' : np.array(pct_ch),\n",
    "#                             'year' : 2020})\n",
    "#     y_fact = pd.concat([new_2020,y_fact]).sort_values(by = ['best_month','year']).reset_index(drop = True)\n",
    "#     df_train1.loc[(df_train1.missing.notna())&(df_train1.missing!=0),'sellin_old'] = df_train1.loc[(df_train1.missing.notna())&(df_train1.missing!=0)].apply(lambda x : interpolate(x,strat = 'constant',c=1),axis = 1)\n",
    "#     df_train = df_train1.copy()\n",
    "#     # drop(['year_old','month_old','pct_change_sellin','pct_change_year','missing'],axis = 1)\n",
    "#     # df_test.drop(['year_old','month_old'],axis = 1,inplace= True)\n",
    "#     df_test['sellin_old'] = df_test['sellin_old'].clip(df_test['sku_name'+target+'enc2'],df_test['sku_name'+target+'enc1'])\n",
    "#     df_train['sellin_old'] = df_train['sellin_old'].clip(df_train['sku_name'+target+'enc2'],df_train['sku_name'+target+'enc1'])\n",
    "#     return df_train,df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:49:59.764646Z",
     "iopub.status.busy": "2022-08-24T14:49:59.763367Z",
     "iopub.status.idle": "2022-08-24T14:49:59.769669Z",
     "shell.execute_reply": "2022-08-24T14:49:59.768268Z",
     "shell.execute_reply.started": "2022-08-24T14:49:59.764590Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.histplot(train['month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:05:56.089465Z",
     "iopub.status.busy": "2022-08-24T14:05:56.088808Z",
     "iopub.status.idle": "2022-08-24T14:05:56.097924Z",
     "shell.execute_reply": "2022-08-24T14:05:56.097082Z",
     "shell.execute_reply.started": "2022-08-24T14:05:56.089431Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.groupby('best_month').get_group(2)\n",
    "# fact[fact.best_month == 2]\n",
    "# df_train[df_train.sku_name == 'YOSHTLYNYOSHZZ']['sellin'].min()\n",
    "# df_test['sku_name'+target+'enc2']\n",
    "# df_test\n",
    "# df_test['sku_name'+target+'enc2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:05:56.099699Z",
     "iopub.status.busy": "2022-08-24T14:05:56.099193Z",
     "iopub.status.idle": "2022-08-24T14:05:56.110950Z",
     "shell.execute_reply": "2022-08-24T14:05:56.109821Z",
     "shell.execute_reply.started": "2022-08-24T14:05:56.099667Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train,df_test = add_more(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:05:56.112899Z",
     "iopub.status.busy": "2022-08-24T14:05:56.112564Z",
     "iopub.status.idle": "2022-08-24T14:05:56.142025Z",
     "shell.execute_reply": "2022-08-24T14:05:56.141237Z",
     "shell.execute_reply.started": "2022-08-24T14:05:56.112869Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test.loc[df_test.sellin_old.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:50:06.108293Z",
     "iopub.status.busy": "2022-08-24T14:50:06.107754Z",
     "iopub.status.idle": "2022-08-24T14:50:06.118371Z",
     "shell.execute_reply": "2022-08-24T14:50:06.117202Z",
     "shell.execute_reply.started": "2022-08-24T14:50:06.108253Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.loc[df_test.sellin_old.isna(),['sellin_old','period_old']] = 0\n",
    "df_test.loc[df_test.sellin_old2.isna(),['sellin_old2','period_old2']] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:50:07.943095Z",
     "iopub.status.busy": "2022-08-24T14:50:07.942564Z",
     "iopub.status.idle": "2022-08-24T14:50:07.973417Z",
     "shell.execute_reply": "2022-08-24T14:50:07.972214Z",
     "shell.execute_reply.started": "2022-08-24T14:50:07.943052Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test['size'].fillna(0,inplace = True)\n",
    "# df_train['size'] = df_train['sku_name'].map(df_train.groupby('sku_name').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:05:56.184426Z",
     "iopub.status.busy": "2022-08-24T14:05:56.182813Z",
     "iopub.status.idle": "2022-08-24T14:05:58.164709Z",
     "shell.execute_reply": "2022-08-24T14:05:58.163563Z",
     "shell.execute_reply.started": "2022-08-24T14:05:56.184379Z"
    }
   },
   "outputs": [],
   "source": [
    "# new_df = pd.concat([df_test.drop('pct_change',axis = 1),df_train[df_test.drop('pct_change',axis = 1).columns.tolist()]])\n",
    "# ids = test.sku_name.unique().tolist()\n",
    "# i = 5\n",
    "# x1 = new_df.groupby('sku_name').get_group(ids[i])[['month','year','sellin_old']].sort_values(by = ['year','month'])['sellin_old'].values\n",
    "# x2 = new_df.groupby('sku_name').get_group(ids[i])[['month','year','sellin_old']].sort_values(by = ['year','month'])['sellin_old'].values[-5:]\n",
    "# plt.plot(x1)\n",
    "# plt.plot(range(x1.shape[0]-5,x1.shape[0]),x2)\n",
    "# plt.axhline(y = np.median(x1[:-4]), color = 'r', linestyle = '-')\n",
    "# plt.axhline(y = np.mean(x1[:-4]), color = 'g', linestyle = '-')\n",
    "# df_train.loc[df_train.date]\n",
    "# df_train.groupby(['sku_name','date'])['sellin'].sum().reset_index()\n",
    "# plt.plot(df_train.groupby(['year','month'])['sellin'].sum().values)\n",
    "# for m in range(1,13):\n",
    "# plt.plot(df_train.loc[df_train.month == 10].groupby('year')['sellin'].mean())\n",
    "# (df_train.loc[(df_train.month == 10)&(df_train.year == 2019),'sellin'].sort_values().values)\n",
    "# plt.plot(df_train.loc[(df_train.month == 10)&(df_train.year == 2021),'sellin'].sort_values().values)\n",
    "# df_train['n_disc'] = df_train['sku_name'].map(df_train.groupby('sku_name').apply(lambda x : np.array((x['cum_disc']*(x['date']+1)).sort_values().unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:50:13.311671Z",
     "iopub.status.busy": "2022-08-24T14:50:13.311170Z",
     "iopub.status.idle": "2022-08-24T14:50:13.333704Z",
     "shell.execute_reply": "2022-08-24T14:50:13.332647Z",
     "shell.execute_reply.started": "2022-08-24T14:50:13.311631Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['date'] = df_train['date'].astype('int')\n",
    "df_test['date'] = df_test['date'].astype('int')\n",
    "df_train['size'] = df_train['size'].astype('int')\n",
    "df_test['size'] = df_test['size'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:50:19.430162Z",
     "iopub.status.busy": "2022-08-24T14:50:19.429596Z",
     "iopub.status.idle": "2022-08-24T14:50:19.436513Z",
     "shell.execute_reply": "2022-08-24T14:50:19.435060Z",
     "shell.execute_reply.started": "2022-08-24T14:50:19.430118Z"
    }
   },
   "outputs": [],
   "source": [
    "# # df_train['n_disc'][0]\n",
    "# ll = df_train.pivot(index = 'sku_name',columns = 'date',values = 'cum_disc')\n",
    "# for i in ll.loc[ll[8] == 1].index :\n",
    "#     plt.plot(df_train.loc[df_train.sku_name==i,'date'],df_train.loc[df_train.sku_name==i,'sellin'])\n",
    "# # == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:50:24.111187Z",
     "iopub.status.busy": "2022-08-24T14:50:24.110683Z",
     "iopub.status.idle": "2022-08-24T14:50:24.116854Z",
     "shell.execute_reply": "2022-08-24T14:50:24.115507Z",
     "shell.execute_reply.started": "2022-08-24T14:50:24.111149Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.groupby('n_disc').get_group(df_train.n_disc.unique()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:50:26.657290Z",
     "iopub.status.busy": "2022-08-24T14:50:26.655918Z",
     "iopub.status.idle": "2022-08-24T14:50:26.666011Z",
     "shell.execute_reply": "2022-08-24T14:50:26.665150Z",
     "shell.execute_reply.started": "2022-08-24T14:50:26.657229Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test.columns\n",
    "# df_test.select_dtypes(include = 'int').columns.tolist()\n",
    "# df_train[['month', 'year', 'CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
    "#        'CAT_GENDER_WOMEN', 'Weeks', 'date', 'price',\n",
    "#        'size', 'sellin_old', 'period_old', 'sellin_old2', 'period_old2',\n",
    "#        'first_appear']].isna().sum()\n",
    "df_test[['month', 'year', 'CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
    "       'CAT_GENDER_WOMEN', 'Weeks', 'date', 'price',\n",
    "       'size', 'sellin_old', 'period_old', 'sellin_old2', 'period_old2',\n",
    "       'first_appear']] = df_test[['month', 'year', 'CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
    "       'CAT_GENDER_WOMEN', 'Weeks', 'date', 'price',\n",
    "       'size', 'sellin_old', 'period_old', 'sellin_old2', 'period_old2',\n",
    "       'first_appear']].astype('int')\n",
    "df_train[['month', 'year', 'CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
    "       'CAT_GENDER_WOMEN', 'Weeks', 'date', 'price',\n",
    "       'size', 'sellin_old', 'period_old', 'sellin_old2', 'period_old2',\n",
    "       'first_appear']] = df_train[['month', 'year', 'CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
    "       'CAT_GENDER_WOMEN', 'Weeks', 'date', 'price',\n",
    "       'size', 'sellin_old', 'period_old', 'sellin_old2', 'period_old2',\n",
    "       'first_appear']].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:50:36.199055Z",
     "iopub.status.busy": "2022-08-24T14:50:36.197926Z",
     "iopub.status.idle": "2022-08-24T14:50:36.208160Z",
     "shell.execute_reply": "2022-08-24T14:50:36.206751Z",
     "shell.execute_reply.started": "2022-08-24T14:50:36.199008Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = df_test.select_dtypes(include = 'float64').columns.tolist()\n",
    "# scale = df_test.drop(['Weeks'],axis = 1).select_dtypes(include = 'float64').columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'year',\n",
       " 'CAT_GENDER_BOTH',\n",
       " 'CAT_GENDER_MEN',\n",
       " 'CAT_GENDER_WOMEN',\n",
       " 'Weeks',\n",
       " 'date',\n",
       " 'price',\n",
       " 'size',\n",
       " 'sellin_old',\n",
       " 'period_old',\n",
       " 'sellin_old2',\n",
       " 'period_old2',\n",
       " 'first_appear',\n",
       " 'enc_sku']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.select_dtypes(include = 'int').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.910e+02, 3.540e+02, 1.162e+03, ..., 1.000e+00, 2.000e+00,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 8.910e+02, 3.540e+02, ..., 0.000e+00, 1.000e+00,\n",
       "        2.000e+00]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pca.fit_transform(df_train[['sellin','sellin_old','date']].values.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['month',\n",
    " 'year',\n",
    " 'CAT_GENDER_BOTH',\n",
    " 'CAT_GENDER_MEN',\n",
    " 'CAT_GENDER_WOMEN',\n",
    " 'Weeks',\n",
    " 'date',\n",
    " 'price',\n",
    " 'size',\n",
    " 'sellin_old',\n",
    " 'period_old',\n",
    " 'sellin_old2',\n",
    " 'period_old2',\n",
    " 'first_appear']\n",
    "for li in col_list:\n",
    "    df_test[li] = df_test[li]- df_train[li].min()\n",
    "    df_train[li] = df_train[li]- df_train[li].min()\n",
    "Xtest_list = []\n",
    "X_list = []\n",
    "for li in col_list:\n",
    "    nparray_tr = np.array(df_train[li])\n",
    "    nparray_te = np.array(df_test[li])\n",
    "    Xtest_list.append(nparray_te)\n",
    "    X_list.append(nparray_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntitiyEmbedding:\n",
    "    def __init__(self):\n",
    "        self.input_model = []\n",
    "        self.output_model = []\n",
    "        self.features = []\n",
    "        self.embeddings = []\n",
    "\n",
    "    def add(self, feature, input_shape, output_shape):\n",
    "        self.features.append(feature)\n",
    "        self.embeddings.append(feature)\n",
    "        input_model = Input(shape=(1,),name=(feature + '_input'))\n",
    "        output_model = Embedding(input_shape, output_shape,name=(feature + '_out'))(input_model)\n",
    "        output_model = Reshape(target_shape=(output_shape,))(output_model)\n",
    "        self.input_model.append(input_model)\n",
    "        self.output_model.append(output_model)\n",
    "\n",
    "    def dense(self, feature, output_shape):\n",
    "        self.features.append(feature)\n",
    "        input_model = Input(shape=(output_shape,),name=(feature + '_input'))\n",
    "        output_model = Dense(output_shape,name=(feature + '_out'))(input_model)\n",
    "        self.input_model.append(input_model)\n",
    "        self.output_model.append(output_model)\n",
    "\n",
    "    def concatenate(self):\n",
    "        output_model = Concatenate()(self.output_model)\n",
    "        output_model = Dense(1000, kernel_initializer=\"uniform\")(output_model)\n",
    "        output_model = Activation('relu')(output_model)\n",
    "        output_model = Dense(500, kernel_initializer=\"uniform\")(output_model)\n",
    "        output_model = Activation('relu')(output_model)\n",
    "        output_model = Dense(1)(output_model)\n",
    "        output_model = Activation('sigmoid')(output_model)\n",
    "        self.model = KerasModel(inputs=self.input_model, outputs=output_model)\n",
    "        self.model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=12, batch_size=128):\n",
    "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "        pred = self.model.predict(X)\n",
    "        return pred\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "        \n",
    "    def get_weight(self):\n",
    "        weights = {}\n",
    "        for feature in self.features:\n",
    "            w = self.model.get_layer(feature + '_out').get_weights()[0]\n",
    "            columns = []\n",
    "            for i in range(w.shape[1]):\n",
    "                columns.append(feature + '_' + str(i))\n",
    "            w = pd.DataFrame(w, columns=columns)\n",
    "            w.index.names = [feature]\n",
    "            weights[feature] = w\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model as KerasModel\n",
    "from keras.layers import Input, Dense, Activation, Reshape, Dropout\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for \n",
    "f = []\n",
    "for li in col_list:\n",
    "    f.append(max(df_train[li].max(),df_test[li].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 6, 1, 1, 1, 1, 73, 455, 57, 22073, 54, 22073, 57, 70]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_columns =['month','year','CAT_GENDER_BOTH','CAT_GENDER_MEN',\n",
    "                   'CAT_GENDER_WOMEN','Weeks','date',\n",
    "                    'price','size','sellin_old','period_old',\n",
    "                   'sellin_old2','period_old2','first_appear']\n",
    "\n",
    "model = EntitiyEmbedding()\n",
    "model.add('month', input_shape=12, output_shape=5)\n",
    "model.add('year', input_shape=7, output_shape=3)\n",
    "model.dense('Weeks', output_shape=1)\n",
    "model.dense('CAT_GENDER_BOTH', output_shape=1)\n",
    "model.dense('CAT_GENDER_MEN', output_shape=1)\n",
    "\n",
    "model.dense('CAT_GENDER_WOMEN', output_shape=1)\n",
    "model.add('date', input_shape=74, output_shape=32)\n",
    "model.add('price', input_shape=456, output_shape=10)\n",
    "\n",
    "model.add('size', input_shape=58, output_shape=10)\n",
    "model.add('sellin_old', input_shape=22074, output_shape=10)\n",
    "model.add('period_old', input_shape=55, output_shape=10)\n",
    "model.add('sellin_old2', input_shape=22074, output_shape=10)\n",
    "model.add('period_old2', input_shape=58, output_shape=10)\n",
    "model.add('first_appear', input_shape=71, output_shape=10)\n",
    "\n",
    "# model.add('day', input_shape=31, output_shape=10)\n",
    "# model.add('StateHoliday', input_shape=4, output_shape=3)\n",
    "# model.add('hasCompetitionmonths', input_shape=25, output_shape=2)\n",
    "# model.add('hasPromo2weeks', input_shape=26, output_shape=1)\n",
    "# model.add('latest_promo2_months', input_shape=4, output_shape=1)\n",
    "# model.dense('CompetitionDistance', output_shape=1)\n",
    "# model.add('StoreType', input_shape=5, output_shape=2)\n",
    "# model.add('Assortment', input_shape=4, output_shape=3)\n",
    "# model.add('PromoInterval', input_shape=4, output_shape=3)\n",
    "# model.add('CompetitionOpenSinceYear', input_shape=18, output_shape=4)\n",
    "# model.add('Promo2SinceYear', input_shape=8, output_shape=4)\n",
    "# model.add('State',input_shape=12, output_shape=6)\n",
    "# model.add('week_of_year', input_shape=53, output_shape=10)\n",
    "# model.dense('temperature', output_shape=3)\n",
    "# model.dense('humidity', output_shape=3)\n",
    "# model.dense('windspeed', output_shape=2)\n",
    "# model.dense('CloudCover',  output_shape=1)\n",
    "# model.add('Events', input_shape=22, output_shape=4)\n",
    "# model.dense('state_trend', output_shape=1)\n",
    "model.concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "month_input (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "year_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "date_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "price_input (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "size_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sellin_old_input (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "period_old_input (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sellin_old2_input (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "period_old2_input (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_appear_input (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "month_out (Embedding)           (None, 1, 5)         60          month_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "year_out (Embedding)            (None, 1, 3)         21          year_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Weeks_input (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CAT_GENDER_BOTH_input (InputLay [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CAT_GENDER_MEN_input (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CAT_GENDER_WOMEN_input (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "date_out (Embedding)            (None, 1, 32)        2368        date_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "price_out (Embedding)           (None, 1, 10)        4560        price_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "size_out (Embedding)            (None, 1, 10)        580         size_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sellin_old_out (Embedding)      (None, 1, 10)        220740      sellin_old_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "period_old_out (Embedding)      (None, 1, 10)        550         period_old_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sellin_old2_out (Embedding)     (None, 1, 10)        220740      sellin_old2_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "period_old2_out (Embedding)     (None, 1, 10)        580         period_old2_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "first_appear_out (Embedding)    (None, 1, 10)        710         first_appear_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 5)            0           month_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 3)            0           year_out[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Weeks_out (Dense)               (None, 1)            2           Weeks_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "CAT_GENDER_BOTH_out (Dense)     (None, 1)            2           CAT_GENDER_BOTH_input[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "CAT_GENDER_MEN_out (Dense)      (None, 1)            2           CAT_GENDER_MEN_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "CAT_GENDER_WOMEN_out (Dense)    (None, 1)            2           CAT_GENDER_WOMEN_input[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 32)           0           date_out[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 10)           0           price_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_23 (Reshape)            (None, 10)           0           size_out[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_24 (Reshape)            (None, 10)           0           sellin_old_out[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_25 (Reshape)            (None, 10)           0           period_old_out[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_26 (Reshape)            (None, 10)           0           sellin_old2_out[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_27 (Reshape)            (None, 10)           0           period_old2_out[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_28 (Reshape)            (None, 10)           0           first_appear_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 114)          0           reshape_19[0][0]                 \n",
      "                                                                 reshape_20[0][0]                 \n",
      "                                                                 Weeks_out[0][0]                  \n",
      "                                                                 CAT_GENDER_BOTH_out[0][0]        \n",
      "                                                                 CAT_GENDER_MEN_out[0][0]         \n",
      "                                                                 CAT_GENDER_WOMEN_out[0][0]       \n",
      "                                                                 reshape_21[0][0]                 \n",
      "                                                                 reshape_22[0][0]                 \n",
      "                                                                 reshape_23[0][0]                 \n",
      "                                                                 reshape_24[0][0]                 \n",
      "                                                                 reshape_25[0][0]                 \n",
      "                                                                 reshape_26[0][0]                 \n",
      "                                                                 reshape_27[0][0]                 \n",
      "                                                                 reshape_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1000)         115000      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1000)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 500)          500500      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 500)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            501         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1)            0           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,066,918\n",
      "Trainable params: 1,066,918\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "338/338 [==============================] - 4s 12ms/step - loss: 0.0934\n",
      "Epoch 2/10\n",
      "338/338 [==============================] - 4s 12ms/step - loss: 0.0726\n",
      "Epoch 3/10\n",
      "338/338 [==============================] - 4s 12ms/step - loss: 0.0690\n",
      "Epoch 4/10\n",
      "338/338 [==============================] - 4s 12ms/step - loss: 0.0669:\n",
      "Epoch 5/10\n",
      "338/338 [==============================] - 4s 13ms/step - loss: 0.0651\n",
      "Epoch 6/10\n",
      "338/338 [==============================] - 4s 12ms/step - loss: 0.0636\n",
      "Epoch 7/10\n",
      "338/338 [==============================] - 4s 13ms/step - loss: 0.0620\n",
      "Epoch 8/10\n",
      "338/338 [==============================] - 4s 13ms/step - loss: 0.0607\n",
      "Epoch 9/10\n",
      "338/338 [==============================] - 4s 13ms/step - loss: 0.0594\n",
      "Epoch 10/10\n",
      "338/338 [==============================] - 4s 13ms/step - loss: 0.0579\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['sellin'] +1\n",
    "cmax = np.max(np.log1p(np.array(y_train)))\n",
    "model.fit(X_list, np.log1p(np.array(y_train))/cmax , epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "we = model.get_weight()\n",
    "emb_list = encoding_columns\n",
    "for col in emb_list:\n",
    "    df_train = df_train.merge(we[col].reset_index(),how='left',on=[col])\n",
    "    df_test = df_test.merge(we[col].reset_index(),how='left',on=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.corr()\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:11:09.229701Z",
     "iopub.status.busy": "2022-08-24T14:11:09.229282Z",
     "iopub.status.idle": "2022-08-24T14:11:09.235813Z",
     "shell.execute_reply": "2022-08-24T14:11:09.234433Z",
     "shell.execute_reply.started": "2022-08-24T14:11:09.229659Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train\n",
    "# df_train\n",
    "# df_test.columns\n",
    "# df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:58:07.201239Z",
     "iopub.status.busy": "2022-08-24T14:58:07.200337Z",
     "iopub.status.idle": "2022-08-24T14:58:51.177590Z",
     "shell.execute_reply": "2022-08-24T14:58:51.176434Z",
     "shell.execute_reply.started": "2022-08-24T14:58:07.201193Z"
    }
   },
   "outputs": [],
   "source": [
    "# feat =[]\n",
    "# th = 0.95\n",
    "# for c in df_test.select_dtypes(exclude = 'object').columns :\n",
    "#     if sum(df_train.corr()[c]>th) ==1 :\n",
    "#         feat.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:00:02.600645Z",
     "iopub.status.busy": "2022-08-24T15:00:02.600180Z",
     "iopub.status.idle": "2022-08-24T15:00:02.609547Z",
     "shell.execute_reply": "2022-08-24T15:00:02.608120Z",
     "shell.execute_reply.started": "2022-08-24T15:00:02.600610Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(feat)\n",
    "# feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:00:18.404039Z",
     "iopub.status.busy": "2022-08-24T15:00:18.403587Z",
     "iopub.status.idle": "2022-08-24T15:00:18.513407Z",
     "shell.execute_reply": "2022-08-24T15:00:18.511807Z",
     "shell.execute_reply.started": "2022-08-24T15:00:18.403995Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "for s in scale:\n",
    "    rs = RobustScaler()\n",
    "    df_train[s] = rs.fit_transform(df_train[s].values.reshape(-1, 1))\n",
    "    df_test[s] = rs.transform(df_test[s].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:00:24.799952Z",
     "iopub.status.busy": "2022-08-24T15:00:24.799395Z",
     "iopub.status.idle": "2022-08-24T15:00:24.805000Z",
     "shell.execute_reply": "2022-08-24T15:00:24.804028Z",
     "shell.execute_reply.started": "2022-08-24T15:00:24.799912Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# SC = MinMaxScaler()\n",
    "# df_train['sellin'] = SC.fit_transform(df_train['sellin'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:00:25.598267Z",
     "iopub.status.busy": "2022-08-24T15:00:25.597782Z",
     "iopub.status.idle": "2022-08-24T15:00:25.604755Z",
     "shell.execute_reply": "2022-08-24T15:00:25.603234Z",
     "shell.execute_reply.started": "2022-08-24T15:00:25.598229Z"
    }
   },
   "outputs": [],
   "source": [
    "# # df_train['sellin'].min()\n",
    "# # df_test.shape\n",
    "# # df_train\n",
    "# target = 'sellin'\n",
    "# prediction_columns = df_test.columns.tolist()\n",
    "# encoding_columns = [t for t in df_train.columns if t not in prediction_columns]\n",
    "# X = df_train.drop(encoding_columns+[target,'sku_name'],axis=1)\n",
    "# y = df_train[target]\n",
    "# # max_ = X['sku_name_target_enc1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:00:27.351711Z",
     "iopub.status.busy": "2022-08-24T15:00:27.351328Z",
     "iopub.status.idle": "2022-08-24T15:00:27.357217Z",
     "shell.execute_reply": "2022-08-24T15:00:27.355630Z",
     "shell.execute_reply.started": "2022-08-24T15:00:27.351680Z"
    }
   },
   "outputs": [],
   "source": [
    "# target = 'sellin'\n",
    "# prediction_columns = df_test.columns.tolist()\n",
    "# encoding_columns = [t for t in df_train.columns if t not in prediction_columns]\n",
    "# X = df_train.drop(encoding_columns+[target],axis=1)\n",
    "# y = df_train[target]\n",
    "# # max_ = X['sku_name_target_enc1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:00:28.015573Z",
     "iopub.status.busy": "2022-08-24T15:00:28.014913Z",
     "iopub.status.idle": "2022-08-24T15:00:28.021422Z",
     "shell.execute_reply": "2022-08-24T15:00:28.019945Z",
     "shell.execute_reply.started": "2022-08-24T15:00:28.015503Z"
    }
   },
   "outputs": [],
   "source": [
    "# cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:00:44.703309Z",
     "iopub.status.busy": "2022-08-24T15:00:44.702227Z",
     "iopub.status.idle": "2022-08-24T15:00:44.718337Z",
     "shell.execute_reply": "2022-08-24T15:00:44.714820Z",
     "shell.execute_reply.started": "2022-08-24T15:00:44.703222Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "#     y_true_rescaled = sca.inverse_transform(y_true.values.reshape(-1,1))\n",
    "#     y_pred_rescaled = sca.inverse_transform(y_pred.reshape(-1,1))\n",
    "    return  np.mean(np.abs(y_true - y_pred))*1013#(np.sqrt(np.mean(np.square((y_true - y_pred) / (y_true+2)))))\n",
    "\n",
    "def feval_RMSPE(preds, lgbm_train):\n",
    "    labels = lgbm_train.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),0), False\n",
    "\n",
    "params = {\n",
    "      \"objective\": \"mae\", \n",
    "      \"metric\": \"mae\", \n",
    "      \"boosting_type\": \"gbdt\",\n",
    "      'early_stopping_rounds': 30,\n",
    "      'learning_rate': 0.01,\n",
    "#       'lambda_l1': 1,\n",
    "#       'lambda_l2': 1,\n",
    "#       'feature_fraction': 0.8,\n",
    "#       'bagging_fraction': 0.8,\n",
    "    \n",
    "#       \"objective\": \"mae\", \n",
    "#       \"metric\": \"mae\", \n",
    "#       \"boosting_type\": \"gbdt\",\n",
    "#       'early_stopping_rounds': 30,\n",
    "#       'learning_rate': 0.01,\n",
    "#     'num_leaves': 170,\n",
    "#     'min_data_in_leaf': 10, \n",
    "#     'min_child_weight': 0.066978276178616,\n",
    "#     'max_depth': 10,\n",
    "#     'bagging_fraction': 0.6277904572518515, \n",
    "#     'feature_fraction': 0.6965518420559522, \n",
    "#     'lambda_l1': 1.6347289329468329, \n",
    "#     'lambda_l2': 0.1374430845238362 \n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:06:31.976379Z",
     "iopub.status.busy": "2022-08-24T14:06:31.975589Z",
     "iopub.status.idle": "2022-08-24T14:06:31.984222Z",
     "shell.execute_reply": "2022-08-24T14:06:31.983172Z",
     "shell.execute_reply.started": "2022-08-24T14:06:31.976338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'year', 'CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
       "       'CAT_GENDER_WOMEN', 'Weeks', 'date', 'price', 'size', 'sellin_old',\n",
       "       ...\n",
       "       'first_appear_6', 'first_appear_7', 'first_appear_8', 'first_appear_9',\n",
       "       'first_appear_10', 'first_appear_11', 'first_appear_12',\n",
       "       'first_appear_13', 'first_appear_14', 'first_appear_15'],\n",
       "      dtype='object', length=1241)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test.columns\n",
    "# df_train.drop(encoding_columns+[target]+['product_lifecycle_stage'],axis = 1)\n",
    "# (train[target]-train[target].min()+1)\n",
    "# sns.distplot(np.log1p(df_train[target] +1))\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = df_train.sku_name.isin(df_test.sku_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:37:49.299239Z",
     "iopub.status.busy": "2022-08-24T15:37:49.298265Z",
     "iopub.status.idle": "2022-08-24T15:39:05.987891Z",
     "shell.execute_reply": "2022-08-24T15:39:05.986512Z",
     "shell.execute_reply.started": "2022-08-24T15:37:49.299184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.982122\tvalid_1's l1: 0.991388\n",
      "[200]\ttraining's l1: 0.729084\tvalid_1's l1: 0.743748\n",
      "[300]\ttraining's l1: 0.654842\tvalid_1's l1: 0.673034\n",
      "[400]\ttraining's l1: 0.626739\tvalid_1's l1: 0.648072\n",
      "[500]\ttraining's l1: 0.612726\tvalid_1's l1: 0.636288\n",
      "[600]\ttraining's l1: 0.60455\tvalid_1's l1: 0.630371\n",
      "[700]\ttraining's l1: 0.598524\tvalid_1's l1: 0.626703\n",
      "[800]\ttraining's l1: 0.593907\tvalid_1's l1: 0.624165\n",
      "[900]\ttraining's l1: 0.587659\tvalid_1's l1: 0.620728\n",
      "[1000]\ttraining's l1: 0.583578\tvalid_1's l1: 0.618624\n",
      "[1100]\ttraining's l1: 0.580894\tvalid_1's l1: 0.617439\n",
      "[1200]\ttraining's l1: 0.579324\tvalid_1's l1: 0.616998\n",
      "[1300]\ttraining's l1: 0.57658\tvalid_1's l1: 0.6159\n",
      "[1400]\ttraining's l1: 0.574156\tvalid_1's l1: 0.615176\n",
      "[1500]\ttraining's l1: 0.572367\tvalid_1's l1: 0.614616\n",
      "[1600]\ttraining's l1: 0.571035\tvalid_1's l1: 0.61412\n",
      "[1700]\ttraining's l1: 0.569901\tvalid_1's l1: 0.613719\n",
      "[1800]\ttraining's l1: 0.569334\tvalid_1's l1: 0.613647\n",
      "Early stopping, best iteration is:\n",
      "[1831]\ttraining's l1: 0.5692\tvalid_1's l1: 0.613599\n",
      "****************************************************************************************************\n",
      "Fold : 2\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.980793\tvalid_1's l1: 0.996803\n",
      "[200]\ttraining's l1: 0.729121\tvalid_1's l1: 0.746936\n",
      "[300]\ttraining's l1: 0.655018\tvalid_1's l1: 0.674794\n",
      "[400]\ttraining's l1: 0.626893\tvalid_1's l1: 0.648003\n",
      "[500]\ttraining's l1: 0.61336\tvalid_1's l1: 0.635849\n",
      "[600]\ttraining's l1: 0.605313\tvalid_1's l1: 0.629691\n",
      "[700]\ttraining's l1: 0.599735\tvalid_1's l1: 0.625622\n",
      "[800]\ttraining's l1: 0.594912\tvalid_1's l1: 0.62251\n",
      "[900]\ttraining's l1: 0.590102\tvalid_1's l1: 0.619594\n",
      "[1000]\ttraining's l1: 0.585939\tvalid_1's l1: 0.617538\n",
      "[1100]\ttraining's l1: 0.582558\tvalid_1's l1: 0.615956\n",
      "[1200]\ttraining's l1: 0.580265\tvalid_1's l1: 0.61504\n",
      "[1300]\ttraining's l1: 0.578028\tvalid_1's l1: 0.614264\n",
      "Early stopping, best iteration is:\n",
      "[1300]\ttraining's l1: 0.578028\tvalid_1's l1: 0.614264\n",
      "****************************************************************************************************\n",
      "Fold : 3\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.98155\tvalid_1's l1: 0.995761\n",
      "[200]\ttraining's l1: 0.729338\tvalid_1's l1: 0.750964\n",
      "[300]\ttraining's l1: 0.654913\tvalid_1's l1: 0.679464\n",
      "[400]\ttraining's l1: 0.626655\tvalid_1's l1: 0.653617\n",
      "[500]\ttraining's l1: 0.612838\tvalid_1's l1: 0.642362\n",
      "[600]\ttraining's l1: 0.604119\tvalid_1's l1: 0.635876\n",
      "[700]\ttraining's l1: 0.59787\tvalid_1's l1: 0.631912\n",
      "[800]\ttraining's l1: 0.592285\tvalid_1's l1: 0.628557\n",
      "[900]\ttraining's l1: 0.587381\tvalid_1's l1: 0.626152\n",
      "[1000]\ttraining's l1: 0.583343\tvalid_1's l1: 0.624498\n",
      "[1100]\ttraining's l1: 0.581213\tvalid_1's l1: 0.623454\n",
      "[1200]\ttraining's l1: 0.579262\tvalid_1's l1: 0.62249\n",
      "[1300]\ttraining's l1: 0.576047\tvalid_1's l1: 0.620918\n",
      "[1400]\ttraining's l1: 0.573346\tvalid_1's l1: 0.619735\n",
      "[1500]\ttraining's l1: 0.571305\tvalid_1's l1: 0.619042\n",
      "[1600]\ttraining's l1: 0.568345\tvalid_1's l1: 0.617941\n",
      "[1700]\ttraining's l1: 0.56597\tvalid_1's l1: 0.617195\n",
      "[1800]\ttraining's l1: 0.564292\tvalid_1's l1: 0.616805\n",
      "[1900]\ttraining's l1: 0.560901\tvalid_1's l1: 0.615708\n",
      "[2000]\ttraining's l1: 0.558908\tvalid_1's l1: 0.615086\n",
      "Early stopping, best iteration is:\n",
      "[1989]\ttraining's l1: 0.558932\tvalid_1's l1: 0.615077\n",
      "****************************************************************************************************\n",
      "Fold : 4\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.979939\tvalid_1's l1: 0.994096\n",
      "[200]\ttraining's l1: 0.727767\tvalid_1's l1: 0.749813\n",
      "[300]\ttraining's l1: 0.653814\tvalid_1's l1: 0.680469\n",
      "[400]\ttraining's l1: 0.625983\tvalid_1's l1: 0.655214\n",
      "[500]\ttraining's l1: 0.61177\tvalid_1's l1: 0.643001\n",
      "[600]\ttraining's l1: 0.603927\tvalid_1's l1: 0.637414\n",
      "[700]\ttraining's l1: 0.598185\tvalid_1's l1: 0.633791\n",
      "[800]\ttraining's l1: 0.593132\tvalid_1's l1: 0.630578\n",
      "[900]\ttraining's l1: 0.587524\tvalid_1's l1: 0.627274\n",
      "[1000]\ttraining's l1: 0.582703\tvalid_1's l1: 0.625095\n",
      "[1100]\ttraining's l1: 0.579428\tvalid_1's l1: 0.623531\n",
      "[1200]\ttraining's l1: 0.577605\tvalid_1's l1: 0.622913\n",
      "[1300]\ttraining's l1: 0.574839\tvalid_1's l1: 0.621923\n",
      "[1400]\ttraining's l1: 0.571566\tvalid_1's l1: 0.62071\n",
      "[1500]\ttraining's l1: 0.568848\tvalid_1's l1: 0.619662\n",
      "[1600]\ttraining's l1: 0.567345\tvalid_1's l1: 0.619026\n",
      "[1700]\ttraining's l1: 0.565647\tvalid_1's l1: 0.618461\n",
      "[1800]\ttraining's l1: 0.56318\tvalid_1's l1: 0.617652\n",
      "[1900]\ttraining's l1: 0.5602\tvalid_1's l1: 0.616366\n",
      "[2000]\ttraining's l1: 0.558093\tvalid_1's l1: 0.615658\n",
      "[2100]\ttraining's l1: 0.555859\tvalid_1's l1: 0.61492\n",
      "[2200]\ttraining's l1: 0.553066\tvalid_1's l1: 0.614039\n",
      "[2300]\ttraining's l1: 0.55098\tvalid_1's l1: 0.613425\n",
      "[2400]\ttraining's l1: 0.54901\tvalid_1's l1: 0.612907\n",
      "[2500]\ttraining's l1: 0.546933\tvalid_1's l1: 0.612333\n",
      "[2600]\ttraining's l1: 0.545746\tvalid_1's l1: 0.612197\n",
      "[2700]\ttraining's l1: 0.545004\tvalid_1's l1: 0.612171\n",
      "[2800]\ttraining's l1: 0.543613\tvalid_1's l1: 0.611858\n",
      "[2900]\ttraining's l1: 0.541712\tvalid_1's l1: 0.61132\n",
      "[3000]\ttraining's l1: 0.539957\tvalid_1's l1: 0.610774\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.539957\tvalid_1's l1: 0.610774\n",
      "****************************************************************************************************\n",
      "Fold : 5\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.979908\tvalid_1's l1: 0.979753\n",
      "[200]\ttraining's l1: 0.727768\tvalid_1's l1: 0.74506\n",
      "[300]\ttraining's l1: 0.654005\tvalid_1's l1: 0.681264\n",
      "[400]\ttraining's l1: 0.625858\tvalid_1's l1: 0.659732\n",
      "[500]\ttraining's l1: 0.612631\tvalid_1's l1: 0.650421\n",
      "[600]\ttraining's l1: 0.604076\tvalid_1's l1: 0.644503\n",
      "[700]\ttraining's l1: 0.598429\tvalid_1's l1: 0.64087\n",
      "[800]\ttraining's l1: 0.595141\tvalid_1's l1: 0.639023\n",
      "[900]\ttraining's l1: 0.589338\tvalid_1's l1: 0.636118\n",
      "[1000]\ttraining's l1: 0.58545\tvalid_1's l1: 0.6344\n",
      "[1100]\ttraining's l1: 0.582558\tvalid_1's l1: 0.63318\n",
      "[1200]\ttraining's l1: 0.579868\tvalid_1's l1: 0.631971\n",
      "[1300]\ttraining's l1: 0.57745\tvalid_1's l1: 0.630884\n",
      "[1400]\ttraining's l1: 0.576255\tvalid_1's l1: 0.630437\n",
      "[1500]\ttraining's l1: 0.573657\tvalid_1's l1: 0.629455\n",
      "[1600]\ttraining's l1: 0.570502\tvalid_1's l1: 0.62812\n",
      "[1700]\ttraining's l1: 0.568328\tvalid_1's l1: 0.627185\n",
      "[1800]\ttraining's l1: 0.566105\tvalid_1's l1: 0.626052\n",
      "[1900]\ttraining's l1: 0.564491\tvalid_1's l1: 0.625505\n",
      "[2000]\ttraining's l1: 0.563082\tvalid_1's l1: 0.624859\n",
      "[2100]\ttraining's l1: 0.561135\tvalid_1's l1: 0.624205\n",
      "[2200]\ttraining's l1: 0.558887\tvalid_1's l1: 0.623467\n",
      "[2300]\ttraining's l1: 0.557189\tvalid_1's l1: 0.622809\n",
      "[2400]\ttraining's l1: 0.5557\tvalid_1's l1: 0.622285\n",
      "[2500]\ttraining's l1: 0.553977\tvalid_1's l1: 0.621547\n",
      "[2600]\ttraining's l1: 0.55231\tvalid_1's l1: 0.620958\n",
      "[2700]\ttraining's l1: 0.551296\tvalid_1's l1: 0.620644\n",
      "Early stopping, best iteration is:\n",
      "[2687]\ttraining's l1: 0.551337\tvalid_1's l1: 0.620628\n",
      "****************************************************************************************************\n",
      "Fold : 6\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.979629\tvalid_1's l1: 0.998068\n",
      "[200]\ttraining's l1: 0.728596\tvalid_1's l1: 0.748941\n",
      "[300]\ttraining's l1: 0.654932\tvalid_1's l1: 0.681569\n",
      "[400]\ttraining's l1: 0.627329\tvalid_1's l1: 0.657104\n",
      "[500]\ttraining's l1: 0.613448\tvalid_1's l1: 0.64558\n",
      "[600]\ttraining's l1: 0.605493\tvalid_1's l1: 0.639674\n",
      "[700]\ttraining's l1: 0.59898\tvalid_1's l1: 0.63539\n",
      "[800]\ttraining's l1: 0.593505\tvalid_1's l1: 0.631952\n",
      "[900]\ttraining's l1: 0.588759\tvalid_1's l1: 0.629541\n",
      "[1000]\ttraining's l1: 0.583273\tvalid_1's l1: 0.626709\n",
      "[1100]\ttraining's l1: 0.579892\tvalid_1's l1: 0.625021\n",
      "[1200]\ttraining's l1: 0.577421\tvalid_1's l1: 0.623725\n",
      "[1300]\ttraining's l1: 0.575679\tvalid_1's l1: 0.622775\n",
      "[1400]\ttraining's l1: 0.573123\tvalid_1's l1: 0.621673\n",
      "[1500]\ttraining's l1: 0.57137\tvalid_1's l1: 0.620855\n",
      "[1600]\ttraining's l1: 0.56915\tvalid_1's l1: 0.620007\n",
      "[1700]\ttraining's l1: 0.566797\tvalid_1's l1: 0.619174\n",
      "[1800]\ttraining's l1: 0.564905\tvalid_1's l1: 0.618376\n",
      "[1900]\ttraining's l1: 0.563226\tvalid_1's l1: 0.617508\n",
      "[2000]\ttraining's l1: 0.561693\tvalid_1's l1: 0.616946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2100]\ttraining's l1: 0.560395\tvalid_1's l1: 0.616517\n",
      "[2200]\ttraining's l1: 0.559701\tvalid_1's l1: 0.616151\n",
      "[2300]\ttraining's l1: 0.558608\tvalid_1's l1: 0.615447\n",
      "[2400]\ttraining's l1: 0.556735\tvalid_1's l1: 0.614754\n",
      "[2500]\ttraining's l1: 0.55534\tvalid_1's l1: 0.614239\n",
      "[2600]\ttraining's l1: 0.553839\tvalid_1's l1: 0.61366\n",
      "[2700]\ttraining's l1: 0.552686\tvalid_1's l1: 0.613213\n",
      "[2800]\ttraining's l1: 0.551103\tvalid_1's l1: 0.612588\n",
      "[2900]\ttraining's l1: 0.549504\tvalid_1's l1: 0.612011\n",
      "[3000]\ttraining's l1: 0.547104\tvalid_1's l1: 0.611381\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.547104\tvalid_1's l1: 0.611381\n",
      "****************************************************************************************************\n",
      "Fold : 7\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.982093\tvalid_1's l1: 0.983272\n",
      "[200]\ttraining's l1: 0.728465\tvalid_1's l1: 0.74227\n",
      "[300]\ttraining's l1: 0.654211\tvalid_1's l1: 0.674672\n",
      "[400]\ttraining's l1: 0.625791\tvalid_1's l1: 0.649471\n",
      "[500]\ttraining's l1: 0.612561\tvalid_1's l1: 0.63901\n",
      "[600]\ttraining's l1: 0.604031\tvalid_1's l1: 0.632542\n",
      "[700]\ttraining's l1: 0.597947\tvalid_1's l1: 0.628235\n",
      "[800]\ttraining's l1: 0.592487\tvalid_1's l1: 0.624849\n",
      "[900]\ttraining's l1: 0.587391\tvalid_1's l1: 0.622228\n",
      "[1000]\ttraining's l1: 0.58293\tvalid_1's l1: 0.619995\n",
      "[1100]\ttraining's l1: 0.579051\tvalid_1's l1: 0.61851\n",
      "[1200]\ttraining's l1: 0.575918\tvalid_1's l1: 0.617319\n",
      "[1300]\ttraining's l1: 0.573031\tvalid_1's l1: 0.616178\n",
      "[1400]\ttraining's l1: 0.571086\tvalid_1's l1: 0.615563\n",
      "[1500]\ttraining's l1: 0.569432\tvalid_1's l1: 0.615148\n",
      "[1600]\ttraining's l1: 0.568249\tvalid_1's l1: 0.614731\n",
      "[1700]\ttraining's l1: 0.566756\tvalid_1's l1: 0.614211\n",
      "[1800]\ttraining's l1: 0.565424\tvalid_1's l1: 0.613865\n",
      "[1900]\ttraining's l1: 0.563771\tvalid_1's l1: 0.613245\n",
      "[2000]\ttraining's l1: 0.561394\tvalid_1's l1: 0.612472\n",
      "[2100]\ttraining's l1: 0.559735\tvalid_1's l1: 0.611988\n",
      "[2200]\ttraining's l1: 0.557968\tvalid_1's l1: 0.611429\n",
      "[2300]\ttraining's l1: 0.556254\tvalid_1's l1: 0.610883\n",
      "[2400]\ttraining's l1: 0.554814\tvalid_1's l1: 0.610487\n",
      "[2500]\ttraining's l1: 0.553514\tvalid_1's l1: 0.610156\n",
      "[2600]\ttraining's l1: 0.552384\tvalid_1's l1: 0.609779\n",
      "[2700]\ttraining's l1: 0.551429\tvalid_1's l1: 0.609539\n",
      "[2800]\ttraining's l1: 0.55019\tvalid_1's l1: 0.609193\n",
      "[2900]\ttraining's l1: 0.548749\tvalid_1's l1: 0.608867\n",
      "[3000]\ttraining's l1: 0.548297\tvalid_1's l1: 0.608822\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.548297\tvalid_1's l1: 0.608822\n",
      "****************************************************************************************************\n",
      "Fold : 8\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.978447\tvalid_1's l1: 0.989205\n",
      "[200]\ttraining's l1: 0.727708\tvalid_1's l1: 0.743747\n",
      "[300]\ttraining's l1: 0.653552\tvalid_1's l1: 0.672716\n",
      "[400]\ttraining's l1: 0.625543\tvalid_1's l1: 0.64717\n",
      "[500]\ttraining's l1: 0.611521\tvalid_1's l1: 0.636019\n",
      "[600]\ttraining's l1: 0.60323\tvalid_1's l1: 0.630597\n",
      "[700]\ttraining's l1: 0.598001\tvalid_1's l1: 0.627408\n",
      "[800]\ttraining's l1: 0.593023\tvalid_1's l1: 0.624413\n",
      "[900]\ttraining's l1: 0.588067\tvalid_1's l1: 0.621646\n",
      "[1000]\ttraining's l1: 0.582718\tvalid_1's l1: 0.618633\n",
      "[1100]\ttraining's l1: 0.579701\tvalid_1's l1: 0.617248\n",
      "[1200]\ttraining's l1: 0.576965\tvalid_1's l1: 0.615751\n",
      "[1300]\ttraining's l1: 0.574939\tvalid_1's l1: 0.61479\n",
      "[1400]\ttraining's l1: 0.572042\tvalid_1's l1: 0.613435\n",
      "[1500]\ttraining's l1: 0.568578\tvalid_1's l1: 0.61192\n",
      "[1600]\ttraining's l1: 0.567022\tvalid_1's l1: 0.611437\n",
      "[1700]\ttraining's l1: 0.565679\tvalid_1's l1: 0.610987\n",
      "[1800]\ttraining's l1: 0.56338\tvalid_1's l1: 0.610129\n",
      "[1900]\ttraining's l1: 0.561765\tvalid_1's l1: 0.609523\n",
      "[2000]\ttraining's l1: 0.560106\tvalid_1's l1: 0.608903\n",
      "[2100]\ttraining's l1: 0.558768\tvalid_1's l1: 0.608449\n",
      "[2200]\ttraining's l1: 0.556517\tvalid_1's l1: 0.607806\n",
      "[2300]\ttraining's l1: 0.554044\tvalid_1's l1: 0.607109\n",
      "[2400]\ttraining's l1: 0.551443\tvalid_1's l1: 0.606396\n",
      "[2500]\ttraining's l1: 0.549292\tvalid_1's l1: 0.605849\n",
      "[2600]\ttraining's l1: 0.546474\tvalid_1's l1: 0.605062\n",
      "[2700]\ttraining's l1: 0.543756\tvalid_1's l1: 0.604409\n",
      "Early stopping, best iteration is:\n",
      "[2758]\ttraining's l1: 0.542491\tvalid_1's l1: 0.604148\n",
      "****************************************************************************************************\n",
      "Fold : 9\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.981014\tvalid_1's l1: 0.986886\n",
      "[200]\ttraining's l1: 0.728844\tvalid_1's l1: 0.739307\n",
      "[300]\ttraining's l1: 0.655003\tvalid_1's l1: 0.670347\n",
      "[400]\ttraining's l1: 0.627311\tvalid_1's l1: 0.645967\n",
      "[500]\ttraining's l1: 0.614113\tvalid_1's l1: 0.634694\n",
      "[600]\ttraining's l1: 0.60574\tvalid_1's l1: 0.628483\n",
      "[700]\ttraining's l1: 0.599941\tvalid_1's l1: 0.624723\n",
      "[800]\ttraining's l1: 0.595605\tvalid_1's l1: 0.621341\n",
      "[900]\ttraining's l1: 0.591295\tvalid_1's l1: 0.618285\n",
      "[1000]\ttraining's l1: 0.586737\tvalid_1's l1: 0.615183\n",
      "[1100]\ttraining's l1: 0.581827\tvalid_1's l1: 0.612355\n",
      "[1200]\ttraining's l1: 0.577886\tvalid_1's l1: 0.610489\n",
      "[1300]\ttraining's l1: 0.574659\tvalid_1's l1: 0.608992\n",
      "[1400]\ttraining's l1: 0.572033\tvalid_1's l1: 0.607729\n",
      "[1500]\ttraining's l1: 0.569718\tvalid_1's l1: 0.606894\n",
      "[1600]\ttraining's l1: 0.567144\tvalid_1's l1: 0.606032\n",
      "[1700]\ttraining's l1: 0.564483\tvalid_1's l1: 0.605264\n",
      "[1800]\ttraining's l1: 0.56198\tvalid_1's l1: 0.604234\n",
      "[1900]\ttraining's l1: 0.560056\tvalid_1's l1: 0.603469\n",
      "[2000]\ttraining's l1: 0.557804\tvalid_1's l1: 0.602713\n",
      "[2100]\ttraining's l1: 0.555405\tvalid_1's l1: 0.601896\n",
      "[2200]\ttraining's l1: 0.553028\tvalid_1's l1: 0.601127\n",
      "[2300]\ttraining's l1: 0.551628\tvalid_1's l1: 0.60075\n",
      "[2400]\ttraining's l1: 0.550194\tvalid_1's l1: 0.600347\n",
      "[2500]\ttraining's l1: 0.549139\tvalid_1's l1: 0.600092\n",
      "[2600]\ttraining's l1: 0.548095\tvalid_1's l1: 0.599785\n",
      "[2700]\ttraining's l1: 0.546593\tvalid_1's l1: 0.599399\n",
      "[2800]\ttraining's l1: 0.54452\tvalid_1's l1: 0.598901\n",
      "[2900]\ttraining's l1: 0.542026\tvalid_1's l1: 0.598471\n",
      "[3000]\ttraining's l1: 0.539146\tvalid_1's l1: 0.597715\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.539146\tvalid_1's l1: 0.597715\n",
      "****************************************************************************************************\n",
      "Fold : 10\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's l1: 0.981514\tvalid_1's l1: 0.989665\n",
      "[200]\ttraining's l1: 0.730502\tvalid_1's l1: 0.737956\n",
      "[300]\ttraining's l1: 0.656639\tvalid_1's l1: 0.663435\n",
      "[400]\ttraining's l1: 0.628938\tvalid_1's l1: 0.637155\n",
      "[500]\ttraining's l1: 0.614491\tvalid_1's l1: 0.625658\n",
      "[600]\ttraining's l1: 0.606575\tvalid_1's l1: 0.620367\n",
      "[700]\ttraining's l1: 0.600892\tvalid_1's l1: 0.616627\n",
      "[800]\ttraining's l1: 0.595167\tvalid_1's l1: 0.613126\n",
      "[900]\ttraining's l1: 0.59034\tvalid_1's l1: 0.610518\n",
      "[1000]\ttraining's l1: 0.586707\tvalid_1's l1: 0.60879\n",
      "[1100]\ttraining's l1: 0.583898\tvalid_1's l1: 0.60762\n",
      "[1200]\ttraining's l1: 0.581997\tvalid_1's l1: 0.606876\n",
      "[1300]\ttraining's l1: 0.579941\tvalid_1's l1: 0.606042\n",
      "[1400]\ttraining's l1: 0.577306\tvalid_1's l1: 0.604866\n",
      "[1500]\ttraining's l1: 0.574665\tvalid_1's l1: 0.603937\n",
      "[1600]\ttraining's l1: 0.571824\tvalid_1's l1: 0.602689\n",
      "[1700]\ttraining's l1: 0.570088\tvalid_1's l1: 0.602054\n",
      "[1800]\ttraining's l1: 0.568651\tvalid_1's l1: 0.601331\n",
      "[1900]\ttraining's l1: 0.567605\tvalid_1's l1: 0.600853\n",
      "[2000]\ttraining's l1: 0.566139\tvalid_1's l1: 0.600224\n",
      "[2100]\ttraining's l1: 0.564899\tvalid_1's l1: 0.599981\n",
      "[2200]\ttraining's l1: 0.562614\tvalid_1's l1: 0.599338\n",
      "[2300]\ttraining's l1: 0.560852\tvalid_1's l1: 0.598753\n",
      "[2400]\ttraining's l1: 0.55961\tvalid_1's l1: 0.598395\n",
      "[2500]\ttraining's l1: 0.557376\tvalid_1's l1: 0.597844\n",
      "[2600]\ttraining's l1: 0.555336\tvalid_1's l1: 0.597167\n",
      "[2700]\ttraining's l1: 0.554436\tvalid_1's l1: 0.596945\n",
      "[2800]\ttraining's l1: 0.553116\tvalid_1's l1: 0.596526\n",
      "[2900]\ttraining's l1: 0.550895\tvalid_1's l1: 0.596067\n",
      "[3000]\ttraining's l1: 0.549436\tvalid_1's l1: 0.595913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.549436\tvalid_1's l1: 0.595913\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "104530.26789782607\n"
     ]
    }
   ],
   "source": [
    "# cols = ['CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
    "#        'CAT_GENDER_WOMEN', 'Weeks', 'date', 'size', 'sku_namesellinenc6',\n",
    "#        'sku_namesellinenc5', 'sku_namesellinenc4', 'sku_namesellinenc',\n",
    "#        'sku_namesellinenc1', 'sku_namesellinenc2', 'sku_namesellinenc3',\n",
    "#        'sku_nameselloutenc6', 'sku_nameselloutenc5', 'sku_nameselloutenc4',\n",
    "#        'sku_nameselloutenc', 'sku_nameselloutenc1', 'sku_nameselloutenc2',\n",
    "#        'sku_nameselloutenc3', 'sku_namepriceenc6', 'sku_namepriceenc5',\n",
    "#        'sku_namepriceenc4', 'sku_namepriceenc', 'sku_namepriceenc1',\n",
    "#        'sku_namepriceenc2', 'sku_namepriceenc3',\n",
    "#        'sku_namestarting_inventoryenc6', 'sku_namestarting_inventoryenc5',\n",
    "#        'sku_namestarting_inventoryenc4', 'sku_namestarting_inventoryenc',\n",
    "#        'sku_namestarting_inventoryenc1', 'sku_namestarting_inventoryenc2',\n",
    "#        'sku_namestarting_inventoryenc3', 'sku_nameleftover_inventoryenc6',\n",
    "#        'sku_nameleftover_inventoryenc5', 'sku_nameleftover_inventoryenc4',\n",
    "#        'sku_nameleftover_inventoryenc', 'sku_nameleftover_inventoryenc1',\n",
    "#        'sku_nameleftover_inventoryenc2', 'sku_nameleftover_inventoryenc3',\n",
    "#        'sellin_old', 'period_old']\n",
    "# cols = feat\n",
    "kfolds = 10\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=kfolds, random_state=19901028, shuffle=True)\n",
    "# kf = PurgedGroupTimeSeriesSplit(n_splits = kfolds, group_gap = 1)\n",
    "oof = pd.DataFrame()                 # out-of-fold result\n",
    "models = []                          # models\n",
    "params = {\n",
    "      \"objective\": \"mae\", \n",
    "      \"metric\": \"mae\", \n",
    "      \"boosting_type\": \"gbdt\",\n",
    "      'early_stopping_rounds': 30,\n",
    "      'learning_rate': 0.01,\n",
    "#       'lambda_l1': 1,\n",
    "#       'lambda_l2': 1,\n",
    "#       'feature_fraction': 0.8,\n",
    "#       'bagging_fraction': 0.8,\n",
    "    \n",
    "#       \"objective\": \"mae\", \n",
    "#       \"metric\": \"mae\", \n",
    "#       \"boosting_type\": \"gbdt\",\n",
    "#       'early_stopping_rounds': 30,\n",
    "#       'learning_rate': 0.01,\n",
    "#     'num_leaves': 170,\n",
    "#     'min_data_in_leaf': 10, \n",
    "#     'min_child_weight': 0.066978276178616,\n",
    "#     'max_depth': 10,\n",
    "#     'bagging_fraction': 0.6277904572518515, \n",
    "#     'feature_fraction': 0.6965518420559522, \n",
    "#     'lambda_l1': 1.6347289329468329, \n",
    "#     'lambda_l2': 0.1374430845238362 \n",
    "  }\n",
    "# validation score\n",
    "\n",
    "def rmspe_log(y_true, y_pred):\n",
    "    min_sellin = -1\n",
    "    y_true_l = np.expm1(y_true)-min_sellin\n",
    "    y_pred_l = np.expm1(y_pred)-min_sellin\n",
    "    return  np.mean(np.abs(y_true_l - y_pred_l))*1013#(np.sqrt(np.mean(np.square((y_true - y_pred) / (y_true+2)))))\n",
    "\n",
    "def feval_RMSPE_log(preds, lgbm_train):\n",
    "    labels = lgbm_train.get_label()\n",
    "    return 'RMSPE', round(rmspe_log(y_true = labels, y_pred = preds),0), False\n",
    "target = 'sellin'\n",
    "scooores = []\n",
    "prediction_columns = df_test.columns.tolist()\n",
    "# encoding_columns = [t for t in df_train.columns if t not in prediction_columns]\n",
    "feat_log = ['year', 'month', 'price', 'CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
    "       'CAT_GENDER_WOMEN', 'Weeks', 'date', 'size', 'sellin_old',\n",
    "       'sellin_old2', 'period_old', 'period_old2', 'sku_namesellinenc6',\n",
    "       'sku_namesellinenc5', 'sku_namesellinenc4', 'sku_namesellinenc',\n",
    "       'sku_namesellinenc1', 'sku_namesellinenc2', 'sku_namesellinenc3',\n",
    "       'sku_nameselloutenc6', 'sku_nameselloutenc5', 'sku_nameselloutenc4',\n",
    "       'sku_nameselloutenc', 'sku_nameselloutenc1', 'sku_nameselloutenc2',\n",
    "       'sku_nameselloutenc3', 'sku_namepriceenc6', 'sku_namepriceenc5',\n",
    "       'sku_namepriceenc4', 'sku_namepriceenc', 'sku_namepriceenc1',\n",
    "       'sku_namepriceenc2', 'sku_namepriceenc3',\n",
    "       'sku_namestarting_inventoryenc6', 'sku_namestarting_inventoryenc5',\n",
    "       'sku_namestarting_inventoryenc4', 'sku_namestarting_inventoryenc',\n",
    "       'sku_namestarting_inventoryenc1', 'sku_namestarting_inventoryenc2',\n",
    "       'sku_namestarting_inventoryenc3', 'sku_nameleftover_inventoryenc6',\n",
    "       'sku_nameleftover_inventoryenc5', 'sku_nameleftover_inventoryenc4',\n",
    "       'sku_nameleftover_inventoryenc', 'sku_nameleftover_inventoryenc1',\n",
    "       'sku_nameleftover_inventoryenc2', 'sku_nameleftover_inventoryenc3',\n",
    "       'enc_sku']\n",
    "feat = ['year', 'month', 'price', 'CAT_GENDER_BOTH', 'CAT_GENDER_MEN',\n",
    "       'CAT_GENDER_WOMEN', 'sku_namesellinenc6',\n",
    "       'sku_namesellinenc5', 'sku_namesellinenc4', 'sku_namesellinenc',\n",
    "       'sku_namesellinenc1', 'sku_namesellinenc2', 'sku_namesellinenc3',\n",
    "       'sku_nameselloutenc6', 'sku_nameselloutenc5', 'sku_nameselloutenc4',\n",
    "       'sku_nameselloutenc', 'sku_nameselloutenc1', 'sku_nameselloutenc2',\n",
    "       'sku_nameselloutenc3', 'sku_namepriceenc6', 'sku_namepriceenc5',\n",
    "       'sku_namepriceenc4', 'sku_namepriceenc', 'sku_namepriceenc1',\n",
    "       'sku_namepriceenc2', 'sku_namepriceenc3',\n",
    "       'sku_namestarting_inventoryenc6', 'sku_namestarting_inventoryenc5',\n",
    "       'sku_namestarting_inventoryenc4', 'sku_namestarting_inventoryenc',\n",
    "       'sku_namestarting_inventoryenc1', 'sku_namestarting_inventoryenc2',\n",
    "       'sku_namestarting_inventoryenc3', 'sku_nameleftover_inventoryenc6',\n",
    "       'sku_nameleftover_inventoryenc5', 'sku_nameleftover_inventoryenc4',\n",
    "       'sku_nameleftover_inventoryenc', 'sku_nameleftover_inventoryenc1',\n",
    "       'sku_nameleftover_inventoryenc2', 'sku_nameleftover_inventoryenc3',\n",
    "       'enc_sku']\n",
    "# X = df_train.drop(encoding_columns+[target,'sku_name','enc_sku','product_lifecycle_stage'],axis=1)\n",
    "X = df_train[prediction_columns].drop(['sku_name','enc_sku','product_lifecycle_stage'],axis =1)\n",
    "X_log = df_train[prediction_columns] .drop(['sku_name','enc_sku','product_lifecycle_stage'],axis =1)\n",
    "min_sellin = df_train[target].min()\n",
    "y_log = np.log1p(df_train[target] -min_sellin)\n",
    "y = df_train[target]\n",
    "cats = []\n",
    "oof = np.zeros(len(X))\n",
    "models = [] \n",
    "scores = 0.0   \n",
    "\n",
    "features_importance= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
    "\n",
    "oof_log = np.zeros(len(X))\n",
    "models_log = [] \n",
    "scores_log = 0.0   \n",
    "\n",
    "features_importance_log= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    print(\"Fold :\", fold+1)\n",
    "\n",
    "    # create dataset\n",
    "#     X_train, y_train = X.loc[trn_idx], y[trn_idx]\n",
    "#     X_valid, y_valid = X.loc[val_idx], y[val_idx]\n",
    "    X_train_log, y_train_log = X_log.loc[trn_idx], y_log[trn_idx]\n",
    "    X_valid_log, y_valid_log = X_log.loc[val_idx], y_log[val_idx]\n",
    "\n",
    "    #RMSPE weight\n",
    "#     weights_trn = np.where(mask1,0.9,0.1)[trn_idx]\n",
    "#     lgbm_train = lgbm.Dataset(X_train,y_train,weight = weights_trn)\n",
    "    lgbm_train_log = lgbm.Dataset(X_train_log,y_train_log)#,weight = weights_trn)\n",
    "\n",
    "#     weights_val = np.where(mask1,0.9,0.1)[val_idx]\n",
    "#     lgbm_valid = lgbm.Dataset(X_valid,y_valid,reference = lgbm_train,weight = weights_val)\n",
    "    lgbm_valid_log = lgbm.Dataset(X_valid_log,y_valid_log,reference = lgbm_train_log)#,weight = weights_val)\n",
    "\n",
    "    # model \n",
    "#     model = lgbm.train(params=params,\n",
    "#                       train_set=lgbm_train,\n",
    "#                       valid_sets=[lgbm_train, lgbm_valid],\n",
    "#                       num_boost_round=3000,         \n",
    "# #                       feval='mae',\n",
    "#                       verbose_eval=100\n",
    "# #                       categorical_feature = cats                \n",
    "#                      )\n",
    "    model_log = lgbm.train(params=params,\n",
    "                      train_set=lgbm_train_log,\n",
    "                      valid_sets=[lgbm_train_log, lgbm_valid_log],\n",
    "                      num_boost_round=3000,         \n",
    "#                       feval='mae',\n",
    "                      verbose_eval=100\n",
    "#                       categorical_feature = cats                \n",
    "                     )\n",
    "\n",
    "    # validation \n",
    "#     y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    y_pred_log = model_log.predict(X_valid_log, num_iteration=model_log.best_iteration)\n",
    "\n",
    "#     features = X_train.columns\n",
    "#     oof[val_idx] = y_pred\n",
    "    oof_log[val_idx] = y_pred_log\n",
    "#     RMSPE_log = round(rmspe_log(y_true = y_valid_log, y_pred = y_pred_log),3)\n",
    "#     RMSPE = round(rmspe(y_true = y_valid, y_pred = y_pred),3)\n",
    "#     print(f'Performance of the　prediction: , RMSPE: {RMSPE}')\n",
    "#     print(f'Performance of the　prediction 2 : , RMSPE: {RMSPE_log}')\n",
    "#     fold_importance_df= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
    "#     fold_importance_df['Feature']= X.columns\n",
    "#     fold_importance_df['Importance']= model.feature_importance()\n",
    "#     fold_importance_df[\"fold\"] = fold + 1\n",
    "#     features_importance = pd.concat([features_importance, fold_importance_df], axis=0)\n",
    "    \n",
    "    ##################################\n",
    "    fold_importance_df_log= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
    "    fold_importance_df_log['Feature']= X_log.columns\n",
    "    fold_importance_df_log['Importance']= model_log.feature_importance()\n",
    "    fold_importance_df_log[\"fold\"] = fold + 1\n",
    "    features_importance_log = pd.concat([features_importance_log, fold_importance_df_log], axis=0)\n",
    "    #keep scores and models\n",
    "#     scores += RMSPE / kfolds\n",
    "    scores_log += RMSPE_log / kfolds\n",
    "\n",
    "#     models.append(model)\n",
    "    models_log.append(model_log) \n",
    "    print(\"*\" * 100)\n",
    "# print('Errors without '+ c)\n",
    "# scooores.append(rmspe(y,oof))\n",
    "# print(rmspe(y,oof))\n",
    "print(\"*\" * 100)\n",
    "print(rmspe_log(y_log,oof_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f21fd260c8>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# np.expm1(1)\n",
    "# plt.plot(np.sort_values(y_log))\n",
    "# plt.plot((np.log1p(df_train['sellin']+1)).sort_values().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:39:39.204299Z",
     "iopub.status.busy": "2022-08-24T15:39:39.203133Z",
     "iopub.status.idle": "2022-08-24T15:39:39.212302Z",
     "shell.execute_reply": "2022-08-24T15:39:39.210571Z",
     "shell.execute_reply.started": "2022-08-24T15:39:39.204256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261428.19986777686"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train['preds'] = oof\n",
    "df_train['preds_log'] = np.expm1(oof_log) + min_sellin\n",
    "# df_train['preds'] = oof\n",
    "# models[5].predict(X, num_iteration=model.best_iteration)\n",
    "# df_train ['errors'] = (df_train['preds'] - df_train['sellin'])\n",
    "\n",
    "# df_train ['errors_log'] = (df_train['preds_log'] - df_train['sellin'])\n",
    "# abs(df_train[df_train.sku_name.isin(df_test.sku_name.unique())]['errors']).mean()*1013\n",
    "rmspe(df_train[df_train.sku_name.isin(df_test.sku_name.unique())]['sellin'],\n",
    "     df_train[df_train.sku_name.isin(df_test.sku_name.unique())]['preds_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.957380037547232"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train['preds_log']\n",
    "oof_log.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.linspace(0,1,100)\n",
    "l = []\n",
    "for w in W:\n",
    "    l.append(rmspe(df_train[df_train.sku_name.isin(df_test.sku_name.unique())]['sellin'],\n",
    "     (1-w)*df_train[df_train.sku_name.isin(df_test.sku_name.unique())]['preds_log']+w*df_train[df_train.sku_name.isin(df_test.sku_name.unique())]['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(W,l)\n",
    "# df_train[df_train.abs_err>500][X.columns.tolist()+['preds','preds_log','errors','sellin']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sort = df_train.sort_values(by = 'abs_err',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(df_train_sort.sellin.values)\n",
    "# plt.plot(df_train_sort['errors'].values)\n",
    "# i = \n",
    "i=i+1\n",
    "print(df_train.columns[i])\n",
    "\n",
    "(df_train[df_train.abs_err>2000][df_train.columns[i]].nunique()/df_train[df_train.columns[i]].nunique()\n",
    ")/(df_train[df_train.abs_err>2000]['sku_name'].nunique()/df_train['sku_name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (df_train[df_train.abs_err>6000].sku_name).unique()[0]\n",
    "# for s in sk:\n",
    "x = df_train.loc[df_train.sku_name == s,'date'].values\n",
    "y1 = df_train.loc[df_train.sku_name == s,'sellin'].values\n",
    "y2 = df_train.loc[df_train.sku_name == s,'preds'].values\n",
    "plt.plot(x,y1,c = 'black')\n",
    "plt.plot(x,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sk\n",
    "# df_train.corr()['errors_log'].sort_values(ascending = False,key = abs)\n",
    "df_train['final_pc'] = df_train['sku_name'].map(df_train.groupby('sku_name').apply(lambda x :x['cum_pc'].values[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train.abs_err>3000].price.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(df_train.date,df_train.cum_pc)\n",
    "df_train[(df_train.abs_err>3000)& (df_train.date>0)].corr()['sellin'].sort_values(ascending = False,key = abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'FLAG100','date','size','sellin_old'\n",
    "df_train['pc'] = df_train.groupby('sku_name')['sellin'].pct_change().fillna(0)\n",
    "df_train['cum_pc'] = df_train.groupby('sku_name').apply(lambda x : (x['pc']+1).cumprod()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.corr()['errors'].sort_values(ascending = False,key = abs)\n",
    "df_train['abs_err'] = abs(df_train['errors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 'sellin'\n",
    "plt.scatter(x = df_train[mask1].groupby(g)['abs_err'].mean().index, y = df_train[mask1].groupby(g)['abs_err'].mean().values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(df_train.groupby('date')['abs_err'].mean())\n",
    "# df_train[df_train.date==5][['abs_err']].mean()\n",
    "i =2\n",
    "mask1 = df_train.sku_name.isin(df_test.sku_name.unique())\n",
    "(df_train[mask1].groupby(df_train.columns[i])['abs_err'].mean().sort_values(ascending = False)>100).mean()\n",
    "\n",
    "# df_train.loc[df_train.month ==12].corr()['abs_err'].sort_values(ascending = False,key = abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.columns[2]\n",
    "# df_train['FLAG100'].unique().shape\n",
    "medians = df_train.groupby(['sku_name'])['sellin'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_train.merge(medians,on = ['sku_name'],suffixes = (None,'_med'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask1\n",
    "# df_train[mask1]\n",
    "# train_df['sellin_old2']\n",
    "train_df['sellin_old2'] = train_df.groupby('sku_name')['sellin'].shift(2).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()['abs_err']['sellin_old2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:39:44.432560Z",
     "iopub.status.busy": "2022-08-24T15:39:44.431781Z",
     "iopub.status.idle": "2022-08-24T15:39:44.440078Z",
     "shell.execute_reply": "2022-08-24T15:39:44.438651Z",
     "shell.execute_reply.started": "2022-08-24T15:39:44.432509Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train ['errors'] = (df_train['preds'] - df_train['sellin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:24:45.822954Z",
     "iopub.status.busy": "2022-08-24T15:24:45.822356Z",
     "iopub.status.idle": "2022-08-24T15:24:46.695056Z",
     "shell.execute_reply": "2022-08-24T15:24:46.694315Z",
     "shell.execute_reply.started": "2022-08-24T15:24:45.822922Z"
    }
   },
   "outputs": [],
   "source": [
    "a = df_train.groupby('sku_name')['errors'].apply(lambda x : abs(x).mean()).reset_index()\n",
    "a[a.sku_name.isin(df_test.sku_name.unique())]['errors'].mean()*1013\n",
    "# .sort_values(by = 'errors',key = abs,ascending =False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:39:47.935281Z",
     "iopub.status.busy": "2022-08-24T15:39:47.934841Z",
     "iopub.status.idle": "2022-08-24T15:39:47.956899Z",
     "shell.execute_reply": "2022-08-24T15:39:47.954913Z",
     "shell.execute_reply.started": "2022-08-24T15:39:47.935246Z"
    }
   },
   "outputs": [],
   "source": [
    "abs(df_train[df_train.sku_name.isin(df_test.sku_name.unique())]['errors']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T11:41:08.176006Z",
     "iopub.status.busy": "2022-08-24T11:41:08.175503Z",
     "iopub.status.idle": "2022-08-24T11:41:09.507149Z",
     "shell.execute_reply": "2022-08-24T11:41:09.505760Z",
     "shell.execute_reply.started": "2022-08-24T11:41:08.175963Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_model = KNeighborsRegressor().fit(df_train[cols], y)\n",
    "predicted_values = knn_model.predict(df_test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T11:48:28.086069Z",
     "iopub.status.busy": "2022-08-24T11:48:28.085364Z",
     "iopub.status.idle": "2022-08-24T11:48:28.098577Z",
     "shell.execute_reply": "2022-08-24T11:48:28.097184Z",
     "shell.execute_reply.started": "2022-08-24T11:48:28.086029Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:30:57.734071Z",
     "iopub.status.busy": "2022-08-24T14:30:57.733725Z",
     "iopub.status.idle": "2022-08-24T14:30:57.759301Z",
     "shell.execute_reply": "2022-08-24T14:30:57.758557Z",
     "shell.execute_reply.started": "2022-08-24T14:30:57.734044Z"
    }
   },
   "outputs": [],
   "source": [
    "# ##### plt.scatter(df_train.loc[df_train.year==2021,'sellin_old'],\n",
    "# #             df_train.loc[df_train.year==2021,'sellin'],\n",
    "# #             c = df_train.loc[df_train.year==2021,'cum_disc'])\n",
    "# # df_train.loc[df_train.year ==2021,'month'].max()\n",
    "# # plt.plot(df_train.groupby('year')['sellin'].sum()/(df_train.groupby('year')['month'].max()))\n",
    "# # plt.plot(df_train.groupby('date')['sellin'].sum())\n",
    "# i = 45\n",
    "# ids = df_train.loc[df_train.date == i,'sku_name'].values \n",
    "\n",
    "# df_train.loc[(df_train.sku_name.isin(ids)) & (df_train.date == i),'sellin'] = df_train[(df_train.sku_name.isin(ids)) ].groupby('sku_name')['sellin'].median().values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T11:41:20.431981Z",
     "iopub.status.busy": "2022-08-24T11:41:20.431227Z",
     "iopub.status.idle": "2022-08-24T11:41:20.438819Z",
     "shell.execute_reply": "2022-08-24T11:41:20.438001Z",
     "shell.execute_reply.started": "2022-08-24T11:41:20.431941Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_values*1013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T11:02:56.033278Z",
     "iopub.status.busy": "2022-08-24T11:02:56.032804Z",
     "iopub.status.idle": "2022-08-24T11:02:56.039051Z",
     "shell.execute_reply": "2022-08-24T11:02:56.037685Z",
     "shell.execute_reply.started": "2022-08-24T11:02:56.033237Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train_1, X_test_local, y_train_1, y_test_local = train_test_split(X, y, test_size=0.1,shuffle =True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T11:02:59.438446Z",
     "iopub.status.busy": "2022-08-24T11:02:59.437184Z",
     "iopub.status.idle": "2022-08-24T11:02:59.446567Z",
     "shell.execute_reply": "2022-08-24T11:02:59.445457Z",
     "shell.execute_reply.started": "2022-08-24T11:02:59.438381Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# y_train_1.reset_index(drop = True,inplace = True)\n",
    "# X_train_1.reset_index(drop = True,inplace = True)\n",
    "# X_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T11:03:01.651362Z",
     "iopub.status.busy": "2022-08-24T11:03:01.650704Z",
     "iopub.status.idle": "2022-08-24T11:03:01.655145Z",
     "shell.execute_reply": "2022-08-24T11:03:01.654293Z",
     "shell.execute_reply.started": "2022-08-24T11:03:01.651322Z"
    }
   },
   "outputs": [],
   "source": [
    "                         # models\n",
    "# gkf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T13:51:05.142556Z",
     "iopub.status.busy": "2022-08-24T13:51:05.140063Z",
     "iopub.status.idle": "2022-08-24T13:51:05.146717Z",
     "shell.execute_reply": "2022-08-24T13:51:05.145820Z",
     "shell.execute_reply.started": "2022-08-24T13:51:05.142512Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for fold, (trn_idx, val_idx) in enumerate(kf.split(y, groups=X['date'].values)):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T11:06:31.531610Z",
     "iopub.status.busy": "2022-08-24T11:06:31.531185Z",
     "iopub.status.idle": "2022-08-24T11:06:31.540591Z",
     "shell.execute_reply": "2022-08-24T11:06:31.539527Z",
     "shell.execute_reply.started": "2022-08-24T11:06:31.531574Z"
    }
   },
   "outputs": [],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T11:10:15.744194Z",
     "iopub.status.busy": "2022-08-22T11:10:15.743574Z",
     "iopub.status.idle": "2022-08-22T11:10:15.753398Z",
     "shell.execute_reply": "2022-08-22T11:10:15.752247Z",
     "shell.execute_reply.started": "2022-08-22T11:10:15.744133Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(models,X_test_local,y_test_local,X_train_1):\n",
    "    target = np.zeros(len(X_test_local))\n",
    "    # target2 = np.zeros(len(X_test))\n",
    "    #light gbm models\n",
    "    for model in models:\n",
    "        pred = model.predict(X_test_local[X_train_1.columns], num_iteration=model.best_iteration)\n",
    "        target += pred / len(models)\n",
    "    \n",
    "    return rmspe(y_test_local, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T11:10:17.732710Z",
     "iopub.status.busy": "2022-08-22T11:10:17.731871Z",
     "iopub.status.idle": "2022-08-22T11:10:17.741228Z",
     "shell.execute_reply": "2022-08-22T11:10:17.739733Z",
     "shell.execute_reply.started": "2022-08-22T11:10:17.732650Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_1.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T11:10:20.116977Z",
     "iopub.status.busy": "2022-08-22T11:10:20.116085Z",
     "iopub.status.idle": "2022-08-22T11:10:22.750589Z",
     "shell.execute_reply": "2022-08-22T11:10:22.749234Z",
     "shell.execute_reply.started": "2022-08-22T11:10:20.116923Z"
    }
   },
   "outputs": [],
   "source": [
    "# display_importances(features_importance)\n",
    "print('local test prediction is : ' + str(eval_model(models,X_test_local,y_test_local,X_train_1)))\n",
    "print('oof score is :' +str(rmspe(y_train_1, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T19:07:37.882759Z",
     "iopub.status.busy": "2022-08-21T19:07:37.882115Z",
     "iopub.status.idle": "2022-08-21T19:07:39.831138Z",
     "shell.execute_reply": "2022-08-21T19:07:39.830242Z",
     "shell.execute_reply.started": "2022-08-21T19:07:37.882720Z"
    }
   },
   "outputs": [],
   "source": [
    "# display_importances(features_importance)\n",
    "print('local test prediction is : ' + str(eval_model(models,X_test_local,y_test_local,X_train_1,SC)))\n",
    "print('oof score is :' +str(rmspe(y_train_1, oof,SC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T19:09:07.015914Z",
     "iopub.status.busy": "2022-08-21T19:09:07.015539Z",
     "iopub.status.idle": "2022-08-21T19:09:07.023107Z",
     "shell.execute_reply": "2022-08-21T19:09:07.022122Z",
     "shell.execute_reply.started": "2022-08-21T19:09:07.015887Z"
    }
   },
   "outputs": [],
   "source": [
    ".period_old.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:37:15.955333Z",
     "iopub.status.busy": "2022-08-24T15:37:15.954853Z",
     "iopub.status.idle": "2022-08-24T15:37:16.841966Z",
     "shell.execute_reply": "2022-08-24T15:37:16.840518Z",
     "shell.execute_reply.started": "2022-08-24T15:37:15.955294Z"
    }
   },
   "outputs": [],
   "source": [
    "display_importances(features_importance)\n",
    "# print('local test prediction is : ' + str(eval_model(models,X_test_local,y_test_local,X_train_1)))\n",
    "# print('oof score is :' +str(rmspe(y_train_1, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T18:55:12.066438Z",
     "iopub.status.busy": "2022-08-21T18:55:12.066043Z",
     "iopub.status.idle": "2022-08-21T18:55:12.073020Z",
     "shell.execute_reply": "2022-08-21T18:55:12.072158Z",
     "shell.execute_reply.started": "2022-08-21T18:55:12.066405Z"
    }
   },
   "outputs": [],
   "source": [
    "'maybe add weeks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:02:43.403937Z",
     "iopub.status.busy": "2022-08-24T15:02:43.403371Z",
     "iopub.status.idle": "2022-08-24T15:02:43.419909Z",
     "shell.execute_reply": "2022-08-24T15:02:43.418617Z",
     "shell.execute_reply.started": "2022-08-24T15:02:43.403874Z"
    }
   },
   "outputs": [],
   "source": [
    "# eval_model(models,X_test_local,y_test_local,X_train_1)\n",
    "rmspe(y,oof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:02:48.691703Z",
     "iopub.status.busy": "2022-08-24T15:02:48.691248Z",
     "iopub.status.idle": "2022-08-24T15:02:48.699811Z",
     "shell.execute_reply": "2022-08-24T15:02:48.698401Z",
     "shell.execute_reply.started": "2022-08-24T15:02:48.691666Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = df_test[X.columns.tolist()].copy()\n",
    "# X_train\n",
    "# len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:02:50.431334Z",
     "iopub.status.busy": "2022-08-24T15:02:50.430878Z",
     "iopub.status.idle": "2022-08-24T15:02:50.933409Z",
     "shell.execute_reply": "2022-08-24T15:02:50.932416Z",
     "shell.execute_reply.started": "2022-08-24T15:02:50.431296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amakr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df_test['Item_ID'] = df_test['sku_name'] +'_'+ df_test['month'].astype(str)+ '_'+df_test['year'].astype(str)\n",
    "y_pred = df_test[['Item_ID']]\n",
    "target = np.zeros(len(X_test))\n",
    "target2 = np.zeros(len(X_test))\n",
    "#light gbm models\n",
    "for model in models_log:\n",
    "    pred = model.predict(X_test[X.columns], num_iteration=model.best_iteration)\n",
    "    pred = np.expm1(pred)+min_sellin\n",
    "    target += pred / len(models)\n",
    "# X_test['cum_disc'] = 0\n",
    "# for model in models:\n",
    "#     pred = model.predict(X_test[X_valid.columns], num_iteration=model.best_iteration)\n",
    "#     target2 += pred / len(models)\n",
    "# target = (target+target2)/2\n",
    "y_pred = y_pred.assign(target_y= target)\n",
    "sub = ss.merge(y_pred,on = 'Item_ID')\n",
    "sub['target'] = (sub['target_y'])*1013\n",
    "sub['target'] = (sub['target'].astype('int') )\n",
    "sub = sub[['Item_ID','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<lightgbm.basic.Booster at 0x1f223da4508>,\n",
       " <lightgbm.basic.Booster at 0x1f21fb11dc8>,\n",
       " <lightgbm.basic.Booster at 0x1f21c71ad88>,\n",
       " <lightgbm.basic.Booster at 0x1f223da4d08>,\n",
       " <lightgbm.basic.Booster at 0x1f21fce4048>,\n",
       " <lightgbm.basic.Booster at 0x1f21bf47348>,\n",
       " <lightgbm.basic.Booster at 0x1f21fb7a1c8>,\n",
       " <lightgbm.basic.Booster at 0x1f21c5eaf48>,\n",
       " <lightgbm.basic.Booster at 0x1f2236d7e88>,\n",
       " <lightgbm.basic.Booster at 0x1f220ce9d88>]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:02:54.075729Z",
     "iopub.status.busy": "2022-08-24T15:02:54.075295Z",
     "iopub.status.idle": "2022-08-24T15:02:54.091746Z",
     "shell.execute_reply": "2022-08-24T15:02:54.090069Z",
     "shell.execute_reply.started": "2022-08-24T15:02:54.075695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.98073133, 4.28275561, 2.98466074, ..., 2.46379435, 2.3960153 ,\n",
       "       2.23091279])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[X.columns], num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T15:03:06.096288Z",
     "iopub.status.busy": "2022-08-24T15:03:06.095615Z",
     "iopub.status.idle": "2022-08-24T15:03:06.110476Z",
     "shell.execute_reply": "2022-08-24T15:03:06.108629Z",
     "shell.execute_reply.started": "2022-08-24T15:03:06.096235Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('goofy.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T13:57:46.545625Z",
     "iopub.status.busy": "2022-08-24T13:57:46.545215Z",
     "iopub.status.idle": "2022-08-24T13:57:46.551468Z",
     "shell.execute_reply": "2022-08-24T13:57:46.550397Z",
     "shell.execute_reply.started": "2022-08-24T13:57:46.545593Z"
    }
   },
   "outputs": [],
   "source": [
    "# [s for s in df_test.sku_name.unique() if s not in df_train.sku_name.unique()]\n",
    "# sub.loc[sub.Item_ID.isin(df_test.loc[df_test.sku_name == 'CATHHALREYZZ','Item_ID'].values),'target'] = 0\n",
    "# sub\n",
    "df_test['sellin'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T13:58:18.714788Z",
     "iopub.status.busy": "2022-08-24T13:58:18.714130Z",
     "iopub.status.idle": "2022-08-24T13:58:18.742773Z",
     "shell.execute_reply": "2022-08-24T13:58:18.741543Z",
     "shell.execute_reply.started": "2022-08-24T13:58:18.714751Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df = pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:04:00.398761Z",
     "iopub.status.busy": "2022-08-24T14:04:00.398352Z",
     "iopub.status.idle": "2022-08-24T14:04:00.615968Z",
     "shell.execute_reply": "2022-08-24T14:04:00.615086Z",
     "shell.execute_reply.started": "2022-08-24T14:04:00.398727Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 4\n",
    "a =new_df[new_df.sku_name.isin(df_test.sku_name.unique())].groupby('sku_name').get_group(df_test.sku_name.unique()[i])\n",
    "x= a['date'].values\n",
    "y = a['sellin'].values\n",
    "plt.plot(x[:-4],y[:-4])\n",
    "plt.plot(x[-5:],y[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:02:32.348198Z",
     "iopub.status.busy": "2022-08-24T14:02:32.347819Z",
     "iopub.status.idle": "2022-08-24T14:02:32.354647Z",
     "shell.execute_reply": "2022-08-24T14:02:32.353853Z",
     "shell.execute_reply.started": "2022-08-24T14:02:32.348167Z"
    }
   },
   "outputs": [],
   "source": [
    "x[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T11:07:42.143033Z",
     "iopub.status.busy": "2022-08-24T11:07:42.141737Z",
     "iopub.status.idle": "2022-08-24T11:07:42.156377Z",
     "shell.execute_reply": "2022-08-24T11:07:42.155182Z",
     "shell.execute_reply.started": "2022-08-24T11:07:42.142989Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission_aero.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:11:59.161746Z",
     "iopub.status.busy": "2022-08-24T14:11:59.161293Z",
     "iopub.status.idle": "2022-08-24T14:11:59.171668Z",
     "shell.execute_reply": "2022-08-24T14:11:59.170215Z",
     "shell.execute_reply.started": "2022-08-24T14:11:59.161708Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "params = {'objective': 'reg:squarederror', \n",
    "          'eta': 0.01, \n",
    "#               'max_depth': 6, \n",
    "#               'subsample': 0.7, \n",
    "#               'colsample_bytree': 0.8,  \n",
    "          'eval_metric': 'rmse', \n",
    "          'seed': 42, \n",
    "#           'silent': True,\n",
    "}\n",
    "verbose = 100\n",
    "models_xgb =[]\n",
    "oof_xgb = np.zeros(len(X))\n",
    "# models = [] \n",
    "scores_xgb = 0.0   \n",
    "\n",
    "features_importance_xgb= pd.DataFrame({'Feature':[], 'Importance':[]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:12:00.297883Z",
     "iopub.status.busy": "2022-08-24T14:12:00.297194Z",
     "iopub.status.idle": "2022-08-24T14:16:50.115591Z",
     "shell.execute_reply": "2022-08-24T14:16:50.114518Z",
     "shell.execute_reply.started": "2022-08-24T14:12:00.297846Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# for fold, (trn_idx, val_idx) in enumerate(kf.split(y, groups=X['date'].values)):\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(X_log, y_log)):\n",
    "    print(\"Fold :\", fold+1)\n",
    "    \n",
    "    # create dataset\n",
    "    X_train, y_train = X.loc[trn_idx], y[trn_idx]\n",
    "    X_valid, y_valid = X.loc[val_idx], y[val_idx]\n",
    "    \n",
    "    #RMSPE weight\n",
    "#     weights = 1/(w_train)\n",
    "    model = xgb.train(params\n",
    "                  , xgb.DMatrix(X_train, y_train)\n",
    "                  , 10000\n",
    "                  , [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_valid, y_valid), 'valid')]\n",
    "                  , verbose_eval=verbose\n",
    "                  , early_stopping_rounds=30\n",
    "                 )\n",
    "    # validation\n",
    "    y_pred = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)\n",
    "#     test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "#     y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    features = X_train.columns\n",
    "    oof[val_idx] = y_pred\n",
    "    RMSPE = round(rmspe(y_true = y_valid, y_pred = y_pred),3)\n",
    "    print(f'Performance of the　prediction: , RMSPE: {RMSPE}')\n",
    "    fold_importance_df_xgb= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
    "    fold_importance_df_xgb['Feature']= features\n",
    "    fold_importance_df_xgb['Importance']= fold_importance_df_xgb['Feature'].map(model.get_score(importance_type = 'gain')).fillna(0)\n",
    "    fold_importance_df_xgb[\"fold\"] = fold + 1\n",
    "    features_importance_xgb = pd.concat([features_importance_xgb, fold_importance_df_xgb], axis=0)\n",
    "    #keep scores and models\n",
    "    scores_xgb += RMSPE / kfolds\n",
    "    models_xgb.append(model)\n",
    "    print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:17:38.669228Z",
     "iopub.status.busy": "2022-08-24T14:17:38.668797Z",
     "iopub.status.idle": "2022-08-24T14:17:38.819058Z",
     "shell.execute_reply": "2022-08-24T14:17:38.817729Z",
     "shell.execute_reply.started": "2022-08-24T14:17:38.669195Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.array(list(model.get_score(importance_type='gain').values())).shape\n",
    "# fold_importance_df_xgb\n",
    "# len(model.feature_names)\n",
    "df_test['Item_ID'] = df_test['sku_name'] +'_'+ df_test['month'].astype(str)+ '_'+df_test['year'].astype(str)\n",
    "y_pred = df_test[['Item_ID']]\n",
    "target = np.zeros(len(X_test))\n",
    "target2 = np.zeros(len(X_test))\n",
    "#light gbm models\n",
    "for model in models_xgb:\n",
    "    pred = model.predict(xgb.DMatrix(X_test[X_valid.columns]), ntree_limit=model.best_ntree_limit)\n",
    "    target += pred / len(models_xgb)\n",
    "# X_test['cum_disc'] = 0\n",
    "# for model in models:\n",
    "#     pred = model.predict(, num_iteration=model.best_iteration)\n",
    "#     target2 += pred / len(models)\n",
    "# target = (target+target2)/2\n",
    "y_pred = y_pred.assign(target_y= target)\n",
    "sub_xgb = ss.merge(y_pred,on = 'Item_ID')\n",
    "sub_xgb['target'] = (sub_xgb['target_y'])*1013\n",
    "sub_xgb['target'] = (sub_xgb['target'].astype('int') )\n",
    "sub_xgb = sub_xgb[['Item_ID','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:18:04.080463Z",
     "iopub.status.busy": "2022-08-24T14:18:04.080033Z",
     "iopub.status.idle": "2022-08-24T14:18:04.089841Z",
     "shell.execute_reply": "2022-08-24T14:18:04.088673Z",
     "shell.execute_reply.started": "2022-08-24T14:18:04.080416Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_xgb.to_csv('xgb_sub.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T15:50:21.841278Z",
     "iopub.status.busy": "2022-08-22T15:50:21.840804Z",
     "iopub.status.idle": "2022-08-22T15:50:21.855284Z",
     "shell.execute_reply": "2022-08-22T15:50:21.853842Z",
     "shell.execute_reply.started": "2022-08-22T15:50:21.841243Z"
    }
   },
   "outputs": [],
   "source": [
    "# sub_blend = sub[['Item_ID']]\n",
    "# sub_blend['target'] = ((sub_xgb['target']*rmspe(y,oof_xgb))+(sub['target']*rmspe(y,oof)))/(rmspe(y,oof)+rmspe(y,oof_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-24T14:10:16.017152Z",
     "iopub.status.busy": "2022-08-24T14:10:16.015687Z",
     "iopub.status.idle": "2022-08-24T14:10:16.030318Z",
     "shell.execute_reply": "2022-08-24T14:10:16.029380Z",
     "shell.execute_reply.started": "2022-08-24T14:10:16.017083Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T15:50:59.694579Z",
     "iopub.status.busy": "2022-08-22T15:50:59.694182Z",
     "iopub.status.idle": "2022-08-22T15:50:59.706554Z",
     "shell.execute_reply": "2022-08-22T15:50:59.705623Z",
     "shell.execute_reply.started": "2022-08-22T15:50:59.694547Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_blend.to_csv('sub_blend.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-22T15:45:21.667823Z",
     "iopub.status.idle": "2022-08-22T15:45:21.668549Z",
     "shell.execute_reply": "2022-08-22T15:45:21.668222Z",
     "shell.execute_reply.started": "2022-08-22T15:45:21.668188Z"
    }
   },
   "outputs": [],
   "source": [
    "# models[5].predict(X_test[X_valid.columns], num_iteration=model.best_iteration)*1013\n",
    "# sns.distplot(df_train.sellin)\n",
    "# sns.distplot(sub.target\n",
    "# df_test.drop('item_ID',axis = 1).columns\n",
    "# df_test.drop('Item_ID',axis = 1).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T17:13:43.082894Z",
     "iopub.status.busy": "2022-08-20T17:13:43.082271Z",
     "iopub.status.idle": "2022-08-20T17:13:43.100367Z",
     "shell.execute_reply": "2022-08-20T17:13:43.099662Z",
     "shell.execute_reply.started": "2022-08-20T17:13:43.082853Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df = pd.concat([df_test.assign(sellin= sub.target/1013).drop('Item_ID',axis = 1),df_train[df_test.drop('Item_ID',axis = 1).columns.tolist()+['sellin']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T17:13:44.520114Z",
     "iopub.status.busy": "2022-08-20T17:13:44.519548Z",
     "iopub.status.idle": "2022-08-20T17:13:44.525555Z",
     "shell.execute_reply": "2022-08-20T17:13:44.524583Z",
     "shell.execute_reply.started": "2022-08-20T17:13:44.520080Z"
    }
   },
   "outputs": [],
   "source": [
    "ids = test.sku_name.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T17:14:35.265157Z",
     "iopub.status.busy": "2022-08-20T17:14:35.264023Z",
     "iopub.status.idle": "2022-08-20T17:14:35.412809Z",
     "shell.execute_reply": "2022-08-20T17:14:35.412023Z",
     "shell.execute_reply.started": "2022-08-20T17:14:35.265110Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "x1 = new_df.groupby('sku_name').get_group(ids[i])[['month','year','sellin_old']].sort_values(by = ['year','month'])['sellin_old'].values\n",
    "x2 = new_df.groupby('sku_name').get_group(ids[i])[['month','year','sellin_old']].sort_values(by = ['year','month'])['sellin_old'].values[-5:]\n",
    "plt.plot(x1)\n",
    "plt.plot(range(x1.shape[0]-5,x1.shape[0]),x2)\n",
    "plt.axhline(y = np.median(x1[:-4]), color = 'r', linestyle = '-')\n",
    "plt.axhline(y = np.mean(x1[:-4]), color = 'g', linestyle = '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T17:14:38.694318Z",
     "iopub.status.busy": "2022-08-20T17:14:38.693255Z",
     "iopub.status.idle": "2022-08-20T17:14:38.700541Z",
     "shell.execute_reply": "2022-08-20T17:14:38.699655Z",
     "shell.execute_reply.started": "2022-08-20T17:14:38.694278Z"
    }
   },
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T11:03:50.336265Z",
     "iopub.status.busy": "2022-08-20T11:03:50.335191Z",
     "iopub.status.idle": "2022-08-20T11:03:50.370102Z",
     "shell.execute_reply": "2022-08-20T11:03:50.368840Z",
     "shell.execute_reply.started": "2022-08-20T11:03:50.336204Z"
    }
   },
   "outputs": [],
   "source": [
    "# x1[:-4]\n",
    "new_df.groupby(['sku_name','year','month']).size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:33:32.269619Z",
     "iopub.status.busy": "2022-08-20T15:33:32.269271Z",
     "iopub.status.idle": "2022-08-20T15:33:56.858571Z",
     "shell.execute_reply": "2022-08-20T15:33:56.857637Z",
     "shell.execute_reply.started": "2022-08-20T15:33:32.269575Z"
    }
   },
   "outputs": [],
   "source": [
    "# str(df_train['year']) +'-'+str(df_train['month'])\n",
    "# df_train[['year']]\n",
    "# df_train['date'] = (df_train['year'].astype(str)+ '-'+df_train['month'].astype(str)).apply(lambda _: pd.to_datetime(_,format='%Y-%m', errors='coerce'))\n",
    "# df_train\n",
    "df_train['is_train'] = 1\n",
    "df_test['is_test'] = 1\n",
    "years = list(range(2016,2022))\n",
    "ids = df_train.sku_name.unique().tolist()\n",
    "months = list(range(1,13))\n",
    "new_frame = pd.DataFrame({'sku_name':np.repeat(ids,len(years)*len(months)),\n",
    "                         'month':months*len(ids)*len(years),\n",
    "                         'year':np.repeat(years,len(months)).tolist()*len(ids),\n",
    "                         'time_step': list(range(len(years)*len(months)))*len(ids)})\n",
    "new_frame = new_frame.sort_values(by = ['sku_name','year','month']).reset_index(drop =True).merge(df_train[['sku_name','year','month','sellin','is_train']],how = 'left', on = ['sku_name','year','month'])\n",
    "new_frame['date'] = (new_frame['year'].astype(str)+ '-'+new_frame['month'].astype(str)).apply(lambda _: pd.to_datetime(_,format='%Y-%m', errors='coerce'))\n",
    "df_test['time_step'] = [70,71,72,73]*int(df_test.shape[0]/4)\n",
    "new_frame = pd.concat([new_frame.loc[new_frame.date<'2021-11'],df_test])\n",
    "#\n",
    "#.apply(lambda _: pd.to_datetime(_,format='%Y-%m', errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:40:59.423381Z",
     "iopub.status.busy": "2022-08-20T15:40:59.423049Z",
     "iopub.status.idle": "2022-08-20T15:40:59.431530Z",
     "shell.execute_reply": "2022-08-20T15:40:59.430749Z",
     "shell.execute_reply.started": "2022-08-20T15:40:59.423349Z"
    }
   },
   "outputs": [],
   "source": [
    "new_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:33:56.860524Z",
     "iopub.status.busy": "2022-08-20T15:33:56.860244Z",
     "iopub.status.idle": "2022-08-20T15:33:56.864010Z",
     "shell.execute_reply": "2022-08-20T15:33:56.863109Z",
     "shell.execute_reply.started": "2022-08-20T15:33:56.860499Z"
    }
   },
   "outputs": [],
   "source": [
    "# new_frame.loc[(new_frame.year == 2021)&(new_frame.month == 1),'Item_ID'].isna().any()\n",
    "# new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:33:56.865761Z",
     "iopub.status.busy": "2022-08-20T15:33:56.865230Z",
     "iopub.status.idle": "2022-08-20T15:34:20.270280Z",
     "shell.execute_reply": "2022-08-20T15:34:20.269402Z",
     "shell.execute_reply.started": "2022-08-20T15:33:56.865700Z"
    }
   },
   "outputs": [],
   "source": [
    "new_frame['date'] = (new_frame['year'].astype(str)+ '-'+new_frame['month'].astype(str)).apply(lambda _: pd.to_datetime(_,format='%Y-%m', errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:34:20.272734Z",
     "iopub.status.busy": "2022-08-20T15:34:20.272434Z",
     "iopub.status.idle": "2022-08-20T15:34:20.276971Z",
     "shell.execute_reply": "2022-08-20T15:34:20.275981Z",
     "shell.execute_reply.started": "2022-08-20T15:34:20.272710Z"
    }
   },
   "outputs": [],
   "source": [
    "new_frame.index = new_frame['date']\n",
    "# a = new_frame[['sku_name','sellin']].gro/upby('sku_name').apply(lambda x: x.interpolate(method = 'time'))\n",
    "# new_frame['2021-11':'2022-2'] =[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T14:21:45.082366Z",
     "iopub.status.busy": "2022-08-20T14:21:45.082043Z",
     "iopub.status.idle": "2022-08-20T14:21:45.121411Z",
     "shell.execute_reply": "2022-08-20T14:21:45.120754Z",
     "shell.execute_reply.started": "2022-08-20T14:21:45.082340Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T14:21:45.661067Z",
     "iopub.status.busy": "2022-08-20T14:21:45.660191Z",
     "iopub.status.idle": "2022-08-20T14:21:45.670573Z",
     "shell.execute_reply": "2022-08-20T14:21:45.669883Z",
     "shell.execute_reply.started": "2022-08-20T14:21:45.661025Z"
    }
   },
   "outputs": [],
   "source": [
    "s.sellin.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:01:22.422745Z",
     "iopub.status.busy": "2022-08-20T15:01:22.421665Z",
     "iopub.status.idle": "2022-08-20T15:01:22.474331Z",
     "shell.execute_reply": "2022-08-20T15:01:22.473295Z",
     "shell.execute_reply.started": "2022-08-20T15:01:22.422679Z"
    }
   },
   "outputs": [],
   "source": [
    "# s\n",
    "# s.loc[s.sellin.isna(),'time_step'].values\n",
    "s = new_frame.groupby('sku_name').get_group(ids[1])[['sellin','time_step']]\n",
    "x = s.loc[s.sellin.notnull(),'time_step'].values-1\n",
    "xp = s.loc[s.sellin.notnull(),'time_step'].values\n",
    "fp =  s.loc[s.sellin.notnull(),'sellin'].values\n",
    "\n",
    "vals = np.array([n for n in x if n not in xp]+[70,71,72,73])\n",
    "vals = vals[vals>=0]\n",
    "np.interp(vals,xp,fp).shape[0] - s.loc[s.time_step.isin(vals),'sellin'].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:39:56.252827Z",
     "iopub.status.busy": "2022-08-20T15:39:56.252487Z",
     "iopub.status.idle": "2022-08-20T15:39:56.257360Z",
     "shell.execute_reply": "2022-08-20T15:39:56.256829Z",
     "shell.execute_reply.started": "2022-08-20T15:39:56.252801Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.interp(vals,xp,fp)\n",
    "# s.loc[s.time_step.isin(vals),'sellin']\n",
    "# s.loc[s.time_step.isin(vals)]\n",
    "new_frame2.shape[0] - df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:01:01.363807Z",
     "iopub.status.busy": "2022-08-20T15:01:01.363437Z",
     "iopub.status.idle": "2022-08-20T15:01:01.370591Z",
     "shell.execute_reply": "2022-08-20T15:01:01.369868Z",
     "shell.execute_reply.started": "2022-08-20T15:01:01.363778Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T14:46:54.275004Z",
     "iopub.status.busy": "2022-08-20T14:46:54.274647Z",
     "iopub.status.idle": "2022-08-20T14:46:54.287056Z",
     "shell.execute_reply": "2022-08-20T14:46:54.286143Z",
     "shell.execute_reply.started": "2022-08-20T14:46:54.274973Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.interp(x,xp,fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:34:20.278819Z",
     "iopub.status.busy": "2022-08-20T15:34:20.278156Z",
     "iopub.status.idle": "2022-08-20T15:34:20.287856Z",
     "shell.execute_reply": "2022-08-20T15:34:20.286766Z",
     "shell.execute_reply.started": "2022-08-20T15:34:20.278759Z"
    }
   },
   "outputs": [],
   "source": [
    "def interpol2(s,is_test = True):\n",
    "    x = s.loc[s.sellin.notnull(),'time_step'].values-1\n",
    "    xp = s.loc[s.sellin.notnull(),'time_step'].values\n",
    "    fp =  s.loc[s.sellin.notnull(),'sellin'].values\n",
    "    if is_test:\n",
    "        vals = np.array([n for n in x if n not in xp]+[70,71,72,73])\n",
    "    else:\n",
    "        vals = np.array([n for n in x if n not in xp])\n",
    "    vals = vals[vals>=0]\n",
    "    if fp.shape[0]<2:\n",
    "        s.loc[s.time_step.isin(vals),'sellin'] = 0\n",
    "    else:\n",
    "        s.loc[s.time_step.isin(vals),'sellin'] = np.interp(vals,xp,fp)\n",
    "    return s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:34:20.289157Z",
     "iopub.status.busy": "2022-08-20T15:34:20.288939Z",
     "iopub.status.idle": "2022-08-20T15:34:20.981552Z",
     "shell.execute_reply": "2022-08-20T15:34:20.980738Z",
     "shell.execute_reply.started": "2022-08-20T15:34:20.289135Z"
    }
   },
   "outputs": [],
   "source": [
    "new_ids = [i for i in train.sku_name.unique() if i not in test.sku_name.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:34:20.983123Z",
     "iopub.status.busy": "2022-08-20T15:34:20.982896Z",
     "iopub.status.idle": "2022-08-20T15:34:33.935005Z",
     "shell.execute_reply": "2022-08-20T15:34:33.934312Z",
     "shell.execute_reply.started": "2022-08-20T15:34:20.983100Z"
    }
   },
   "outputs": [],
   "source": [
    "# a = new_frame[new_frame.sku_name.isin(df_test.sku_name.unique())].groupby('sku_name')[['time_step','sellin']].apply(lambda x : interpol2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:34:44.342905Z",
     "iopub.status.busy": "2022-08-20T15:34:44.342534Z",
     "iopub.status.idle": "2022-08-20T15:34:50.480112Z",
     "shell.execute_reply": "2022-08-20T15:34:50.479003Z",
     "shell.execute_reply.started": "2022-08-20T15:34:44.342876Z"
    }
   },
   "outputs": [],
   "source": [
    "a = new_frame[new_frame.sku_name.isin(df_test.sku_name.unique())].reset_index(drop = True).groupby('sku_name',as_index = True)[['time_step','sellin','sku_name']].apply(lambda x : interpol2(x))\n",
    "b = new_frame[new_frame.sku_name.isin(new_ids)].reset_index(drop = True).groupby('sku_name',as_index = True)[['time_step','sellin','sku_name']].apply(lambda x : interpol2(x,is_test = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:34:51.669348Z",
     "iopub.status.busy": "2022-08-20T15:34:51.668227Z",
     "iopub.status.idle": "2022-08-20T15:34:53.800676Z",
     "shell.execute_reply": "2022-08-20T15:34:53.799745Z",
     "shell.execute_reply.started": "2022-08-20T15:34:51.669300Z"
    }
   },
   "outputs": [],
   "source": [
    "a = a.groupby('sku_name',as_index = True).apply(lambda x :x.shift(1)).fillna(-1)\n",
    "a['time_step'] = a['time_step']+1 \n",
    "b= b.groupby('sku_name',as_index = True).apply(lambda x :x.shift(1)).fillna(-1)\n",
    "b['time_step'] = b['time_step']+1 \n",
    "new_frame2 = new_frame.merge(a, on= ['sku_name','time_step'],how = 'left',suffixes = (None,'_old') ).merge(a, on= ['sku_name','time_step'],suffixes = (None,'_old'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:38:18.458200Z",
     "iopub.status.busy": "2022-08-20T15:38:18.457857Z",
     "iopub.status.idle": "2022-08-20T15:38:18.491761Z",
     "shell.execute_reply": "2022-08-20T15:38:18.491055Z",
     "shell.execute_reply.started": "2022-08-20T15:38:18.458173Z"
    }
   },
   "outputs": [],
   "source": [
    "new_frame2.loc[(new_frame2.is_train == 1)&(new_frame2.sku_name.notnull())]\n",
    "# df_train.shape\n",
    "# new_frame2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T15:18:34.042652Z",
     "iopub.status.busy": "2022-08-20T15:18:34.042062Z",
     "iopub.status.idle": "2022-08-20T15:18:34.062404Z",
     "shell.execute_reply": "2022-08-20T15:18:34.061631Z",
     "shell.execute_reply.started": "2022-08-20T15:18:34.042620Z"
    }
   },
   "outputs": [],
   "source": [
    "a.groupby('sku_name').get_group(test.sku_name.unique()[0])[['sellin']].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a.groupby('sku_name').get_group(ids[0])['sellin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-20T11:15:50.450348Z",
     "iopub.status.busy": "2022-08-20T11:15:50.449931Z",
     "iopub.status.idle": "2022-08-20T11:15:50.460220Z",
     "shell.execute_reply": "2022-08-20T11:15:50.459026Z",
     "shell.execute_reply.started": "2022-08-20T11:15:50.450313Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission_42_neg4.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(models)\n",
    "ss['sku_month'] = ss['Item_ID'].apply(lambda x: x.split('_')[0])+'_'+ss['Item_ID'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sku_month'] = df_train['sku_name']+'_'+df_train['month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss.loc[ss.sku_month.isin(df_train.sku_month)]\n",
    "plt.plot(np.log(df_train['sellin'].sort_values().values[3:-301]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.apply(lambda x: '_'.join(x['sku_name'],x['month']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_range = range(1,15)\n",
    "cluster_errors = []\n",
    "for num_clusters in cluster_range:\n",
    "    clusters = KMeans(num_clusters, n_init = 5)\n",
    "    clusters.fit(df_train[sellin+sellout+onhand+['month','year']])\n",
    "    labels = clusters.labels_\n",
    "    centroids = clusters.cluster_centers_\n",
    "    cluster_errors.append(clusters.inertia_)\n",
    "\n",
    "clusters_df = pd.DataFrame({\"num_clusters\": cluster_range, \"cluster_errors\": cluster_errors})\n",
    "# clusters_df\n",
    "from matplotlib import cm\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-14T09:53:08.696502Z",
     "iopub.status.busy": "2022-08-14T09:53:08.695403Z",
     "iopub.status.idle": "2022-08-14T09:53:21.919397Z",
     "shell.execute_reply": "2022-08-14T09:53:21.918187Z",
     "shell.execute_reply.started": "2022-08-14T09:53:08.696460Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-14T09:53:24.328113Z",
     "iopub.status.busy": "2022-08-14T09:53:24.327657Z",
     "iopub.status.idle": "2022-08-14T09:53:25.839127Z",
     "shell.execute_reply": "2022-08-14T09:53:25.837798Z",
     "shell.execute_reply.started": "2022-08-14T09:53:24.328072Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "from flaml import AutoML\n",
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-14T09:53:27.147178Z",
     "iopub.status.busy": "2022-08-14T09:53:27.146435Z"
    }
   },
   "outputs": [],
   "source": [
    "automl.fit(X_train, y_train, task=\"regression\",metric='mae',time_budget=898)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T00:43:20.940440Z",
     "iopub.status.busy": "2022-08-11T00:43:20.939967Z",
     "iopub.status.idle": "2022-08-11T00:43:20.947011Z",
     "shell.execute_reply": "2022-08-11T00:43:20.946109Z",
     "shell.execute_reply.started": "2022-08-11T00:43:20.940389Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Best ML learner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best mae on validation data: {0:.4g}'.format(automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T00:45:46.294252Z",
     "iopub.status.busy": "2022-08-11T00:45:46.293822Z",
     "iopub.status.idle": "2022-08-11T00:45:46.369245Z",
     "shell.execute_reply": "2022-08-11T00:45:46.368311Z",
     "shell.execute_reply.started": "2022-08-11T00:45:46.294217Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['Item_ID'] = df_test['sku_name'] +'_'+ df_test['month'].astype(str)+ '_'+df_test['year'].astype(str)\n",
    "y_pred = df_test[['Item_ID']]\n",
    "target = np.zeros(len(X_test))\n",
    "\n",
    "#light gbm models\n",
    "\n",
    "pred = automl.predict(df_test[X_train.columns])\n",
    "target = pred \n",
    "y_pred = y_pred.assign(target_y= target)\n",
    "sub = ss.merge(y_pred,on = 'Item_ID')\n",
    "sub['target'] = sub['target_y']*1013\n",
    "sub['target'] = sub['target'].astype('int') \n",
    "sub = sub[['Item_ID','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T00:46:22.871627Z",
     "iopub.status.busy": "2022-08-11T00:46:22.870513Z",
     "iopub.status.idle": "2022-08-11T00:46:22.882219Z",
     "shell.execute_reply": "2022-08-11T00:46:22.881334Z",
     "shell.execute_reply.started": "2022-08-11T00:46:22.871582Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission_21.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
