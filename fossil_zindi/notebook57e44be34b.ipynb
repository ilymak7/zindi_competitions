{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-17T01:10:32.515206Z",
     "iopub.status.busy": "2022-08-17T01:10:32.514367Z",
     "iopub.status.idle": "2022-08-17T01:10:35.286122Z",
     "shell.execute_reply": "2022-08-17T01:10:35.284667Z",
     "shell.execute_reply.started": "2022-08-17T01:10:32.515106Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgbm# .loc[df_test.sku_name == new_id_test[0]]\n",
    "from sklearn.preprocessing import LabelEncoder as LE\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:10].index\n",
    "    best_features = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:50]\n",
    "    best_features.reset_index(inplace=True)\n",
    "    print(best_features.dtypes)\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=best_features)\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:20.345758Z",
     "iopub.status.busy": "2022-08-17T02:49:20.345340Z",
     "iopub.status.idle": "2022-08-17T02:49:20.578913Z",
     "shell.execute_reply": "2022-08-17T02:49:20.577791Z",
     "shell.execute_reply.started": "2022-08-17T02:49:20.345726Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/fossl-zindi/Train.csv')\n",
    "test = pd.read_csv('../input/fossl-zindi/Test.csv')\n",
    "ss = pd.read_csv('../input/fossl-zindi/SampleSubmission.csv')\n",
    "dict_s = pd.read_csv('../input/fossl-zindi/DataDictionary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:20.721009Z",
     "iopub.status.busy": "2022-08-17T02:49:20.720577Z",
     "iopub.status.idle": "2022-08-17T02:49:20.730020Z",
     "shell.execute_reply": "2022-08-17T02:49:20.728465Z",
     "shell.execute_reply.started": "2022-08-17T02:49:20.720978Z"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "add_weeks = False\n",
    "add_pivotal_sum = False\n",
    "add_pivotal_max = False\n",
    "encode_channels = False\n",
    "add_pivotal_min = False\n",
    "add_kmeans = False\n",
    "# enode_channels = False\n",
    "add_similar_month = False\n",
    "import calendar\n",
    "def count_weekends(m,y):\n",
    "    day_to_count = calendar.SUNDAY\n",
    "\n",
    "    matrix = calendar.monthcalendar(y,m)\n",
    "\n",
    "    num_days = sum(1 for x in matrix if x[day_to_count] != 0)\n",
    "    return num_days%4\n",
    "if add_weeks:\n",
    "    test['Weeks'] = test.apply(lambda x: count_weekends(x.month, x.year), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:23.155179Z",
     "iopub.status.busy": "2022-08-17T02:49:23.154743Z",
     "iopub.status.idle": "2022-08-17T02:49:23.290809Z",
     "shell.execute_reply": "2022-08-17T02:49:23.289937Z",
     "shell.execute_reply.started": "2022-08-17T02:49:23.155144Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "target = 'sellin'\n",
    "prediction_columns = test.columns.tolist()\n",
    "encoding_columns = [t for t in train.columns if t not in prediction_columns]\n",
    "sellin = ['sellin','sellin_channel_1','sellin_channel_2','sellin_channel_3','sellin_channel_4',\n",
    "         'sellin_channel_5','sellin_channel_6','sellin_channel_7','sellin_channel_8']\n",
    "sellout = ['sellout','sellout_channel_1','sellout_channel_2','sellout_channel_3','sellout_channel_4',\n",
    "         'sellout_channel_5','sellout_channel_6','sellout_channel_7','sellout_channel_8','sellout_channel_9',\n",
    "           'sellout_channel_10']\n",
    "onhand= ['onhand_inventory','onhand_inventory_channel_1','onhand_inventory_channel_2','onhand_inventory_channel_3','onhand_inventory_channel_4',\n",
    "         'onhand_inventory_channel_5','onhand_inventory_channel_6','onhand_inventory_channel_7','onhand_inventory_channel_8','onhand_inventory_channel_9',\n",
    "           'onhand_inventory_channel_10']\n",
    "pivotal_sum_fea = ['sku_name_target_enc_sum_month_'+str(i+1) for i in range(12) ]\n",
    "pivotal_min_fea = ['sku_name_target_enc_min_month_'+str(i+1) for i in range(12) ]\n",
    "pivotal_max_fea = ['sku_name_target_enc_max_month_'+str(i+1) for i in range(12) ]\n",
    "pivot_fea = pivotal_sum_fea + pivotal_max_fea + pivotal_min_fea\n",
    "# new_fea = [f for f in X_train.columns if f not in pivot_fea ]\n",
    "price_enc =  ['sku_namepriceenc6','sku_namepriceenc5','sku_namepriceenc4','sku_namepriceenc','sku_namepriceenc1','sku_namepriceenc2','sku_namepriceenc3']\n",
    "sellin_enc =  ['sku_namesellinenc6','sku_namesellinenc5','sku_namesellinenc4','sku_namesellinenc','sku_namesellinenc1','sku_namesellinenc2','sku_namesellinenc3']\n",
    "sellout_enc =  ['sku_nameselloutenc6','sku_nameselloutenc5','sku_nameselloutenc4','sku_nameselloutenc','sku_nameselloutenc1','sku_nameselloutenc2','sku_nameselloutenc3']\n",
    "onhand_inventory_enc =  ['sku_nameonhand_inventoryenc6','sku_nameonhand_inventoryenc5','sku_nameonhand_inventoryenc4','sku_nameonhand_inventoryenc','sku_nameonhand_inventoryenc1','sku_nameonhand_inventoryenc2','sku_nameonhand_inventoryenc3']\n",
    "starting_inventory_enc =  ['sku_namestarting_inventoryenc6','sku_namestarting_inventoryenc5','sku_namestarting_inventoryenc4','sku_namestarting_inventoryenc','sku_namestarting_inventoryenc1','sku_namestarting_inventoryenc2','sku_namestarting_inventoryenc3']\n",
    "enc_features = price_enc + sellin_enc + sellout_enc + onhand_inventory_enc + starting_inventory_enc \n",
    "df_train['price0'] = df_train['price']//100\n",
    "df_train['price1'] = (df_train['price']//10)%10\n",
    "df_train['price2'] = df_train['price']%10\n",
    "df_train['price3'] = df_train['price']//10\n",
    "df_train[sellin+sellout+onhand+['leftover_inventory','starting_inventory']] = df_train[sellin+sellout+onhand+['leftover_inventory','starting_inventory']]/1013\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:23.599284Z",
     "iopub.status.busy": "2022-08-17T02:49:23.598736Z",
     "iopub.status.idle": "2022-08-17T02:49:23.632036Z",
     "shell.execute_reply": "2022-08-17T02:49:23.631211Z",
     "shell.execute_reply.started": "2022-08-17T02:49:23.599247Z"
    }
   },
   "outputs": [],
   "source": [
    "def target_encode(df_train,df_test,target):\n",
    "    sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "    sku_name_target_max = df_train.groupby('sku_name')[target].max()\n",
    "    sku_name_target_min = df_train.groupby('sku_name')[target].min()\n",
    "    sku_name_target_std = df_train.groupby('sku_name')[target].std()\n",
    "    sku_name_target_median = df_train.groupby('sku_name')[target].apply(lambda x : np.median(x))\n",
    "    sku_name_target_q95 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95))\n",
    "    sku_name_target_q05 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05))\n",
    "    # sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "    df_test['sku_name'+target+'enc'] = df_test['sku_name'].map(sku_name_target_mean)\n",
    "    df_test['sku_name'+target+'enc'].fillna((df_test['sku_name'+target+'enc'].mean()), inplace=True)\n",
    "    df_test['sku_name'+target+'enc1'] = df_test['sku_name'].map(sku_name_target_max)\n",
    "    df_test['sku_name'+target+'enc1'].fillna((df_test['sku_name'+target+'enc1'].mean()), inplace=True)\n",
    "    df_test['sku_name'+target+'enc2'] = df_test['sku_name'].map(sku_name_target_min)\n",
    "    df_test['sku_name'+target+'enc2'].fillna((df_test['sku_name'+target+'enc2'].mean()), inplace=True)\n",
    "    df_test['sku_name'+target+'enc3'] = df_test['sku_name'].map(sku_name_target_std)\n",
    "    df_test['sku_name'+target+'enc3'].fillna((df_test['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "    df_test['sku_name'+target+'enc4'] = df_test['sku_name'].map(sku_name_target_median)\n",
    "    df_test['sku_name'+target+'enc4'].fillna((df_test['sku_name'+target+'enc4'].mean()), inplace=True)\n",
    "    df_test['sku_name'+target+'enc5'] = df_test['sku_name'].map(sku_name_target_q95)\n",
    "    df_test['sku_name'+target+'enc5'].fillna((df_test['sku_name'+target+'enc5'].mean()), inplace=True)\n",
    "    df_test['sku_name'+target+'enc6'] = df_test['sku_name'].map(sku_name_target_q05)\n",
    "    df_test['sku_name'+target+'enc6'].fillna((df_test['sku_name'+target+'enc6'].mean()), inplace=True)\n",
    "    tmp =np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 19910325)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05))\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "    df_train['sku_name'+target+'enc6'] = tmp\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1991032)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95))\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "    df_train['sku_name'+target+'enc5'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1991035)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.median(x))\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "    df_train['sku_name'+target+'enc4'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1910325)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].mean()\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "    df_train['sku_name'+target+'enc'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1991025)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_max = df_train.iloc[idx_1].groupby('sku_name')[target].max()\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_max)\n",
    "    df_train['sku_name'+target+'enc1'] = tmp\n",
    "    # from sklearn.model_selection import KFold/\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1990325)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_min = df_train.iloc[idx_1].groupby('sku_name')[target].min()\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_min)\n",
    "    df_train['sku_name'+target+'enc2'] = tmp\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 19910325)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_std = df_train.iloc[idx_1].groupby('sku_name')[target].std()\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_std)\n",
    "    df_train['sku_name'+target+'enc3'] = tmp\n",
    "    df_train['sku_name'+target+'enc'].fillna((df_train['sku_name'+target+'enc'].mean()), inplace=True)\n",
    "    df_train['sku_name'+target+'enc1'].fillna((df_train['sku_name'+target+'enc1'].mean()), inplace=True)\n",
    "    df_train['sku_name'+target+'enc2'].fillna((df_train['sku_name'+target+'enc2'].mean()), inplace=True)\n",
    "    df_train['sku_name'+target+'enc3'].fillna((df_train['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "    df_train['sku_name'+target+'enc4'].fillna((df_train['sku_name'+target+'enc4'].mean()), inplace=True)\n",
    "    df_train['sku_name'+target+'enc5'].fillna((df_train['sku_name'+target+'enc5'].mean()), inplace=True)\n",
    "    df_train['sku_name'+target+'enc6'].fillna((df_train['sku_name'+target+'enc6'].mean()), inplace=True)\n",
    "    return df_train, df_test\n",
    "# train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmax(axis = 1) # other encoding\n",
    "# train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmin(axis = 1).reset_index() # other encoding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:25.561088Z",
     "iopub.status.busy": "2022-08-17T02:49:25.560316Z",
     "iopub.status.idle": "2022-08-17T02:49:25.596504Z",
     "shell.execute_reply": "2022-08-17T02:49:25.595281Z",
     "shell.execute_reply.started": "2022-08-17T02:49:25.561049Z"
    }
   },
   "outputs": [],
   "source": [
    "def target_encode_p(df_train,df_test,target):\n",
    "    sku_name_target_mean = df_train.groupby('sku_name')[target].mean().round().astype('int16')\n",
    "    sku_name_target_max = df_train.groupby('sku_name')[target].max().round().astype('int16')\n",
    "    sku_name_target_min = df_train.groupby('sku_name')[target].min().round().astype('int16')\n",
    "    sku_name_target_std = df_train.groupby('sku_name')[target].std()\n",
    "    sku_name_target_median = df_train.groupby('sku_name')[target].apply(lambda x : np.median(x).round().astype('int16'))\n",
    "    sku_name_target_q95 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95).round().astype('int16'))\n",
    "    sku_name_target_q05 = df_train.groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05).round().astype('int16'))\n",
    "    # sku_name_target_mean = df_train.groupby('sku_name')[target].mean()\n",
    "    df_test['sku_name'+target+'enc'] = df_test['sku_name'].map(sku_name_target_mean)\n",
    "    df_test['sku_name'+target+'enc'].fillna((df_test['sku_name'+target+'enc'].mean().round().astype('int16')), inplace=True)\n",
    "    df_test['sku_name'+target+'enc1'] = df_test['sku_name'].map(sku_name_target_max)\n",
    "    df_test['sku_name'+target+'enc1'].fillna((df_test['sku_name'+target+'enc1'].mean().round().astype('int16')), inplace=True)\n",
    "    df_test['sku_name'+target+'enc2'] = df_test['sku_name'].map(sku_name_target_min)\n",
    "    df_test['sku_name'+target+'enc2'].fillna((df_test['sku_name'+target+'enc2'].mean().round().astype('int16')), inplace=True)\n",
    "    df_test['sku_name'+target+'enc3'] = df_test['sku_name'].map(sku_name_target_std)\n",
    "    df_test['sku_name'+target+'enc3'].fillna((df_test['sku_name'+target+'enc3']), inplace=True)\n",
    "    df_test['sku_name'+target+'enc4'] = df_test['sku_name'].map(sku_name_target_median)\n",
    "    df_test['sku_name'+target+'enc4'].fillna((df_test['sku_name'+target+'enc4'].mean().round().astype('int16')), inplace=True)\n",
    "    df_test['sku_name'+target+'enc5'] = df_test['sku_name'].map(sku_name_target_q95)\n",
    "    df_test['sku_name'+target+'enc5'].fillna((df_test['sku_name'+target+'enc5'].mean().round().astype('int16')), inplace=True)\n",
    "    df_test['sku_name'+target+'enc6'] = df_test['sku_name'].map(sku_name_target_q05)\n",
    "    df_test['sku_name'+target+'enc6'].fillna((df_test['sku_name'+target+'enc6'].mean().round().astype('int16')), inplace=True)\n",
    "    tmp =np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 19910325)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.05).round().astype('int16'))\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "    df_train['sku_name'+target+'enc6'] = tmp\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1991032)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.quantile(x,0.95).round().astype('int16'))\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "    df_train['sku_name'+target+'enc5'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1991035)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].apply(lambda x : np.median(x).round().astype('int16'))\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "    df_train['sku_name'+target+'enc4'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1910325)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_mean = df_train.iloc[idx_1].groupby('sku_name')[target].mean().round().astype('int16')\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_mean)\n",
    "    df_train['sku_name'+target+'enc'] = tmp\n",
    "\n",
    "\n",
    "\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1991025)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_max = df_train.iloc[idx_1].groupby('sku_name')[target].max().round().astype('int16')\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_max)\n",
    "    df_train['sku_name'+target+'enc1'] = tmp\n",
    "    # from sklearn.model_selection import KFold/\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 1990325)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_min = df_train.iloc[idx_1].groupby('sku_name')[target].min().round().astype('int16')\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_min)\n",
    "    df_train['sku_name'+target+'enc2'] = tmp\n",
    "    # from sklearn.model_selection import KFold\n",
    "    tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "    kf = KFold(n_splits = 5, shuffle=True,random_state = 19910325)\n",
    "    for idx_1, idx_2 in kf.split(df_train):\n",
    "        target_std = df_train.iloc[idx_1].groupby('sku_name')[target].std()\n",
    "\n",
    "        tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(target_std)\n",
    "    df_train['sku_name'+target+'enc3'] = tmp\n",
    "    df_train['sku_name'+target+'enc'].fillna((df_train['sku_name'+target+'enc'].mean().round().astype('int16')), inplace=True)\n",
    "    df_train['sku_name'+target+'enc1'].fillna((df_train['sku_name'+target+'enc1'].mean().round().astype('int16')), inplace=True)\n",
    "    df_train['sku_name'+target+'enc2'].fillna((df_train['sku_name'+target+'enc2'].mean().round().astype('int16')), inplace=True)\n",
    "    df_train['sku_name'+target+'enc3'].fillna((df_train['sku_name'+target+'enc3'].mean()), inplace=True)\n",
    "    df_train['sku_name'+target+'enc4'].fillna((df_train['sku_name'+target+'enc4'].mean().round().astype('int16').round().astype('int16')), inplace=True)\n",
    "    df_train['sku_name'+target+'enc5'].fillna((df_train['sku_name'+target+'enc5'].mean().round().astype('int16')), inplace=True)\n",
    "    df_train['sku_name'+target+'enc6'].fillna((df_train['sku_name'+target+'enc6'].mean().round().astype('int16')), inplace=True)\n",
    "    return df_train, df_test\n",
    "# train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmax(axis = 1) # other encoding\n",
    "# train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').idxmin(axis = 1).reset_index() # other encoding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:26.719519Z",
     "iopub.status.busy": "2022-08-17T02:49:26.718639Z",
     "iopub.status.idle": "2022-08-17T02:49:59.763580Z",
     "shell.execute_reply": "2022-08-17T02:49:59.762291Z",
     "shell.execute_reply.started": "2022-08-17T02:49:26.719479Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train,df_test = target_encode(df_train,df_test,'sellin')\n",
    "df_train,df_test = target_encode(df_train,df_test,'sellout')\n",
    "# df_train,df_test = target_encode_p(df_train,df_test,'price0')\n",
    "# df_train,df_test = target_encode_p(df_train,df_test,'price1')\n",
    "# df_train,df_test = target_encode_p(df_train,df_test,'price2')\n",
    "# df_train,df_test = target_encode_p(df_train,df_test,'price3')\n",
    "df_train,df_test = target_encode(df_train,df_test,'price')\n",
    "\n",
    "# df_train,df_test = target_encode(df_train,df_test,'starting_inventory')\n",
    "df_train,df_test = target_encode(df_train,df_test,'leftover_inventory')\n",
    "pcl = df_train.groupby(['sku_name','year','month'])['product_lifecycle_stage'].apply(lambda x : x.unique()[0]).reset_index()\n",
    "pcl_test = df_train.groupby('sku_name')['product_lifecycle_stage'].apply(lambda x:x.values[-1])\n",
    "df_train.drop('product_lifecycle_stage',axis = 1,inplace = True)\n",
    "new_target = df_train.groupby(['sku_name','year','month'])['sellin'].sum().reset_index()\n",
    "df_train = df_train.merge(pcl,on = ['sku_name','year','month'],how = 'left')\n",
    "df_test['product_lifecycle_stage'] = df_test['sku_name'].map(pcl_test)\n",
    "target = 'sellin'\n",
    "prediction_columns = df_test.columns.tolist()\n",
    "encoding_columns = [t for t in df_train.columns if t not in prediction_columns]\n",
    "# X = df_train.drop(encoding_columns+[target],axis=1)\n",
    "# y = df_train[target]\n",
    "df_train = df_train.drop([target],axis=1).merge(new_target,on = ['sku_name','year','month'],how = 'left').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:59.765966Z",
     "iopub.status.busy": "2022-08-17T02:49:59.765561Z",
     "iopub.status.idle": "2022-08-17T02:49:59.778565Z",
     "shell.execute_reply": "2022-08-17T02:49:59.777400Z",
     "shell.execute_reply.started": "2022-08-17T02:49:59.765933Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test\n",
    "# def rowIndex(row):\n",
    "#     return row.name\n",
    "def last_known_sellin(df_train,df_test):\n",
    "#     months_train = \n",
    "# df_train.iloc[1:].apply(rowIndex,axis= 1)-1\n",
    "    ma = df_train.groupby('sku_name').apply(lambda x : np.median(x))\n",
    "    df_train['medians'] = df_train['sku_name'].map(ma)\n",
    "    a = df_train.merge(df_train.shift(1)[['sku_name','year','month','sellin']] ,left_index = True,right_index = True,suffixes = (None,'_old'))\n",
    "    b = df_test.merge(df_train.loc[df_train.sku_name.isin(df_test.sku_name)].groupby('sku_name').apply(lambda x:x.iloc[-1])[['year','month','sellin']].reset_index(),\n",
    "                 on = 'sku_name',how = 'left', suffixes = (None,'_old'))\n",
    "    a['sellin_old'] = np.where(a['sku_name'] == a['sku_name_old'], a['sellin_old'] , np.nan)\n",
    "    a['period_old'] = np.where(a['sku_name'] == a['sku_name_old'], (a['year']-a['year_old'])*12 + (a['month']-a['month_old']) , np.nan)\n",
    "    b['period_old'] = (b['year']-b['year_old'])*12 + (b['month']-b['month_old'])\n",
    "    b['sellin_old'] = b['sellin']\n",
    "    a['sellin_old'] = a['sellin_old'].fillna(a['medians'])\n",
    "    b['sellin_old'] = b['sellin_old'].fillna(np.median(a['medians'].values))\n",
    "    a.drop(['sku_name_old','medians'],axis = 1,inplace = True)\n",
    "    b.drop(['sellin'],axis = 1,inplace = True)\n",
    "    return a,b\n",
    "# df_train.shift(1)[['sku_name','year','month','sellin']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:59.780683Z",
     "iopub.status.busy": "2022-08-17T02:49:59.780125Z",
     "iopub.status.idle": "2022-08-17T02:49:59.841439Z",
     "shell.execute_reply": "2022-08-17T02:49:59.840416Z",
     "shell.execute_reply.started": "2022-08-17T02:49:59.780648Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([df_train[prediction_columns],df_test[prediction_columns]])\n",
    "le = LE()\n",
    "all_data['enc_sku'] = le.fit_transform(all_data['sku_name'])\n",
    "df_train['enc_sku'] = all_data.iloc[:df_train.shape[0]]['enc_sku']\n",
    "df_test['enc_sku'] = all_data.iloc[df_train.shape[0]:]['enc_sku']\n",
    "\n",
    "le = LE()\n",
    "all_data['product_lifecycle_stage'] = le.fit_transform(all_data['product_lifecycle_stage'])\n",
    "df_train['product_lifecycle_stage'] = all_data.iloc[:df_train.shape[0]]['product_lifecycle_stage']\n",
    "df_test['product_lifecycle_stage'] = all_data.iloc[df_train.shape[0]:]['product_lifecycle_stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:49:59.844291Z",
     "iopub.status.busy": "2022-08-17T02:49:59.843908Z",
     "iopub.status.idle": "2022-08-17T02:50:00.045283Z",
     "shell.execute_reply": "2022-08-17T02:50:00.044145Z",
     "shell.execute_reply.started": "2022-08-17T02:49:59.844259Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.groupby(['sku_name','year','month']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:00.046819Z",
     "iopub.status.busy": "2022-08-17T02:50:00.046475Z",
     "iopub.status.idle": "2022-08-17T02:50:00.868872Z",
     "shell.execute_reply": "2022-08-17T02:50:00.867888Z",
     "shell.execute_reply.started": "2022-08-17T02:50:00.046790Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train,df_test = last_known_sellin(df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:00.871007Z",
     "iopub.status.busy": "2022-08-17T02:50:00.870642Z",
     "iopub.status.idle": "2022-08-17T02:50:00.905513Z",
     "shell.execute_reply": "2022-08-17T02:50:00.904051Z",
     "shell.execute_reply.started": "2022-08-17T02:50:00.870976Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train1/\n",
    "add_similar_products = True\n",
    "if encode_channels:\n",
    "        sku_name_channel_enc = df_train.groupby('sku_name')[sellin[1:]].max().idxmax(axis=1) # other encoding\n",
    "        sku_name_channel_enc1 = df_train.groupby('sku_name')[sellin[1:]].min().idxmin(axis=1)# train.groupby('sku_name')[sellin[1:]].min().idxmin(axis=1) # other encoding\n",
    "        df_train['sku_name_channel_enc'] = df_train['sku_name'].map(sku_name_channel_enc)\n",
    "        df_train['sku_name_channel_enc1'] = df_train['sku_name'].map(sku_name_channel_enc1)\n",
    "        df_test['sku_name_channel_enc'] = df_test['sku_name'].map(sku_name_channel_enc)\n",
    "        df_test['sku_name_channel_enc1'] = df_test['sku_name'].map(sku_name_channel_enc1)\n",
    "        df_test['sku_name_channel_enc1'].fillna('sellin_channel_1', inplace=True)\n",
    "        df_test['sku_name_channel_enc'].fillna('sellin_channel_4', inplace=True)\n",
    "        le = LE()\n",
    "        df_train['sku_name_channel_enc1'] = le.fit_transform(df_train['sku_name_channel_enc1'])\n",
    "        df_test['sku_name_channel_enc1'] = le.transform(df_test['sku_name_channel_enc1'])\n",
    "        le = LE()\n",
    "        df_train['sku_name_channel_enc'] = le.fit_transform(df_train['sku_name_channel_enc'])\n",
    "        df_test['sku_name_channel_enc'] = le.transform(df_test['sku_name_channel_enc'])\n",
    "if add_pivotal_sum:\n",
    "        cols = ['month_'+str(i+1) for i in range(12) ]\n",
    "        exp = df_train.groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "        exp.columns = ['sku_name']+ cols\n",
    "        from sklearn.impute import KNNImputer\n",
    "#         imputer = KNNImputer(n_neighbors=5)\n",
    "#         exp[cols] = imputer.fit_transform(exp[cols])\n",
    "#         exp.fillna(0,inplace = True)\n",
    "        exp.set_index('sku_name',inplace = True)\n",
    "        for c in cols:\n",
    "            df_test['sku_name_target_enc_sum_'+c] = df_test['sku_name'].map(exp[c])\n",
    "            tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "            kf = KFold(n_splits = 5, shuffle=True,random_state = 1991032)\n",
    "            for idx_1, idx_2 in kf.split(df_train):\n",
    "                exp2 = df_train.iloc[idx_1].groupby(['sku_name','month'])[sellin[0]].sum().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "                exp2.columns = ['sku_name']+ cols\n",
    "#                 imputer = KNNImputer(n_neighbors=20)\n",
    "#                 exp2[cols] = imputer.fit_transform(exp2[cols])\n",
    "                exp2.set_index('sku_name',inplace = True)\n",
    "\n",
    "                tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(exp2[c])\n",
    "                df_train['sku_name_target_enc_sum_'+c] = tmp\n",
    "        imputer = KNNImputer(n_neighbors=20)\n",
    "        df_train[['sku_name_target_enc_sum_'+j for j in cols]] = imputer.fit_transform(df_train[['sku_name_target_enc_sum_'+j for j in cols]])\n",
    "if add_pivotal_min:\n",
    "        cols = ['month_'+str(i+1) for i in range(12) ]\n",
    "        exp = df_train.groupby(['sku_name','month'])[sellin[0]].min().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "        exp.columns = ['sku_name']+ cols\n",
    "        from sklearn.impute import KNNImputer\n",
    "#         imputer = KNNImputer(n_neighbors=5)\n",
    "#         exp[cols] = imputer.fit_transform(exp[cols])\n",
    "#         exp.fillna(0,inplace = True)\n",
    "    \n",
    "        \n",
    "        exp.set_index('sku_name',inplace = True)\n",
    "        for c in cols:\n",
    "            df_test['sku_name_target_enc_min_'+c] = df_test['sku_name'].map(exp[c])\n",
    "            tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "            kf = KFold(n_splits = 5, shuffle=True,random_state = 1910325)\n",
    "            for idx_1, idx_2 in kf.split(df_train):\n",
    "                exp2 = df_train.iloc[idx_1].groupby(['sku_name','month'])[sellin[0]].min().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "                exp2.columns = ['sku_name']+ cols\n",
    "#                 imputer = KNNImputer(n_neighbors=5)\n",
    "#                 exp2[cols] = imputer.fit_transform(exp2[cols])\n",
    "                exp2.set_index('sku_name',inplace = True)\n",
    "\n",
    "                tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(exp2[c])\n",
    "                df_train['sku_name_target_enc_min_'+c] = tmp\n",
    "        imputer = KNNImputer(n_neighbors=20)\n",
    "        df_train[['sku_name_target_enc_min_'+j for j in cols]] = imputer.fit_transform(df_train[['sku_name_target_enc_min_'+j for j in cols]])\n",
    "if add_pivotal_max:\n",
    "        cols = ['month_'+str(i+1) for i in range(12) ]\n",
    "        exp = df_train.groupby(['sku_name','month'])[sellin[0]].max().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "        exp.columns = ['sku_name']+ cols\n",
    "        from sklearn.impute import KNNImputer\n",
    "#         exp.fillna(0,inplace = True)\n",
    "\n",
    "        exp.set_index('sku_name',inplace = True)\n",
    "        for c in cols:\n",
    "            df_test['sku_name_target_enc_max_'+c] = df_test['sku_name'].map(exp[c])\n",
    "            tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "            kf = KFold(n_splits = 5, shuffle=True,random_state = 9910325)\n",
    "            for idx_1, idx_2 in kf.split(df_train):\n",
    "                exp2 = df_train.iloc[idx_1].groupby(['sku_name','month'])[sellin[0]].max().reset_index().pivot(index='sku_name', columns='month',values = 'sellin').reset_index()\n",
    "                exp2.columns = ['sku_name']+ cols\n",
    "#                 imputer = KNNImputer(n_neighbors=5)\n",
    "#                 exp2[cols] = imputer.fit_transform(exp2[cols])\n",
    "                exp2.set_index('sku_name',inplace = True)\n",
    "\n",
    "                tmp[idx_2] = df_train['sku_name'].iloc[idx_2].map(exp2[c])\n",
    "                df_train['sku_name_target_enc_max_'+c] = tmp\n",
    "        imputer = KNNImputer(n_neighbors=20)\n",
    "        df_train[['sku_name_target_enc_max_'+j for j in cols]] = imputer.fit_transform(df_train[['sku_name_target_enc_max_'+j for j in cols]])\n",
    "\n",
    "if add_similar_month:\n",
    "        df_train['new_index'] = df_train['sku_name']+'_'+df_train['month'].astype(str)\n",
    "        df_test['new_index'] = df_test['sku_name']+'_'+df_test['month'].astype(str)\n",
    "        new_df = df_train.groupby('new_index')['sellin'].mean()\n",
    "        df_test['sku_name_target_enc_overfit'] = df_test['new_index'].map(new_df)\n",
    "        df_test['sku_name_target_enc_overfit'].fillna((df_test['sku_name_target_enc_overfit'].mean()), inplace=True)\n",
    "        tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "        kf = KFold(n_splits = 5, shuffle=True,random_state = 29910325)\n",
    "        for idx_1, idx_2 in kf.split(df_train):\n",
    "            target_mean = df_train.iloc[idx_1].groupby('new_index')['sellin'].mean()\n",
    "\n",
    "            tmp[idx_2] = df_train['new_index'].iloc[idx_2].map(target_mean)\n",
    "        df_train['sku_name_target_enc_overfit'] = tmp\n",
    "        df_train['sku_name_target_enc_overfit'].fillna((df_train['sku_name_target_enc_overfit'].mean()), inplace=True)\n",
    "        df_train.drop('new_index',axis = 1, inplace = True)\n",
    "        df_test.drop('new_index',axis = 1, inplace = True)\n",
    "# What i suppose is similar products\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:00.907293Z",
     "iopub.status.busy": "2022-08-17T02:50:00.906904Z",
     "iopub.status.idle": "2022-08-17T02:50:00.954411Z",
     "shell.execute_reply": "2022-08-17T02:50:00.952965Z",
     "shell.execute_reply.started": "2022-08-17T02:50:00.907265Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = df_train.groupby(['sku_name','month'])['sellin'].sum().reset_index().pivot(index = 'sku_name',columns = 'month', values = 'sellin').idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:00.956344Z",
     "iopub.status.busy": "2022-08-17T02:50:00.956004Z",
     "iopub.status.idle": "2022-08-17T02:50:00.984404Z",
     "shell.execute_reply": "2022-08-17T02:50:00.983509Z",
     "shell.execute_reply.started": "2022-08-17T02:50:00.956315Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['best_month'] = df_test['sku_name'].map(groups)\n",
    "df_train['best_month'] = df_train['sku_name'].map(groups).astype('int')\n",
    "df_test['best_month'].fillna(10,inplace = True)\n",
    "df_test['best_month'] = df_test['best_month'].astype('int')\n",
    "df_test['period_old'] = df_test['period_old'].fillna(0).astype('int')\n",
    "df_train['period_old'] = df_train['period_old'].fillna(0).astype('int')\n",
    "\n",
    "# groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:00.986022Z",
     "iopub.status.busy": "2022-08-17T02:50:00.985691Z",
     "iopub.status.idle": "2022-08-17T02:50:01.005680Z",
     "shell.execute_reply": "2022-08-17T02:50:01.004402Z",
     "shell.execute_reply.started": "2022-08-17T02:50:00.985991Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train1 = df_train.copy()\n",
    "df_test1 = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:01.009347Z",
     "iopub.status.busy": "2022-08-17T02:50:01.008970Z",
     "iopub.status.idle": "2022-08-17T02:50:01.026237Z",
     "shell.execute_reply": "2022-08-17T02:50:01.025000Z",
     "shell.execute_reply.started": "2022-08-17T02:50:01.009307Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train1['pct_change_sellin'] = df_train1.groupby('sku_name')['sellin'].pct_change().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:01.028177Z",
     "iopub.status.busy": "2022-08-17T02:50:01.027845Z",
     "iopub.status.idle": "2022-08-17T02:50:01.065517Z",
     "shell.execute_reply": "2022-08-17T02:50:01.064575Z",
     "shell.execute_reply.started": "2022-08-17T02:50:01.028148Z"
    }
   },
   "outputs": [],
   "source": [
    "fact = df_train1[['sku_name','month','year','best_month','pct_change_sellin']].groupby(['best_month','month'])['pct_change_sellin'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:01.067485Z",
     "iopub.status.busy": "2022-08-17T02:50:01.067126Z",
     "iopub.status.idle": "2022-08-17T02:50:01.073031Z",
     "shell.execute_reply": "2022-08-17T02:50:01.071592Z",
     "shell.execute_reply.started": "2022-08-17T02:50:01.067454Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test1 = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:01.075347Z",
     "iopub.status.busy": "2022-08-17T02:50:01.074825Z",
     "iopub.status.idle": "2022-08-17T02:50:01.167483Z",
     "shell.execute_reply": "2022-08-17T02:50:01.166626Z",
     "shell.execute_reply.started": "2022-08-17T02:50:01.075304Z"
    }
   },
   "outputs": [],
   "source": [
    "for m in [11,12,1]:\n",
    "    for bm in range(1,13):\n",
    "        if m==12:\n",
    "            M = 1\n",
    "        else:\n",
    "            M = m+1\n",
    "        df_test.loc[(df_test.best_month == bm)& (df_test.month == M),'sellin_old' ] = df_test.loc[(df_test.best_month == bm)& (df_test.month == M),'sellin_old' ]* (fact.loc[(fact.best_month == bm)& (fact.month == m),'pct_change_sellin'].values+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:01.169439Z",
     "iopub.status.busy": "2022-08-17T02:50:01.168880Z",
     "iopub.status.idle": "2022-08-17T02:50:01.199593Z",
     "shell.execute_reply": "2022-08-17T02:50:01.198452Z",
     "shell.execute_reply.started": "2022-08-17T02:50:01.169404Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train1.groupby('sku_name').get_group('ROSEETTENOVE')[['sellin','pct_change_sellin']]\n",
    "# df_train1.loc[df_train1.period_old>36,['sellin','sellin_old']].describe()\n",
    "a = df_train1[df_train1.year<2021].groupby(['sku_name','year'])['sellin'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T01:23:00.039961Z",
     "iopub.status.busy": "2022-08-17T01:23:00.038992Z",
     "iopub.status.idle": "2022-08-17T01:23:00.060117Z",
     "shell.execute_reply": "2022-08-17T01:23:00.058962Z",
     "shell.execute_reply.started": "2022-08-17T01:23:00.039908Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train1[df_train1.year<2021].groupby(['sku_name','year'])['sellin'].mean()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T01:23:44.848804Z",
     "iopub.status.busy": "2022-08-17T01:23:44.847985Z",
     "iopub.status.idle": "2022-08-17T01:23:45.413873Z",
     "shell.execute_reply": "2022-08-17T01:23:45.413008Z",
     "shell.execute_reply.started": "2022-08-17T01:23:44.848764Z"
    }
   },
   "outputs": [],
   "source": [
    "# a.groupby('sku_name')['sellin'].pct_change().fillna(0)\n",
    "# df_train1[df_train1.year<2021].groupby(['sku_name','year'])['sellin']\n",
    "b = a.groupby('sku_name')['sellin'].pct_change().fillna(0)/a.groupby('sku_name')['year'].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T01:27:19.502432Z",
     "iopub.status.busy": "2022-08-17T01:27:19.502023Z",
     "iopub.status.idle": "2022-08-17T01:27:19.519941Z",
     "shell.execute_reply": "2022-08-17T01:27:19.518881Z",
     "shell.execute_reply.started": "2022-08-17T01:27:19.502381Z"
    }
   },
   "outputs": [],
   "source": [
    "# max(1,0)\n",
    "# plt.plot(a.iloc[:4]['sellin'])\n",
    "# a.loc[a.sku_name == a.sku_name.unique()[1],['year','sellin']]\n",
    "# plt.scatter(x = a.year,y = a.sellin)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T01:28:15.272943Z",
     "iopub.status.busy": "2022-08-17T01:28:15.271838Z",
     "iopub.status.idle": "2022-08-17T01:28:15.406186Z",
     "shell.execute_reply": "2022-08-17T01:28:15.404979Z",
     "shell.execute_reply.started": "2022-08-17T01:28:15.272883Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train1 = df_train1.merge(a[['sku_name','year','pct_change_year']], on = ['sku_name','year'],how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T01:35:51.504045Z",
     "iopub.status.busy": "2022-08-17T01:35:51.503169Z",
     "iopub.status.idle": "2022-08-17T01:35:51.543473Z",
     "shell.execute_reply": "2022-08-17T01:35:51.542606Z",
     "shell.execute_reply.started": "2022-08-17T01:35:51.504001Z"
    }
   },
   "outputs": [],
   "source": [
    "y_fact = df_train1[df_train1.year<2021].groupby(['best_month','year'])['pct_change_year'].mean().reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in in range(1,13):\n",
    "#     for bm in range(1,13):\n",
    "#         if m==12:\n",
    "#             M = 1\n",
    "#         else:\n",
    "#             M = m+1\n",
    "#         df_train1.loc[(df_train1.best_month == bm)& (df_train1.month == M)&(df_train1.period_old > 1),'sellin_old' ] = df_train1.loc[(df_train1.best_month == bm)& (df_train1.month == M)&(df_train1.period_old > 1),'sellin_old' ]& (fact.month == m),'pct_change_sellin'].values+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T01:39:23.713130Z",
     "iopub.status.busy": "2022-08-17T01:39:23.712769Z",
     "iopub.status.idle": "2022-08-17T01:39:23.729172Z",
     "shell.execute_reply": "2022-08-17T01:39:23.728215Z",
     "shell.execute_reply.started": "2022-08-17T01:39:23.713103Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train1.loc[(df_train1.best_month == 1)& (df_train1.month == 1)&(df_train1.period_old > 1),['sellin_old','period_old']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:39:23.557898Z",
     "iopub.status.busy": "2022-08-17T02:39:23.557433Z",
     "iopub.status.idle": "2022-08-17T02:39:23.568531Z",
     "shell.execute_reply": "2022-08-17T02:39:23.566963Z",
     "shell.execute_reply.started": "2022-08-17T02:39:23.557862Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test1.loc[(df_test1.best_month == bm)& (df_test1.month == M),'sellin_old' ]* \n",
    "# fact.loc[(fact.best_month == bm-2)& (fact.month == m),'pct_change_sellin'].values\n",
    "# df_test1['sellin_old'].round()\n",
    "# for y in range(2016,2022):\n",
    "#     for y_old in range(2016,2022):\n",
    "#         for m in range(1,13):\n",
    "#             for m_o in range(1,13):\n",
    "#                 for b_m in in range(1,13):\n",
    "#                     if (m_o == m+1) or ((m_o==12)&m ==1):\n",
    "#                         df_train1.loc[(df_train1.best_month == b_m)& (df_train1.month == m)& (df_train1.month == m_o) ,'sellin_old'] =\n",
    "def missing_years(y,m,y_o,m_o):\n",
    "    flag = True\n",
    "    if m_o>m and not ((m_o == 12) & (m ==1 )):\n",
    "        flag = False\n",
    "    missing_y = []\n",
    "    while y>y_o:\n",
    "        missing_y.append(y_o)\n",
    "        y_o=y_o+1\n",
    "    missing_m = []\n",
    "    if flag:\n",
    "        while m>m_o+1:\n",
    "            m_o=m_o+1\n",
    "            missing_m.append(m_o)\n",
    "            \n",
    "    else:\n",
    "            while m<m_o and not ((m_o == 12) & (m ==1 )):\n",
    "                m_o=m_o-1\n",
    "                missing_m.append(m_o-1)\n",
    "    if (len(missing_y)==0) & (len(missing_m)==0):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.array(missing_y),np.array(missing_m),flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:39:24.092333Z",
     "iopub.status.busy": "2022-08-17T02:39:24.091627Z",
     "iopub.status.idle": "2022-08-17T02:39:25.829464Z",
     "shell.execute_reply": "2022-08-17T02:39:25.828365Z",
     "shell.execute_reply.started": "2022-08-17T02:39:24.092292Z"
    }
   },
   "outputs": [],
   "source": [
    "c = df_train1.apply(lambda x : missing_years(x['year'],x['month'],x['year_old'],x['month_old']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:39:27.548405Z",
     "iopub.status.busy": "2022-08-17T02:39:27.547529Z",
     "iopub.status.idle": "2022-08-17T02:39:27.555059Z",
     "shell.execute_reply": "2022-08-17T02:39:27.553692Z",
     "shell.execute_reply.started": "2022-08-17T02:39:27.548363Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test1['sellin_old']\n",
    "# bm\n",
    "# df_train1.iloc[1][['year','month','month_old','year_old']]\n",
    "df_train1['missing'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:39:28.897528Z",
     "iopub.status.busy": "2022-08-17T02:39:28.896656Z",
     "iopub.status.idle": "2022-08-17T02:39:28.908663Z",
     "shell.execute_reply": "2022-08-17T02:39:28.907575Z",
     "shell.execute_reply.started": "2022-08-17T02:39:28.897485Z"
    }
   },
   "outputs": [],
   "source": [
    "# df\n",
    "df_train1['missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:40:41.139681Z",
     "iopub.status.busy": "2022-08-17T02:40:41.138674Z",
     "iopub.status.idle": "2022-08-17T02:40:41.175479Z",
     "shell.execute_reply": "2022-08-17T02:40:41.174360Z",
     "shell.execute_reply.started": "2022-08-17T02:40:41.139641Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train1.loc[(df_train1['missing'].notnull())&(df_train1.period_old>1),['year','month','year_old','month_old','missing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:13.138692Z",
     "iopub.status.busy": "2022-08-17T02:50:13.137962Z",
     "iopub.status.idle": "2022-08-17T02:50:13.166522Z",
     "shell.execute_reply": "2022-08-17T02:50:13.165614Z",
     "shell.execute_reply.started": "2022-08-17T02:50:13.138655Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train2 = df_train.copy()\n",
    "df_train = df_train[df_train.period_old<2].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:16.282169Z",
     "iopub.status.busy": "2022-08-17T02:50:16.281568Z",
     "iopub.status.idle": "2022-08-17T02:50:16.325391Z",
     "shell.execute_reply": "2022-08-17T02:50:16.324593Z",
     "shell.execute_reply.started": "2022-08-17T02:50:16.282135Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:50:19.928578Z",
     "iopub.status.busy": "2022-08-17T02:50:19.928142Z",
     "iopub.status.idle": "2022-08-17T02:50:20.002218Z",
     "shell.execute_reply": "2022-08-17T02:50:20.000891Z",
     "shell.execute_reply.started": "2022-08-17T02:50:19.928520Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = df_test.select_dtypes(include = 'float64').columns.tolist()\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "rs = RobustScaler()\n",
    "for s in scale:\n",
    "    df_train[s] = rs.fit_transform(df_train[s].values.reshape(-1, 1))\n",
    "    df_test[s] = rs.transform(df_test[s].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:58:09.189125Z",
     "iopub.status.busy": "2022-08-17T02:58:09.187990Z",
     "iopub.status.idle": "2022-08-17T02:58:09.197199Z",
     "shell.execute_reply": "2022-08-17T02:58:09.195874Z",
     "shell.execute_reply.started": "2022-08-17T02:58:09.189071Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return  np.mean(np.abs(y_true - y_pred))*1013#(np.sqrt(np.mean(np.square((y_true - y_pred) / (y_true+2)))))\n",
    "\n",
    "def feval_RMSPE(preds, lgbm_train):\n",
    "    labels = lgbm_train.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),0), False\n",
    "\n",
    "params = {\n",
    "      \"objective\": \"mae\", \n",
    "      \"metric\": \"mae\", \n",
    "      \"boosting_type\": \"gbdt\",\n",
    "      'early_stopping_rounds': 30,\n",
    "      'learning_rate': 0.01,\n",
    "#     'num_leaves': 170,\n",
    "#     'min_data_in_leaf': 10, \n",
    "#     'min_child_weight': 0.066978276178616,\n",
    "#     'max_depth': 83, \n",
    "#     'bagging_fraction': 0.6277904572518515, \n",
    "#     'feature_fraction': 0.6965518420559522, \n",
    "#     'lambda_l1': 1.6347289329468329, \n",
    "#     'lambda_l2': 0.1374430845238362 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:58:09.983883Z",
     "iopub.status.busy": "2022-08-17T02:58:09.983124Z",
     "iopub.status.idle": "2022-08-17T02:58:09.989212Z",
     "shell.execute_reply": "2022-08-17T02:58:09.987976Z",
     "shell.execute_reply.started": "2022-08-17T02:58:09.983844Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train1.loc[df_train1.sku_name == df_test.sku_name.values[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:58:10.521180Z",
     "iopub.status.busy": "2022-08-17T02:58:10.520577Z",
     "iopub.status.idle": "2022-08-17T02:58:10.525443Z",
     "shell.execute_reply": "2022-08-17T02:58:10.524482Z",
     "shell.execute_reply.started": "2022-08-17T02:58:10.521145Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test.loc[df_test.sku_name == df_test.sku_name.values[-1]]\n",
    "# df_test.loc[df_test.period_old.isna(),'period_old'] #= np.array([0,1,2,3])\n",
    "# df_test['period_old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:58:11.312263Z",
     "iopub.status.busy": "2022-08-17T02:58:11.311507Z",
     "iopub.status.idle": "2022-08-17T02:58:11.381301Z",
     "shell.execute_reply": "2022-08-17T02:58:11.380337Z",
     "shell.execute_reply.started": "2022-08-17T02:58:11.312224Z"
    }
   },
   "outputs": [],
   "source": [
    "kfolds = 10\n",
    "from sklearn.model_selection import KFold,GroupKFold\n",
    "kf = KFold(n_splits=kfolds, random_state=1991028, shuffle=True)\n",
    "oof = pd.DataFrame()                 # out-of-fold result\n",
    "models = []                          # models\n",
    "scores = 0.0   \n",
    "\n",
    "features_importance= pd.DataFrame({'Feature':[], 'Importance':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:58:14.682292Z",
     "iopub.status.busy": "2022-08-17T02:58:14.681119Z",
     "iopub.status.idle": "2022-08-17T02:58:14.692952Z",
     "shell.execute_reply": "2022-08-17T02:58:14.691217Z",
     "shell.execute_reply.started": "2022-08-17T02:58:14.682248Z"
    }
   },
   "outputs": [],
   "source": [
    "target = 'sellin'\n",
    "prediction_columns = df_test.columns.tolist()\n",
    "encoding_columns = [t for t in df_train.columns if t not in prediction_columns]\n",
    "X = df_train.drop(encoding_columns+[target,'sku_name','enc_sku','product_lifecycle_stage','period_old'],axis=1)\n",
    "y = df_train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:58:15.749761Z",
     "iopub.status.busy": "2022-08-17T02:58:15.749354Z",
     "iopub.status.idle": "2022-08-17T02:58:15.754679Z",
     "shell.execute_reply": "2022-08-17T02:58:15.753378Z",
     "shell.execute_reply.started": "2022-08-17T02:58:15.749727Z"
    }
   },
   "outputs": [],
   "source": [
    "# X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T02:58:16.839261Z",
     "iopub.status.busy": "2022-08-17T02:58:16.838836Z",
     "iopub.status.idle": "2022-08-17T03:00:51.191405Z",
     "shell.execute_reply": "2022-08-17T03:00:51.190036Z",
     "shell.execute_reply.started": "2022-08-17T02:58:16.839228Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):#, groups=X[\"best_month\"])):\n",
    "\n",
    "    print(\"Fold :\", fold+1)\n",
    "    \n",
    "    # create dataset\n",
    "    X_train, y_train = X.loc[trn_idx], y[trn_idx]\n",
    "    X_valid, y_valid = X.loc[val_idx], y[val_idx]\n",
    "    \n",
    "    #RMSPE weight\n",
    "#     weights = 1/(w_train)\n",
    "    lgbm_train = lgbm.Dataset(X_train,y_train)#,weight = weights)\n",
    "\n",
    "#     weights = 1/(w_valid)\n",
    "    lgbm_valid = lgbm.Dataset(X_valid,y_valid,reference = lgbm_train)#,weight = weights)\n",
    "    \n",
    "    # model \n",
    "    model = lgbm.train(params=params,\n",
    "                      train_set=lgbm_train,\n",
    "                      valid_sets=[lgbm_train, lgbm_valid],\n",
    "                      num_boost_round=15000,         \n",
    "#                       feval='mae',\n",
    "#                     feval=lambda preds, lgbm_train: [feval_RMSE(preds, lgbm_train), \n",
    "#                                                   feval_MAPE(preds, lgbm_train),\n",
    "#                                                      mae(preds, lgbm_train.get_label())\n",
    "#                                                     ],\n",
    "                      verbose_eval=100,\n",
    "#                       categorical_feature = cats                \n",
    "                     )\n",
    "    \n",
    "    # validation \n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    oof[val_idx] = y_pred\n",
    "    features = X_train.columns\n",
    "    RMSPE = round(rmspe(y_true = y_valid, y_pred = y_pred),3)\n",
    "    print(f'Performance of the　prediction: , RMSPE: {RMSPE}')\n",
    "    fold_importance_df= pd.DataFrame({'Feature':[], 'Importance':[]})\n",
    "    fold_importance_df['Feature']= features\n",
    "    fold_importance_df['Importance']= model.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold + 1\n",
    "    features_importance = pd.concat([features_importance, fold_importance_df], axis=0)\n",
    "    #keep scores and models\n",
    "    scores += RMSPE / kfolds\n",
    "    models.append(model)\n",
    "    print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T03:00:56.698517Z",
     "iopub.status.busy": "2022-08-17T03:00:56.697566Z",
     "iopub.status.idle": "2022-08-17T03:00:56.702981Z",
     "shell.execute_reply": "2022-08-17T03:00:56.701986Z",
     "shell.execute_reply.started": "2022-08-17T03:00:56.698475Z"
    }
   },
   "outputs": [],
   "source": [
    "# models = models[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T03:00:58.109627Z",
     "iopub.status.busy": "2022-08-17T03:00:58.108673Z",
     "iopub.status.idle": "2022-08-17T03:00:59.579100Z",
     "shell.execute_reply": "2022-08-17T03:00:59.577897Z",
     "shell.execute_reply.started": "2022-08-17T03:00:58.109532Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.best_month.mode()\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "# cv = list(GroupKFold(n_splits=10).split(df_train, df_train[\"sellin\"], groups=df_train[\"best_month\"]))\n",
    "X_test = df_test[X.columns.tolist()].copy()\n",
    "df_test['Item_ID'] = df_test['sku_name'] +'_'+ df_test['month'].astype(str)+ '_'+df_test['year'].astype(str)\n",
    "y_pred = df_test[['Item_ID']]\n",
    "target = np.zeros(len(X_test))\n",
    "target2 = np.zeros(len(X_test))\n",
    "#light gbm models\n",
    "for model in models:\n",
    "    pred = model.predict(X_test[X_valid.columns], num_iteration=model.best_iteration)\n",
    "    target += pred / len(models)\n",
    "y_pred = y_pred.assign(target_y= target)\n",
    "sub = ss.merge(y_pred,on = 'Item_ID')\n",
    "sub['target'] = sub['target_y'].round()*1013\n",
    "# sub['target'] = (sub['target'].astype('int') )\n",
    "sub = sub[['Item_ID','target']]\n",
    "display_importances(features_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T03:00:59.581587Z",
     "iopub.status.busy": "2022-08-17T03:00:59.581193Z",
     "iopub.status.idle": "2022-08-17T03:00:59.597906Z",
     "shell.execute_reply": "2022-08-17T03:00:59.596640Z",
     "shell.execute_reply.started": "2022-08-17T03:00:59.581537Z"
    }
   },
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-17T03:01:10.732114Z",
     "iopub.status.busy": "2022-08-17T03:01:10.730601Z",
     "iopub.status.idle": "2022-08-17T03:01:10.745804Z",
     "shell.execute_reply": "2022-08-17T03:01:10.744153Z",
     "shell.execute_reply.started": "2022-08-17T03:01:10.732044Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission_63.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-16T01:47:33.487496Z",
     "iopub.status.busy": "2022-08-16T01:47:33.486625Z",
     "iopub.status.idle": "2022-08-16T01:47:33.493445Z",
     "shell.execute_reply": "2022-08-16T01:47:33.492451Z",
     "shell.execute_reply.started": "2022-08-16T01:47:33.487452Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = df_test[X.columns.tolist()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-16T01:49:01.601047Z",
     "iopub.status.busy": "2022-08-16T01:49:01.599832Z",
     "iopub.status.idle": "2022-08-16T01:49:01.615977Z",
     "shell.execute_reply": "2022-08-16T01:49:01.614803Z",
     "shell.execute_reply.started": "2022-08-16T01:49:01.601003Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# from sklearn.model selection import \n",
    "def fit_predict(n_splits, params, x_train = X, y_train = y, x_test = X_test):\n",
    "    \n",
    "    oof = np.zeros(x_train.shape[0])\n",
    "    \n",
    "    y_preds = []\n",
    "    \n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=1991028)\n",
    "    for train_idx, valid_idx in cv.split(x_train, y_train):\n",
    "        \n",
    "        x_train_train = x_train.iloc[train_idx]\n",
    "        y_train_train = y_train.iloc[train_idx]\n",
    "        x_train_valid = x_train.iloc[valid_idx]\n",
    "        y_train_valid = y_train.iloc[valid_idx]\n",
    "\n",
    "        lgb_train = lgb.Dataset(data=x_train_train.astype('float32'), label=y_train_train.astype('float32'))\n",
    "        lgb_valid = lgb.Dataset(data=x_train_valid.astype('float32'), label=y_train_valid.astype('float32'))\n",
    "\n",
    "        estimator = lgb.train(params, lgb_train, 15000, valid_sets=lgb_valid,\n",
    "                              early_stopping_rounds=30, verbose_eval=-1)\n",
    "\n",
    "        oof_part = estimator.predict(x_train_valid, num_iteration=estimator.best_iteration)\n",
    "        oof[valid_idx] = oof_part\n",
    "        \n",
    "        if x_test is not None:\n",
    "            y_part = estimator.predict(x_test, num_iteration=estimator.best_iteration)\n",
    "            y_preds.append(y_part)\n",
    "        \n",
    "    score = rmspe(y_train, oof)\n",
    "    print('Score:', score)\n",
    "    \n",
    "    y_pred = np.mean(y_preds, axis=0)\n",
    "    \n",
    "    return y_pred, oof, score\n",
    "## Optuna\n",
    "import optuna\n",
    "\n",
    "\n",
    "columns_to_try = ['sellin']\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'boosting_type': 'gbdt',\n",
    "#         'boost_from_average': True,\n",
    "        'num_threads': 4,\n",
    "        'random_state': 25031991,\n",
    "        'learning_rate': 0.025,\n",
    "        'verbose': -1,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 1000),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 200),\n",
    "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 0.001, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 100),\n",
    "        'bagging_fraction': trial.suggest_loguniform('bagging_fraction', .5, .99),\n",
    "        'feature_fraction': trial.suggest_loguniform('feature_fraction', .5, .99),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 2),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 2)\n",
    "    }\n",
    "    \n",
    "#     scores = []\n",
    "#     for column in columns_to_try:\n",
    "    _ ,_ , score = fit_predict(10, params, X, y, X_test)\n",
    "#         scores.append(score)\n",
    "    \n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-16T01:49:02.844831Z",
     "iopub.status.busy": "2022-08-16T01:49:02.844122Z",
     "iopub.status.idle": "2022-08-16T03:26:38.133192Z",
     "shell.execute_reply": "2022-08-16T03:26:38.131945Z",
     "shell.execute_reply.started": "2022-08-16T01:49:02.844787Z"
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'num_leaves': 170, 'min_data_in_leaf': 10, 'min_child_weight': 0.066978276178616, 'max_depth': 83, 'bagging_fraction': 0.6277904572518515, 'feature_fraction': 0.6965518420559522, 'lambda_l1': 1.6347289329468329, 'lambda_l2': 0.1374430845238362}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
